[
    {
        "source": " A chair is a type of seat, typically designed for one person and consisting of one or more legs, a flat or slightly angled seat and a back-rest. It may be made of wood, metal, or synthetic materials, and may be padded or upholstered in various colors and fabrics.",
        "target": "Chairs vary in design. An armchair has armrests fixed to the seat; a recliner is upholstered and features a mechanism that lowers the chair's back and raises into place a footrest; a rocking chair has legs fixed to two long curved slats; and a wheelchair has wheels fixed to an axis under the seat."
    },
    {
        "source": "A chair is a type of seat, typically designed for one person and consisting of one or more legs, a flat or slightly angled seat and a back-rest. It may be made of wood, metal, or synthetic materials, and may be padded or upholstered in various colors and fabrics. Chairs vary in design. An armchair has armrests fixed to the seat; a recliner is upholstered and features a mechanism that lowers the chair's back and raises into place a footrest; a rocking chair has legs fixed to two long curved slats; and a wheelchair has wheels fixed to an axis under the seat.",
        "target": "Chair comes from the early 13th-century English word chaere, from Old French chaiere (\"chair, seat, throne\"), from Latin cathedra (\"seat\")."
    },
    {
        "source": "Chairs vary in design. An armchair has armrests fixed to the seat; a recliner is upholstered and features a mechanism that lowers the chair's back and raises into place a footrest; a rocking chair has legs fixed to two long curved slats; and a wheelchair has wheels fixed to an axis under the seat. Chair comes from the early 13th-century English word chaere, from Old French chaiere (\"chair, seat, throne\"), from Latin cathedra (\"seat\").",
        "target": "The chair has been used since antiquity, although for many centuries it was a symbolic article of state and dignity rather than an article for ordinary use. \"The chair\" is still used as the emblem of authority in the House of Commons in the United Kingdom and Canada, and in many other settings. In keeping with this historical connotation of the \"chair\" as the symbol of authority, committees, boards of directors, and academic departments all have a 'chairman' or 'chair'. Endowed professorships are referred to as chairs.\nIt was not until the 16th century that chairs became common. Until then, people sat on chests, benches, and stools, which were the ordinary seats of everyday life. The number of chairs which have survived from an earlier date is exceedingly limited; most examples are of ecclesiastical, seigneurial or feudal origin.[citation needed]"
    },
    {
        "source": "Chair comes from the early 13th-century English word chaere, from Old French chaiere (\"chair, seat, throne\"), from Latin cathedra (\"seat\"). The chair has been used since antiquity, although for many centuries it was a symbolic article of state and dignity rather than an article for ordinary use. \"The chair\" is still used as the emblem of authority in the House of Commons in the United Kingdom and Canada, and in many other settings. In keeping with this historical connotation of the \"chair\" as the symbol of authority, committees, boards of directors, and academic departments all have a 'chairman' or 'chair'. Endowed professorships are referred to as chairs.\nIt was not until the 16th century that chairs became common. Until then, people sat on chests, benches, and stools, which were the ordinary seats of everyday life. The number of chairs which have survived from an earlier date is exceedingly limited; most examples are of ecclesiastical, seigneurial or feudal origin.[citation needed]",
        "target": "Chairs were in existence since at least the Early Dynastic Period of Egypt (c.3100 BC). They were covered with cloth or leather, were made of carved wood, and were much lower than today's chairs  chair seats were sometimes only 10 inches (25cm) high. In ancient Egypt, chairs appear to have been of great richness and splendor. Fashioned of ebony and ivory, or of carved and gilded wood, they were covered with costly materials, magnificent patterns and supported upon representations of the legs of beasts or the figures of captives. Generally speaking, the higher ranked an individual was, the taller and more sumptuous was the chair he sat on and the greater the honor. On state occasions, the pharaoh sat on a throne, often with a little footstool in front of it."
    },
    {
        "source": "The chair has been used since antiquity, although for many centuries it was a symbolic article of state and dignity rather than an article for ordinary use. \"The chair\" is still used as the emblem of authority in the House of Commons in the United Kingdom and Canada, and in many other settings. In keeping with this historical connotation of the \"chair\" as the symbol of authority, committees, boards of directors, and academic departments all have a 'chairman' or 'chair'. Endowed professorships are referred to as chairs.\nIt was not until the 16th century that chairs became common. Until then, people sat on chests, benches, and stools, which were the ordinary seats of everyday life. The number of chairs which have survived from an earlier date is exceedingly limited; most examples are of ecclesiastical, seigneurial or feudal origin.[citation needed] Chairs were in existence since at least the Early Dynastic Period of Egypt (c.3100 BC). They were covered with cloth or leather, were made of carved wood, and were much lower than today's chairs  chair seats were sometimes only 10 inches (25cm) high. In ancient Egypt, chairs appear to have been of great richness and splendor. Fashioned of ebony and ivory, or of carved and gilded wood, they were covered with costly materials, magnificent patterns and supported upon representations of the legs of beasts or the figures of captives. Generally speaking, the higher ranked an individual was, the taller and more sumptuous was the chair he sat on and the greater the honor. On state occasions, the pharaoh sat on a throne, often with a little footstool in front of it.",
        "target": "The average Egyptian family seldom had chairs, and if they did, it was usually only the master of the household who sat on a chair. Among the better off, the chairs might be painted to look like the ornate inlaid and carved chairs of the rich, but the craftsmanship was usually poor."
    },
    {
        "source": "Chairs were in existence since at least the Early Dynastic Period of Egypt (c.3100 BC). They were covered with cloth or leather, were made of carved wood, and were much lower than today's chairs  chair seats were sometimes only 10 inches (25cm) high. In ancient Egypt, chairs appear to have been of great richness and splendor. Fashioned of ebony and ivory, or of carved and gilded wood, they were covered with costly materials, magnificent patterns and supported upon representations of the legs of beasts or the figures of captives. Generally speaking, the higher ranked an individual was, the taller and more sumptuous was the chair he sat on and the greater the honor. On state occasions, the pharaoh sat on a throne, often with a little footstool in front of it. The average Egyptian family seldom had chairs, and if they did, it was usually only the master of the household who sat on a chair. Among the better off, the chairs might be painted to look like the ornate inlaid and carved chairs of the rich, but the craftsmanship was usually poor.",
        "target": "The earliest images of chairs in China are from 6th-century Buddhist murals and stele, but the practice of sitting in chairs at that time was rare. It was not until the 12th century that chairs became widespread in China. Scholars disagree on the reasons for the adoption of the chair. The most common theories are that the chair was an outgrowth of indigenous Chinese furniture, that it evolved from a camp stool imported from Central Asia, that it was introduced to China by Christian missionaries in the 7th century, and that the chair came to China from India as a form of Buddhist monastic furniture. In modern China, unlike Korea or Japan, it is no longer common to sit at floor level."
    },
    {
        "source": "The average Egyptian family seldom had chairs, and if they did, it was usually only the master of the household who sat on a chair. Among the better off, the chairs might be painted to look like the ornate inlaid and carved chairs of the rich, but the craftsmanship was usually poor. The earliest images of chairs in China are from 6th-century Buddhist murals and stele, but the practice of sitting in chairs at that time was rare. It was not until the 12th century that chairs became widespread in China. Scholars disagree on the reasons for the adoption of the chair. The most common theories are that the chair was an outgrowth of indigenous Chinese furniture, that it evolved from a camp stool imported from Central Asia, that it was introduced to China by Christian missionaries in the 7th century, and that the chair came to China from India as a form of Buddhist monastic furniture. In modern China, unlike Korea or Japan, it is no longer common to sit at floor level.",
        "target": "In Europe, it was owing in great measure to the Renaissance that the chair ceased to be a privilege of state and became a standard item of furniture for anyone who could afford to buy it. Once the idea of privilege faded the chair speedily came into general use. Almost at once the chair began to change every few years to reflect the fashions of the day."
    },
    {
        "source": "The earliest images of chairs in China are from 6th-century Buddhist murals and stele, but the practice of sitting in chairs at that time was rare. It was not until the 12th century that chairs became widespread in China. Scholars disagree on the reasons for the adoption of the chair. The most common theories are that the chair was an outgrowth of indigenous Chinese furniture, that it evolved from a camp stool imported from Central Asia, that it was introduced to China by Christian missionaries in the 7th century, and that the chair came to China from India as a form of Buddhist monastic furniture. In modern China, unlike Korea or Japan, it is no longer common to sit at floor level. In Europe, it was owing in great measure to the Renaissance that the chair ceased to be a privilege of state and became a standard item of furniture for anyone who could afford to buy it. Once the idea of privilege faded the chair speedily came into general use. Almost at once the chair began to change every few years to reflect the fashions of the day.",
        "target": "Thomas Edward Bowdich visited the main Palace of the Ashanti Empire in 1819, and observed chairs engrossed with gold in the empire. \nIn the 1800s, chairs became more common in American households and usually there was a chair provided for every family member to sit down to dinner. By the 1830s, factory-manufactured fancy chairs like those by Sears, Roebuck, and Co. allowed families to purchase machined sets. With the Industrial Revolution, chairs became much more available."
    },
    {
        "source": "In Europe, it was owing in great measure to the Renaissance that the chair ceased to be a privilege of state and became a standard item of furniture for anyone who could afford to buy it. Once the idea of privilege faded the chair speedily came into general use. Almost at once the chair began to change every few years to reflect the fashions of the day. Thomas Edward Bowdich visited the main Palace of the Ashanti Empire in 1819, and observed chairs engrossed with gold in the empire. \nIn the 1800s, chairs became more common in American households and usually there was a chair provided for every family member to sit down to dinner. By the 1830s, factory-manufactured fancy chairs like those by Sears, Roebuck, and Co. allowed families to purchase machined sets. With the Industrial Revolution, chairs became much more available.",
        "target": "The 20th century saw an increasing use of technology in chair construction with such things as all-metal folding chairs, metal-legged chairs, the Slumber Chair,[citation needed] moulded plastic chairs and ergonomic chairs. The recliner became a popular form, at least in part due to radio and television. In the 1930s, stair lifts were commercially available to help people suffering from Polio and other diseases to navigate stairs."
    },
    {
        "source": "Thomas Edward Bowdich visited the main Palace of the Ashanti Empire in 1819, and observed chairs engrossed with gold in the empire. \nIn the 1800s, chairs became more common in American households and usually there was a chair provided for every family member to sit down to dinner. By the 1830s, factory-manufactured fancy chairs like those by Sears, Roebuck, and Co. allowed families to purchase machined sets. With the Industrial Revolution, chairs became much more available. The 20th century saw an increasing use of technology in chair construction with such things as all-metal folding chairs, metal-legged chairs, the Slumber Chair,[citation needed] moulded plastic chairs and ergonomic chairs. The recliner became a popular form, at least in part due to radio and television. In the 1930s, stair lifts were commercially available to help people suffering from Polio and other diseases to navigate stairs.",
        "target": "The modern movement of the 1960s produced new forms of chairs: the butterfly chair (originally called the Hardoy chair), bean bags, and the egg-shaped pod chair that turns. It also introduced the first mass-produced plastic chairs such as the Bofinger chair in 1966. Technological advances led to molded plywood and wood laminate chairs, as well as chairs made of leather or polymers. Mechanical technology incorporated into the chair enabled adjustable chairs, especially for office use. Motors embedded in the chair resulted in massage chairs."
    },
    {
        "source": "The 20th century saw an increasing use of technology in chair construction with such things as all-metal folding chairs, metal-legged chairs, the Slumber Chair,[citation needed] moulded plastic chairs and ergonomic chairs. The recliner became a popular form, at least in part due to radio and television. In the 1930s, stair lifts were commercially available to help people suffering from Polio and other diseases to navigate stairs. The modern movement of the 1960s produced new forms of chairs: the butterfly chair (originally called the Hardoy chair), bean bags, and the egg-shaped pod chair that turns. It also introduced the first mass-produced plastic chairs such as the Bofinger chair in 1966. Technological advances led to molded plywood and wood laminate chairs, as well as chairs made of leather or polymers. Mechanical technology incorporated into the chair enabled adjustable chairs, especially for office use. Motors embedded in the chair resulted in massage chairs.",
        "target": "Chairs can be made from wood, metal, or other strong materials, like stone or acrylic. In some cases, multiple materials are used to construct a chair; for example, the legs and frame may be made from metal and the seat and back may be made from plastic. Chairs may have hard surfaces of wood, metal, plastic, or other materials, or some or all of these hard surfaces may be covered with upholstery or padding. The design may be made of porous materials, or be drilled with holes for decoration; a low back or gaps can provide ventilation. The back may extend above the height of the occupant's head, which can optionally contain a headrest. Chairs can also be made from more creative materials, such as recycled materials like cutlery and wooden play bricks, pencils, plumbing tubes, rope, corrugated cardboard, and PVC pipe."
    },
    {
        "source": "The modern movement of the 1960s produced new forms of chairs: the butterfly chair (originally called the Hardoy chair), bean bags, and the egg-shaped pod chair that turns. It also introduced the first mass-produced plastic chairs such as the Bofinger chair in 1966. Technological advances led to molded plywood and wood laminate chairs, as well as chairs made of leather or polymers. Mechanical technology incorporated into the chair enabled adjustable chairs, especially for office use. Motors embedded in the chair resulted in massage chairs. Chairs can be made from wood, metal, or other strong materials, like stone or acrylic. In some cases, multiple materials are used to construct a chair; for example, the legs and frame may be made from metal and the seat and back may be made from plastic. Chairs may have hard surfaces of wood, metal, plastic, or other materials, or some or all of these hard surfaces may be covered with upholstery or padding. The design may be made of porous materials, or be drilled with holes for decoration; a low back or gaps can provide ventilation. The back may extend above the height of the occupant's head, which can optionally contain a headrest. Chairs can also be made from more creative materials, such as recycled materials like cutlery and wooden play bricks, pencils, plumbing tubes, rope, corrugated cardboard, and PVC pipe.",
        "target": "In rare cases, chairs are made out of unusual materials, especially as a form of art or experimentation. Raimonds Cirulis, a Latvian interior designer, created a volcanic hanging chair that is handmade out of volcanic rock. Peter Brenner, a Dutch-born German designer, has created a chair made from lollipop sugar  60 pounds (27kg) of confectioners' sugar."
    },
    {
        "source": "Chairs can be made from wood, metal, or other strong materials, like stone or acrylic. In some cases, multiple materials are used to construct a chair; for example, the legs and frame may be made from metal and the seat and back may be made from plastic. Chairs may have hard surfaces of wood, metal, plastic, or other materials, or some or all of these hard surfaces may be covered with upholstery or padding. The design may be made of porous materials, or be drilled with holes for decoration; a low back or gaps can provide ventilation. The back may extend above the height of the occupant's head, which can optionally contain a headrest. Chairs can also be made from more creative materials, such as recycled materials like cutlery and wooden play bricks, pencils, plumbing tubes, rope, corrugated cardboard, and PVC pipe. In rare cases, chairs are made out of unusual materials, especially as a form of art or experimentation. Raimonds Cirulis, a Latvian interior designer, created a volcanic hanging chair that is handmade out of volcanic rock. Peter Brenner, a Dutch-born German designer, has created a chair made from lollipop sugar  60 pounds (27kg) of confectioners' sugar.",
        "target": "Chair design considers intended usage, ergonomics (how comfortable it is for the occupant), as well as non-ergonomic functional requirements such as size, stacking ability, folding ability, weight, durability, stain resistance, and artistic design."
    },
    {
        "source": "In rare cases, chairs are made out of unusual materials, especially as a form of art or experimentation. Raimonds Cirulis, a Latvian interior designer, created a volcanic hanging chair that is handmade out of volcanic rock. Peter Brenner, a Dutch-born German designer, has created a chair made from lollipop sugar  60 pounds (27kg) of confectioners' sugar. Chair design considers intended usage, ergonomics (how comfortable it is for the occupant), as well as non-ergonomic functional requirements such as size, stacking ability, folding ability, weight, durability, stain resistance, and artistic design.",
        "target": "Ergonomic design distributes the weight of the occupant to various parts of the body. This is done by having an easily adjustable seat height. A seat that is higher results in dangling feet and increased pressure on the underside of the knees (\"popliteal fold\"). It may also result in no weight on the feet which means more weight elsewhere. A lower seat may shift too much weight to the \"seat bones\" (\"ischial tuberosities\"). Gas springs are attached to the body of the chair in order to give height adjustment and more comfort to the user."
    },
    {
        "source": "Chair design considers intended usage, ergonomics (how comfortable it is for the occupant), as well as non-ergonomic functional requirements such as size, stacking ability, folding ability, weight, durability, stain resistance, and artistic design. Ergonomic design distributes the weight of the occupant to various parts of the body. This is done by having an easily adjustable seat height. A seat that is higher results in dangling feet and increased pressure on the underside of the knees (\"popliteal fold\"). It may also result in no weight on the feet which means more weight elsewhere. A lower seat may shift too much weight to the \"seat bones\" (\"ischial tuberosities\"). Gas springs are attached to the body of the chair in order to give height adjustment and more comfort to the user.",
        "target": "Some chairs have foot rests. Around 15% of women and 2% of men need foot rests, even at the 16-inch (41cm) chair height. A stool or other simple chair may have a simple straight or curved bar near the bottom for the sitter to place their feet on."
    },
    {
        "source": "Ergonomic design distributes the weight of the occupant to various parts of the body. This is done by having an easily adjustable seat height. A seat that is higher results in dangling feet and increased pressure on the underside of the knees (\"popliteal fold\"). It may also result in no weight on the feet which means more weight elsewhere. A lower seat may shift too much weight to the \"seat bones\" (\"ischial tuberosities\"). Gas springs are attached to the body of the chair in order to give height adjustment and more comfort to the user. Some chairs have foot rests. Around 15% of women and 2% of men need foot rests, even at the 16-inch (41cm) chair height. A stool or other simple chair may have a simple straight or curved bar near the bottom for the sitter to place their feet on.",
        "target": "Actual chair dimensions are determined by measurements of the human body or anthropometric measurements. The two most relevant anthropometric measurement for chair design is the popliteal height and buttock popliteal length."
    },
    {
        "source": "Some chairs have foot rests. Around 15% of women and 2% of men need foot rests, even at the 16-inch (41cm) chair height. A stool or other simple chair may have a simple straight or curved bar near the bottom for the sitter to place their feet on. Actual chair dimensions are determined by measurements of the human body or anthropometric measurements. The two most relevant anthropometric measurement for chair design is the popliteal height and buttock popliteal length.",
        "target": "For someone seated, the popliteal height is the distance from the underside of the foot to the underside of the thigh at the knees. It is sometimes called the \"stool height\". The term \"sitting height\" is reserved for the height to the top of the head when seated. For American men, the median popliteal height is 16.3 inches (41cm) and for American women it is 15.0 inches (38cm). The popliteal height, after adjusting for heels, clothing and other issues, is used to determine the height of the chair seat. Mass-produced chairs are typically 17 inches (43cm) high.[citation needed]"
    },
    {
        "source": "Actual chair dimensions are determined by measurements of the human body or anthropometric measurements. The two most relevant anthropometric measurement for chair design is the popliteal height and buttock popliteal length. For someone seated, the popliteal height is the distance from the underside of the foot to the underside of the thigh at the knees. It is sometimes called the \"stool height\". The term \"sitting height\" is reserved for the height to the top of the head when seated. For American men, the median popliteal height is 16.3 inches (41cm) and for American women it is 15.0 inches (38cm). The popliteal height, after adjusting for heels, clothing and other issues, is used to determine the height of the chair seat. Mass-produced chairs are typically 17 inches (43cm) high.[citation needed]",
        "target": "Researchers such as Mary Blade and Galen Cranz found that sitting on the edge of a high stool with feet on the floor is less harmful for the lower back than sitting up straight on a conventional chair."
    },
    {
        "source": "For someone seated, the popliteal height is the distance from the underside of the foot to the underside of the thigh at the knees. It is sometimes called the \"stool height\". The term \"sitting height\" is reserved for the height to the top of the head when seated. For American men, the median popliteal height is 16.3 inches (41cm) and for American women it is 15.0 inches (38cm). The popliteal height, after adjusting for heels, clothing and other issues, is used to determine the height of the chair seat. Mass-produced chairs are typically 17 inches (43cm) high.[citation needed] Researchers such as Mary Blade and Galen Cranz found that sitting on the edge of a high stool with feet on the floor is less harmful for the lower back than sitting up straight on a conventional chair.",
        "target": "Different types of chairs can have a variety of seating positions, depending on the intended task. Typically, chairs intended for people completing work or dining can only recline very slightly (otherwise the occupant is too far away from the desk or table). Dental chairs are necessarily reclined. Research has shown that the best seated posture is a reclined posture of 100110. In order to recline, the back-rest may be independently adjustable. A reclining seat and back will reduce the load on the occupant's back muscles. In general, if the occupant is supposed to sit for a long time, weight needs to be taken off the seat area and thus \"easy\" chairs intended for long periods of sitting are generally at least slightly reclined."
    },
    {
        "source": "Researchers such as Mary Blade and Galen Cranz found that sitting on the edge of a high stool with feet on the floor is less harmful for the lower back than sitting up straight on a conventional chair. Different types of chairs can have a variety of seating positions, depending on the intended task. Typically, chairs intended for people completing work or dining can only recline very slightly (otherwise the occupant is too far away from the desk or table). Dental chairs are necessarily reclined. Research has shown that the best seated posture is a reclined posture of 100110. In order to recline, the back-rest may be independently adjustable. A reclining seat and back will reduce the load on the occupant's back muscles. In general, if the occupant is supposed to sit for a long time, weight needs to be taken off the seat area and thus \"easy\" chairs intended for long periods of sitting are generally at least slightly reclined.",
        "target": "The back of the chair will support some of the weight of the occupant, reducing the weight on other parts of the body. Some back-rests support only the lumbar region, while shoulder height back-rests support the entire back and shoulders. Headrests support the head as well and are important in vehicles for preventing \"whiplash\" neck injuries in rear-end collisions where the head is jerked back suddenly. Reclining chairs typically have at least shoulder-height back-rests to shift weight to the shoulders."
    },
    {
        "source": "Different types of chairs can have a variety of seating positions, depending on the intended task. Typically, chairs intended for people completing work or dining can only recline very slightly (otherwise the occupant is too far away from the desk or table). Dental chairs are necessarily reclined. Research has shown that the best seated posture is a reclined posture of 100110. In order to recline, the back-rest may be independently adjustable. A reclining seat and back will reduce the load on the occupant's back muscles. In general, if the occupant is supposed to sit for a long time, weight needs to be taken off the seat area and thus \"easy\" chairs intended for long periods of sitting are generally at least slightly reclined. The back of the chair will support some of the weight of the occupant, reducing the weight on other parts of the body. Some back-rests support only the lumbar region, while shoulder height back-rests support the entire back and shoulders. Headrests support the head as well and are important in vehicles for preventing \"whiplash\" neck injuries in rear-end collisions where the head is jerked back suddenly. Reclining chairs typically have at least shoulder-height back-rests to shift weight to the shoulders.",
        "target": "There may be cases where padding is not desirable, such as chairs that are intended primarily for outdoor use. Where padding is not desirable, contouring may be used instead. A contoured seat pan attempts to distribute weight without padding. By matching the shape of the occupant's buttocks, weight is distributed and maximum pressure is reduced."
    },
    {
        "source": "The back of the chair will support some of the weight of the occupant, reducing the weight on other parts of the body. Some back-rests support only the lumbar region, while shoulder height back-rests support the entire back and shoulders. Headrests support the head as well and are important in vehicles for preventing \"whiplash\" neck injuries in rear-end collisions where the head is jerked back suddenly. Reclining chairs typically have at least shoulder-height back-rests to shift weight to the shoulders. There may be cases where padding is not desirable, such as chairs that are intended primarily for outdoor use. Where padding is not desirable, contouring may be used instead. A contoured seat pan attempts to distribute weight without padding. By matching the shape of the occupant's buttocks, weight is distributed and maximum pressure is reduced.",
        "target": "A chair may or may not have armrests; chairs with armrests are termed \"armchairs\". In French, a distinction is made between fauteuil and chaise, the terms for chairs with and without armrests, respectively. In Germany, an armchair was once called a Krankensessel, or sick-chair, because it was intended for people who were too ill to stand or sit without extra support."
    },
    {
        "source": "There may be cases where padding is not desirable, such as chairs that are intended primarily for outdoor use. Where padding is not desirable, contouring may be used instead. A contoured seat pan attempts to distribute weight without padding. By matching the shape of the occupant's buttocks, weight is distributed and maximum pressure is reduced. A chair may or may not have armrests; chairs with armrests are termed \"armchairs\". In French, a distinction is made between fauteuil and chaise, the terms for chairs with and without armrests, respectively. In Germany, an armchair was once called a Krankensessel, or sick-chair, because it was intended for people who were too ill to stand or sit without extra support.",
        "target": "If present, armrests will support part of the body weight through the arms if the arms are resting on the armrests. Elbow rest height is used to determine the height of the armrests. Armrests should support the forearm and not the sensitive elbow area. Hence in some chair designs, the armrest is not continuous to the chair back, but is missing in the elbow area. Armrests further have the function of making entry and exit from the chair easier (but from the side it becomes more difficult)."
    },
    {
        "source": "A chair may or may not have armrests; chairs with armrests are termed \"armchairs\". In French, a distinction is made between fauteuil and chaise, the terms for chairs with and without armrests, respectively. In Germany, an armchair was once called a Krankensessel, or sick-chair, because it was intended for people who were too ill to stand or sit without extra support. If present, armrests will support part of the body weight through the arms if the arms are resting on the armrests. Elbow rest height is used to determine the height of the armrests. Armrests should support the forearm and not the sensitive elbow area. Hence in some chair designs, the armrest is not continuous to the chair back, but is missing in the elbow area. Armrests further have the function of making entry and exit from the chair easier (but from the side it becomes more difficult).",
        "target": "For someone seated, the buttock popliteal length is the horizontal distance from the back most part of the buttocks to the back of the lower leg. This anthropometric measurement is used to determine the seat depth. Mass-produced chairs are typically 1517 inches (3843cm) deep.[citation needed]"
    },
    {
        "source": "If present, armrests will support part of the body weight through the arms if the arms are resting on the armrests. Elbow rest height is used to determine the height of the armrests. Armrests should support the forearm and not the sensitive elbow area. Hence in some chair designs, the armrest is not continuous to the chair back, but is missing in the elbow area. Armrests further have the function of making entry and exit from the chair easier (but from the side it becomes more difficult). For someone seated, the buttock popliteal length is the horizontal distance from the back most part of the buttocks to the back of the lower leg. This anthropometric measurement is used to determine the seat depth. Mass-produced chairs are typically 1517 inches (3843cm) deep.[citation needed]",
        "target": "Additional anthropometric measurements may be relevant to designing a chair. Hip breadth is used for chair width and armrest width. The buttock-knee length is used to determine \"leg room\" between rows of chairs. \"Seat pitch\" is the distance between rows of seats. In some airplanes and stadiums the leg room (the seat pitch less the thickness of the seat at thigh level) is so small that it is sometimes insufficient for the average person."
    },
    {
        "source": "For someone seated, the buttock popliteal length is the horizontal distance from the back most part of the buttocks to the back of the lower leg. This anthropometric measurement is used to determine the seat depth. Mass-produced chairs are typically 1517 inches (3843cm) deep.[citation needed] Additional anthropometric measurements may be relevant to designing a chair. Hip breadth is used for chair width and armrest width. The buttock-knee length is used to determine \"leg room\" between rows of chairs. \"Seat pitch\" is the distance between rows of seats. In some airplanes and stadiums the leg room (the seat pitch less the thickness of the seat at thigh level) is so small that it is sometimes insufficient for the average person.",
        "target": "A wide variety of chairs have emerged throughout the ages, some based on formal usages, and others based on domestic needs, and some based on needs within the workplace or various professions."
    },
    {
        "source": "Additional anthropometric measurements may be relevant to designing a chair. Hip breadth is used for chair width and armrest width. The buttock-knee length is used to determine \"leg room\" between rows of chairs. \"Seat pitch\" is the distance between rows of seats. In some airplanes and stadiums the leg room (the seat pitch less the thickness of the seat at thigh level) is so small that it is sometimes insufficient for the average person. A wide variety of chairs have emerged throughout the ages, some based on formal usages, and others based on domestic needs, and some based on needs within the workplace or various professions.",
        "target": "An office chair is one used by employees within an office. Modern office chairs are usually adjustable and wheeled. Caster wheels are attached to the feet of chairs to give more mobility."
    },
    {
        "source": "A wide variety of chairs have emerged throughout the ages, some based on formal usages, and others based on domestic needs, and some based on needs within the workplace or various professions. An office chair is one used by employees within an office. Modern office chairs are usually adjustable and wheeled. Caster wheels are attached to the feet of chairs to give more mobility.",
        "target": "A dining room chair is a specific type of design, used around a dining room table.  It can be found in most ordinary residential homes, and also may appear in formal settings, such as any formal event or reception that includes a formal meal or banquet."
    },
    {
        "source": "An office chair is one used by employees within an office. Modern office chairs are usually adjustable and wheeled. Caster wheels are attached to the feet of chairs to give more mobility. A dining room chair is a specific type of design, used around a dining room table.  It can be found in most ordinary residential homes, and also may appear in formal settings, such as any formal event or reception that includes a formal meal or banquet.",
        "target": "A work chair is a specialized chair, adapted to the needs of a particular profession or setting. For example, a designing chair will be used for designers who sit at high easels; it will usually have added height."
    },
    {
        "source": "A dining room chair is a specific type of design, used around a dining room table.  It can be found in most ordinary residential homes, and also may appear in formal settings, such as any formal event or reception that includes a formal meal or banquet. A work chair is a specialized chair, adapted to the needs of a particular profession or setting. For example, a designing chair will be used for designers who sit at high easels; it will usually have added height.",
        "target": "Some chairs have two curved bands of wood (also known as rockers) attached to the bottom of the legs. They are called rocking chairs."
    },
    {
        "source": "A work chair is a specialized chair, adapted to the needs of a particular profession or setting. For example, a designing chair will be used for designers who sit at high easels; it will usually have added height. Some chairs have two curved bands of wood (also known as rockers) attached to the bottom of the legs. They are called rocking chairs.",
        "target": "A kneeling chair adds an additional body part, the knees, to support the weight of the body. A sit-stand chair distributes most of the weight of the occupant to the feet. Many chairs are padded or have cushions. Padding can be on the seat of the chair only, on the seat and back, or also on any arm rests or foot rest the chair may have. Padding will not shift the weight to different parts of the body (unless the chair is so soft that the shape is altered). However, padding does distribute the weight by increasing the area of contact between the chair and the body, and thus reducing the amount of pressure at any given point. By contrast, a hard wood chair feels hard because the contact point between the occupant and the chair is small. In lieu of padding, flexible materials, such as wicker, may be used instead with similar effects of distributing the weight."
    },
    {
        "source": "Some chairs have two curved bands of wood (also known as rockers) attached to the bottom of the legs. They are called rocking chairs. A kneeling chair adds an additional body part, the knees, to support the weight of the body. A sit-stand chair distributes most of the weight of the occupant to the feet. Many chairs are padded or have cushions. Padding can be on the seat of the chair only, on the seat and back, or also on any arm rests or foot rest the chair may have. Padding will not shift the weight to different parts of the body (unless the chair is so soft that the shape is altered). However, padding does distribute the weight by increasing the area of contact between the chair and the body, and thus reducing the amount of pressure at any given point. By contrast, a hard wood chair feels hard because the contact point between the occupant and the chair is small. In lieu of padding, flexible materials, such as wicker, may be used instead with similar effects of distributing the weight.",
        "target": "Chair seats vary widely in construction and may or may not match construction of the chair's back (back-rest)."
    },
    {
        "source": "Chair seats vary widely in construction and may or may not match construction of the chair's back (back-rest). Some systems include:",
        "target": "Design considerations for chairs have been codified into standards. ISO 9241, \"Ergonomic requirements for office work with visual display terminals (VDTs)  Part 5: Workstation layout and postural requirements\", is the most common one for modern chair design."
    },
    {
        "source": "Some systems include: Design considerations for chairs have been codified into standards. ISO 9241, \"Ergonomic requirements for office work with visual display terminals (VDTs)  Part 5: Workstation layout and postural requirements\", is the most common one for modern chair design.",
        "target": "There are multiple specific standards for different types of chairs. Dental chairs are specified by ISO 6875. Bean bag chairs are specified by ANSI standard ASTM F1912-98. ISO 7174 specifies stability of rocking and tilting chairs. ASTM F1858-98 specifies plastic lawn chairs. ASTM E1822-02b defines the combustibility of chairs when they are stacked."
    },
    {
        "source": "Design considerations for chairs have been codified into standards. ISO 9241, \"Ergonomic requirements for office work with visual display terminals (VDTs)  Part 5: Workstation layout and postural requirements\", is the most common one for modern chair design. There are multiple specific standards for different types of chairs. Dental chairs are specified by ISO 6875. Bean bag chairs are specified by ANSI standard ASTM F1912-98. ISO 7174 specifies stability of rocking and tilting chairs. ASTM F1858-98 specifies plastic lawn chairs. ASTM E1822-02b defines the combustibility of chairs when they are stacked.",
        "target": "The Business and Institutional Furniture Manufacturer's Association (BIFMA) defines ANSI/BIFMA X5.1 (titled: General-Purpose Office Chairs  Tests) for testing of commercial-grade chairs. It requires:"
    },
    {
        "source": "There are multiple specific standards for different types of chairs. Dental chairs are specified by ISO 6875. Bean bag chairs are specified by ANSI standard ASTM F1912-98. ISO 7174 specifies stability of rocking and tilting chairs. ASTM F1858-98 specifies plastic lawn chairs. ASTM E1822-02b defines the combustibility of chairs when they are stacked. The Business and Institutional Furniture Manufacturer's Association (BIFMA) defines ANSI/BIFMA X5.1 (titled: General-Purpose Office Chairs  Tests) for testing of commercial-grade chairs. It requires:",
        "target": "The specification further defines heavier \"proof\" loads that chairs must withstand. Under these higher loads, the chair may be damaged, but it must not fail catastrophically."
    },
    {
        "source": "The Business and Institutional Furniture Manufacturer's Association (BIFMA) defines ANSI/BIFMA X5.1 (titled: General-Purpose Office Chairs  Tests) for testing of commercial-grade chairs. It requires: The specification further defines heavier \"proof\" loads that chairs must withstand. Under these higher loads, the chair may be damaged, but it must not fail catastrophically.",
        "target": "Large institutions that make bulk purchases will reference these standards within their own even more detailed criteria for purchase. Governments will often issue standards for purchases by government agencies (e.g. Canada's Canadian General Standards Board CAN/CGSB 44.15M on \"Straight Stacking Chair, Steel\" or CAN/CGSB 44.232-2002 on \"Task Chairs for Office Work with Visual Display Terminal\")."
    },
    {
        "source": "The specification further defines heavier \"proof\" loads that chairs must withstand. Under these higher loads, the chair may be damaged, but it must not fail catastrophically. Large institutions that make bulk purchases will reference these standards within their own even more detailed criteria for purchase. Governments will often issue standards for purchases by government agencies (e.g. Canada's Canadian General Standards Board CAN/CGSB 44.15M on \"Straight Stacking Chair, Steel\" or CAN/CGSB 44.232-2002 on \"Task Chairs for Office Work with Visual Display Terminal\").",
        "target": "Chairs may be rated by the length of time that they may be used comfortably  an 8-hour chair, a 24-hour chair, and so on. Such chairs are specified for tasks which require extended periods of sitting, such as for receptionists or supervisors of a control panel."
    },
    {
        "source": "Large institutions that make bulk purchases will reference these standards within their own even more detailed criteria for purchase. Governments will often issue standards for purchases by government agencies (e.g. Canada's Canadian General Standards Board CAN/CGSB 44.15M on \"Straight Stacking Chair, Steel\" or CAN/CGSB 44.232-2002 on \"Task Chairs for Office Work with Visual Display Terminal\"). Chairs may be rated by the length of time that they may be used comfortably  an 8-hour chair, a 24-hour chair, and so on. Such chairs are specified for tasks which require extended periods of sitting, such as for receptionists or supervisors of a control panel.",
        "target": "In place of a built-in footrest, some chairs come with a matching ottoman. An ottoman is a short stool that is intended to be used as a footrest but can sometimes be used as a stool. If matched to a glider chair, the ottoman may be mounted on swing arms so that the ottoman rocks back and forth with the main glider."
    },
    {
        "source": "Chairs may be rated by the length of time that they may be used comfortably  an 8-hour chair, a 24-hour chair, and so on. Such chairs are specified for tasks which require extended periods of sitting, such as for receptionists or supervisors of a control panel. In place of a built-in footrest, some chairs come with a matching ottoman. An ottoman is a short stool that is intended to be used as a footrest but can sometimes be used as a stool. If matched to a glider chair, the ottoman may be mounted on swing arms so that the ottoman rocks back and forth with the main glider.",
        "target": "A chair cover is a temporary fabric cover for a side chair. They are typically rented for formal events such as wedding receptions to increase the attractiveness of the chairs and decor. The chair covers may come with decorative chair ties, a ribbon to be tied as a bow behind the chair. Covers for sofas and couches are also available for homes with small children and pets. In the second half of the 20th century, some people used custom clear plastic covers for expensive sofas and chairs to protect them."
    },
    {
        "source": "In place of a built-in footrest, some chairs come with a matching ottoman. An ottoman is a short stool that is intended to be used as a footrest but can sometimes be used as a stool. If matched to a glider chair, the ottoman may be mounted on swing arms so that the ottoman rocks back and forth with the main glider. A chair cover is a temporary fabric cover for a side chair. They are typically rented for formal events such as wedding receptions to increase the attractiveness of the chairs and decor. The chair covers may come with decorative chair ties, a ribbon to be tied as a bow behind the chair. Covers for sofas and couches are also available for homes with small children and pets. In the second half of the 20th century, some people used custom clear plastic covers for expensive sofas and chairs to protect them.",
        "target": "Chair pads are cushions for chairs. They contain cotton or foam for padding. Some are decorative. In cars, they may be used to increase the height of the driver. Orthopedic back-rests provide support for the back. Car seats sometimes have built-in and adjustable lumbar supports. These can also be used on kitchen chairs."
    },
    {
        "source": "A chair cover is a temporary fabric cover for a side chair. They are typically rented for formal events such as wedding receptions to increase the attractiveness of the chairs and decor. The chair covers may come with decorative chair ties, a ribbon to be tied as a bow behind the chair. Covers for sofas and couches are also available for homes with small children and pets. In the second half of the 20th century, some people used custom clear plastic covers for expensive sofas and chairs to protect them. Chair pads are cushions for chairs. They contain cotton or foam for padding. Some are decorative. In cars, they may be used to increase the height of the driver. Orthopedic back-rests provide support for the back. Car seats sometimes have built-in and adjustable lumbar supports. These can also be used on kitchen chairs.",
        "target": "Chair mats are mats meant to cover different types of flooring. They are usually made from plastic. This allows chairs on wheels to roll easily over the carpet and protects the carpet or floor. They come in various shapes, some specifically sized to fit partially under a desk."
    },
    {
        "source": "Chair pads are cushions for chairs. They contain cotton or foam for padding. Some are decorative. In cars, they may be used to increase the height of the driver. Orthopedic back-rests provide support for the back. Car seats sometimes have built-in and adjustable lumbar supports. These can also be used on kitchen chairs. Chair mats are mats meant to cover different types of flooring. They are usually made from plastic. This allows chairs on wheels to roll easily over the carpet and protects the carpet or floor. They come in various shapes, some specifically sized to fit partially under a desk.",
        "target": "Remote control bags can be draped over the arm of easy chairs or sofas and used to hold remote controls for home cinemas. They are counter-weighted so as to not slide off the arms under the weight of the remote controls."
    },
    {
        "source": "Chair mats are mats meant to cover different types of flooring. They are usually made from plastic. This allows chairs on wheels to roll easily over the carpet and protects the carpet or floor. They come in various shapes, some specifically sized to fit partially under a desk. Remote control bags can be draped over the arm of easy chairs or sofas and used to hold remote controls for home cinemas. They are counter-weighted so as to not slide off the arms under the weight of the remote controls.",
        "target": "Chair glides are attached to the feet of chairs to prevent them from scratching or snagging on the floor."
    },
    {
        "source": "Remote control bags can be draped over the arm of easy chairs or sofas and used to hold remote controls for home cinemas. They are counter-weighted so as to not slide off the arms under the weight of the remote controls. Chair glides are attached to the feet of chairs to prevent them from scratching or snagging on the floor.",
        "target": "An antimacassar is a cloth covering for a headrest to protect the fabric and enable easy washing."
    },
    {
        "source": "Chair glides are attached to the feet of chairs to prevent them from scratching or snagging on the floor. An antimacassar is a cloth covering for a headrest to protect the fabric and enable easy washing.",
        "target": "Christo created Wrapped Chair in 1961 with found objects (chairs), lacquer, canvas, rope, and paint. It is an early work showing his and his wife Jeanne Claudes iconic style of partially or wholly hiding objects within wrapped cloth and ropes. Their work developed into large-scale public site-specific artworks and environmental art, which the pair are most well known for. For Wrapped Chair, Christo plays with the identity of the object by concealing parts and revealing others. There are multiple variations of this work and similar ones involving chairs displayed at museums around the world, including a similar work titled Two Wrapped Chairs from 1961."
    },
    {
        "source": "An antimacassar is a cloth covering for a headrest to protect the fabric and enable easy washing. Christo created Wrapped Chair in 1961 with found objects (chairs), lacquer, canvas, rope, and paint. It is an early work showing his and his wife Jeanne Claudes iconic style of partially or wholly hiding objects within wrapped cloth and ropes. Their work developed into large-scale public site-specific artworks and environmental art, which the pair are most well known for. For Wrapped Chair, Christo plays with the identity of the object by concealing parts and revealing others. There are multiple variations of this work and similar ones involving chairs displayed at museums around the world, including a similar work titled Two Wrapped Chairs from 1961.",
        "target": "In the same year that Christo created Wrapped Chair, Pablo Picasso also created La Chaise. Made of painted sheet metal, Picassos sculptural chair exemplifies what many artists love about the chair as a subject: the contrast of form and function."
    },
    {
        "source": "Christo created Wrapped Chair in 1961 with found objects (chairs), lacquer, canvas, rope, and paint. It is an early work showing his and his wife Jeanne Claudes iconic style of partially or wholly hiding objects within wrapped cloth and ropes. Their work developed into large-scale public site-specific artworks and environmental art, which the pair are most well known for. For Wrapped Chair, Christo plays with the identity of the object by concealing parts and revealing others. There are multiple variations of this work and similar ones involving chairs displayed at museums around the world, including a similar work titled Two Wrapped Chairs from 1961. In the same year that Christo created Wrapped Chair, Pablo Picasso also created La Chaise. Made of painted sheet metal, Picassos sculptural chair exemplifies what many artists love about the chair as a subject: the contrast of form and function.",
        "target": "One and Three Chairs, 1965, is a conceptual artwork created by Joseph Kosuth. The work is an assemblage of a manufactured chair, the photo of said chair, and the dictionary definition of the word chair. This work changes each time it is installed, since the location selects and photographs the chair for installation. A dominating part of Kosuths work is the impersonal aspect of all the parts since his artistic hand is not easily seen in the pre-made objects presented."
    },
    {
        "source": "In the same year that Christo created Wrapped Chair, Pablo Picasso also created La Chaise. Made of painted sheet metal, Picassos sculptural chair exemplifies what many artists love about the chair as a subject: the contrast of form and function. One and Three Chairs, 1965, is a conceptual artwork created by Joseph Kosuth. The work is an assemblage of a manufactured chair, the photo of said chair, and the dictionary definition of the word chair. This work changes each time it is installed, since the location selects and photographs the chair for installation. A dominating part of Kosuths work is the impersonal aspect of all the parts since his artistic hand is not easily seen in the pre-made objects presented.",
        "target": "The Broken Chair is a monumental sculpture in wood, constructed of 5.5 tons of wood, 12 metres (39ft) high standing across the street from the Palace of Nations in Geneva. It has broken leg symbolizing opposition to land mines and cluster bombs. In 2001, Steve Mann exhibited a chair sculpture at San Francisco Art Institute. The chair had spikes that retracted when a credit card was inserted to download a seating license. Later other museums and galleries were equipped with the \"Pay to Sit\" chair, with a global central seating license server located in Toronto. The first sitting session was free, with a database of persons who had already used their free session."
    },
    {
        "source": "One and Three Chairs, 1965, is a conceptual artwork created by Joseph Kosuth. The work is an assemblage of a manufactured chair, the photo of said chair, and the dictionary definition of the word chair. This work changes each time it is installed, since the location selects and photographs the chair for installation. A dominating part of Kosuths work is the impersonal aspect of all the parts since his artistic hand is not easily seen in the pre-made objects presented. The Broken Chair is a monumental sculpture in wood, constructed of 5.5 tons of wood, 12 metres (39ft) high standing across the street from the Palace of Nations in Geneva. It has broken leg symbolizing opposition to land mines and cluster bombs. In 2001, Steve Mann exhibited a chair sculpture at San Francisco Art Institute. The chair had spikes that retracted when a credit card was inserted to download a seating license. Later other museums and galleries were equipped with the \"Pay to Sit\" chair, with a global central seating license server located in Toronto. The first sitting session was free, with a database of persons who had already used their free session.",
        "target": "In a performance piece at the 2012 Republican National Convention, Clint Eastwood addressed an empty chair, as if it represented President Barack Obama (meant to be construed as MIA or ineffectual). The address was controversial, with critics describing it as bizarre and supporters describing it as poignant. Japanese designer Tokujin Yoshioka has created several chairs as art forms such as \"Honey-pop\": honey-comb paper chair (2001), \"Pane chair\": natural fiber chair (2006), and \"Venus\": natural crystal chair (2007)."
    },
    {
        "source": "The Broken Chair is a monumental sculpture in wood, constructed of 5.5 tons of wood, 12 metres (39ft) high standing across the street from the Palace of Nations in Geneva. It has broken leg symbolizing opposition to land mines and cluster bombs. In 2001, Steve Mann exhibited a chair sculpture at San Francisco Art Institute. The chair had spikes that retracted when a credit card was inserted to download a seating license. Later other museums and galleries were equipped with the \"Pay to Sit\" chair, with a global central seating license server located in Toronto. The first sitting session was free, with a database of persons who had already used their free session. In a performance piece at the 2012 Republican National Convention, Clint Eastwood addressed an empty chair, as if it represented President Barack Obama (meant to be construed as MIA or ineffectual). The address was controversial, with critics describing it as bizarre and supporters describing it as poignant. Japanese designer Tokujin Yoshioka has created several chairs as art forms such as \"Honey-pop\": honey-comb paper chair (2001), \"Pane chair\": natural fiber chair (2006), and \"Venus\": natural crystal chair (2007).",
        "target": "New York industrial designer Ian Stell creates steel and wood kinetic sculptures that transform into chairs, including Roll Bottom Chair (2016) that turns into a secretariat desk and Loop that transforms into two interlocking chairs when expanded (2015)."
    },
    {
        "source": " In computer science, binary search, also known as half-interval search, logarithmic search, or binary chop, is a search algorithm that finds the position of a target value within a sorted array. Binary search compares the target value to the middle element of the array. If they are not equal, the half in which the target cannot lie is eliminated and the search continues on the remaining half, again taking the middle element to compare to the target value, and repeating this until the target value is found. If the search ends with the remaining half being empty, the target is not in the array.",
        "target": "Binary search runs in logarithmic time in the worst case, making \n\n\n\nO\n(\nlog\n\nn\n)\n\n\n{\\displaystyle O(\\log n)}\n\n comparisons, where \n\n\n\nn\n\n\n{\\displaystyle n}\n\n is the number of elements in the array.[a] Binary search is faster than linear search except for small arrays. However, the array must be sorted first to be able to apply binary search. There are specialized data structures designed for fast searching, such as hash tables, that can be searched more efficiently than binary search. However, binary search can be used to solve a wider range of problems, such as finding the next-smallest or next-largest element in the array relative to the target even if it is absent from the array."
    },
    {
        "source": "In computer science, binary search, also known as half-interval search, logarithmic search, or binary chop, is a search algorithm that finds the position of a target value within a sorted array. Binary search compares the target value to the middle element of the array. If they are not equal, the half in which the target cannot lie is eliminated and the search continues on the remaining half, again taking the middle element to compare to the target value, and repeating this until the target value is found. If the search ends with the remaining half being empty, the target is not in the array. Binary search runs in logarithmic time in the worst case, making \n\n\n\nO\n(\nlog\n\nn\n)\n\n\n{\\displaystyle O(\\log n)}\n\n comparisons, where \n\n\n\nn\n\n\n{\\displaystyle n}\n\n is the number of elements in the array.[a] Binary search is faster than linear search except for small arrays. However, the array must be sorted first to be able to apply binary search. There are specialized data structures designed for fast searching, such as hash tables, that can be searched more efficiently than binary search. However, binary search can be used to solve a wider range of problems, such as finding the next-smallest or next-largest element in the array relative to the target even if it is absent from the array.",
        "target": "There are numerous variations of binary search. In particular, fractional cascading speeds up binary searches for the same value in multiple arrays. Fractional cascading efficiently solves a number of search problems in computational geometry and in numerous other fields. Exponential search extends binary search to unbounded lists. The binary search tree and B-tree data structures are based on binary search."
    },
    {
        "source": "Binary search runs in logarithmic time in the worst case, making \n\n\n\nO\n(\nlog\n\nn\n)\n\n\n{\\displaystyle O(\\log n)}\n\n comparisons, where \n\n\n\nn\n\n\n{\\displaystyle n}\n\n is the number of elements in the array.[a] Binary search is faster than linear search except for small arrays. However, the array must be sorted first to be able to apply binary search. There are specialized data structures designed for fast searching, such as hash tables, that can be searched more efficiently than binary search. However, binary search can be used to solve a wider range of problems, such as finding the next-smallest or next-largest element in the array relative to the target even if it is absent from the array. There are numerous variations of binary search. In particular, fractional cascading speeds up binary searches for the same value in multiple arrays. Fractional cascading efficiently solves a number of search problems in computational geometry and in numerous other fields. Exponential search extends binary search to unbounded lists. The binary search tree and B-tree data structures are based on binary search.",
        "target": "Binary search works on sorted arrays. Binary search begins by comparing an element in the middle of the array with the target value. If the target value matches the element, its position in the array is returned. If the target value is less than the element, the search continues in the lower half of the array. If the target value is greater than the element, the search continues in the upper half of the array. By doing this, the algorithm eliminates the half in which the target value cannot lie in each iteration."
    },
    {
        "source": "There are numerous variations of binary search. In particular, fractional cascading speeds up binary searches for the same value in multiple arrays. Fractional cascading efficiently solves a number of search problems in computational geometry and in numerous other fields. Exponential search extends binary search to unbounded lists. The binary search tree and B-tree data structures are based on binary search. Binary search works on sorted arrays. Binary search begins by comparing an element in the middle of the array with the target value. If the target value matches the element, its position in the array is returned. If the target value is less than the element, the search continues in the lower half of the array. If the target value is greater than the element, the search continues in the upper half of the array. By doing this, the algorithm eliminates the half in which the target value cannot lie in each iteration.",
        "target": "Given an array \n\n\n\nA\n\n\n{\\displaystyle A}\n\n of \n\n\n\nn\n\n\n{\\displaystyle n}\n\n elements with values or records \n\n\n\n\nA\n\n0\n\n\n,\n\nA\n\n1\n\n\n,\n\nA\n\n2\n\n\n,\n\n,\n\nA\n\nn\n\n1\n\n\n\n\n{\\displaystyle A_{0},A_{1},A_{2},\\ldots ,A_{n-1}}\n\nsorted such that \n\n\n\n\nA\n\n0\n\n\n\n\nA\n\n1\n\n\n\n\nA\n\n2\n\n\n\n\n\n\nA\n\nn\n\n1\n\n\n\n\n{\\displaystyle A_{0}\\leq A_{1}\\leq A_{2}\\leq \\cdots \\leq A_{n-1}}\n\n, and target value \n\n\n\nT\n\n\n{\\displaystyle T}\n\n, the following subroutine uses binary search to find the index of \n\n\n\nT\n\n\n{\\displaystyle T}\n\n in \n\n\n\nA\n\n\n{\\displaystyle A}\n\n."
    },
    {
        "source": "Binary search works on sorted arrays. Binary search begins by comparing an element in the middle of the array with the target value. If the target value matches the element, its position in the array is returned. If the target value is less than the element, the search continues in the lower half of the array. If the target value is greater than the element, the search continues in the upper half of the array. By doing this, the algorithm eliminates the half in which the target value cannot lie in each iteration. Given an array \n\n\n\nA\n\n\n{\\displaystyle A}\n\n of \n\n\n\nn\n\n\n{\\displaystyle n}\n\n elements with values or records \n\n\n\n\nA\n\n0\n\n\n,\n\nA\n\n1\n\n\n,\n\nA\n\n2\n\n\n,\n\n,\n\nA\n\nn\n\n1\n\n\n\n\n{\\displaystyle A_{0},A_{1},A_{2},\\ldots ,A_{n-1}}\n\nsorted such that \n\n\n\n\nA\n\n0\n\n\n\n\nA\n\n1\n\n\n\n\nA\n\n2\n\n\n\n\n\n\nA\n\nn\n\n1\n\n\n\n\n{\\displaystyle A_{0}\\leq A_{1}\\leq A_{2}\\leq \\cdots \\leq A_{n-1}}\n\n, and target value \n\n\n\nT\n\n\n{\\displaystyle T}\n\n, the following subroutine uses binary search to find the index of \n\n\n\nT\n\n\n{\\displaystyle T}\n\n in \n\n\n\nA\n\n\n{\\displaystyle A}\n\n.",
        "target": "This iterative procedure keeps track of the search boundaries with the two variables \n\n\n\nL\n\n\n{\\displaystyle L}\n\n and \n\n\n\nR\n\n\n{\\displaystyle R}\n\n. The procedure may be expressed in pseudocode as follows, where the variable names and types remain the same as above, floor is the floor function, and unsuccessful refers to a specific value that conveys the failure of the search."
    },
    {
        "source": "Given an array \n\n\n\nA\n\n\n{\\displaystyle A}\n\n of \n\n\n\nn\n\n\n{\\displaystyle n}\n\n elements with values or records \n\n\n\n\nA\n\n0\n\n\n,\n\nA\n\n1\n\n\n,\n\nA\n\n2\n\n\n,\n\n,\n\nA\n\nn\n\n1\n\n\n\n\n{\\displaystyle A_{0},A_{1},A_{2},\\ldots ,A_{n-1}}\n\nsorted such that \n\n\n\n\nA\n\n0\n\n\n\n\nA\n\n1\n\n\n\n\nA\n\n2\n\n\n\n\n\n\nA\n\nn\n\n1\n\n\n\n\n{\\displaystyle A_{0}\\leq A_{1}\\leq A_{2}\\leq \\cdots \\leq A_{n-1}}\n\n, and target value \n\n\n\nT\n\n\n{\\displaystyle T}\n\n, the following subroutine uses binary search to find the index of \n\n\n\nT\n\n\n{\\displaystyle T}\n\n in \n\n\n\nA\n\n\n{\\displaystyle A}\n\n. This iterative procedure keeps track of the search boundaries with the two variables \n\n\n\nL\n\n\n{\\displaystyle L}\n\n and \n\n\n\nR\n\n\n{\\displaystyle R}\n\n. The procedure may be expressed in pseudocode as follows, where the variable names and types remain the same as above, floor is the floor function, and unsuccessful refers to a specific value that conveys the failure of the search.",
        "target": "Alternatively, the algorithm may take the ceiling of \n\n\n\n\n\n\nL\n+\nR\n\n2\n\n\n\n\n{\\displaystyle {\\frac {L+R}{2}}}\n\n. This may change the result if the target value appears more than once in the array."
    },
    {
        "source": "This iterative procedure keeps track of the search boundaries with the two variables \n\n\n\nL\n\n\n{\\displaystyle L}\n\n and \n\n\n\nR\n\n\n{\\displaystyle R}\n\n. The procedure may be expressed in pseudocode as follows, where the variable names and types remain the same as above, floor is the floor function, and unsuccessful refers to a specific value that conveys the failure of the search. Alternatively, the algorithm may take the ceiling of \n\n\n\n\n\n\nL\n+\nR\n\n2\n\n\n\n\n{\\displaystyle {\\frac {L+R}{2}}}\n\n. This may change the result if the target value appears more than once in the array.",
        "target": "In the above procedure, the algorithm checks whether the middle element (\n\n\n\nm\n\n\n{\\displaystyle m}\n\n) is equal to the target (\n\n\n\nT\n\n\n{\\displaystyle T}\n\n) in every iteration. Some implementations leave out this check during each iteration. The algorithm would perform this check only when one element is left (when \n\n\n\nL\n=\nR\n\n\n{\\displaystyle L=R}\n\n). This results in a faster comparison loop, as one comparison is eliminated per iteration, while it requires only one more iteration on average."
    },
    {
        "source": "Alternatively, the algorithm may take the ceiling of \n\n\n\n\n\n\nL\n+\nR\n\n2\n\n\n\n\n{\\displaystyle {\\frac {L+R}{2}}}\n\n. This may change the result if the target value appears more than once in the array. In the above procedure, the algorithm checks whether the middle element (\n\n\n\nm\n\n\n{\\displaystyle m}\n\n) is equal to the target (\n\n\n\nT\n\n\n{\\displaystyle T}\n\n) in every iteration. Some implementations leave out this check during each iteration. The algorithm would perform this check only when one element is left (when \n\n\n\nL\n=\nR\n\n\n{\\displaystyle L=R}\n\n). This results in a faster comparison loop, as one comparison is eliminated per iteration, while it requires only one more iteration on average.",
        "target": "Hermann Bottenbruch published the first implementation to leave out this check in 1962."
    },
    {
        "source": "In the above procedure, the algorithm checks whether the middle element (\n\n\n\nm\n\n\n{\\displaystyle m}\n\n) is equal to the target (\n\n\n\nT\n\n\n{\\displaystyle T}\n\n) in every iteration. Some implementations leave out this check during each iteration. The algorithm would perform this check only when one element is left (when \n\n\n\nL\n=\nR\n\n\n{\\displaystyle L=R}\n\n). This results in a faster comparison loop, as one comparison is eliminated per iteration, while it requires only one more iteration on average. Hermann Bottenbruch published the first implementation to leave out this check in 1962.",
        "target": "Where ceil is the ceiling function, the pseudocode for this version is:"
    },
    {
        "source": "Hermann Bottenbruch published the first implementation to leave out this check in 1962. Where ceil is the ceiling function, the pseudocode for this version is:",
        "target": "The procedure may return any index whose element is equal to the target value, even if there are duplicate elements in the array. For example, if the array to be searched was \n\n\n\n[\n1\n,\n2\n,\n3\n,\n4\n,\n4\n,\n5\n,\n6\n,\n7\n]\n\n\n{\\displaystyle [1,2,3,4,4,5,6,7]}\n\n and the target was \n\n\n\n4\n\n\n{\\displaystyle 4}\n\n, then it would be correct for the algorithm to either return the 4th (index 3) or 5th (index 4) element. The regular procedure would return the 4th element (index 3) in this case. It does not always return the first duplicate (consider \n\n\n\n[\n1\n,\n2\n,\n4\n,\n4\n,\n4\n,\n5\n,\n6\n,\n7\n]\n\n\n{\\displaystyle [1,2,4,4,4,5,6,7]}\n\n which still returns the 4th element). However, it is sometimes necessary to find the leftmost element or the rightmost element for a target value that is duplicated in the array. In the above example, the 4th element is the leftmost element of the value 4, while the 5th element is the rightmost element of the value 4. The alternative procedure above will always return the index of the rightmost element if such an element exists."
    },
    {
        "source": "Where ceil is the ceiling function, the pseudocode for this version is: The procedure may return any index whose element is equal to the target value, even if there are duplicate elements in the array. For example, if the array to be searched was \n\n\n\n[\n1\n,\n2\n,\n3\n,\n4\n,\n4\n,\n5\n,\n6\n,\n7\n]\n\n\n{\\displaystyle [1,2,3,4,4,5,6,7]}\n\n and the target was \n\n\n\n4\n\n\n{\\displaystyle 4}\n\n, then it would be correct for the algorithm to either return the 4th (index 3) or 5th (index 4) element. The regular procedure would return the 4th element (index 3) in this case. It does not always return the first duplicate (consider \n\n\n\n[\n1\n,\n2\n,\n4\n,\n4\n,\n4\n,\n5\n,\n6\n,\n7\n]\n\n\n{\\displaystyle [1,2,4,4,4,5,6,7]}\n\n which still returns the 4th element). However, it is sometimes necessary to find the leftmost element or the rightmost element for a target value that is duplicated in the array. In the above example, the 4th element is the leftmost element of the value 4, while the 5th element is the rightmost element of the value 4. The alternative procedure above will always return the index of the rightmost element if such an element exists.",
        "target": "To find the leftmost element, the following procedure can be used:"
    },
    {
        "source": "The procedure may return any index whose element is equal to the target value, even if there are duplicate elements in the array. For example, if the array to be searched was \n\n\n\n[\n1\n,\n2\n,\n3\n,\n4\n,\n4\n,\n5\n,\n6\n,\n7\n]\n\n\n{\\displaystyle [1,2,3,4,4,5,6,7]}\n\n and the target was \n\n\n\n4\n\n\n{\\displaystyle 4}\n\n, then it would be correct for the algorithm to either return the 4th (index 3) or 5th (index 4) element. The regular procedure would return the 4th element (index 3) in this case. It does not always return the first duplicate (consider \n\n\n\n[\n1\n,\n2\n,\n4\n,\n4\n,\n4\n,\n5\n,\n6\n,\n7\n]\n\n\n{\\displaystyle [1,2,4,4,4,5,6,7]}\n\n which still returns the 4th element). However, it is sometimes necessary to find the leftmost element or the rightmost element for a target value that is duplicated in the array. In the above example, the 4th element is the leftmost element of the value 4, while the 5th element is the rightmost element of the value 4. The alternative procedure above will always return the index of the rightmost element if such an element exists. To find the leftmost element, the following procedure can be used:",
        "target": "If \n\n\n\nL\n<\nn\n\n\n{\\displaystyle L<n}\n\n and \n\n\n\n\nA\n\nL\n\n\n=\nT\n\n\n{\\displaystyle A_{L}=T}\n\n, then \n\n\n\n\nA\n\nL\n\n\n\n\n{\\displaystyle A_{L}}\n\n is the leftmost element that equals \n\n\n\nT\n\n\n{\\displaystyle T}\n\n. Even if \n\n\n\nT\n\n\n{\\displaystyle T}\n\n is not in the array, \n\n\n\nL\n\n\n{\\displaystyle L}\n\n is the rank of \n\n\n\nT\n\n\n{\\displaystyle T}\n\n in the array, or the number of elements in the array that are less than \n\n\n\nT\n\n\n{\\displaystyle T}\n\n."
    },
    {
        "source": "To find the leftmost element, the following procedure can be used: If \n\n\n\nL\n<\nn\n\n\n{\\displaystyle L<n}\n\n and \n\n\n\n\nA\n\nL\n\n\n=\nT\n\n\n{\\displaystyle A_{L}=T}\n\n, then \n\n\n\n\nA\n\nL\n\n\n\n\n{\\displaystyle A_{L}}\n\n is the leftmost element that equals \n\n\n\nT\n\n\n{\\displaystyle T}\n\n. Even if \n\n\n\nT\n\n\n{\\displaystyle T}\n\n is not in the array, \n\n\n\nL\n\n\n{\\displaystyle L}\n\n is the rank of \n\n\n\nT\n\n\n{\\displaystyle T}\n\n in the array, or the number of elements in the array that are less than \n\n\n\nT\n\n\n{\\displaystyle T}\n\n.",
        "target": "Where floor is the floor function, the pseudocode for this version is:"
    },
    {
        "source": "If \n\n\n\nL\n<\nn\n\n\n{\\displaystyle L<n}\n\n and \n\n\n\n\nA\n\nL\n\n\n=\nT\n\n\n{\\displaystyle A_{L}=T}\n\n, then \n\n\n\n\nA\n\nL\n\n\n\n\n{\\displaystyle A_{L}}\n\n is the leftmost element that equals \n\n\n\nT\n\n\n{\\displaystyle T}\n\n. Even if \n\n\n\nT\n\n\n{\\displaystyle T}\n\n is not in the array, \n\n\n\nL\n\n\n{\\displaystyle L}\n\n is the rank of \n\n\n\nT\n\n\n{\\displaystyle T}\n\n in the array, or the number of elements in the array that are less than \n\n\n\nT\n\n\n{\\displaystyle T}\n\n. Where floor is the floor function, the pseudocode for this version is:",
        "target": "To find the rightmost element, the following procedure can be used:"
    },
    {
        "source": "Where floor is the floor function, the pseudocode for this version is: To find the rightmost element, the following procedure can be used:",
        "target": "If \n\n\n\nR\n>\n0\n\n\n{\\displaystyle R>0}\n\n and \n\n\n\n\nA\n\nR\n\n1\n\n\n=\nT\n\n\n{\\displaystyle A_{R-1}=T}\n\n, then \n\n\n\n\nA\n\nR\n\n1\n\n\n\n\n{\\displaystyle A_{R-1}}\n\n is the rightmost element that equals \n\n\n\nT\n\n\n{\\displaystyle T}\n\n. Even if \n\n\n\nT\n\n\n{\\displaystyle T}\n\n is not in the array, \n\n\n\nn\n\nR\n\n\n{\\displaystyle n-R}\n\n is the number of elements in the array that are greater than \n\n\n\nT\n\n\n{\\displaystyle T}\n\n."
    },
    {
        "source": "To find the rightmost element, the following procedure can be used: If \n\n\n\nR\n>\n0\n\n\n{\\displaystyle R>0}\n\n and \n\n\n\n\nA\n\nR\n\n1\n\n\n=\nT\n\n\n{\\displaystyle A_{R-1}=T}\n\n, then \n\n\n\n\nA\n\nR\n\n1\n\n\n\n\n{\\displaystyle A_{R-1}}\n\n is the rightmost element that equals \n\n\n\nT\n\n\n{\\displaystyle T}\n\n. Even if \n\n\n\nT\n\n\n{\\displaystyle T}\n\n is not in the array, \n\n\n\nn\n\nR\n\n\n{\\displaystyle n-R}\n\n is the number of elements in the array that are greater than \n\n\n\nT\n\n\n{\\displaystyle T}\n\n.",
        "target": "Where floor is the floor function, the pseudocode for this version is:"
    },
    {
        "source": "If \n\n\n\nR\n>\n0\n\n\n{\\displaystyle R>0}\n\n and \n\n\n\n\nA\n\nR\n\n1\n\n\n=\nT\n\n\n{\\displaystyle A_{R-1}=T}\n\n, then \n\n\n\n\nA\n\nR\n\n1\n\n\n\n\n{\\displaystyle A_{R-1}}\n\n is the rightmost element that equals \n\n\n\nT\n\n\n{\\displaystyle T}\n\n. Even if \n\n\n\nT\n\n\n{\\displaystyle T}\n\n is not in the array, \n\n\n\nn\n\nR\n\n\n{\\displaystyle n-R}\n\n is the number of elements in the array that are greater than \n\n\n\nT\n\n\n{\\displaystyle T}\n\n. Where floor is the floor function, the pseudocode for this version is:",
        "target": "The above procedure only performs exact matches, finding the position of a target value. However, it is trivial to extend binary search to perform approximate matches because binary search operates on sorted arrays. For example, binary search can be used to compute, for a given value, its rank (the number of smaller elements), predecessor (next-smallest element), successor (next-largest element), and nearest neighbor. Range queries seeking the number of elements between two values can be performed with two rank queries."
    },
    {
        "source": "Where floor is the floor function, the pseudocode for this version is: The above procedure only performs exact matches, finding the position of a target value. However, it is trivial to extend binary search to perform approximate matches because binary search operates on sorted arrays. For example, binary search can be used to compute, for a given value, its rank (the number of smaller elements), predecessor (next-smallest element), successor (next-largest element), and nearest neighbor. Range queries seeking the number of elements between two values can be performed with two rank queries.",
        "target": "In terms of the number of comparisons, the performance of binary search can be analyzed by viewing the run of the procedure on a binary tree. The root node of the tree is the middle element of the array. The middle element of the lower half is the left child node of the root, and the middle element of the upper half is the right child node of the root. The rest of the tree is built in a similar fashion. Starting from the root node, the left or right subtrees are traversed depending on whether the target value is less or more than the node under consideration."
    },
    {
        "source": "The above procedure only performs exact matches, finding the position of a target value. However, it is trivial to extend binary search to perform approximate matches because binary search operates on sorted arrays. For example, binary search can be used to compute, for a given value, its rank (the number of smaller elements), predecessor (next-smallest element), successor (next-largest element), and nearest neighbor. Range queries seeking the number of elements between two values can be performed with two rank queries. In terms of the number of comparisons, the performance of binary search can be analyzed by viewing the run of the procedure on a binary tree. The root node of the tree is the middle element of the array. The middle element of the lower half is the left child node of the root, and the middle element of the upper half is the right child node of the root. The rest of the tree is built in a similar fashion. Starting from the root node, the left or right subtrees are traversed depending on whether the target value is less or more than the node under consideration.",
        "target": "In the worst case, binary search makes \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}(n)+1\\rfloor }\n\n iterations of the comparison loop, where the \n\n\n\n\n\n\n\n\n{\\textstyle \\lfloor \\cdot \\rfloor }\n\n notation denotes the floor function that yields the greatest integer less than or equal to the argument, and \n\n\n\n\nlog\n\n2\n\n\n\n\n{\\textstyle \\log _{2}}\n\n is the binary logarithm. This is because the worst case is reached when the search reaches the deepest level of the tree, and there are always \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}(n)+1\\rfloor }\n\n levels in the tree for any binary search."
    },
    {
        "source": "In terms of the number of comparisons, the performance of binary search can be analyzed by viewing the run of the procedure on a binary tree. The root node of the tree is the middle element of the array. The middle element of the lower half is the left child node of the root, and the middle element of the upper half is the right child node of the root. The rest of the tree is built in a similar fashion. Starting from the root node, the left or right subtrees are traversed depending on whether the target value is less or more than the node under consideration. In the worst case, binary search makes \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}(n)+1\\rfloor }\n\n iterations of the comparison loop, where the \n\n\n\n\n\n\n\n\n{\\textstyle \\lfloor \\cdot \\rfloor }\n\n notation denotes the floor function that yields the greatest integer less than or equal to the argument, and \n\n\n\n\nlog\n\n2\n\n\n\n\n{\\textstyle \\log _{2}}\n\n is the binary logarithm. This is because the worst case is reached when the search reaches the deepest level of the tree, and there are always \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}(n)+1\\rfloor }\n\n levels in the tree for any binary search.",
        "target": "The worst case may also be reached when the target element is not in the array. If \n\n\n\nn\n\n\n{\\textstyle n}\n\n is one less than a power of two, then this is always the case. Otherwise, the search may perform \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}(n)+1\\rfloor }\n\niterations if the search reaches the deepest level of the tree. However, it may make \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n\n\n{\\textstyle \\lfloor \\log _{2}(n)\\rfloor }\n\n iterations, which is one less than the worst case, if the search ends at the second-deepest level of the tree."
    },
    {
        "source": "In the worst case, binary search makes \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}(n)+1\\rfloor }\n\n iterations of the comparison loop, where the \n\n\n\n\n\n\n\n\n{\\textstyle \\lfloor \\cdot \\rfloor }\n\n notation denotes the floor function that yields the greatest integer less than or equal to the argument, and \n\n\n\n\nlog\n\n2\n\n\n\n\n{\\textstyle \\log _{2}}\n\n is the binary logarithm. This is because the worst case is reached when the search reaches the deepest level of the tree, and there are always \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}(n)+1\\rfloor }\n\n levels in the tree for any binary search. The worst case may also be reached when the target element is not in the array. If \n\n\n\nn\n\n\n{\\textstyle n}\n\n is one less than a power of two, then this is always the case. Otherwise, the search may perform \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}(n)+1\\rfloor }\n\niterations if the search reaches the deepest level of the tree. However, it may make \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n\n\n{\\textstyle \\lfloor \\log _{2}(n)\\rfloor }\n\n iterations, which is one less than the worst case, if the search ends at the second-deepest level of the tree.",
        "target": "On average, assuming that each element is equally likely to be searched, binary search makes \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n(\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n\n2\n)\n\n/\n\nn\n\n\n{\\displaystyle \\lfloor \\log _{2}(n)\\rfloor +1-(2^{\\lfloor \\log _{2}(n)\\rfloor +1}-\\lfloor \\log _{2}(n)\\rfloor -2)/n}\n\n iterations when the target element is in the array. This is approximately equal to \n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n1\n\n\n{\\displaystyle \\log _{2}(n)-1}\n\n iterations. When the target element is not in the array, binary search makes \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n2\n\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n/\n\n(\nn\n+\n1\n)\n\n\n{\\displaystyle \\lfloor \\log _{2}(n)\\rfloor +2-2^{\\lfloor \\log _{2}(n)\\rfloor +1}/(n+1)}\n\n iterations on average, assuming that the range between and outside elements is equally likely to be searched."
    },
    {
        "source": "The worst case may also be reached when the target element is not in the array. If \n\n\n\nn\n\n\n{\\textstyle n}\n\n is one less than a power of two, then this is always the case. Otherwise, the search may perform \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}(n)+1\\rfloor }\n\niterations if the search reaches the deepest level of the tree. However, it may make \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n\n\n{\\textstyle \\lfloor \\log _{2}(n)\\rfloor }\n\n iterations, which is one less than the worst case, if the search ends at the second-deepest level of the tree. On average, assuming that each element is equally likely to be searched, binary search makes \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n(\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n\n2\n)\n\n/\n\nn\n\n\n{\\displaystyle \\lfloor \\log _{2}(n)\\rfloor +1-(2^{\\lfloor \\log _{2}(n)\\rfloor +1}-\\lfloor \\log _{2}(n)\\rfloor -2)/n}\n\n iterations when the target element is in the array. This is approximately equal to \n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n1\n\n\n{\\displaystyle \\log _{2}(n)-1}\n\n iterations. When the target element is not in the array, binary search makes \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n2\n\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n/\n\n(\nn\n+\n1\n)\n\n\n{\\displaystyle \\lfloor \\log _{2}(n)\\rfloor +2-2^{\\lfloor \\log _{2}(n)\\rfloor +1}/(n+1)}\n\n iterations on average, assuming that the range between and outside elements is equally likely to be searched.",
        "target": "In the best case, where the target value is the middle element of the array, its position is returned after one iteration."
    },
    {
        "source": "On average, assuming that each element is equally likely to be searched, binary search makes \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n(\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n\n2\n)\n\n/\n\nn\n\n\n{\\displaystyle \\lfloor \\log _{2}(n)\\rfloor +1-(2^{\\lfloor \\log _{2}(n)\\rfloor +1}-\\lfloor \\log _{2}(n)\\rfloor -2)/n}\n\n iterations when the target element is in the array. This is approximately equal to \n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n1\n\n\n{\\displaystyle \\log _{2}(n)-1}\n\n iterations. When the target element is not in the array, binary search makes \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n2\n\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n/\n\n(\nn\n+\n1\n)\n\n\n{\\displaystyle \\lfloor \\log _{2}(n)\\rfloor +2-2^{\\lfloor \\log _{2}(n)\\rfloor +1}/(n+1)}\n\n iterations on average, assuming that the range between and outside elements is equally likely to be searched. In the best case, where the target value is the middle element of the array, its position is returned after one iteration.",
        "target": "In terms of iterations, no search algorithm that works only by comparing elements can exhibit better average and worst-case performance than binary search. The comparison tree representing binary search has the fewest levels possible as every level above the lowest level of the tree is filled completely.[b] Otherwise, the search algorithm can eliminate few elements in an iteration, increasing the number of iterations required in the average and worst case. This is the case for other search algorithms based on comparisons, as while they may work faster on some target values, the average performance over all elements is worse than binary search. By dividing the array in half, binary search ensures that the size of both subarrays are as similar as possible."
    },
    {
        "source": "In the best case, where the target value is the middle element of the array, its position is returned after one iteration. In terms of iterations, no search algorithm that works only by comparing elements can exhibit better average and worst-case performance than binary search. The comparison tree representing binary search has the fewest levels possible as every level above the lowest level of the tree is filled completely.[b] Otherwise, the search algorithm can eliminate few elements in an iteration, increasing the number of iterations required in the average and worst case. This is the case for other search algorithms based on comparisons, as while they may work faster on some target values, the average performance over all elements is worse than binary search. By dividing the array in half, binary search ensures that the size of both subarrays are as similar as possible.",
        "target": "Binary search requires three pointers to elements, which may be array indices or pointers to memory locations, regardless of the size of the array. Therefore, the space complexity of binary search is \n\n\n\nO\n(\n1\n)\n\n\n{\\displaystyle O(1)}\n\n in the word RAM model of computation."
    },
    {
        "source": "In terms of iterations, no search algorithm that works only by comparing elements can exhibit better average and worst-case performance than binary search. The comparison tree representing binary search has the fewest levels possible as every level above the lowest level of the tree is filled completely.[b] Otherwise, the search algorithm can eliminate few elements in an iteration, increasing the number of iterations required in the average and worst case. This is the case for other search algorithms based on comparisons, as while they may work faster on some target values, the average performance over all elements is worse than binary search. By dividing the array in half, binary search ensures that the size of both subarrays are as similar as possible. Binary search requires three pointers to elements, which may be array indices or pointers to memory locations, regardless of the size of the array. Therefore, the space complexity of binary search is \n\n\n\nO\n(\n1\n)\n\n\n{\\displaystyle O(1)}\n\n in the word RAM model of computation.",
        "target": "The average number of iterations performed by binary search depends on the probability of each element being searched. The average case is different for successful searches and unsuccessful searches. It will be assumed that each element is equally likely to be searched for successful searches. For unsuccessful searches, it will be assumed that the intervals between and outside elements are equally likely to be searched. The average case for successful searches is the number of iterations required to search every element exactly once, divided by \n\n\n\nn\n\n\n{\\displaystyle n}\n\n, the number of elements. The average case for unsuccessful searches is the number of iterations required to search an element within every interval exactly once, divided by the \n\n\n\nn\n+\n1\n\n\n{\\displaystyle n+1}\n\n intervals."
    },
    {
        "source": "Binary search requires three pointers to elements, which may be array indices or pointers to memory locations, regardless of the size of the array. Therefore, the space complexity of binary search is \n\n\n\nO\n(\n1\n)\n\n\n{\\displaystyle O(1)}\n\n in the word RAM model of computation. The average number of iterations performed by binary search depends on the probability of each element being searched. The average case is different for successful searches and unsuccessful searches. It will be assumed that each element is equally likely to be searched for successful searches. For unsuccessful searches, it will be assumed that the intervals between and outside elements are equally likely to be searched. The average case for successful searches is the number of iterations required to search every element exactly once, divided by \n\n\n\nn\n\n\n{\\displaystyle n}\n\n, the number of elements. The average case for unsuccessful searches is the number of iterations required to search an element within every interval exactly once, divided by the \n\n\n\nn\n+\n1\n\n\n{\\displaystyle n+1}\n\n intervals.",
        "target": "In the binary tree representation, a successful search can be represented by a path from the root to the target node, called an internal path. The length of a path is the number of edges (connections between nodes) that the path passes through. The number of iterations performed by a search, given that the corresponding path has length \n\n\n\nl\n\n\n{\\displaystyle l}\n\n, is \n\n\n\nl\n+\n1\n\n\n{\\displaystyle l+1}\n\n counting the initial iteration. The internal path length is the sum of the lengths of all unique internal paths. Since there is only one path from the root to any single node, each internal path represents a search for a specific element. If there are \n\n\n\nn\n\n\n{\\displaystyle n}\n\n elements, which is a positive integer, and the internal path length is \n\n\n\nI\n(\nn\n)\n\n\n{\\displaystyle I(n)}\n\n, then the average number of iterations for a successful search \n\n\n\nT\n(\nn\n)\n=\n1\n+\n\n\n\nI\n(\nn\n)\n\nn\n\n\n\n\n{\\displaystyle T(n)=1+{\\frac {I(n)}{n}}}\n\n, with the one iteration added to count the initial iteration."
    },
    {
        "source": "The average number of iterations performed by binary search depends on the probability of each element being searched. The average case is different for successful searches and unsuccessful searches. It will be assumed that each element is equally likely to be searched for successful searches. For unsuccessful searches, it will be assumed that the intervals between and outside elements are equally likely to be searched. The average case for successful searches is the number of iterations required to search every element exactly once, divided by \n\n\n\nn\n\n\n{\\displaystyle n}\n\n, the number of elements. The average case for unsuccessful searches is the number of iterations required to search an element within every interval exactly once, divided by the \n\n\n\nn\n+\n1\n\n\n{\\displaystyle n+1}\n\n intervals. In the binary tree representation, a successful search can be represented by a path from the root to the target node, called an internal path. The length of a path is the number of edges (connections between nodes) that the path passes through. The number of iterations performed by a search, given that the corresponding path has length \n\n\n\nl\n\n\n{\\displaystyle l}\n\n, is \n\n\n\nl\n+\n1\n\n\n{\\displaystyle l+1}\n\n counting the initial iteration. The internal path length is the sum of the lengths of all unique internal paths. Since there is only one path from the root to any single node, each internal path represents a search for a specific element. If there are \n\n\n\nn\n\n\n{\\displaystyle n}\n\n elements, which is a positive integer, and the internal path length is \n\n\n\nI\n(\nn\n)\n\n\n{\\displaystyle I(n)}\n\n, then the average number of iterations for a successful search \n\n\n\nT\n(\nn\n)\n=\n1\n+\n\n\n\nI\n(\nn\n)\n\nn\n\n\n\n\n{\\displaystyle T(n)=1+{\\frac {I(n)}{n}}}\n\n, with the one iteration added to count the initial iteration.",
        "target": "Since binary search is the optimal algorithm for searching with comparisons, this problem is reduced to calculating the minimum internal path length of all binary trees with \n\n\n\nn\n\n\n{\\displaystyle n}\n\n nodes, which is equal to:"
    },
    {
        "source": "In the binary tree representation, a successful search can be represented by a path from the root to the target node, called an internal path. The length of a path is the number of edges (connections between nodes) that the path passes through. The number of iterations performed by a search, given that the corresponding path has length \n\n\n\nl\n\n\n{\\displaystyle l}\n\n, is \n\n\n\nl\n+\n1\n\n\n{\\displaystyle l+1}\n\n counting the initial iteration. The internal path length is the sum of the lengths of all unique internal paths. Since there is only one path from the root to any single node, each internal path represents a search for a specific element. If there are \n\n\n\nn\n\n\n{\\displaystyle n}\n\n elements, which is a positive integer, and the internal path length is \n\n\n\nI\n(\nn\n)\n\n\n{\\displaystyle I(n)}\n\n, then the average number of iterations for a successful search \n\n\n\nT\n(\nn\n)\n=\n1\n+\n\n\n\nI\n(\nn\n)\n\nn\n\n\n\n\n{\\displaystyle T(n)=1+{\\frac {I(n)}{n}}}\n\n, with the one iteration added to count the initial iteration. Since binary search is the optimal algorithm for searching with comparisons, this problem is reduced to calculating the minimum internal path length of all binary trees with \n\n\n\nn\n\n\n{\\displaystyle n}\n\n nodes, which is equal to:",
        "target": "I\n(\nn\n)\n=\n\n\n\nk\n=\n1\n\n\nn\n\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nk\n)\n\n\n\n\n\n{\\displaystyle I(n)=\\sum _{k=1}^{n}\\left\\lfloor \\log _{2}(k)\\right\\rfloor }"
    },
    {
        "source": "Since binary search is the optimal algorithm for searching with comparisons, this problem is reduced to calculating the minimum internal path length of all binary trees with \n\n\n\nn\n\n\n{\\displaystyle n}\n\n nodes, which is equal to: I\n(\nn\n)\n=\n\n\n\nk\n=\n1\n\n\nn\n\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nk\n)\n\n\n\n\n\n{\\displaystyle I(n)=\\sum _{k=1}^{n}\\left\\lfloor \\log _{2}(k)\\right\\rfloor }",
        "target": "For example, in a 7-element array, the root requires one iteration, the two elements below the root require two iterations, and the four elements below require three iterations. In this case, the internal path length is:"
    },
    {
        "source": "I\n(\nn\n)\n=\n\n\n\nk\n=\n1\n\n\nn\n\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nk\n)\n\n\n\n\n\n{\\displaystyle I(n)=\\sum _{k=1}^{n}\\left\\lfloor \\log _{2}(k)\\right\\rfloor } For example, in a 7-element array, the root requires one iteration, the two elements below the root require two iterations, and the four elements below require three iterations. In this case, the internal path length is:",
        "target": "\n\nk\n=\n1\n\n\n7\n\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nk\n)\n\n\n\n=\n0\n+\n2\n(\n1\n)\n+\n4\n(\n2\n)\n=\n2\n+\n8\n=\n10\n\n\n{\\displaystyle \\sum _{k=1}^{7}\\left\\lfloor \\log _{2}(k)\\right\\rfloor =0+2(1)+4(2)=2+8=10}"
    },
    {
        "source": "For example, in a 7-element array, the root requires one iteration, the two elements below the root require two iterations, and the four elements below require three iterations. In this case, the internal path length is: \n\nk\n=\n1\n\n\n7\n\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nk\n)\n\n\n\n=\n0\n+\n2\n(\n1\n)\n+\n4\n(\n2\n)\n=\n2\n+\n8\n=\n10\n\n\n{\\displaystyle \\sum _{k=1}^{7}\\left\\lfloor \\log _{2}(k)\\right\\rfloor =0+2(1)+4(2)=2+8=10}",
        "target": "The average number of iterations would be \n\n\n\n1\n+\n\n\n10\n7\n\n\n=\n2\n\n\n3\n7\n\n\n\n\n{\\displaystyle 1+{\\frac {10}{7}}=2{\\frac {3}{7}}}\n\n based on the equation for the average case. The sum for \n\n\n\nI\n(\nn\n)\n\n\n{\\displaystyle I(n)}\n\n can be simplified to:"
    },
    {
        "source": "\n\nk\n=\n1\n\n\n7\n\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nk\n)\n\n\n\n=\n0\n+\n2\n(\n1\n)\n+\n4\n(\n2\n)\n=\n2\n+\n8\n=\n10\n\n\n{\\displaystyle \\sum _{k=1}^{7}\\left\\lfloor \\log _{2}(k)\\right\\rfloor =0+2(1)+4(2)=2+8=10} The average number of iterations would be \n\n\n\n1\n+\n\n\n10\n7\n\n\n=\n2\n\n\n3\n7\n\n\n\n\n{\\displaystyle 1+{\\frac {10}{7}}=2{\\frac {3}{7}}}\n\n based on the equation for the average case. The sum for \n\n\n\nI\n(\nn\n)\n\n\n{\\displaystyle I(n)}\n\n can be simplified to:",
        "target": "I\n(\nn\n)\n=\n\n\n\nk\n=\n1\n\n\nn\n\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nk\n)\n\n\n\n=\n(\nn\n+\n1\n)\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n\n\n2\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n+\n1\n\n\n+\n2\n\n\n{\\displaystyle I(n)=\\sum _{k=1}^{n}\\left\\lfloor \\log _{2}(k)\\right\\rfloor =(n+1)\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor -2^{\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor +1}+2}"
    },
    {
        "source": "The average number of iterations would be \n\n\n\n1\n+\n\n\n10\n7\n\n\n=\n2\n\n\n3\n7\n\n\n\n\n{\\displaystyle 1+{\\frac {10}{7}}=2{\\frac {3}{7}}}\n\n based on the equation for the average case. The sum for \n\n\n\nI\n(\nn\n)\n\n\n{\\displaystyle I(n)}\n\n can be simplified to: I\n(\nn\n)\n=\n\n\n\nk\n=\n1\n\n\nn\n\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nk\n)\n\n\n\n=\n(\nn\n+\n1\n)\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n\n\n2\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n+\n1\n\n\n+\n2\n\n\n{\\displaystyle I(n)=\\sum _{k=1}^{n}\\left\\lfloor \\log _{2}(k)\\right\\rfloor =(n+1)\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor -2^{\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor +1}+2}",
        "target": "Substituting the equation for \n\n\n\nI\n(\nn\n)\n\n\n{\\displaystyle I(n)}\n\n into the equation for \n\n\n\nT\n(\nn\n)\n\n\n{\\displaystyle T(n)}\n\n:"
    },
    {
        "source": "I\n(\nn\n)\n=\n\n\n\nk\n=\n1\n\n\nn\n\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nk\n)\n\n\n\n=\n(\nn\n+\n1\n)\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n\n\n2\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n+\n1\n\n\n+\n2\n\n\n{\\displaystyle I(n)=\\sum _{k=1}^{n}\\left\\lfloor \\log _{2}(k)\\right\\rfloor =(n+1)\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor -2^{\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor +1}+2} Substituting the equation for \n\n\n\nI\n(\nn\n)\n\n\n{\\displaystyle I(n)}\n\n into the equation for \n\n\n\nT\n(\nn\n)\n\n\n{\\displaystyle T(n)}\n\n:",
        "target": "T\n(\nn\n)\n=\n1\n+\n\n\n\n(\nn\n+\n1\n)\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n\n\n2\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n+\n1\n\n\n+\n2\n\nn\n\n\n=\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n(\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n\n2\n)\n\n/\n\nn\n\n\n{\\displaystyle T(n)=1+{\\frac {(n+1)\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor -2^{\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor +1}+2}{n}}=\\lfloor \\log _{2}(n)\\rfloor +1-(2^{\\lfloor \\log _{2}(n)\\rfloor +1}-\\lfloor \\log _{2}(n)\\rfloor -2)/n}"
    },
    {
        "source": "Substituting the equation for \n\n\n\nI\n(\nn\n)\n\n\n{\\displaystyle I(n)}\n\n into the equation for \n\n\n\nT\n(\nn\n)\n\n\n{\\displaystyle T(n)}\n\n: T\n(\nn\n)\n=\n1\n+\n\n\n\n(\nn\n+\n1\n)\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n\n\n2\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n+\n1\n\n\n+\n2\n\nn\n\n\n=\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n(\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n\n2\n)\n\n/\n\nn\n\n\n{\\displaystyle T(n)=1+{\\frac {(n+1)\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor -2^{\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor +1}+2}{n}}=\\lfloor \\log _{2}(n)\\rfloor +1-(2^{\\lfloor \\log _{2}(n)\\rfloor +1}-\\lfloor \\log _{2}(n)\\rfloor -2)/n}",
        "target": "For integer \n\n\n\nn\n\n\n{\\displaystyle n}\n\n, this is equivalent to the equation for the average case on a successful search specified above."
    },
    {
        "source": "T\n(\nn\n)\n=\n1\n+\n\n\n\n(\nn\n+\n1\n)\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n\n\n2\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n+\n1\n\n\n+\n2\n\nn\n\n\n=\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n(\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n\n2\n)\n\n/\n\nn\n\n\n{\\displaystyle T(n)=1+{\\frac {(n+1)\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor -2^{\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor +1}+2}{n}}=\\lfloor \\log _{2}(n)\\rfloor +1-(2^{\\lfloor \\log _{2}(n)\\rfloor +1}-\\lfloor \\log _{2}(n)\\rfloor -2)/n} For integer \n\n\n\nn\n\n\n{\\displaystyle n}\n\n, this is equivalent to the equation for the average case on a successful search specified above.",
        "target": "Unsuccessful searches can be represented by augmenting the tree with external nodes, which forms an extended binary tree. If an internal node, or a node present in the tree, has fewer than two child nodes, then additional child nodes, called external nodes, are added so that each internal node has two children. By doing so, an unsuccessful search can be represented as a path to an external node, whose parent is the single element that remains during the last iteration. An external path is a path from the root to an external node. The external path length is the sum of the lengths of all unique external paths. If there are \n\n\n\nn\n\n\n{\\displaystyle n}\n\n elements, which is a positive integer, and the external path length is \n\n\n\nE\n(\nn\n)\n\n\n{\\displaystyle E(n)}\n\n, then the average number of iterations for an unsuccessful search \n\n\n\n\nT\n\n\n(\nn\n)\n=\n\n\n\nE\n(\nn\n)\n\n\nn\n+\n1\n\n\n\n\n\n{\\displaystyle T'(n)={\\frac {E(n)}{n+1}}}\n\n, with the one iteration added to count the initial iteration. The external path length is divided by \n\n\n\nn\n+\n1\n\n\n{\\displaystyle n+1}\n\n instead of \n\n\n\nn\n\n\n{\\displaystyle n}\n\n because there are \n\n\n\nn\n+\n1\n\n\n{\\displaystyle n+1}\n\n external paths, representing the intervals between and outside the elements of the array."
    },
    {
        "source": "For integer \n\n\n\nn\n\n\n{\\displaystyle n}\n\n, this is equivalent to the equation for the average case on a successful search specified above. Unsuccessful searches can be represented by augmenting the tree with external nodes, which forms an extended binary tree. If an internal node, or a node present in the tree, has fewer than two child nodes, then additional child nodes, called external nodes, are added so that each internal node has two children. By doing so, an unsuccessful search can be represented as a path to an external node, whose parent is the single element that remains during the last iteration. An external path is a path from the root to an external node. The external path length is the sum of the lengths of all unique external paths. If there are \n\n\n\nn\n\n\n{\\displaystyle n}\n\n elements, which is a positive integer, and the external path length is \n\n\n\nE\n(\nn\n)\n\n\n{\\displaystyle E(n)}\n\n, then the average number of iterations for an unsuccessful search \n\n\n\n\nT\n\n\n(\nn\n)\n=\n\n\n\nE\n(\nn\n)\n\n\nn\n+\n1\n\n\n\n\n\n{\\displaystyle T'(n)={\\frac {E(n)}{n+1}}}\n\n, with the one iteration added to count the initial iteration. The external path length is divided by \n\n\n\nn\n+\n1\n\n\n{\\displaystyle n+1}\n\n instead of \n\n\n\nn\n\n\n{\\displaystyle n}\n\n because there are \n\n\n\nn\n+\n1\n\n\n{\\displaystyle n+1}\n\n external paths, representing the intervals between and outside the elements of the array.",
        "target": "This problem can similarly be reduced to determining the minimum external path length of all binary trees with \n\n\n\nn\n\n\n{\\displaystyle n}\n\n nodes. For all binary trees, the external path length is equal to the internal path length plus \n\n\n\n2\nn\n\n\n{\\displaystyle 2n}\n\n. Substituting the equation for \n\n\n\nI\n(\nn\n)\n\n\n{\\displaystyle I(n)}\n\n:"
    },
    {
        "source": "Unsuccessful searches can be represented by augmenting the tree with external nodes, which forms an extended binary tree. If an internal node, or a node present in the tree, has fewer than two child nodes, then additional child nodes, called external nodes, are added so that each internal node has two children. By doing so, an unsuccessful search can be represented as a path to an external node, whose parent is the single element that remains during the last iteration. An external path is a path from the root to an external node. The external path length is the sum of the lengths of all unique external paths. If there are \n\n\n\nn\n\n\n{\\displaystyle n}\n\n elements, which is a positive integer, and the external path length is \n\n\n\nE\n(\nn\n)\n\n\n{\\displaystyle E(n)}\n\n, then the average number of iterations for an unsuccessful search \n\n\n\n\nT\n\n\n(\nn\n)\n=\n\n\n\nE\n(\nn\n)\n\n\nn\n+\n1\n\n\n\n\n\n{\\displaystyle T'(n)={\\frac {E(n)}{n+1}}}\n\n, with the one iteration added to count the initial iteration. The external path length is divided by \n\n\n\nn\n+\n1\n\n\n{\\displaystyle n+1}\n\n instead of \n\n\n\nn\n\n\n{\\displaystyle n}\n\n because there are \n\n\n\nn\n+\n1\n\n\n{\\displaystyle n+1}\n\n external paths, representing the intervals between and outside the elements of the array. This problem can similarly be reduced to determining the minimum external path length of all binary trees with \n\n\n\nn\n\n\n{\\displaystyle n}\n\n nodes. For all binary trees, the external path length is equal to the internal path length plus \n\n\n\n2\nn\n\n\n{\\displaystyle 2n}\n\n. Substituting the equation for \n\n\n\nI\n(\nn\n)\n\n\n{\\displaystyle I(n)}\n\n:",
        "target": "E\n(\nn\n)\n=\nI\n(\nn\n)\n+\n2\nn\n=\n\n[\n\n(\nn\n+\n1\n)\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n\n\n2\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n+\n1\n\n\n+\n2\n\n]\n\n+\n2\nn\n=\n(\nn\n+\n1\n)\n(\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n2\n)\n\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n\n{\\displaystyle E(n)=I(n)+2n=\\left[(n+1)\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor -2^{\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor +1}+2\\right]+2n=(n+1)(\\lfloor \\log _{2}(n)\\rfloor +2)-2^{\\lfloor \\log _{2}(n)\\rfloor +1}}"
    },
    {
        "source": "This problem can similarly be reduced to determining the minimum external path length of all binary trees with \n\n\n\nn\n\n\n{\\displaystyle n}\n\n nodes. For all binary trees, the external path length is equal to the internal path length plus \n\n\n\n2\nn\n\n\n{\\displaystyle 2n}\n\n. Substituting the equation for \n\n\n\nI\n(\nn\n)\n\n\n{\\displaystyle I(n)}\n\n: E\n(\nn\n)\n=\nI\n(\nn\n)\n+\n2\nn\n=\n\n[\n\n(\nn\n+\n1\n)\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n\n\n2\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n+\n1\n\n\n+\n2\n\n]\n\n+\n2\nn\n=\n(\nn\n+\n1\n)\n(\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n2\n)\n\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n\n{\\displaystyle E(n)=I(n)+2n=\\left[(n+1)\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor -2^{\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor +1}+2\\right]+2n=(n+1)(\\lfloor \\log _{2}(n)\\rfloor +2)-2^{\\lfloor \\log _{2}(n)\\rfloor +1}}",
        "target": "Substituting the equation for \n\n\n\nE\n(\nn\n)\n\n\n{\\displaystyle E(n)}\n\n into the equation for \n\n\n\n\nT\n\n\n(\nn\n)\n\n\n{\\displaystyle T'(n)}\n\n, the average case for unsuccessful searches can be determined:"
    },
    {
        "source": "E\n(\nn\n)\n=\nI\n(\nn\n)\n+\n2\nn\n=\n\n[\n\n(\nn\n+\n1\n)\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n\n\n2\n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n+\n1\n)\n\n\n\n+\n1\n\n\n+\n2\n\n]\n\n+\n2\nn\n=\n(\nn\n+\n1\n)\n(\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n2\n)\n\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n\n{\\displaystyle E(n)=I(n)+2n=\\left[(n+1)\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor -2^{\\left\\lfloor \\log _{2}(n+1)\\right\\rfloor +1}+2\\right]+2n=(n+1)(\\lfloor \\log _{2}(n)\\rfloor +2)-2^{\\lfloor \\log _{2}(n)\\rfloor +1}} Substituting the equation for \n\n\n\nE\n(\nn\n)\n\n\n{\\displaystyle E(n)}\n\n into the equation for \n\n\n\n\nT\n\n\n(\nn\n)\n\n\n{\\displaystyle T'(n)}\n\n, the average case for unsuccessful searches can be determined:",
        "target": "T\n\n\n(\nn\n)\n=\n\n\n\n(\nn\n+\n1\n)\n(\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n2\n)\n\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n\n(\nn\n+\n1\n)\n\n\n\n=\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n2\n\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n/\n\n(\nn\n+\n1\n)\n\n\n{\\displaystyle T'(n)={\\frac {(n+1)(\\lfloor \\log _{2}(n)\\rfloor +2)-2^{\\lfloor \\log _{2}(n)\\rfloor +1}}{(n+1)}}=\\lfloor \\log _{2}(n)\\rfloor +2-2^{\\lfloor \\log _{2}(n)\\rfloor +1}/(n+1)}"
    },
    {
        "source": "Substituting the equation for \n\n\n\nE\n(\nn\n)\n\n\n{\\displaystyle E(n)}\n\n into the equation for \n\n\n\n\nT\n\n\n(\nn\n)\n\n\n{\\displaystyle T'(n)}\n\n, the average case for unsuccessful searches can be determined: T\n\n\n(\nn\n)\n=\n\n\n\n(\nn\n+\n1\n)\n(\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n2\n)\n\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n\n(\nn\n+\n1\n)\n\n\n\n=\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n2\n\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n/\n\n(\nn\n+\n1\n)\n\n\n{\\displaystyle T'(n)={\\frac {(n+1)(\\lfloor \\log _{2}(n)\\rfloor +2)-2^{\\lfloor \\log _{2}(n)\\rfloor +1}}{(n+1)}}=\\lfloor \\log _{2}(n)\\rfloor +2-2^{\\lfloor \\log _{2}(n)\\rfloor +1}/(n+1)}",
        "target": "Each iteration of the binary search procedure defined above makes one or two comparisons, checking if the middle element is equal to the target in each iteration. Assuming that each element is equally likely to be searched, each iteration makes 1.5 comparisons on average. A variation of the algorithm checks whether the middle element is equal to the target at the end of the search. On average, this eliminates half a comparison from each iteration. This slightly cuts the time taken per iteration on most computers. However, it guarantees that the search takes the maximum number of iterations, on average adding one iteration to the search. Because the comparison loop is performed only \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}(n)+1\\rfloor }\n\n times in the worst case, the slight increase in efficiency per iteration does not compensate for the extra iteration for all but very large \n\n\n\nn\n\n\n{\\textstyle n}\n\n.[c]"
    },
    {
        "source": "T\n\n\n(\nn\n)\n=\n\n\n\n(\nn\n+\n1\n)\n(\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n2\n)\n\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n\n(\nn\n+\n1\n)\n\n\n\n=\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n2\n\n\n2\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n+\n1\n\n\n\n/\n\n(\nn\n+\n1\n)\n\n\n{\\displaystyle T'(n)={\\frac {(n+1)(\\lfloor \\log _{2}(n)\\rfloor +2)-2^{\\lfloor \\log _{2}(n)\\rfloor +1}}{(n+1)}}=\\lfloor \\log _{2}(n)\\rfloor +2-2^{\\lfloor \\log _{2}(n)\\rfloor +1}/(n+1)} Each iteration of the binary search procedure defined above makes one or two comparisons, checking if the middle element is equal to the target in each iteration. Assuming that each element is equally likely to be searched, each iteration makes 1.5 comparisons on average. A variation of the algorithm checks whether the middle element is equal to the target at the end of the search. On average, this eliminates half a comparison from each iteration. This slightly cuts the time taken per iteration on most computers. However, it guarantees that the search takes the maximum number of iterations, on average adding one iteration to the search. Because the comparison loop is performed only \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}(n)+1\\rfloor }\n\n times in the worst case, the slight increase in efficiency per iteration does not compensate for the extra iteration for all but very large \n\n\n\nn\n\n\n{\\textstyle n}\n\n.[c]",
        "target": "In analyzing the performance of binary search, another consideration is the time required to compare two elements. For integers and strings, the time required increases linearly as the encoding length (usually the number of bits) of the elements increase. For example, comparing a pair of 64-bit unsigned integers would require comparing up to double the bits as comparing a pair of 32-bit unsigned integers. The worst case is achieved when the integers are equal. This can be significant when the encoding lengths of the elements are large, such as with large integer types or long strings, which makes comparing elements expensive. Furthermore, comparing floating-point values (the most common digital representation of real numbers) is often more expensive than comparing integers or short strings."
    },
    {
        "source": "Each iteration of the binary search procedure defined above makes one or two comparisons, checking if the middle element is equal to the target in each iteration. Assuming that each element is equally likely to be searched, each iteration makes 1.5 comparisons on average. A variation of the algorithm checks whether the middle element is equal to the target at the end of the search. On average, this eliminates half a comparison from each iteration. This slightly cuts the time taken per iteration on most computers. However, it guarantees that the search takes the maximum number of iterations, on average adding one iteration to the search. Because the comparison loop is performed only \n\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}(n)+1\\rfloor }\n\n times in the worst case, the slight increase in efficiency per iteration does not compensate for the extra iteration for all but very large \n\n\n\nn\n\n\n{\\textstyle n}\n\n.[c] In analyzing the performance of binary search, another consideration is the time required to compare two elements. For integers and strings, the time required increases linearly as the encoding length (usually the number of bits) of the elements increase. For example, comparing a pair of 64-bit unsigned integers would require comparing up to double the bits as comparing a pair of 32-bit unsigned integers. The worst case is achieved when the integers are equal. This can be significant when the encoding lengths of the elements are large, such as with large integer types or long strings, which makes comparing elements expensive. Furthermore, comparing floating-point values (the most common digital representation of real numbers) is often more expensive than comparing integers or short strings.",
        "target": "On most computer architectures, the processor has a hardware cache separate from RAM. Since they are located within the processor itself, caches are much faster to access but usually store much less data than RAM. Therefore, most processors store memory locations that have been accessed recently, along with memory locations close to it. For example, when an array element is accessed, the element itself may be stored along with the elements that are stored close to it in RAM, making it faster to sequentially access array elements that are close in index to each other (locality of reference). On a sorted array, binary search can jump to distant memory locations if the array is large, unlike algorithms (such as linear search and linear probing in hash tables) which access elements in sequence. This adds slightly to the running time of binary search for large arrays on most systems."
    },
    {
        "source": "In analyzing the performance of binary search, another consideration is the time required to compare two elements. For integers and strings, the time required increases linearly as the encoding length (usually the number of bits) of the elements increase. For example, comparing a pair of 64-bit unsigned integers would require comparing up to double the bits as comparing a pair of 32-bit unsigned integers. The worst case is achieved when the integers are equal. This can be significant when the encoding lengths of the elements are large, such as with large integer types or long strings, which makes comparing elements expensive. Furthermore, comparing floating-point values (the most common digital representation of real numbers) is often more expensive than comparing integers or short strings. On most computer architectures, the processor has a hardware cache separate from RAM. Since they are located within the processor itself, caches are much faster to access but usually store much less data than RAM. Therefore, most processors store memory locations that have been accessed recently, along with memory locations close to it. For example, when an array element is accessed, the element itself may be stored along with the elements that are stored close to it in RAM, making it faster to sequentially access array elements that are close in index to each other (locality of reference). On a sorted array, binary search can jump to distant memory locations if the array is large, unlike algorithms (such as linear search and linear probing in hash tables) which access elements in sequence. This adds slightly to the running time of binary search for large arrays on most systems.",
        "target": "Sorted arrays with binary search are a very inefficient solution when insertion and deletion operations are interleaved with retrieval, taking \n\n\n\nO\n(\nn\n)\n\n\n{\\textstyle O(n)}\n\n time for each such operation. In addition, sorted arrays can complicate memory use especially when elements are often inserted into the array. There are other data structures that support much more efficient insertion and deletion. Binary search can be used to perform exact matching and set membership (determining whether a target value is in a collection of values). There are data structures that support faster exact matching and set membership. However, unlike many other searching schemes, binary search can be used for efficient approximate matching, usually performing such matches in \n\n\n\nO\n(\nlog\n\nn\n)\n\n\n{\\textstyle O(\\log n)}\n\n time regardless of the type or structure of the values themselves. In addition, there are some operations, like finding the smallest and largest element, that can be performed efficiently on a sorted array."
    },
    {
        "source": "On most computer architectures, the processor has a hardware cache separate from RAM. Since they are located within the processor itself, caches are much faster to access but usually store much less data than RAM. Therefore, most processors store memory locations that have been accessed recently, along with memory locations close to it. For example, when an array element is accessed, the element itself may be stored along with the elements that are stored close to it in RAM, making it faster to sequentially access array elements that are close in index to each other (locality of reference). On a sorted array, binary search can jump to distant memory locations if the array is large, unlike algorithms (such as linear search and linear probing in hash tables) which access elements in sequence. This adds slightly to the running time of binary search for large arrays on most systems. Sorted arrays with binary search are a very inefficient solution when insertion and deletion operations are interleaved with retrieval, taking \n\n\n\nO\n(\nn\n)\n\n\n{\\textstyle O(n)}\n\n time for each such operation. In addition, sorted arrays can complicate memory use especially when elements are often inserted into the array. There are other data structures that support much more efficient insertion and deletion. Binary search can be used to perform exact matching and set membership (determining whether a target value is in a collection of values). There are data structures that support faster exact matching and set membership. However, unlike many other searching schemes, binary search can be used for efficient approximate matching, usually performing such matches in \n\n\n\nO\n(\nlog\n\nn\n)\n\n\n{\\textstyle O(\\log n)}\n\n time regardless of the type or structure of the values themselves. In addition, there are some operations, like finding the smallest and largest element, that can be performed efficiently on a sorted array.",
        "target": "Linear search is a simple search algorithm that checks every record until it finds the target value. Linear search can be done on a linked list, which allows for faster insertion and deletion than an array. Binary search is faster than linear search for sorted arrays except if the array is short, although the array needs to be sorted beforehand.[d] All sorting algorithms based on comparing elements, such as quicksort and merge sort, require at least \n\n\n\nO\n(\nn\nlog\n\nn\n)\n\n\n{\\textstyle O(n\\log n)}\n\n comparisons in the worst case. Unlike linear search, binary search can be used for efficient approximate matching. There are operations such as finding the smallest and largest element that can be done efficiently on a sorted array but not on an unsorted array."
    },
    {
        "source": "Sorted arrays with binary search are a very inefficient solution when insertion and deletion operations are interleaved with retrieval, taking \n\n\n\nO\n(\nn\n)\n\n\n{\\textstyle O(n)}\n\n time for each such operation. In addition, sorted arrays can complicate memory use especially when elements are often inserted into the array. There are other data structures that support much more efficient insertion and deletion. Binary search can be used to perform exact matching and set membership (determining whether a target value is in a collection of values). There are data structures that support faster exact matching and set membership. However, unlike many other searching schemes, binary search can be used for efficient approximate matching, usually performing such matches in \n\n\n\nO\n(\nlog\n\nn\n)\n\n\n{\\textstyle O(\\log n)}\n\n time regardless of the type or structure of the values themselves. In addition, there are some operations, like finding the smallest and largest element, that can be performed efficiently on a sorted array. Linear search is a simple search algorithm that checks every record until it finds the target value. Linear search can be done on a linked list, which allows for faster insertion and deletion than an array. Binary search is faster than linear search for sorted arrays except if the array is short, although the array needs to be sorted beforehand.[d] All sorting algorithms based on comparing elements, such as quicksort and merge sort, require at least \n\n\n\nO\n(\nn\nlog\n\nn\n)\n\n\n{\\textstyle O(n\\log n)}\n\n comparisons in the worst case. Unlike linear search, binary search can be used for efficient approximate matching. There are operations such as finding the smallest and largest element that can be done efficiently on a sorted array but not on an unsorted array.",
        "target": "A binary search tree is a binary tree data structure that works based on the principle of binary search. The records of the tree are arranged in sorted order, and each record in the tree can be searched using an algorithm similar to binary search, taking on average logarithmic time. Insertion and deletion also require on average logarithmic time in binary search trees. This can be faster than the linear time insertion and deletion of sorted arrays, and binary trees retain the ability to perform all the operations possible on a sorted array, including range and approximate queries."
    },
    {
        "source": "Linear search is a simple search algorithm that checks every record until it finds the target value. Linear search can be done on a linked list, which allows for faster insertion and deletion than an array. Binary search is faster than linear search for sorted arrays except if the array is short, although the array needs to be sorted beforehand.[d] All sorting algorithms based on comparing elements, such as quicksort and merge sort, require at least \n\n\n\nO\n(\nn\nlog\n\nn\n)\n\n\n{\\textstyle O(n\\log n)}\n\n comparisons in the worst case. Unlike linear search, binary search can be used for efficient approximate matching. There are operations such as finding the smallest and largest element that can be done efficiently on a sorted array but not on an unsorted array. A binary search tree is a binary tree data structure that works based on the principle of binary search. The records of the tree are arranged in sorted order, and each record in the tree can be searched using an algorithm similar to binary search, taking on average logarithmic time. Insertion and deletion also require on average logarithmic time in binary search trees. This can be faster than the linear time insertion and deletion of sorted arrays, and binary trees retain the ability to perform all the operations possible on a sorted array, including range and approximate queries.",
        "target": "However, binary search is usually more efficient for searching as binary search trees will most likely be imperfectly balanced, resulting in slightly worse performance than binary search. This even applies to balanced binary search trees, binary search trees that balance their own nodes, because they rarely produce the tree with the fewest possible levels. Except for balanced binary search trees, the tree may be severely imbalanced with few internal nodes with two children, resulting in the average and worst-case search time approaching \n\n\n\nn\n\n\n{\\textstyle n}\n\n comparisons.[e] Binary search trees take more space than sorted arrays."
    },
    {
        "source": "A binary search tree is a binary tree data structure that works based on the principle of binary search. The records of the tree are arranged in sorted order, and each record in the tree can be searched using an algorithm similar to binary search, taking on average logarithmic time. Insertion and deletion also require on average logarithmic time in binary search trees. This can be faster than the linear time insertion and deletion of sorted arrays, and binary trees retain the ability to perform all the operations possible on a sorted array, including range and approximate queries. However, binary search is usually more efficient for searching as binary search trees will most likely be imperfectly balanced, resulting in slightly worse performance than binary search. This even applies to balanced binary search trees, binary search trees that balance their own nodes, because they rarely produce the tree with the fewest possible levels. Except for balanced binary search trees, the tree may be severely imbalanced with few internal nodes with two children, resulting in the average and worst-case search time approaching \n\n\n\nn\n\n\n{\\textstyle n}\n\n comparisons.[e] Binary search trees take more space than sorted arrays.",
        "target": "Binary search trees lend themselves to fast searching in external memory stored in hard disks, as binary search trees can be efficiently structured in filesystems. The B-tree generalizes this method of tree organization. B-trees are frequently used to organize long-term storage such as databases and filesystems."
    },
    {
        "source": "However, binary search is usually more efficient for searching as binary search trees will most likely be imperfectly balanced, resulting in slightly worse performance than binary search. This even applies to balanced binary search trees, binary search trees that balance their own nodes, because they rarely produce the tree with the fewest possible levels. Except for balanced binary search trees, the tree may be severely imbalanced with few internal nodes with two children, resulting in the average and worst-case search time approaching \n\n\n\nn\n\n\n{\\textstyle n}\n\n comparisons.[e] Binary search trees take more space than sorted arrays. Binary search trees lend themselves to fast searching in external memory stored in hard disks, as binary search trees can be efficiently structured in filesystems. The B-tree generalizes this method of tree organization. B-trees are frequently used to organize long-term storage such as databases and filesystems.",
        "target": "For implementing associative arrays, hash tables, a data structure that maps keys to records using a hash function, are generally faster than binary search on a sorted array of records. Most hash table implementations require only amortized constant time on average.[f] However, hashing is not useful for approximate matches, such as computing the next-smallest, next-largest, and nearest key, as the only information given on a failed search is that the target is not present in any record. Binary search is ideal for such matches, performing them in logarithmic time. Binary search also supports approximate matches. Some operations, like finding the smallest and largest element, can be done efficiently on sorted arrays but not on hash tables."
    },
    {
        "source": "Binary search trees lend themselves to fast searching in external memory stored in hard disks, as binary search trees can be efficiently structured in filesystems. The B-tree generalizes this method of tree organization. B-trees are frequently used to organize long-term storage such as databases and filesystems. For implementing associative arrays, hash tables, a data structure that maps keys to records using a hash function, are generally faster than binary search on a sorted array of records. Most hash table implementations require only amortized constant time on average.[f] However, hashing is not useful for approximate matches, such as computing the next-smallest, next-largest, and nearest key, as the only information given on a failed search is that the target is not present in any record. Binary search is ideal for such matches, performing them in logarithmic time. Binary search also supports approximate matches. Some operations, like finding the smallest and largest element, can be done efficiently on sorted arrays but not on hash tables.",
        "target": "A related problem to search is set membership. Any algorithm that does lookup, like binary search, can also be used for set membership. There are other algorithms that are more specifically suited for set membership. A bit array is the simplest, useful when the range of keys is limited. It compactly stores a collection of bits, with each bit representing a single key within the range of keys. Bit arrays are very fast, requiring only \n\n\n\nO\n(\n1\n)\n\n\n{\\textstyle O(1)}\n\n time.  The Judy1 type of Judy array handles 64-bit keys efficiently."
    },
    {
        "source": "For implementing associative arrays, hash tables, a data structure that maps keys to records using a hash function, are generally faster than binary search on a sorted array of records. Most hash table implementations require only amortized constant time on average.[f] However, hashing is not useful for approximate matches, such as computing the next-smallest, next-largest, and nearest key, as the only information given on a failed search is that the target is not present in any record. Binary search is ideal for such matches, performing them in logarithmic time. Binary search also supports approximate matches. Some operations, like finding the smallest and largest element, can be done efficiently on sorted arrays but not on hash tables. A related problem to search is set membership. Any algorithm that does lookup, like binary search, can also be used for set membership. There are other algorithms that are more specifically suited for set membership. A bit array is the simplest, useful when the range of keys is limited. It compactly stores a collection of bits, with each bit representing a single key within the range of keys. Bit arrays are very fast, requiring only \n\n\n\nO\n(\n1\n)\n\n\n{\\textstyle O(1)}\n\n time.  The Judy1 type of Judy array handles 64-bit keys efficiently.",
        "target": "For approximate results, Bloom filters, another probabilistic data structure based on hashing, store a set of keys by encoding the keys using a bit array and multiple hash functions. Bloom filters are much more space-efficient than bit arrays in most cases and not much slower: with \n\n\n\nk\n\n\n{\\textstyle k}\n\n hash functions, membership queries require only \n\n\n\nO\n(\nk\n)\n\n\n{\\textstyle O(k)}\n\n time. However, Bloom filters suffer from false positives.[g][h]"
    },
    {
        "source": "A related problem to search is set membership. Any algorithm that does lookup, like binary search, can also be used for set membership. There are other algorithms that are more specifically suited for set membership. A bit array is the simplest, useful when the range of keys is limited. It compactly stores a collection of bits, with each bit representing a single key within the range of keys. Bit arrays are very fast, requiring only \n\n\n\nO\n(\n1\n)\n\n\n{\\textstyle O(1)}\n\n time.  The Judy1 type of Judy array handles 64-bit keys efficiently. For approximate results, Bloom filters, another probabilistic data structure based on hashing, store a set of keys by encoding the keys using a bit array and multiple hash functions. Bloom filters are much more space-efficient than bit arrays in most cases and not much slower: with \n\n\n\nk\n\n\n{\\textstyle k}\n\n hash functions, membership queries require only \n\n\n\nO\n(\nk\n)\n\n\n{\\textstyle O(k)}\n\n time. However, Bloom filters suffer from false positives.[g][h]",
        "target": "There exist data structures that may improve on binary search in some cases for both searching and other operations available for sorted arrays. For example, searches, approximate matches, and the operations available to sorted arrays can be performed more efficiently than binary search on specialized data structures such as van Emde Boas trees, fusion trees, tries, and bit arrays. These specialized data structures are usually only faster because they take advantage of the properties of keys with a certain attribute (usually keys that are small integers), and thus will be time or space consuming for keys that lack that attribute. As long as the keys can be ordered, these operations can always be done at least efficiently on a sorted array regardless of the keys. Some structures, such as Judy arrays, use a combination of approaches to mitigate this while retaining efficiency and the ability to perform approximate matching."
    },
    {
        "source": "For approximate results, Bloom filters, another probabilistic data structure based on hashing, store a set of keys by encoding the keys using a bit array and multiple hash functions. Bloom filters are much more space-efficient than bit arrays in most cases and not much slower: with \n\n\n\nk\n\n\n{\\textstyle k}\n\n hash functions, membership queries require only \n\n\n\nO\n(\nk\n)\n\n\n{\\textstyle O(k)}\n\n time. However, Bloom filters suffer from false positives.[g][h] There exist data structures that may improve on binary search in some cases for both searching and other operations available for sorted arrays. For example, searches, approximate matches, and the operations available to sorted arrays can be performed more efficiently than binary search on specialized data structures such as van Emde Boas trees, fusion trees, tries, and bit arrays. These specialized data structures are usually only faster because they take advantage of the properties of keys with a certain attribute (usually keys that are small integers), and thus will be time or space consuming for keys that lack that attribute. As long as the keys can be ordered, these operations can always be done at least efficiently on a sorted array regardless of the keys. Some structures, such as Judy arrays, use a combination of approaches to mitigate this while retaining efficiency and the ability to perform approximate matching.",
        "target": "Uniform binary search stores, instead of the lower and upper bounds, the difference in the index of the middle element from the current iteration to the next iteration. A lookup table containing the differences is computed beforehand. For example, if the array to be searched is [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], the middle element (\n\n\n\nm\n\n\n{\\displaystyle m}\n\n) would be 6. In this case, the middle element of the left subarray ([1, 2, 3, 4, 5]) is 3 and the middle element of the right subarray ([7, 8, 9, 10, 11]) is 9. Uniform binary search would store the value of 3 as both indices differ from 6 by this same amount. To reduce the search space, the algorithm either adds or subtracts this change from the index of the middle element. Uniform binary search may be faster on systems where it is inefficient to calculate the midpoint, such as on decimal computers."
    },
    {
        "source": "There exist data structures that may improve on binary search in some cases for both searching and other operations available for sorted arrays. For example, searches, approximate matches, and the operations available to sorted arrays can be performed more efficiently than binary search on specialized data structures such as van Emde Boas trees, fusion trees, tries, and bit arrays. These specialized data structures are usually only faster because they take advantage of the properties of keys with a certain attribute (usually keys that are small integers), and thus will be time or space consuming for keys that lack that attribute. As long as the keys can be ordered, these operations can always be done at least efficiently on a sorted array regardless of the keys. Some structures, such as Judy arrays, use a combination of approaches to mitigate this while retaining efficiency and the ability to perform approximate matching. Uniform binary search stores, instead of the lower and upper bounds, the difference in the index of the middle element from the current iteration to the next iteration. A lookup table containing the differences is computed beforehand. For example, if the array to be searched is [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], the middle element (\n\n\n\nm\n\n\n{\\displaystyle m}\n\n) would be 6. In this case, the middle element of the left subarray ([1, 2, 3, 4, 5]) is 3 and the middle element of the right subarray ([7, 8, 9, 10, 11]) is 9. Uniform binary search would store the value of 3 as both indices differ from 6 by this same amount. To reduce the search space, the algorithm either adds or subtracts this change from the index of the middle element. Uniform binary search may be faster on systems where it is inefficient to calculate the midpoint, such as on decimal computers.",
        "target": "Exponential search extends binary search to unbounded lists. It starts by finding the first element with an index that is both a power of two and greater than the target value. Afterwards, it sets that index as the upper bound, and switches to binary search. A search takes \n\n\n\n\n\nlog\n\n2\n\n\n\nx\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}x+1\\rfloor }\n\n iterations before binary search is started and at most \n\n\n\n\n\nlog\n\n2\n\n\n\nx\n\n\n\n{\\textstyle \\lfloor \\log _{2}x\\rfloor }\n\n iterations of the binary search, where \n\n\n\nx\n\n\n{\\textstyle x}\n\n is the position of the target value. Exponential search works on bounded lists, but becomes an improvement over binary search only if the target value lies near the beginning of the array."
    },
    {
        "source": "Uniform binary search stores, instead of the lower and upper bounds, the difference in the index of the middle element from the current iteration to the next iteration. A lookup table containing the differences is computed beforehand. For example, if the array to be searched is [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], the middle element (\n\n\n\nm\n\n\n{\\displaystyle m}\n\n) would be 6. In this case, the middle element of the left subarray ([1, 2, 3, 4, 5]) is 3 and the middle element of the right subarray ([7, 8, 9, 10, 11]) is 9. Uniform binary search would store the value of 3 as both indices differ from 6 by this same amount. To reduce the search space, the algorithm either adds or subtracts this change from the index of the middle element. Uniform binary search may be faster on systems where it is inefficient to calculate the midpoint, such as on decimal computers. Exponential search extends binary search to unbounded lists. It starts by finding the first element with an index that is both a power of two and greater than the target value. Afterwards, it sets that index as the upper bound, and switches to binary search. A search takes \n\n\n\n\n\nlog\n\n2\n\n\n\nx\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}x+1\\rfloor }\n\n iterations before binary search is started and at most \n\n\n\n\n\nlog\n\n2\n\n\n\nx\n\n\n\n{\\textstyle \\lfloor \\log _{2}x\\rfloor }\n\n iterations of the binary search, where \n\n\n\nx\n\n\n{\\textstyle x}\n\n is the position of the target value. Exponential search works on bounded lists, but becomes an improvement over binary search only if the target value lies near the beginning of the array.",
        "target": "Instead of calculating the midpoint, interpolation search estimates the position of the target value, taking into account the lowest and highest elements in the array as well as length of the array. It works on the basis that the midpoint is not the best guess in many cases. For example, if the target value is close to the highest element in the array, it is likely to be located near the end of the array."
    },
    {
        "source": "Exponential search extends binary search to unbounded lists. It starts by finding the first element with an index that is both a power of two and greater than the target value. Afterwards, it sets that index as the upper bound, and switches to binary search. A search takes \n\n\n\n\n\nlog\n\n2\n\n\n\nx\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}x+1\\rfloor }\n\n iterations before binary search is started and at most \n\n\n\n\n\nlog\n\n2\n\n\n\nx\n\n\n\n{\\textstyle \\lfloor \\log _{2}x\\rfloor }\n\n iterations of the binary search, where \n\n\n\nx\n\n\n{\\textstyle x}\n\n is the position of the target value. Exponential search works on bounded lists, but becomes an improvement over binary search only if the target value lies near the beginning of the array. Instead of calculating the midpoint, interpolation search estimates the position of the target value, taking into account the lowest and highest elements in the array as well as length of the array. It works on the basis that the midpoint is not the best guess in many cases. For example, if the target value is close to the highest element in the array, it is likely to be located near the end of the array.",
        "target": "A common interpolation function is linear interpolation. If \n\n\n\nA\n\n\n{\\displaystyle A}\n\n is the array, \n\n\n\nL\n,\nR\n\n\n{\\displaystyle L,R}\n\n are the lower and upper bounds respectively, and \n\n\n\nT\n\n\n{\\displaystyle T}\n\n is the target, then the target is estimated to be about \n\n\n\n(\nT\n\n\nA\n\nL\n\n\n)\n\n/\n\n(\n\nA\n\nR\n\n\n\n\nA\n\nL\n\n\n)\n\n\n{\\displaystyle (T-A_{L})/(A_{R}-A_{L})}\n\n of the way between \n\n\n\nL\n\n\n{\\displaystyle L}\n\n and \n\n\n\nR\n\n\n{\\displaystyle R}\n\n. When linear interpolation is used, and the distribution of the array elements is uniform or near uniform, interpolation search makes \n\n\n\nO\n(\nlog\n\nlog\n\nn\n)\n\n\n{\\textstyle O(\\log \\log n)}\n\n comparisons."
    },
    {
        "source": "Instead of calculating the midpoint, interpolation search estimates the position of the target value, taking into account the lowest and highest elements in the array as well as length of the array. It works on the basis that the midpoint is not the best guess in many cases. For example, if the target value is close to the highest element in the array, it is likely to be located near the end of the array. A common interpolation function is linear interpolation. If \n\n\n\nA\n\n\n{\\displaystyle A}\n\n is the array, \n\n\n\nL\n,\nR\n\n\n{\\displaystyle L,R}\n\n are the lower and upper bounds respectively, and \n\n\n\nT\n\n\n{\\displaystyle T}\n\n is the target, then the target is estimated to be about \n\n\n\n(\nT\n\n\nA\n\nL\n\n\n)\n\n/\n\n(\n\nA\n\nR\n\n\n\n\nA\n\nL\n\n\n)\n\n\n{\\displaystyle (T-A_{L})/(A_{R}-A_{L})}\n\n of the way between \n\n\n\nL\n\n\n{\\displaystyle L}\n\n and \n\n\n\nR\n\n\n{\\displaystyle R}\n\n. When linear interpolation is used, and the distribution of the array elements is uniform or near uniform, interpolation search makes \n\n\n\nO\n(\nlog\n\nlog\n\nn\n)\n\n\n{\\textstyle O(\\log \\log n)}\n\n comparisons.",
        "target": "In practice, interpolation search is slower than binary search for small arrays, as interpolation search requires extra computation. Its time complexity grows more slowly than binary search, but this only compensates for the extra computation for large arrays."
    },
    {
        "source": "A common interpolation function is linear interpolation. If \n\n\n\nA\n\n\n{\\displaystyle A}\n\n is the array, \n\n\n\nL\n,\nR\n\n\n{\\displaystyle L,R}\n\n are the lower and upper bounds respectively, and \n\n\n\nT\n\n\n{\\displaystyle T}\n\n is the target, then the target is estimated to be about \n\n\n\n(\nT\n\n\nA\n\nL\n\n\n)\n\n/\n\n(\n\nA\n\nR\n\n\n\n\nA\n\nL\n\n\n)\n\n\n{\\displaystyle (T-A_{L})/(A_{R}-A_{L})}\n\n of the way between \n\n\n\nL\n\n\n{\\displaystyle L}\n\n and \n\n\n\nR\n\n\n{\\displaystyle R}\n\n. When linear interpolation is used, and the distribution of the array elements is uniform or near uniform, interpolation search makes \n\n\n\nO\n(\nlog\n\nlog\n\nn\n)\n\n\n{\\textstyle O(\\log \\log n)}\n\n comparisons. In practice, interpolation search is slower than binary search for small arrays, as interpolation search requires extra computation. Its time complexity grows more slowly than binary search, but this only compensates for the extra computation for large arrays.",
        "target": "Fractional cascading is a technique that speeds up binary searches for the same element in multiple sorted arrays. Searching each array separately requires \n\n\n\nO\n(\nk\nlog\n\nn\n)\n\n\n{\\textstyle O(k\\log n)}\n\n time, where \n\n\n\nk\n\n\n{\\textstyle k}\n\n is the number of arrays. Fractional cascading reduces this to \n\n\n\nO\n(\nk\n+\nlog\n\nn\n)\n\n\n{\\textstyle O(k+\\log n)}\n\n by storing specific information in each array about each element and its position in the other arrays."
    },
    {
        "source": "In practice, interpolation search is slower than binary search for small arrays, as interpolation search requires extra computation. Its time complexity grows more slowly than binary search, but this only compensates for the extra computation for large arrays. Fractional cascading is a technique that speeds up binary searches for the same element in multiple sorted arrays. Searching each array separately requires \n\n\n\nO\n(\nk\nlog\n\nn\n)\n\n\n{\\textstyle O(k\\log n)}\n\n time, where \n\n\n\nk\n\n\n{\\textstyle k}\n\n is the number of arrays. Fractional cascading reduces this to \n\n\n\nO\n(\nk\n+\nlog\n\nn\n)\n\n\n{\\textstyle O(k+\\log n)}\n\n by storing specific information in each array about each element and its position in the other arrays.",
        "target": "Fractional cascading was originally developed to efficiently solve various computational geometry problems. Fractional cascading has been applied elsewhere, such as in data mining and Internet Protocol routing."
    },
    {
        "source": "Fractional cascading is a technique that speeds up binary searches for the same element in multiple sorted arrays. Searching each array separately requires \n\n\n\nO\n(\nk\nlog\n\nn\n)\n\n\n{\\textstyle O(k\\log n)}\n\n time, where \n\n\n\nk\n\n\n{\\textstyle k}\n\n is the number of arrays. Fractional cascading reduces this to \n\n\n\nO\n(\nk\n+\nlog\n\nn\n)\n\n\n{\\textstyle O(k+\\log n)}\n\n by storing specific information in each array about each element and its position in the other arrays. Fractional cascading was originally developed to efficiently solve various computational geometry problems. Fractional cascading has been applied elsewhere, such as in data mining and Internet Protocol routing.",
        "target": "Binary search has been generalized to work on certain types of graphs, where the target value is stored in a vertex instead of an array element. Binary search trees are one such generalizationwhen a vertex (node) in the tree is queried, the algorithm either learns that the vertex is the target, or otherwise which subtree the target would be located in. However, this can be further generalized as follows: given an undirected, positively weighted graph and a target vertex, the algorithm learns upon querying a vertex that it is equal to the target, or it is given an incident edge that is on the shortest path from the queried vertex to the target. The standard binary search algorithm is simply the case where the graph is a path. Similarly, binary search trees are the case where the edges to the left or right subtrees are given when the queried vertex is unequal to the target. For all undirected, positively weighted graphs, there is an algorithm that finds the target vertex in \n\n\n\nO\n(\nlog\n\nn\n)\n\n\n{\\displaystyle O(\\log n)}\n\n queries in the worst case."
    },
    {
        "source": "Fractional cascading was originally developed to efficiently solve various computational geometry problems. Fractional cascading has been applied elsewhere, such as in data mining and Internet Protocol routing. Binary search has been generalized to work on certain types of graphs, where the target value is stored in a vertex instead of an array element. Binary search trees are one such generalizationwhen a vertex (node) in the tree is queried, the algorithm either learns that the vertex is the target, or otherwise which subtree the target would be located in. However, this can be further generalized as follows: given an undirected, positively weighted graph and a target vertex, the algorithm learns upon querying a vertex that it is equal to the target, or it is given an incident edge that is on the shortest path from the queried vertex to the target. The standard binary search algorithm is simply the case where the graph is a path. Similarly, binary search trees are the case where the edges to the left or right subtrees are given when the queried vertex is unequal to the target. For all undirected, positively weighted graphs, there is an algorithm that finds the target vertex in \n\n\n\nO\n(\nlog\n\nn\n)\n\n\n{\\displaystyle O(\\log n)}\n\n queries in the worst case.",
        "target": "Noisy binary search algorithms solve the case where the algorithm cannot reliably compare elements of the array. For each pair of elements, there is a certain probability that the algorithm makes the wrong comparison. Noisy binary search can find the correct position of the target with a given probability that controls the reliability of the yielded position. Every noisy binary search procedure must make at least \n\n\n\n(\n1\n\n\n)\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n\nH\n(\np\n)\n\n\n\n\n\n\n10\n\nH\n(\np\n)\n\n\n\n\n\n{\\displaystyle (1-\\tau ){\\frac {\\log _{2}(n)}{H(p)}}-{\\frac {10}{H(p)}}}\n\n comparisons on average, where \n\n\n\nH\n(\np\n)\n=\n\np\n\nlog\n\n2\n\n\n\n(\np\n)\n\n(\n1\n\np\n)\n\nlog\n\n2\n\n\n\n(\n1\n\np\n)\n\n\n{\\displaystyle H(p)=-p\\log _{2}(p)-(1-p)\\log _{2}(1-p)}\n\n is the binary entropy function and \n\n\n\n\n\n\n{\\displaystyle \\tau }\n\n is the probability that the procedure yields the wrong position. The noisy binary search problem can be considered as a case of the Renyi-Ulam game, a variant of Twenty Questions where the answers may be wrong."
    },
    {
        "source": "Binary search has been generalized to work on certain types of graphs, where the target value is stored in a vertex instead of an array element. Binary search trees are one such generalizationwhen a vertex (node) in the tree is queried, the algorithm either learns that the vertex is the target, or otherwise which subtree the target would be located in. However, this can be further generalized as follows: given an undirected, positively weighted graph and a target vertex, the algorithm learns upon querying a vertex that it is equal to the target, or it is given an incident edge that is on the shortest path from the queried vertex to the target. The standard binary search algorithm is simply the case where the graph is a path. Similarly, binary search trees are the case where the edges to the left or right subtrees are given when the queried vertex is unequal to the target. For all undirected, positively weighted graphs, there is an algorithm that finds the target vertex in \n\n\n\nO\n(\nlog\n\nn\n)\n\n\n{\\displaystyle O(\\log n)}\n\n queries in the worst case. Noisy binary search algorithms solve the case where the algorithm cannot reliably compare elements of the array. For each pair of elements, there is a certain probability that the algorithm makes the wrong comparison. Noisy binary search can find the correct position of the target with a given probability that controls the reliability of the yielded position. Every noisy binary search procedure must make at least \n\n\n\n(\n1\n\n\n)\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n\nH\n(\np\n)\n\n\n\n\n\n\n10\n\nH\n(\np\n)\n\n\n\n\n\n{\\displaystyle (1-\\tau ){\\frac {\\log _{2}(n)}{H(p)}}-{\\frac {10}{H(p)}}}\n\n comparisons on average, where \n\n\n\nH\n(\np\n)\n=\n\np\n\nlog\n\n2\n\n\n\n(\np\n)\n\n(\n1\n\np\n)\n\nlog\n\n2\n\n\n\n(\n1\n\np\n)\n\n\n{\\displaystyle H(p)=-p\\log _{2}(p)-(1-p)\\log _{2}(1-p)}\n\n is the binary entropy function and \n\n\n\n\n\n\n{\\displaystyle \\tau }\n\n is the probability that the procedure yields the wrong position. The noisy binary search problem can be considered as a case of the Renyi-Ulam game, a variant of Twenty Questions where the answers may be wrong.",
        "target": "Classical computers are bounded to the worst case of exactly \n\n\n\n\n\nlog\n\n2\n\n\n\nn\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}n+1\\rfloor }\n\n iterations when performing binary search. Quantum algorithms for binary search are still bounded to a proportion of \n\n\n\n\nlog\n\n2\n\n\n\nn\n\n\n{\\textstyle \\log _{2}n}\n\n queries (representing iterations of the classical procedure), but the constant factor is less than one, providing for a lower time complexity on quantum computers. Any exact quantum binary search procedurethat is, a procedure that always yields the correct resultrequires at least \n\n\n\n\n\n1\n\n\n\n(\nln\n\nn\n\n1\n)\n\n0.22\n\nlog\n\n2\n\n\n\nn\n\n\n{\\textstyle {\\frac {1}{\\pi }}(\\ln n-1)\\approx 0.22\\log _{2}n}\n\n queries in the worst case, where \n\n\n\nln\n\n\n{\\textstyle \\ln }\n\n is the natural logarithm. There is an exact quantum binary search procedure that runs in \n\n\n\n4\n\nlog\n\n605\n\n\n\nn\n\n0.433\n\nlog\n\n2\n\n\n\nn\n\n\n{\\textstyle 4\\log _{605}n\\approx 0.433\\log _{2}n}\n\n queries in the worst case. In comparison, Grover's algorithm is the optimal quantum algorithm for searching an unordered list of elements, and it requires \n\n\n\nO\n(\n\n\nn\n\n\n)\n\n\n{\\displaystyle O({\\sqrt {n}})}\n\n queries."
    },
    {
        "source": "Noisy binary search algorithms solve the case where the algorithm cannot reliably compare elements of the array. For each pair of elements, there is a certain probability that the algorithm makes the wrong comparison. Noisy binary search can find the correct position of the target with a given probability that controls the reliability of the yielded position. Every noisy binary search procedure must make at least \n\n\n\n(\n1\n\n\n)\n\n\n\n\nlog\n\n2\n\n\n\n(\nn\n)\n\n\nH\n(\np\n)\n\n\n\n\n\n\n10\n\nH\n(\np\n)\n\n\n\n\n\n{\\displaystyle (1-\\tau ){\\frac {\\log _{2}(n)}{H(p)}}-{\\frac {10}{H(p)}}}\n\n comparisons on average, where \n\n\n\nH\n(\np\n)\n=\n\np\n\nlog\n\n2\n\n\n\n(\np\n)\n\n(\n1\n\np\n)\n\nlog\n\n2\n\n\n\n(\n1\n\np\n)\n\n\n{\\displaystyle H(p)=-p\\log _{2}(p)-(1-p)\\log _{2}(1-p)}\n\n is the binary entropy function and \n\n\n\n\n\n\n{\\displaystyle \\tau }\n\n is the probability that the procedure yields the wrong position. The noisy binary search problem can be considered as a case of the Renyi-Ulam game, a variant of Twenty Questions where the answers may be wrong. Classical computers are bounded to the worst case of exactly \n\n\n\n\n\nlog\n\n2\n\n\n\nn\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}n+1\\rfloor }\n\n iterations when performing binary search. Quantum algorithms for binary search are still bounded to a proportion of \n\n\n\n\nlog\n\n2\n\n\n\nn\n\n\n{\\textstyle \\log _{2}n}\n\n queries (representing iterations of the classical procedure), but the constant factor is less than one, providing for a lower time complexity on quantum computers. Any exact quantum binary search procedurethat is, a procedure that always yields the correct resultrequires at least \n\n\n\n\n\n1\n\n\n\n(\nln\n\nn\n\n1\n)\n\n0.22\n\nlog\n\n2\n\n\n\nn\n\n\n{\\textstyle {\\frac {1}{\\pi }}(\\ln n-1)\\approx 0.22\\log _{2}n}\n\n queries in the worst case, where \n\n\n\nln\n\n\n{\\textstyle \\ln }\n\n is the natural logarithm. There is an exact quantum binary search procedure that runs in \n\n\n\n4\n\nlog\n\n605\n\n\n\nn\n\n0.433\n\nlog\n\n2\n\n\n\nn\n\n\n{\\textstyle 4\\log _{605}n\\approx 0.433\\log _{2}n}\n\n queries in the worst case. In comparison, Grover's algorithm is the optimal quantum algorithm for searching an unordered list of elements, and it requires \n\n\n\nO\n(\n\n\nn\n\n\n)\n\n\n{\\displaystyle O({\\sqrt {n}})}\n\n queries.",
        "target": "The idea of sorting a list of items to allow for faster searching dates back to antiquity. The earliest known example was the Inakibit-Anu tablet from Babylon dating back to c.200 BCE. The tablet contained about 500 sexagesimal numbers and their reciprocals sorted in lexicographical order, which made searching for a specific entry easier. In addition, several lists of names that were sorted by their first letter were discovered on the Aegean Islands. Catholicon, a Latin dictionary finished in 1286 CE, was the first work to describe rules for sorting words into alphabetical order, as opposed to just the first few letters."
    },
    {
        "source": "Classical computers are bounded to the worst case of exactly \n\n\n\n\n\nlog\n\n2\n\n\n\nn\n+\n1\n\n\n\n{\\textstyle \\lfloor \\log _{2}n+1\\rfloor }\n\n iterations when performing binary search. Quantum algorithms for binary search are still bounded to a proportion of \n\n\n\n\nlog\n\n2\n\n\n\nn\n\n\n{\\textstyle \\log _{2}n}\n\n queries (representing iterations of the classical procedure), but the constant factor is less than one, providing for a lower time complexity on quantum computers. Any exact quantum binary search procedurethat is, a procedure that always yields the correct resultrequires at least \n\n\n\n\n\n1\n\n\n\n(\nln\n\nn\n\n1\n)\n\n0.22\n\nlog\n\n2\n\n\n\nn\n\n\n{\\textstyle {\\frac {1}{\\pi }}(\\ln n-1)\\approx 0.22\\log _{2}n}\n\n queries in the worst case, where \n\n\n\nln\n\n\n{\\textstyle \\ln }\n\n is the natural logarithm. There is an exact quantum binary search procedure that runs in \n\n\n\n4\n\nlog\n\n605\n\n\n\nn\n\n0.433\n\nlog\n\n2\n\n\n\nn\n\n\n{\\textstyle 4\\log _{605}n\\approx 0.433\\log _{2}n}\n\n queries in the worst case. In comparison, Grover's algorithm is the optimal quantum algorithm for searching an unordered list of elements, and it requires \n\n\n\nO\n(\n\n\nn\n\n\n)\n\n\n{\\displaystyle O({\\sqrt {n}})}\n\n queries. The idea of sorting a list of items to allow for faster searching dates back to antiquity. The earliest known example was the Inakibit-Anu tablet from Babylon dating back to c.200 BCE. The tablet contained about 500 sexagesimal numbers and their reciprocals sorted in lexicographical order, which made searching for a specific entry easier. In addition, several lists of names that were sorted by their first letter were discovered on the Aegean Islands. Catholicon, a Latin dictionary finished in 1286 CE, was the first work to describe rules for sorting words into alphabetical order, as opposed to just the first few letters.",
        "target": "In 1946, John Mauchly made the first mention of binary search as part of the Moore School Lectures, a seminal and foundational college course in computing. In 1957, William Wesley Peterson published the first method for interpolation search. Every published binary search algorithm worked only for arrays whose length is one less than a power of two[i] until 1960, when Derrick Henry Lehmer published a binary search algorithm that worked on all arrays. In 1962, Hermann Bottenbruch presented an ALGOL 60 implementation of binary search that placed the comparison for equality at the end, increasing the average number of iterations by one, but reducing to one the number of comparisons per iteration. The uniform binary search was developed by A. K. Chandra of Stanford University in 1971. In 1986, Bernard Chazelle and Leonidas J. Guibas introduced fractional cascading as a method to solve numerous search problems in computational geometry."
    },
    {
        "source": "The idea of sorting a list of items to allow for faster searching dates back to antiquity. The earliest known example was the Inakibit-Anu tablet from Babylon dating back to c.200 BCE. The tablet contained about 500 sexagesimal numbers and their reciprocals sorted in lexicographical order, which made searching for a specific entry easier. In addition, several lists of names that were sorted by their first letter were discovered on the Aegean Islands. Catholicon, a Latin dictionary finished in 1286 CE, was the first work to describe rules for sorting words into alphabetical order, as opposed to just the first few letters. In 1946, John Mauchly made the first mention of binary search as part of the Moore School Lectures, a seminal and foundational college course in computing. In 1957, William Wesley Peterson published the first method for interpolation search. Every published binary search algorithm worked only for arrays whose length is one less than a power of two[i] until 1960, when Derrick Henry Lehmer published a binary search algorithm that worked on all arrays. In 1962, Hermann Bottenbruch presented an ALGOL 60 implementation of binary search that placed the comparison for equality at the end, increasing the average number of iterations by one, but reducing to one the number of comparisons per iteration. The uniform binary search was developed by A. K. Chandra of Stanford University in 1971. In 1986, Bernard Chazelle and Leonidas J. Guibas introduced fractional cascading as a method to solve numerous search problems in computational geometry.",
        "target": "Although the basic idea of binary search is comparatively straightforward, the details can be surprisingly tricky"
    },
    {
        "source": "In 1946, John Mauchly made the first mention of binary search as part of the Moore School Lectures, a seminal and foundational college course in computing. In 1957, William Wesley Peterson published the first method for interpolation search. Every published binary search algorithm worked only for arrays whose length is one less than a power of two[i] until 1960, when Derrick Henry Lehmer published a binary search algorithm that worked on all arrays. In 1962, Hermann Bottenbruch presented an ALGOL 60 implementation of binary search that placed the comparison for equality at the end, increasing the average number of iterations by one, but reducing to one the number of comparisons per iteration. The uniform binary search was developed by A. K. Chandra of Stanford University in 1971. In 1986, Bernard Chazelle and Leonidas J. Guibas introduced fractional cascading as a method to solve numerous search problems in computational geometry. Although the basic idea of binary search is comparatively straightforward, the details can be surprisingly tricky",
        "target": "When Jon Bentley assigned binary search as a problem in a course for professional programmers, he found that ninety percent failed to provide a correct solution after several hours of working on it, mainly because the incorrect implementations failed to run or returned a wrong answer in rare edge cases. A study published in 1988 shows that accurate code for it is only found in five out of twenty textbooks. Furthermore, Bentley's own implementation of binary search, published in his 1986 book Programming Pearls, contained an overflow error that remained undetected for over twenty years.  The Java programming language library implementation of binary search had the same overflow bug for more than nine years."
    },
    {
        "source": "Although the basic idea of binary search is comparatively straightforward, the details can be surprisingly tricky When Jon Bentley assigned binary search as a problem in a course for professional programmers, he found that ninety percent failed to provide a correct solution after several hours of working on it, mainly because the incorrect implementations failed to run or returned a wrong answer in rare edge cases. A study published in 1988 shows that accurate code for it is only found in five out of twenty textbooks. Furthermore, Bentley's own implementation of binary search, published in his 1986 book Programming Pearls, contained an overflow error that remained undetected for over twenty years.  The Java programming language library implementation of binary search had the same overflow bug for more than nine years.",
        "target": "In a practical implementation, the variables used to represent the indices will often be of fixed size (integers), and this can result in an arithmetic overflow for very large arrays. If the midpoint of the span is calculated as \n\n\n\n\n\n\nL\n+\nR\n\n2\n\n\n\n\n{\\displaystyle {\\frac {L+R}{2}}}\n\n, then the value of \n\n\n\nL\n+\nR\n\n\n{\\displaystyle L+R}\n\n may exceed the range of integers of the data type used to store the midpoint, even if \n\n\n\nL\n\n\n{\\displaystyle L}\n\n and \n\n\n\nR\n\n\n{\\displaystyle R}\n\n are within the range. If \n\n\n\nL\n\n\n{\\displaystyle L}\n\n and \n\n\n\nR\n\n\n{\\displaystyle R}\n\n are nonnegative, this can be avoided by calculating the midpoint as \n\n\n\nL\n+\n\n\n\nR\n\nL\n\n2\n\n\n\n\n{\\displaystyle L+{\\frac {R-L}{2}}}\n\n."
    },
    {
        "source": "When Jon Bentley assigned binary search as a problem in a course for professional programmers, he found that ninety percent failed to provide a correct solution after several hours of working on it, mainly because the incorrect implementations failed to run or returned a wrong answer in rare edge cases. A study published in 1988 shows that accurate code for it is only found in five out of twenty textbooks. Furthermore, Bentley's own implementation of binary search, published in his 1986 book Programming Pearls, contained an overflow error that remained undetected for over twenty years.  The Java programming language library implementation of binary search had the same overflow bug for more than nine years. In a practical implementation, the variables used to represent the indices will often be of fixed size (integers), and this can result in an arithmetic overflow for very large arrays. If the midpoint of the span is calculated as \n\n\n\n\n\n\nL\n+\nR\n\n2\n\n\n\n\n{\\displaystyle {\\frac {L+R}{2}}}\n\n, then the value of \n\n\n\nL\n+\nR\n\n\n{\\displaystyle L+R}\n\n may exceed the range of integers of the data type used to store the midpoint, even if \n\n\n\nL\n\n\n{\\displaystyle L}\n\n and \n\n\n\nR\n\n\n{\\displaystyle R}\n\n are within the range. If \n\n\n\nL\n\n\n{\\displaystyle L}\n\n and \n\n\n\nR\n\n\n{\\displaystyle R}\n\n are nonnegative, this can be avoided by calculating the midpoint as \n\n\n\nL\n+\n\n\n\nR\n\nL\n\n2\n\n\n\n\n{\\displaystyle L+{\\frac {R-L}{2}}}\n\n.",
        "target": "An infinite loop may occur if the exit conditions for the loop are not defined correctly. Once \n\n\n\nL\n\n\n{\\displaystyle L}\n\n exceeds \n\n\n\nR\n\n\n{\\displaystyle R}\n\n, the search has failed and must convey the failure of the search. In addition, the loop must be exited when the target element is found, or in the case of an implementation where this check is moved to the end, checks for whether the search was successful or failed at the end must be in place. Bentley found that most of the programmers who incorrectly implemented binary search made an error in defining the exit conditions."
    },
    {
        "source": "In a practical implementation, the variables used to represent the indices will often be of fixed size (integers), and this can result in an arithmetic overflow for very large arrays. If the midpoint of the span is calculated as \n\n\n\n\n\n\nL\n+\nR\n\n2\n\n\n\n\n{\\displaystyle {\\frac {L+R}{2}}}\n\n, then the value of \n\n\n\nL\n+\nR\n\n\n{\\displaystyle L+R}\n\n may exceed the range of integers of the data type used to store the midpoint, even if \n\n\n\nL\n\n\n{\\displaystyle L}\n\n and \n\n\n\nR\n\n\n{\\displaystyle R}\n\n are within the range. If \n\n\n\nL\n\n\n{\\displaystyle L}\n\n and \n\n\n\nR\n\n\n{\\displaystyle R}\n\n are nonnegative, this can be avoided by calculating the midpoint as \n\n\n\nL\n+\n\n\n\nR\n\nL\n\n2\n\n\n\n\n{\\displaystyle L+{\\frac {R-L}{2}}}\n\n. An infinite loop may occur if the exit conditions for the loop are not defined correctly. Once \n\n\n\nL\n\n\n{\\displaystyle L}\n\n exceeds \n\n\n\nR\n\n\n{\\displaystyle R}\n\n, the search has failed and must convey the failure of the search. In addition, the loop must be exited when the target element is found, or in the case of an implementation where this check is moved to the end, checks for whether the search was successful or failed at the end must be in place. Bentley found that most of the programmers who incorrectly implemented binary search made an error in defining the exit conditions.",
        "target": "Many languages' standard libraries include binary search routines:"
    },
    {
        "source": "An infinite loop may occur if the exit conditions for the loop are not defined correctly. Once \n\n\n\nL\n\n\n{\\displaystyle L}\n\n exceeds \n\n\n\nR\n\n\n{\\displaystyle R}\n\n, the search has failed and must convey the failure of the search. In addition, the loop must be exited when the target element is found, or in the case of an implementation where this check is moved to the end, checks for whether the search was successful or failed at the end must be in place. Bentley found that most of the programmers who incorrectly implemented binary search made an error in defining the exit conditions. Many languages' standard libraries include binary search routines:",
        "target": "This article was submitted to WikiJournal of Science for external academic peer review in 2018 (reviewer reports). The updated content was reintegrated into the Wikipedia page under a CC-BY-SA-3.0 license (2019). The version of record as reviewed is: \nAnthony Lin; etal. (2 July 2019). \"Binary search algorithm\" (PDF). WikiJournal of Science. 2 (1): 5. doi:10.15347/WJS/2019.005. ISSN2470-6345. WikidataQ81434400."
    },
    {
        "source": " Gurl.com (pronounced \"girl dot com\"; formerly stylized as gURL.com from 1996 to 2011) was an American website for teenage girls that was online from 1996 to 2018. It was created by Rebecca Odes, Esther Drill, and Heather McDonald as a resource centered on teen advice, body image, female sexuality, and other teen-related concerns. First published as an online zine, it later expanded into an online community. At one point, it provided a free e-mail and web hosting service, known as Gurlmail and Gurlpages respectively.",
        "target": "Clothing retailer Delia's purchased the site in 1997; it was later sold to PriMedia in 2001, who in turn sold it to iVillage in 2003.  Alloy (later rebranded as Defy Media) acquired it from iVillage in 2009. The website ceased activity after Defy Media's closure in 2018 and was acquired by Hearst Magazines, who redirected it to Seventeen's website."
    },
    {
        "source": "Gurl.com (pronounced \"girl dot com\"; formerly stylized as gURL.com from 1996 to 2011) was an American website for teenage girls that was online from 1996 to 2018. It was created by Rebecca Odes, Esther Drill, and Heather McDonald as a resource centered on teen advice, body image, female sexuality, and other teen-related concerns. First published as an online zine, it later expanded into an online community. At one point, it provided a free e-mail and web hosting service, known as Gurlmail and Gurlpages respectively. Clothing retailer Delia's purchased the site in 1997; it was later sold to PriMedia in 2001, who in turn sold it to iVillage in 2003.  Alloy (later rebranded as Defy Media) acquired it from iVillage in 2009. The website ceased activity after Defy Media's closure in 2018 and was acquired by Hearst Magazines, who redirected it to Seventeen's website.",
        "target": "As one of the first major websites aimed at teenage girls in the United States, Gurl.com was heavily associated with zine culture and third-wave feminism; it was also used in academia to study the online behavior of teenage girls. Unlike teen magazines in the 1990s, Gurl.com was known for its humorous tone, unconventional approach to teen-related topics compared to mainstream media, and contributions from its audience (such as editorials and artwork). The popularity of Gurl.com led the creators to co-author three teen advice books, the first being Deal With It! A Whole New Approach to Your Body, Brain, and Life as a gURL (1999)."
    },
    {
        "source": "Clothing retailer Delia's purchased the site in 1997; it was later sold to PriMedia in 2001, who in turn sold it to iVillage in 2003.  Alloy (later rebranded as Defy Media) acquired it from iVillage in 2009. The website ceased activity after Defy Media's closure in 2018 and was acquired by Hearst Magazines, who redirected it to Seventeen's website. As one of the first major websites aimed at teenage girls in the United States, Gurl.com was heavily associated with zine culture and third-wave feminism; it was also used in academia to study the online behavior of teenage girls. Unlike teen magazines in the 1990s, Gurl.com was known for its humorous tone, unconventional approach to teen-related topics compared to mainstream media, and contributions from its audience (such as editorials and artwork). The popularity of Gurl.com led the creators to co-author three teen advice books, the first being Deal With It! A Whole New Approach to Your Body, Brain, and Life as a gURL (1999).",
        "target": "Gurl.com won the I.D. Magazine Award for Interactive Media in 1997 and a Webby Award in 1998; its founders received the New York Magazine Award in 1997 for their work on the website. Gurl.com was also met with privacy concerns, as well as criticism from conservative and anti-pornography advocates for its sex-positive stance and sex education resources."
    },
    {
        "source": "As one of the first major websites aimed at teenage girls in the United States, Gurl.com was heavily associated with zine culture and third-wave feminism; it was also used in academia to study the online behavior of teenage girls. Unlike teen magazines in the 1990s, Gurl.com was known for its humorous tone, unconventional approach to teen-related topics compared to mainstream media, and contributions from its audience (such as editorials and artwork). The popularity of Gurl.com led the creators to co-author three teen advice books, the first being Deal With It! A Whole New Approach to Your Body, Brain, and Life as a gURL (1999). Gurl.com won the I.D. Magazine Award for Interactive Media in 1997 and a Webby Award in 1998; its founders received the New York Magazine Award in 1997 for their work on the website. Gurl.com was also met with privacy concerns, as well as criticism from conservative and anti-pornography advocates for its sex-positive stance and sex education resources.",
        "target": "Rebecca Odes and Esther Drill, childhood friends from West Orange, New Jersey, conceived the idea of managing a magazine while they were in high school, as teenagers in the 1980s. Dissatisfied with the teen magazines available to them growing up, they sought to curate alternative media that would properly address the concerns of teenage girls. In 1995, while they were graduate students at the Interactive Telecommunications Program at New York University, they, along with fellow student Heather McDonald, decided to form a female-positive online space aimed at teenagers, as they felt the Internet lacked such communities in the 1990s. They wanted to create an uncensored resource for girls, with features similar to those in a teen magazine, but also wanted to build a community centered on female interests, with peer advice and opinions from other girls. Gurl.com was then created as Odes, Drill, and McDonald's Master's Thesis project. The name of the website combined the word \"girl\" with the acronym \"URL\". The logo of the website contained a closed fist with painted nails. The website was launched in May 1996."
    },
    {
        "source": "Gurl.com won the I.D. Magazine Award for Interactive Media in 1997 and a Webby Award in 1998; its founders received the New York Magazine Award in 1997 for their work on the website. Gurl.com was also met with privacy concerns, as well as criticism from conservative and anti-pornography advocates for its sex-positive stance and sex education resources. Rebecca Odes and Esther Drill, childhood friends from West Orange, New Jersey, conceived the idea of managing a magazine while they were in high school, as teenagers in the 1980s. Dissatisfied with the teen magazines available to them growing up, they sought to curate alternative media that would properly address the concerns of teenage girls. In 1995, while they were graduate students at the Interactive Telecommunications Program at New York University, they, along with fellow student Heather McDonald, decided to form a female-positive online space aimed at teenagers, as they felt the Internet lacked such communities in the 1990s. They wanted to create an uncensored resource for girls, with features similar to those in a teen magazine, but also wanted to build a community centered on female interests, with peer advice and opinions from other girls. Gurl.com was then created as Odes, Drill, and McDonald's Master's Thesis project. The name of the website combined the word \"girl\" with the acronym \"URL\". The logo of the website contained a closed fist with painted nails. The website was launched in May 1996.",
        "target": "After Gurl.com's initial launch, the website was included as a member of EstroNet, a web portal designed to drive traffic to independently owned websites created by women. The clothing retailer Delia's approached Odes, Drill, and McDonald with an acquisition offer and purchased the website in December 1997.:152 Odes, Drill, and McDonald continued to work on the website from Delia's offices. Gurl.com was included as part of the website network iTurf (Delia's online subsidiary) in an attempt to launch an e-commerce market targeting Generation Y. Gurl.com was initially launched as a non-commercial website,:156157 but it began selling merchandise from Delia's catalogue beginning in May 1998. On September 2, 1999, iTurf partnered with America Online to feature content from Gurl.com on their website in a section called AOgirL. In May 2000, Gurl.com sponsored Take Back the Decks: An Evening of Women in Underground Music, an all-female music festival held at Lighthouse Frying Pan in New York City, New York. From November 16 to November 21, 2000, Gurl.com held the Movers, Shakers, and Media Makers Film Festival at the Pioneer Theater in East Village, Manhattan, with Kim Peirce, Christine Vachon, and Nancy Savoca as guests."
    },
    {
        "source": "Rebecca Odes and Esther Drill, childhood friends from West Orange, New Jersey, conceived the idea of managing a magazine while they were in high school, as teenagers in the 1980s. Dissatisfied with the teen magazines available to them growing up, they sought to curate alternative media that would properly address the concerns of teenage girls. In 1995, while they were graduate students at the Interactive Telecommunications Program at New York University, they, along with fellow student Heather McDonald, decided to form a female-positive online space aimed at teenagers, as they felt the Internet lacked such communities in the 1990s. They wanted to create an uncensored resource for girls, with features similar to those in a teen magazine, but also wanted to build a community centered on female interests, with peer advice and opinions from other girls. Gurl.com was then created as Odes, Drill, and McDonald's Master's Thesis project. The name of the website combined the word \"girl\" with the acronym \"URL\". The logo of the website contained a closed fist with painted nails. The website was launched in May 1996. After Gurl.com's initial launch, the website was included as a member of EstroNet, a web portal designed to drive traffic to independently owned websites created by women. The clothing retailer Delia's approached Odes, Drill, and McDonald with an acquisition offer and purchased the website in December 1997.:152 Odes, Drill, and McDonald continued to work on the website from Delia's offices. Gurl.com was included as part of the website network iTurf (Delia's online subsidiary) in an attempt to launch an e-commerce market targeting Generation Y. Gurl.com was initially launched as a non-commercial website,:156157 but it began selling merchandise from Delia's catalogue beginning in May 1998. On September 2, 1999, iTurf partnered with America Online to feature content from Gurl.com on their website in a section called AOgirL. In May 2000, Gurl.com sponsored Take Back the Decks: An Evening of Women in Underground Music, an all-female music festival held at Lighthouse Frying Pan in New York City, New York. From November 16 to November 21, 2000, Gurl.com held the Movers, Shakers, and Media Makers Film Festival at the Pioneer Theater in East Village, Manhattan, with Kim Peirce, Christine Vachon, and Nancy Savoca as guests.",
        "target": "Following the dot-com bubble burst in 2000, Delia's sold or closed down all of their Internet properties in late November 2000, with the exception of Gurl.com.:152 On November 23, 2000, Gurl.com was redesigned with less focus on e-commerce. In May 2001, PriMedia, the parent company of Seventeen, acquired Gurl.com in an attempt to expand its teen-centered properties.:152:33 In August 2003, while downsizing and paying off its debts, PriMedia sold Gurl.com to iVillage, with Drill and McDonald joining staff.:33 In 2005, Gurl.com opened its first mobile store powered by M-Qube, selling ringtones and wallpapers for mobile phones."
    },
    {
        "source": "After Gurl.com's initial launch, the website was included as a member of EstroNet, a web portal designed to drive traffic to independently owned websites created by women. The clothing retailer Delia's approached Odes, Drill, and McDonald with an acquisition offer and purchased the website in December 1997.:152 Odes, Drill, and McDonald continued to work on the website from Delia's offices. Gurl.com was included as part of the website network iTurf (Delia's online subsidiary) in an attempt to launch an e-commerce market targeting Generation Y. Gurl.com was initially launched as a non-commercial website,:156157 but it began selling merchandise from Delia's catalogue beginning in May 1998. On September 2, 1999, iTurf partnered with America Online to feature content from Gurl.com on their website in a section called AOgirL. In May 2000, Gurl.com sponsored Take Back the Decks: An Evening of Women in Underground Music, an all-female music festival held at Lighthouse Frying Pan in New York City, New York. From November 16 to November 21, 2000, Gurl.com held the Movers, Shakers, and Media Makers Film Festival at the Pioneer Theater in East Village, Manhattan, with Kim Peirce, Christine Vachon, and Nancy Savoca as guests. Following the dot-com bubble burst in 2000, Delia's sold or closed down all of their Internet properties in late November 2000, with the exception of Gurl.com.:152 On November 23, 2000, Gurl.com was redesigned with less focus on e-commerce. In May 2001, PriMedia, the parent company of Seventeen, acquired Gurl.com in an attempt to expand its teen-centered properties.:152:33 In August 2003, while downsizing and paying off its debts, PriMedia sold Gurl.com to iVillage, with Drill and McDonald joining staff.:33 In 2005, Gurl.com opened its first mobile store powered by M-Qube, selling ringtones and wallpapers for mobile phones.",
        "target": "In 2009, Alloy acquired Gurl.com as part of their strategy to build a digital entertainment hub aimed at teenagers and young adults. Alloy later relaunched Gurl.com in 2011 with a new logo, containing a cursive font with the \"u\" shaped as a heart. Once Alloy merged with Breaker Media and became Defy Media in 2013, Gurl.com focused on video content and had a YouTube channel. The website ceased activity after 2018 with the closure of Defy Media. Once Gurl.com was redirected to Seventeen's website, Hearst Magazines later announced on February 15, 2019 that they acquired Clevver, including Gurl.com, which Defy Media had grouped with Clevver's network. In 2020, Jamie Petitto, who had been a video editor for Gurl.com from 2012 until its closure, stated in a video post on her social media accounts that Gurl.com had stopped updating since 2017. She also stated that she had offered to buy Gurl.com from Defy Media but could not meet their demand of $3 million."
    },
    {
        "source": "Following the dot-com bubble burst in 2000, Delia's sold or closed down all of their Internet properties in late November 2000, with the exception of Gurl.com.:152 On November 23, 2000, Gurl.com was redesigned with less focus on e-commerce. In May 2001, PriMedia, the parent company of Seventeen, acquired Gurl.com in an attempt to expand its teen-centered properties.:152:33 In August 2003, while downsizing and paying off its debts, PriMedia sold Gurl.com to iVillage, with Drill and McDonald joining staff.:33 In 2005, Gurl.com opened its first mobile store powered by M-Qube, selling ringtones and wallpapers for mobile phones. In 2009, Alloy acquired Gurl.com as part of their strategy to build a digital entertainment hub aimed at teenagers and young adults. Alloy later relaunched Gurl.com in 2011 with a new logo, containing a cursive font with the \"u\" shaped as a heart. Once Alloy merged with Breaker Media and became Defy Media in 2013, Gurl.com focused on video content and had a YouTube channel. The website ceased activity after 2018 with the closure of Defy Media. Once Gurl.com was redirected to Seventeen's website, Hearst Magazines later announced on February 15, 2019 that they acquired Clevver, including Gurl.com, which Defy Media had grouped with Clevver's network. In 2020, Jamie Petitto, who had been a video editor for Gurl.com from 2012 until its closure, stated in a video post on her social media accounts that Gurl.com had stopped updating since 2017. She also stated that she had offered to buy Gurl.com from Defy Media but could not meet their demand of $3 million.",
        "target": "Gurl.com drew inspiration from teen magazines, and its initial launch used a zine format.:154 The website's intended demographic was girls aged 13 or older. Unlike contemporary online communities aimed at young women in the 1990s, Gurl.com had an edgier appearance,:154 using a frank and nonjudgmental approach to address topics such as dating, health, and beauty.:152 Gurl.com also directly addressed topics such as female sexuality, which according to The Cut was not commonly seen in traditional media aimed at teenagers in the 1990s. Early content parodied and satirized mainstream teen magazines.:152 The website initially used drawings of women instead of photos to emphasize body positivity and to avoid body image concerns."
    },
    {
        "source": "In 2009, Alloy acquired Gurl.com as part of their strategy to build a digital entertainment hub aimed at teenagers and young adults. Alloy later relaunched Gurl.com in 2011 with a new logo, containing a cursive font with the \"u\" shaped as a heart. Once Alloy merged with Breaker Media and became Defy Media in 2013, Gurl.com focused on video content and had a YouTube channel. The website ceased activity after 2018 with the closure of Defy Media. Once Gurl.com was redirected to Seventeen's website, Hearst Magazines later announced on February 15, 2019 that they acquired Clevver, including Gurl.com, which Defy Media had grouped with Clevver's network. In 2020, Jamie Petitto, who had been a video editor for Gurl.com from 2012 until its closure, stated in a video post on her social media accounts that Gurl.com had stopped updating since 2017. She also stated that she had offered to buy Gurl.com from Defy Media but could not meet their demand of $3 million. Gurl.com drew inspiration from teen magazines, and its initial launch used a zine format.:154 The website's intended demographic was girls aged 13 or older. Unlike contemporary online communities aimed at young women in the 1990s, Gurl.com had an edgier appearance,:154 using a frank and nonjudgmental approach to address topics such as dating, health, and beauty.:152 Gurl.com also directly addressed topics such as female sexuality, which according to The Cut was not commonly seen in traditional media aimed at teenagers in the 1990s. Early content parodied and satirized mainstream teen magazines.:152 The website initially used drawings of women instead of photos to emphasize body positivity and to avoid body image concerns.",
        "target": "Content on the website was organized into topics such as \"Deal With It\" (daily life), \"Looks Aren't Everything\" (fashion and beauty), \"Where Do I Go From Here?\" (career), and sports.:154 When Gurl.com was given a new design on November 23, 2000, \"Stop, Look, and Listen\" (shopping) and \"Movers, Shakers, and Media Makers\" (celebrities and other women in media) were added as two new sections.:154 \"The Boob Files\" had first-person essays written about breasts that were submitted by contributors.:152 The website also had an advice column run by McDonald, titled \"Help Me, Heather.\""
    },
    {
        "source": "Gurl.com drew inspiration from teen magazines, and its initial launch used a zine format.:154 The website's intended demographic was girls aged 13 or older. Unlike contemporary online communities aimed at young women in the 1990s, Gurl.com had an edgier appearance,:154 using a frank and nonjudgmental approach to address topics such as dating, health, and beauty.:152 Gurl.com also directly addressed topics such as female sexuality, which according to The Cut was not commonly seen in traditional media aimed at teenagers in the 1990s. Early content parodied and satirized mainstream teen magazines.:152 The website initially used drawings of women instead of photos to emphasize body positivity and to avoid body image concerns. Content on the website was organized into topics such as \"Deal With It\" (daily life), \"Looks Aren't Everything\" (fashion and beauty), \"Where Do I Go From Here?\" (career), and sports.:154 When Gurl.com was given a new design on November 23, 2000, \"Stop, Look, and Listen\" (shopping) and \"Movers, Shakers, and Media Makers\" (celebrities and other women in media) were added as two new sections.:154 \"The Boob Files\" had first-person essays written about breasts that were submitted by contributors.:152 The website also had an advice column run by McDonald, titled \"Help Me, Heather.\"",
        "target": "Because Odes, Drill, and McDonald believed that girls prefer creating to being consumers, the website allowed contributions from its users, such as comics, poems, opinions on current events,:154 and reviews. For the same reason, they limited contributions from celebrities, as the website was intended to be a counter against aspirational fantasy. One of Gurl.com's notable contributions from its readers was its comics section, which included serializations such as Those Sucky Emotions and Mizbehavior, both initially listed in the \"Deal With It\" topic.:154 Other comics included Girl Stories by Lauren Weinstein; Fifteen Revolutions and Rachel the Great & Tuna by Rachel Nabors; and Girls in Love and I Heart Sex by Martina Fugazzotto."
    },
    {
        "source": "Content on the website was organized into topics such as \"Deal With It\" (daily life), \"Looks Aren't Everything\" (fashion and beauty), \"Where Do I Go From Here?\" (career), and sports.:154 When Gurl.com was given a new design on November 23, 2000, \"Stop, Look, and Listen\" (shopping) and \"Movers, Shakers, and Media Makers\" (celebrities and other women in media) were added as two new sections.:154 \"The Boob Files\" had first-person essays written about breasts that were submitted by contributors.:152 The website also had an advice column run by McDonald, titled \"Help Me, Heather.\" Because Odes, Drill, and McDonald believed that girls prefer creating to being consumers, the website allowed contributions from its users, such as comics, poems, opinions on current events,:154 and reviews. For the same reason, they limited contributions from celebrities, as the website was intended to be a counter against aspirational fantasy. One of Gurl.com's notable contributions from its readers was its comics section, which included serializations such as Those Sucky Emotions and Mizbehavior, both initially listed in the \"Deal With It\" topic.:154 Other comics included Girl Stories by Lauren Weinstein; Fifteen Revolutions and Rachel the Great & Tuna by Rachel Nabors; and Girls in Love and I Heart Sex by Martina Fugazzotto.",
        "target": "During Alloy's (later rebranded as Defy Media) acquisition of Gurl.com, the company shifted the website's focus towards video editorials. Jamie Petitto was hired to be a host for the video content from 2012 to 2017. She primarily hosted a DIY video series called Do It, Gurl on Gurl.com's YouTube channel, which was nominated for a Streamy Award in 2013."
    },
    {
        "source": "Because Odes, Drill, and McDonald believed that girls prefer creating to being consumers, the website allowed contributions from its users, such as comics, poems, opinions on current events,:154 and reviews. For the same reason, they limited contributions from celebrities, as the website was intended to be a counter against aspirational fantasy. One of Gurl.com's notable contributions from its readers was its comics section, which included serializations such as Those Sucky Emotions and Mizbehavior, both initially listed in the \"Deal With It\" topic.:154 Other comics included Girl Stories by Lauren Weinstein; Fifteen Revolutions and Rachel the Great & Tuna by Rachel Nabors; and Girls in Love and I Heart Sex by Martina Fugazzotto. During Alloy's (later rebranded as Defy Media) acquisition of Gurl.com, the company shifted the website's focus towards video editorials. Jamie Petitto was hired to be a host for the video content from 2012 to 2017. She primarily hosted a DIY video series called Do It, Gurl on Gurl.com's YouTube channel, which was nominated for a Streamy Award in 2013.",
        "target": "While Gurl.com could be accessed without an account, registration was required to submit content and participate in the chat room and message board.:154 Registration was free, and users were strongly advised to create a non-identifying alias to keep them anonymous.:45 The message board, known as the \"Shout-out Boards\",:791 were where users could interact with each other and exchange advice. Gurl.com also had an online avatar-based text chat room server, known as the Gurl Palace, accessible through the computer program The Palace."
    },
    {
        "source": "During Alloy's (later rebranded as Defy Media) acquisition of Gurl.com, the company shifted the website's focus towards video editorials. Jamie Petitto was hired to be a host for the video content from 2012 to 2017. She primarily hosted a DIY video series called Do It, Gurl on Gurl.com's YouTube channel, which was nominated for a Streamy Award in 2013. While Gurl.com could be accessed without an account, registration was required to submit content and participate in the chat room and message board.:154 Registration was free, and users were strongly advised to create a non-identifying alias to keep them anonymous.:45 The message board, known as the \"Shout-out Boards\",:791 were where users could interact with each other and exchange advice. Gurl.com also had an online avatar-based text chat room server, known as the Gurl Palace, accessible through the computer program The Palace.",
        "target": "As well as messaging features, Gurl.com featured online games. Some of the early game content satirized beauty standards, such as the game \"Hairy Gurl\". Later games stuck to Gurl.com's concept of acknowledging girls as creators instead of consumers, such as \"Make Your Own Rock Band\", \"Make Your Own Reality TV Show\", and \"Try the Prom Dress Selector\".:154 It also had personality quizzes, with a well-documented one being \"Paper Doll Psychology\", where users could dress a paper doll and receive an assessment on their personality based on their clothing choices.:152"
    },
    {
        "source": "While Gurl.com could be accessed without an account, registration was required to submit content and participate in the chat room and message board.:154 Registration was free, and users were strongly advised to create a non-identifying alias to keep them anonymous.:45 The message board, known as the \"Shout-out Boards\",:791 were where users could interact with each other and exchange advice. Gurl.com also had an online avatar-based text chat room server, known as the Gurl Palace, accessible through the computer program The Palace. As well as messaging features, Gurl.com featured online games. Some of the early game content satirized beauty standards, such as the game \"Hairy Gurl\". Later games stuck to Gurl.com's concept of acknowledging girls as creators instead of consumers, such as \"Make Your Own Rock Band\", \"Make Your Own Reality TV Show\", and \"Try the Prom Dress Selector\".:154 It also had personality quizzes, with a well-documented one being \"Paper Doll Psychology\", where users could dress a paper doll and receive an assessment on their personality based on their clothing choices.:152",
        "target": "During Delia's ownership from 1997 to 2001, Gurl.com provided an e-mail service through Gurlmail.com and web hosting through Gurlpages.com, both free services owned by Lycos. Many users used Gurlpages to host zines, particularly about female sexuality. Others used Gurlpages to host their creative works, such as poetry, and rants about their daily lives. Websites hosted on Gurlpages were part of Gurl.com's network and allowed users to easily connect with one another."
    },
    {
        "source": "As well as messaging features, Gurl.com featured online games. Some of the early game content satirized beauty standards, such as the game \"Hairy Gurl\". Later games stuck to Gurl.com's concept of acknowledging girls as creators instead of consumers, such as \"Make Your Own Rock Band\", \"Make Your Own Reality TV Show\", and \"Try the Prom Dress Selector\".:154 It also had personality quizzes, with a well-documented one being \"Paper Doll Psychology\", where users could dress a paper doll and receive an assessment on their personality based on their clothing choices.:152 During Delia's ownership from 1997 to 2001, Gurl.com provided an e-mail service through Gurlmail.com and web hosting through Gurlpages.com, both free services owned by Lycos. Many users used Gurlpages to host zines, particularly about female sexuality. Others used Gurlpages to host their creative works, such as poetry, and rants about their daily lives. Websites hosted on Gurlpages were part of Gurl.com's network and allowed users to easily connect with one another.",
        "target": "Following the success of Gurl.com, Odes, Drill, and McDonald received a book deal through a partnership with Scholastic. They published a series of teen advice books based on the editorial content on the website and also included conversations found on Gurl.com's message board.  The first book, Deal With It! A Whole New Approach to Your Body, Brain, and Life as a gURL, was released on September 1, 1999; it offered advice on puberty, queer identities, sex, eating disorders, drug use, and mental health, with a list of resources on each topic. To promote the book, Odes, Drill, and McDonald launched an accompanying website, DealWithIt.com, which hosted an online version of the resources. Deal With It! was received favorably, most reviewers praising the book as a valuable resource about sexual health as well as its tone and presentation; some critics cautioned that parents might not find some of the content appropriate and advised that the book was not suitable for younger readers. Deal With It! was listed at #82 on the American Library Association's Top 100 Banned/Challenged Books from 2000 to 2009, with several organizations challenging the book due to its LGBT-friendly and sex-positive content. Deal With It! became a national bestseller, selling 100,000 copies in the United States by January 2000, and was awarded the I.D. Magazine Award in the Graphics category in July 2000."
    },
    {
        "source": "During Delia's ownership from 1997 to 2001, Gurl.com provided an e-mail service through Gurlmail.com and web hosting through Gurlpages.com, both free services owned by Lycos. Many users used Gurlpages to host zines, particularly about female sexuality. Others used Gurlpages to host their creative works, such as poetry, and rants about their daily lives. Websites hosted on Gurlpages were part of Gurl.com's network and allowed users to easily connect with one another. Following the success of Gurl.com, Odes, Drill, and McDonald received a book deal through a partnership with Scholastic. They published a series of teen advice books based on the editorial content on the website and also included conversations found on Gurl.com's message board.  The first book, Deal With It! A Whole New Approach to Your Body, Brain, and Life as a gURL, was released on September 1, 1999; it offered advice on puberty, queer identities, sex, eating disorders, drug use, and mental health, with a list of resources on each topic. To promote the book, Odes, Drill, and McDonald launched an accompanying website, DealWithIt.com, which hosted an online version of the resources. Deal With It! was received favorably, most reviewers praising the book as a valuable resource about sexual health as well as its tone and presentation; some critics cautioned that parents might not find some of the content appropriate and advised that the book was not suitable for younger readers. Deal With It! was listed at #82 on the American Library Association's Top 100 Banned/Challenged Books from 2000 to 2009, with several organizations challenging the book due to its LGBT-friendly and sex-positive content. Deal With It! became a national bestseller, selling 100,000 copies in the United States by January 2000, and was awarded the I.D. Magazine Award in the Graphics category in July 2000.",
        "target": "Deal With It! was followed by The Looks Book: A Whole New Approach to Beauty, Body Image, and Style on October 1, 2002, which examined beauty standards throughout the ages.:152 Publishers Weekly described the artwork as \"whimsical\" and the book as both intelligent and humorous, suggesting that it presented a message of empowerment."
    },
    {
        "source": "Following the success of Gurl.com, Odes, Drill, and McDonald received a book deal through a partnership with Scholastic. They published a series of teen advice books based on the editorial content on the website and also included conversations found on Gurl.com's message board.  The first book, Deal With It! A Whole New Approach to Your Body, Brain, and Life as a gURL, was released on September 1, 1999; it offered advice on puberty, queer identities, sex, eating disorders, drug use, and mental health, with a list of resources on each topic. To promote the book, Odes, Drill, and McDonald launched an accompanying website, DealWithIt.com, which hosted an online version of the resources. Deal With It! was received favorably, most reviewers praising the book as a valuable resource about sexual health as well as its tone and presentation; some critics cautioned that parents might not find some of the content appropriate and advised that the book was not suitable for younger readers. Deal With It! was listed at #82 on the American Library Association's Top 100 Banned/Challenged Books from 2000 to 2009, with several organizations challenging the book due to its LGBT-friendly and sex-positive content. Deal With It! became a national bestseller, selling 100,000 copies in the United States by January 2000, and was awarded the I.D. Magazine Award in the Graphics category in July 2000. Deal With It! was followed by The Looks Book: A Whole New Approach to Beauty, Body Image, and Style on October 1, 2002, which examined beauty standards throughout the ages.:152 Publishers Weekly described the artwork as \"whimsical\" and the book as both intelligent and humorous, suggesting that it presented a message of empowerment.",
        "target": "The final book, Where Do I Go from Here?: Getting a Life After High School, was released in 2004. The book discussed topics such as entering adulthood, managing finances, alternatives to college, and other social issues in college life, such as incompatible roommates, date rape, and binge drinking. Britta Hays from Tampa Bay Times praised the book for profiling options after high school without bias. Harry Wessel from The Orlando Sentinel described the book as one that would help teenagers make good choices about their future and said that, despite its branding, its advice was also applicable to men."
    },
    {
        "source": "Deal With It! was followed by The Looks Book: A Whole New Approach to Beauty, Body Image, and Style on October 1, 2002, which examined beauty standards throughout the ages.:152 Publishers Weekly described the artwork as \"whimsical\" and the book as both intelligent and humorous, suggesting that it presented a message of empowerment. The final book, Where Do I Go from Here?: Getting a Life After High School, was released in 2004. The book discussed topics such as entering adulthood, managing finances, alternatives to college, and other social issues in college life, such as incompatible roommates, date rape, and binge drinking. Britta Hays from Tampa Bay Times praised the book for profiling options after high school without bias. Harry Wessel from The Orlando Sentinel described the book as one that would help teenagers make good choices about their future and said that, despite its branding, its advice was also applicable to men.",
        "target": "Gurl.com was praised for being a positive community on topics such as female sexuality, queer identity, and body positivity, as well as its inclusion of peer advice from teenage girls, by media outlets such as The Cut, Glamour, and Los Angeles Times. Janelle Brown from Salon.com noted that the accessibility of sex education online had prepared young girls and also allowed them their own sexual agency. Despite the acclaim, Los Angeles Times and Common Sense Media suggested Gurl.com was more appropriate for an older audience. In 1999, the website had approximately 800,000 visitors per month. In 2001, approximately 40% of girls who regularly used the Internet in the United States visited the website."
    },
    {
        "source": "The final book, Where Do I Go from Here?: Getting a Life After High School, was released in 2004. The book discussed topics such as entering adulthood, managing finances, alternatives to college, and other social issues in college life, such as incompatible roommates, date rape, and binge drinking. Britta Hays from Tampa Bay Times praised the book for profiling options after high school without bias. Harry Wessel from The Orlando Sentinel described the book as one that would help teenagers make good choices about their future and said that, despite its branding, its advice was also applicable to men. Gurl.com was praised for being a positive community on topics such as female sexuality, queer identity, and body positivity, as well as its inclusion of peer advice from teenage girls, by media outlets such as The Cut, Glamour, and Los Angeles Times. Janelle Brown from Salon.com noted that the accessibility of sex education online had prepared young girls and also allowed them their own sexual agency. Despite the acclaim, Los Angeles Times and Common Sense Media suggested Gurl.com was more appropriate for an older audience. In 1999, the website had approximately 800,000 visitors per month. In 2001, approximately 40% of girls who regularly used the Internet in the United States visited the website.",
        "target": "Gurl.com was also met with criticisms over its sex-positive stance from conservative groups. In 1999, Salon.com stated that anti-pornography advocates cited concerns that young girls discussing and having accessibility to sex information would lead to an increase in underage sexual activity and be harmful to their development. Abstinence advocate Coleen Kelly Mast argued that Gurl.com gave a one-sided view of human sexuality, claiming that the information would not help lead to \"satisfaction in marriage\". Carol Platt Liebau named Gurl.com as part of her criticisms against the United States' \"sex-obsessed\" culture, criticizing the website for excluding religious and moral discussions about sex as well as for ignoring the opinions of teenage girls who chose to be abstinent. Miriam Grossman included Gurl.com and Deal With It! in her criticisms of sex education, calling the website \"offensive material\" for including information such as BDSM,  sex positions,:5 and gender identities.:166167"
    },
    {
        "source": "Gurl.com was praised for being a positive community on topics such as female sexuality, queer identity, and body positivity, as well as its inclusion of peer advice from teenage girls, by media outlets such as The Cut, Glamour, and Los Angeles Times. Janelle Brown from Salon.com noted that the accessibility of sex education online had prepared young girls and also allowed them their own sexual agency. Despite the acclaim, Los Angeles Times and Common Sense Media suggested Gurl.com was more appropriate for an older audience. In 1999, the website had approximately 800,000 visitors per month. In 2001, approximately 40% of girls who regularly used the Internet in the United States visited the website. Gurl.com was also met with criticisms over its sex-positive stance from conservative groups. In 1999, Salon.com stated that anti-pornography advocates cited concerns that young girls discussing and having accessibility to sex information would lead to an increase in underage sexual activity and be harmful to their development. Abstinence advocate Coleen Kelly Mast argued that Gurl.com gave a one-sided view of human sexuality, claiming that the information would not help lead to \"satisfaction in marriage\". Carol Platt Liebau named Gurl.com as part of her criticisms against the United States' \"sex-obsessed\" culture, criticizing the website for excluding religious and moral discussions about sex as well as for ignoring the opinions of teenage girls who chose to be abstinent. Miriam Grossman included Gurl.com and Deal With It! in her criticisms of sex education, calling the website \"offensive material\" for including information such as BDSM,  sex positions,:5 and gender identities.:166167",
        "target": "Among other criticisms, parents and scholars expressed concern over Gurl.com collecting information from its users and disclosing them to third-party advertisers to study consumer habits,:157 with The American Prospect naming their personality quizzes as an example of acquiring personal data. In 2015, the Canadian Broadcasting Company included Gurl.com among 1,494 websites and mobile apps that were privacy concerns, as it allowed children to unknowingly list too much information about themselves. Anita Hamilton from Time surveyed several female high school students in Manhattan, New York, and out of the four teen websites shown to them, the students liked Gurl.com the least, citing its \"cluttered\" design as partly the reason."
    },
    {
        "source": "Gurl.com was also met with criticisms over its sex-positive stance from conservative groups. In 1999, Salon.com stated that anti-pornography advocates cited concerns that young girls discussing and having accessibility to sex information would lead to an increase in underage sexual activity and be harmful to their development. Abstinence advocate Coleen Kelly Mast argued that Gurl.com gave a one-sided view of human sexuality, claiming that the information would not help lead to \"satisfaction in marriage\". Carol Platt Liebau named Gurl.com as part of her criticisms against the United States' \"sex-obsessed\" culture, criticizing the website for excluding religious and moral discussions about sex as well as for ignoring the opinions of teenage girls who chose to be abstinent. Miriam Grossman included Gurl.com and Deal With It! in her criticisms of sex education, calling the website \"offensive material\" for including information such as BDSM,  sex positions,:5 and gender identities.:166167 Among other criticisms, parents and scholars expressed concern over Gurl.com collecting information from its users and disclosing them to third-party advertisers to study consumer habits,:157 with The American Prospect naming their personality quizzes as an example of acquiring personal data. In 2015, the Canadian Broadcasting Company included Gurl.com among 1,494 websites and mobile apps that were privacy concerns, as it allowed children to unknowingly list too much information about themselves. Anita Hamilton from Time surveyed several female high school students in Manhattan, New York, and out of the four teen websites shown to them, the students liked Gurl.com the least, citing its \"cluttered\" design as partly the reason.",
        "target": "Gurl.com has been used in studies about online behaviors and sexual identities of teenage girls. In a study conducted by Media Metrix and Jupiter Communications in 2000, there was a 125% growth of girls aged 1217 years old using the Internet, which was partially credited to Gurl.com. In a study done by professors Barbara Duncan and Kevin Leander in the same year, they observed that because Gurl.com already had an established network, girls who hosted their website at Gurlpages could easily connect with one another and receive feedback on their work. In 2005, scholar Sharon Mazzarella noted that Gurl.com was among the websites that helped girls be creative and empowered, though there was later increasing moral panic surrounding how harmful messages may influence them.:141"
    },
    {
        "source": "Among other criticisms, parents and scholars expressed concern over Gurl.com collecting information from its users and disclosing them to third-party advertisers to study consumer habits,:157 with The American Prospect naming their personality quizzes as an example of acquiring personal data. In 2015, the Canadian Broadcasting Company included Gurl.com among 1,494 websites and mobile apps that were privacy concerns, as it allowed children to unknowingly list too much information about themselves. Anita Hamilton from Time surveyed several female high school students in Manhattan, New York, and out of the four teen websites shown to them, the students liked Gurl.com the least, citing its \"cluttered\" design as partly the reason. Gurl.com has been used in studies about online behaviors and sexual identities of teenage girls. In a study conducted by Media Metrix and Jupiter Communications in 2000, there was a 125% growth of girls aged 1217 years old using the Internet, which was partially credited to Gurl.com. In a study done by professors Barbara Duncan and Kevin Leander in the same year, they observed that because Gurl.com already had an established network, girls who hosted their website at Gurlpages could easily connect with one another and receive feedback on their work. In 2005, scholar Sharon Mazzarella noted that Gurl.com was among the websites that helped girls be creative and empowered, though there was later increasing moral panic surrounding how harmful messages may influence them.:141",
        "target": "Scholars Ashley D. Grisso and David Weiss noted that users on Gurl.com's message board often discussed their interest in sex, usually respectfully as per the established norm on the website.:45 In spite of this, many discussions about sex on the website were related to male pleasure.:45 Gurl.com encouraged sexual expression, but some users were quick to shame others who disapproved of premarital sex or discussed their sex lives in detail, downplaying individual sexual agency.:36,41,45 A study published in the Journal of Computer-Mediated Communication in 2006 found Gurl.com to be the best example of a female-centric website that encouraged critical thinking skills in young girls through their discussions on current events.:791792"
    },
    {
        "source": "Gurl.com has been used in studies about online behaviors and sexual identities of teenage girls. In a study conducted by Media Metrix and Jupiter Communications in 2000, there was a 125% growth of girls aged 1217 years old using the Internet, which was partially credited to Gurl.com. In a study done by professors Barbara Duncan and Kevin Leander in the same year, they observed that because Gurl.com already had an established network, girls who hosted their website at Gurlpages could easily connect with one another and receive feedback on their work. In 2005, scholar Sharon Mazzarella noted that Gurl.com was among the websites that helped girls be creative and empowered, though there was later increasing moral panic surrounding how harmful messages may influence them.:141 Scholars Ashley D. Grisso and David Weiss noted that users on Gurl.com's message board often discussed their interest in sex, usually respectfully as per the established norm on the website.:45 In spite of this, many discussions about sex on the website were related to male pleasure.:45 Gurl.com encouraged sexual expression, but some users were quick to shame others who disapproved of premarital sex or discussed their sex lives in detail, downplaying individual sexual agency.:36,41,45 A study published in the Journal of Computer-Mediated Communication in 2006 found Gurl.com to be the best example of a female-centric website that encouraged critical thinking skills in young girls through their discussions on current events.:791792",
        "target": "Gurl.com has also been used as an example of the commercialization of the Internet, as well as recognizing young women from Generation Y as a viable marketing demographic. It was named as a site that inspired the growth of websites owned by teenage girls, creating a potential advertising market worth US$15 billion in 2000. Duncan and Leander argued that Gurl.com created spaces of both \"resistance and conformity\", as people who had websites on Gurlpages both expressed themselves in creative writing yet also listed personal information identifying their demographics and consumer habits. Scholar Leslie Regan Shade used Gurl.com as an example of commodification and commercialization of a community in the 1990s, when women were being recognized as a marketing demographic for e-commerce.:157 Echoing Duncan and Leander, she commented that while Gurl.com had a disclaimer stating that their views do not represent their advertisers, the website may have been \"packaged for a homogeneous idyllic audience commodity\", which contrasts with the \"utopian sentiments\" of an online community.:157 Gurl.com was used as an example of stealth marketing in teaching media literacy about advertising.:77"
    },
    {
        "source": "Scholars Ashley D. Grisso and David Weiss noted that users on Gurl.com's message board often discussed their interest in sex, usually respectfully as per the established norm on the website.:45 In spite of this, many discussions about sex on the website were related to male pleasure.:45 Gurl.com encouraged sexual expression, but some users were quick to shame others who disapproved of premarital sex or discussed their sex lives in detail, downplaying individual sexual agency.:36,41,45 A study published in the Journal of Computer-Mediated Communication in 2006 found Gurl.com to be the best example of a female-centric website that encouraged critical thinking skills in young girls through their discussions on current events.:791792 Gurl.com has also been used as an example of the commercialization of the Internet, as well as recognizing young women from Generation Y as a viable marketing demographic. It was named as a site that inspired the growth of websites owned by teenage girls, creating a potential advertising market worth US$15 billion in 2000. Duncan and Leander argued that Gurl.com created spaces of both \"resistance and conformity\", as people who had websites on Gurlpages both expressed themselves in creative writing yet also listed personal information identifying their demographics and consumer habits. Scholar Leslie Regan Shade used Gurl.com as an example of commodification and commercialization of a community in the 1990s, when women were being recognized as a marketing demographic for e-commerce.:157 Echoing Duncan and Leander, she commented that while Gurl.com had a disclaimer stating that their views do not represent their advertisers, the website may have been \"packaged for a homogeneous idyllic audience commodity\", which contrasts with the \"utopian sentiments\" of an online community.:157 Gurl.com was used as an example of stealth marketing in teaching media literacy about advertising.:77",
        "target": "Gurl.com is known for being one of the first major websites aimed at teenage girls in the United States during the 1990s. It was also known for its association and contributions to third-wave feminism, riot grrl, and zine culture in the 1990s. Gurl.com's honest and frank discussions about teen issues inspired teen magazines and other female-centered websites to adopt a similar approach. Its branding was also tied to Generation Y identity."
    },
    {
        "source": " The iMac G3, originally released as the iMac, is a series of Macintosh personal computers that Apple Computer sold from 1998 to 2003. The iMac was Apple's first major product release under CEO Steve Jobs following his return to the financially troubled company he co-founded. Jobs reorganized the company and simplified the product line. The iMac was designed as Apple's new consumer desktop productan inexpensive, consumer-oriented computer that would easily connect to the Internet.",
        "target": "The iMac's all-in-one design is based around a cathode-ray tube display; the G3 processor, components, and connectivity were all included in a single enclosure. Apple's head of design Jony Ive and his team developed a teardrop-shaped, translucent plastic case that was a radical departure from the look of the company's previous computers. The company developed new working methods to finish the computer quickly, and new workflows for designing future products. The iMac eschewed legacy technologies like serial ports and floppy disk drives in favor of CD-ROMs and USB ports."
    },
    {
        "source": "The iMac G3, originally released as the iMac, is a series of Macintosh personal computers that Apple Computer sold from 1998 to 2003. The iMac was Apple's first major product release under CEO Steve Jobs following his return to the financially troubled company he co-founded. Jobs reorganized the company and simplified the product line. The iMac was designed as Apple's new consumer desktop productan inexpensive, consumer-oriented computer that would easily connect to the Internet. The iMac's all-in-one design is based around a cathode-ray tube display; the G3 processor, components, and connectivity were all included in a single enclosure. Apple's head of design Jony Ive and his team developed a teardrop-shaped, translucent plastic case that was a radical departure from the look of the company's previous computers. The company developed new working methods to finish the computer quickly, and new workflows for designing future products. The iMac eschewed legacy technologies like serial ports and floppy disk drives in favor of CD-ROMs and USB ports.",
        "target": "Critical response to the iMac was mixed; journalists said the machine would be good for new computer users but bemoaned the lack of legacy technology, and said the separate mouse and keyboard were uncomfortable. Despite the reviews the iMac was an immediate commercial success, becoming Apple's fastest-selling computer, selling more than six million units in its lifetime."
    },
    {
        "source": "The iMac's all-in-one design is based around a cathode-ray tube display; the G3 processor, components, and connectivity were all included in a single enclosure. Apple's head of design Jony Ive and his team developed a teardrop-shaped, translucent plastic case that was a radical departure from the look of the company's previous computers. The company developed new working methods to finish the computer quickly, and new workflows for designing future products. The iMac eschewed legacy technologies like serial ports and floppy disk drives in favor of CD-ROMs and USB ports. Critical response to the iMac was mixed; journalists said the machine would be good for new computer users but bemoaned the lack of legacy technology, and said the separate mouse and keyboard were uncomfortable. Despite the reviews the iMac was an immediate commercial success, becoming Apple's fastest-selling computer, selling more than six million units in its lifetime.",
        "target": "The original model was revised several times, improving the processor speed, the amount of random-access memory, hard drive space, and other capabilities. The iMac is credited with saving Apple from financial ruin, and for turning personal computers from niche, technical products to mass-consumer fashion. Other computers and consumer products appropriated the translucent plastic look, leading to legal action from Apple. The iMac G3 series was succeeded by the iMac G4, and the iMac G3's position in education markets was replaced by the eMac."
    },
    {
        "source": "Critical response to the iMac was mixed; journalists said the machine would be good for new computer users but bemoaned the lack of legacy technology, and said the separate mouse and keyboard were uncomfortable. Despite the reviews the iMac was an immediate commercial success, becoming Apple's fastest-selling computer, selling more than six million units in its lifetime. The original model was revised several times, improving the processor speed, the amount of random-access memory, hard drive space, and other capabilities. The iMac is credited with saving Apple from financial ruin, and for turning personal computers from niche, technical products to mass-consumer fashion. Other computers and consumer products appropriated the translucent plastic look, leading to legal action from Apple. The iMac G3 series was succeeded by the iMac G4, and the iMac G3's position in education markets was replaced by the eMac.",
        "target": "In the late 1990s, Apple Computer was experiencing severe financial difficulties. At the end of 1997, the company was selling 1.8million Macs per year, in comparison with 4.5million two years earlier. Apple's sales were compromised by licensed Mac systems that undercut and out-performed Apple's own products. Apple was unable to compete in the low-cost computer market, and entirely abandoned the sector."
    },
    {
        "source": "The original model was revised several times, improving the processor speed, the amount of random-access memory, hard drive space, and other capabilities. The iMac is credited with saving Apple from financial ruin, and for turning personal computers from niche, technical products to mass-consumer fashion. Other computers and consumer products appropriated the translucent plastic look, leading to legal action from Apple. The iMac G3 series was succeeded by the iMac G4, and the iMac G3's position in education markets was replaced by the eMac. In the late 1990s, Apple Computer was experiencing severe financial difficulties. At the end of 1997, the company was selling 1.8million Macs per year, in comparison with 4.5million two years earlier. Apple's sales were compromised by licensed Mac systems that undercut and out-performed Apple's own products. Apple was unable to compete in the low-cost computer market, and entirely abandoned the sector.",
        "target": "In December 1996, Apple purchased the NeXT computer company, founded by Steve Jobs. As part of the deal, he returned to Apple, the company he had co-founded in 1976 and then been ousted from in 1985. Apple also acquired NeXT's operating system NeXTSTEP, which would become the foundation for Apple's next-generation operating system Mac OS X. Jobs returned to Apple as an advisor but the company's board of directors dismissed CEO Gil Amelio on July 9, 1997, and Jobs replaced him in an interim capacity."
    },
    {
        "source": "In the late 1990s, Apple Computer was experiencing severe financial difficulties. At the end of 1997, the company was selling 1.8million Macs per year, in comparison with 4.5million two years earlier. Apple's sales were compromised by licensed Mac systems that undercut and out-performed Apple's own products. Apple was unable to compete in the low-cost computer market, and entirely abandoned the sector. In December 1996, Apple purchased the NeXT computer company, founded by Steve Jobs. As part of the deal, he returned to Apple, the company he had co-founded in 1976 and then been ousted from in 1985. Apple also acquired NeXT's operating system NeXTSTEP, which would become the foundation for Apple's next-generation operating system Mac OS X. Jobs returned to Apple as an advisor but the company's board of directors dismissed CEO Gil Amelio on July 9, 1997, and Jobs replaced him in an interim capacity.",
        "target": "Around the same time, Apple's industrial design director Robert Brunner left the company and was succeeded by junior designer Jony Ive, who inherited the award-winning design team. Ive was dispirited with Apple's leadership and also considered leaving. At a meeting announcing Jobs's appointment as Apple's CEO, Jobs told his staff that Apple's problems stemmed from its poor products. Ive noted Jobs's focus on making industrial design a core part of Apple's comeback strategy. Ive and Jobs quickly developed a rapport, and Jobs retained Apple's industrial design team under Ive's leadership."
    },
    {
        "source": "In December 1996, Apple purchased the NeXT computer company, founded by Steve Jobs. As part of the deal, he returned to Apple, the company he had co-founded in 1976 and then been ousted from in 1985. Apple also acquired NeXT's operating system NeXTSTEP, which would become the foundation for Apple's next-generation operating system Mac OS X. Jobs returned to Apple as an advisor but the company's board of directors dismissed CEO Gil Amelio on July 9, 1997, and Jobs replaced him in an interim capacity. Around the same time, Apple's industrial design director Robert Brunner left the company and was succeeded by junior designer Jony Ive, who inherited the award-winning design team. Ive was dispirited with Apple's leadership and also considered leaving. At a meeting announcing Jobs's appointment as Apple's CEO, Jobs told his staff that Apple's problems stemmed from its poor products. Ive noted Jobs's focus on making industrial design a core part of Apple's comeback strategy. Ive and Jobs quickly developed a rapport, and Jobs retained Apple's industrial design team under Ive's leadership.",
        "target": "Jobs streamlined the company into profitability by cost-cutting, but the company still needed compelling products to boost sales. He planned to reduce Apple's extensive and confusing computer offerings to four products: a laptop and desktop model each for professionals and consumers. The planned consumer-oriented desktop computer would become the iMac."
    },
    {
        "source": "Around the same time, Apple's industrial design director Robert Brunner left the company and was succeeded by junior designer Jony Ive, who inherited the award-winning design team. Ive was dispirited with Apple's leadership and also considered leaving. At a meeting announcing Jobs's appointment as Apple's CEO, Jobs told his staff that Apple's problems stemmed from its poor products. Ive noted Jobs's focus on making industrial design a core part of Apple's comeback strategy. Ive and Jobs quickly developed a rapport, and Jobs retained Apple's industrial design team under Ive's leadership. Jobs streamlined the company into profitability by cost-cutting, but the company still needed compelling products to boost sales. He planned to reduce Apple's extensive and confusing computer offerings to four products: a laptop and desktop model each for professionals and consumers. The planned consumer-oriented desktop computer would become the iMac.",
        "target": "Jobs initially wanted the new consumer desktop to be a network computera cheap, low-powered terminal without disk drives that would connect to Internet servers. Ive's design team was given Jobs's specifications for the new product in September 1997: it should be a distinctive, all-in-one computer with a price of about $1,200, much lower than the $2,000 (equivalent to $3,700 in 2023) for current entry-level models. The engineering and design teams had less than one year to deliver a finished product."
    },
    {
        "source": "Jobs streamlined the company into profitability by cost-cutting, but the company still needed compelling products to boost sales. He planned to reduce Apple's extensive and confusing computer offerings to four products: a laptop and desktop model each for professionals and consumers. The planned consumer-oriented desktop computer would become the iMac. Jobs initially wanted the new consumer desktop to be a network computera cheap, low-powered terminal without disk drives that would connect to Internet servers. Ive's design team was given Jobs's specifications for the new product in September 1997: it should be a distinctive, all-in-one computer with a price of about $1,200, much lower than the $2,000 (equivalent to $3,700 in 2023) for current entry-level models. The engineering and design teams had less than one year to deliver a finished product.",
        "target": "The design team tried to discern what objects conveyed the emotions they wanted the computer to evoke. While collaboratively developing sketches, designer Doug Satzger drew an ovoid drawing based on his earlier work on Thomson televisions. Ive and the rest of the team focused on the ovoid design, although Jobs initially rejected the look. Ive defended the design as playful and fun, and persuaded Jobs to accept the idea. Jobs began carrying a foamcore model of the computer around the Apple campus to show it off."
    },
    {
        "source": "Jobs initially wanted the new consumer desktop to be a network computera cheap, low-powered terminal without disk drives that would connect to Internet servers. Ive's design team was given Jobs's specifications for the new product in September 1997: it should be a distinctive, all-in-one computer with a price of about $1,200, much lower than the $2,000 (equivalent to $3,700 in 2023) for current entry-level models. The engineering and design teams had less than one year to deliver a finished product. The design team tried to discern what objects conveyed the emotions they wanted the computer to evoke. While collaboratively developing sketches, designer Doug Satzger drew an ovoid drawing based on his earlier work on Thomson televisions. Ive and the rest of the team focused on the ovoid design, although Jobs initially rejected the look. Ive defended the design as playful and fun, and persuaded Jobs to accept the idea. Jobs began carrying a foamcore model of the computer around the Apple campus to show it off.",
        "target": "When discussing the idea of a machine that inspired positive emotions, the designers mentioned colorful candy dispensers. Materials tests with solid plastics looked cheap, so they made the case translucent. Translucent hardware design was not new to Apple's products; the Power Macintosh 8600, 9600, and Power Macintosh G3 tower computers had translucent green latches, and the LaserWriter 8500, eMate 300, and Studio Display incorporated translucent colored plastics more extensively. Former Apple senior designer Thomas Meyerhoffer described the eMate's plastics as a way of making the product accessible and distinctive. To Ive, the translucency \"came across as cheeky\" but meant the aesthetic design of the internal components would also need to be considered. Inspiration came from translucent items the designers brought to the office; one item was a piece of greenish-blue beach glass. This \"Bondi blue\" object inspired the color Jobs selected for the first iMac."
    },
    {
        "source": "The design team tried to discern what objects conveyed the emotions they wanted the computer to evoke. While collaboratively developing sketches, designer Doug Satzger drew an ovoid drawing based on his earlier work on Thomson televisions. Ive and the rest of the team focused on the ovoid design, although Jobs initially rejected the look. Ive defended the design as playful and fun, and persuaded Jobs to accept the idea. Jobs began carrying a foamcore model of the computer around the Apple campus to show it off. When discussing the idea of a machine that inspired positive emotions, the designers mentioned colorful candy dispensers. Materials tests with solid plastics looked cheap, so they made the case translucent. Translucent hardware design was not new to Apple's products; the Power Macintosh 8600, 9600, and Power Macintosh G3 tower computers had translucent green latches, and the LaserWriter 8500, eMate 300, and Studio Display incorporated translucent colored plastics more extensively. Former Apple senior designer Thomas Meyerhoffer described the eMate's plastics as a way of making the product accessible and distinctive. To Ive, the translucency \"came across as cheeky\" but meant the aesthetic design of the internal components would also need to be considered. Inspiration came from translucent items the designers brought to the office; one item was a piece of greenish-blue beach glass. This \"Bondi blue\" object inspired the color Jobs selected for the first iMac.",
        "target": "Apple's design team radically overhauled its processes to meet the tight deadline. In the past, they had sent two-dimensional blueprints or hand-drawn sketches to toolmakers to create molds, a laborious process that could take months. Instead, Apple relied on computer-aided design (CAD) using the three-dimensional (3D) modeling program Alias Wavefront to sculpt designs, and CNC milling machines and primitive 3D printers to create physical mockups. Apple's product designers wrote software to allow the Wavefront 3D models to be brought into Unigraphics, a program that was used in aerospace design. This process allowed the engineers to compare 3D models of the computer's components with the casing, speeding up the process of finding a workable combination of external and internal elements."
    },
    {
        "source": "When discussing the idea of a machine that inspired positive emotions, the designers mentioned colorful candy dispensers. Materials tests with solid plastics looked cheap, so they made the case translucent. Translucent hardware design was not new to Apple's products; the Power Macintosh 8600, 9600, and Power Macintosh G3 tower computers had translucent green latches, and the LaserWriter 8500, eMate 300, and Studio Display incorporated translucent colored plastics more extensively. Former Apple senior designer Thomas Meyerhoffer described the eMate's plastics as a way of making the product accessible and distinctive. To Ive, the translucency \"came across as cheeky\" but meant the aesthetic design of the internal components would also need to be considered. Inspiration came from translucent items the designers brought to the office; one item was a piece of greenish-blue beach glass. This \"Bondi blue\" object inspired the color Jobs selected for the first iMac. Apple's design team radically overhauled its processes to meet the tight deadline. In the past, they had sent two-dimensional blueprints or hand-drawn sketches to toolmakers to create molds, a laborious process that could take months. Instead, Apple relied on computer-aided design (CAD) using the three-dimensional (3D) modeling program Alias Wavefront to sculpt designs, and CNC milling machines and primitive 3D printers to create physical mockups. Apple's product designers wrote software to allow the Wavefront 3D models to be brought into Unigraphics, a program that was used in aerospace design. This process allowed the engineers to compare 3D models of the computer's components with the casing, speeding up the process of finding a workable combination of external and internal elements.",
        "target": "Jobs reconsidered the network computer concept as similar products struggled in the market, and recalibrated the project as a full-featured computer with optical disc storage and hard drives. The finalized iMac's components and 15-inch (38cm) cathode-ray tube (CRT) display are enclosed within a plastic shell. The computer features translucency throughout, such as the small foot to raise the computer, and the power cord resembling condensation on glass. Port labels and regulatory markings have holographic stickers. The design team added a recessed handle to the back of the computer to make it more personal and approachable for new computer users. The cost of the casing was more than three times that of a typical computer but Ive credited Jobs with intuitively understanding the design aims and not demanding justification for the increased costs. The keyboard and mouse were redesigned with matching translucent plastics and trim for the iMac. Ive was especially proud of the round mouse, which shows the complicated internal components that are partially hidden behind the Apple logo."
    },
    {
        "source": "Apple's design team radically overhauled its processes to meet the tight deadline. In the past, they had sent two-dimensional blueprints or hand-drawn sketches to toolmakers to create molds, a laborious process that could take months. Instead, Apple relied on computer-aided design (CAD) using the three-dimensional (3D) modeling program Alias Wavefront to sculpt designs, and CNC milling machines and primitive 3D printers to create physical mockups. Apple's product designers wrote software to allow the Wavefront 3D models to be brought into Unigraphics, a program that was used in aerospace design. This process allowed the engineers to compare 3D models of the computer's components with the casing, speeding up the process of finding a workable combination of external and internal elements. Jobs reconsidered the network computer concept as similar products struggled in the market, and recalibrated the project as a full-featured computer with optical disc storage and hard drives. The finalized iMac's components and 15-inch (38cm) cathode-ray tube (CRT) display are enclosed within a plastic shell. The computer features translucency throughout, such as the small foot to raise the computer, and the power cord resembling condensation on glass. Port labels and regulatory markings have holographic stickers. The design team added a recessed handle to the back of the computer to make it more personal and approachable for new computer users. The cost of the casing was more than three times that of a typical computer but Ive credited Jobs with intuitively understanding the design aims and not demanding justification for the increased costs. The keyboard and mouse were redesigned with matching translucent plastics and trim for the iMac. Ive was especially proud of the round mouse, which shows the complicated internal components that are partially hidden behind the Apple logo.",
        "target": "Jobs wanted the new computer to be a modern, legacy-free PC without old or proprietary technology. Engineers adapted the Common Hardware Reference Platform specification to speed development. This included standard SO-DIMM RAM of Windows-based PCs, and an Open Firmware read-only memory (ROM). Previous Macintosh computers had complex, machine-specific ROMs but the new computer's instructions were loaded from memory, shortening production time. The iMac has no serial ports, Apple Desktop Bus, or floppy disk drive. To replace the removed ports, the iMac has Universal Serial Bus (USB) ports, which were faster and cheaper than Apple Desktop Bus and serial ports but were very newthe standard was not finalized until after the iMac's releaseand unsupported by any third-party Mac peripheral. Jobs wagered USB would solve the problem of accessory makers abandoning the shrinking Mac market with its special connectors. The iMac does not officially have an expansion slot, but early versions include a \"mezzanine slot\" intended for internal use but which a few third parties produced expansion cards for, such as video card upgrades and SCSI ports. Early models have an IrDA infrared port that wirelessly connects personal digital assistants and other devices. Jobs was furious the initial iMac model came with a tray-loading CD-ROM drive rather than a more-modern slot-loading drive, and nearly canceled the product launch over it. According to Jon Rubinstein, Jobs had always known about the CD tray. Jobs continued with the launch after he was assured subsequent models would include a slot-loading CD-ROM drive as soon as possible."
    },
    {
        "source": "Jobs reconsidered the network computer concept as similar products struggled in the market, and recalibrated the project as a full-featured computer with optical disc storage and hard drives. The finalized iMac's components and 15-inch (38cm) cathode-ray tube (CRT) display are enclosed within a plastic shell. The computer features translucency throughout, such as the small foot to raise the computer, and the power cord resembling condensation on glass. Port labels and regulatory markings have holographic stickers. The design team added a recessed handle to the back of the computer to make it more personal and approachable for new computer users. The cost of the casing was more than three times that of a typical computer but Ive credited Jobs with intuitively understanding the design aims and not demanding justification for the increased costs. The keyboard and mouse were redesigned with matching translucent plastics and trim for the iMac. Ive was especially proud of the round mouse, which shows the complicated internal components that are partially hidden behind the Apple logo. Jobs wanted the new computer to be a modern, legacy-free PC without old or proprietary technology. Engineers adapted the Common Hardware Reference Platform specification to speed development. This included standard SO-DIMM RAM of Windows-based PCs, and an Open Firmware read-only memory (ROM). Previous Macintosh computers had complex, machine-specific ROMs but the new computer's instructions were loaded from memory, shortening production time. The iMac has no serial ports, Apple Desktop Bus, or floppy disk drive. To replace the removed ports, the iMac has Universal Serial Bus (USB) ports, which were faster and cheaper than Apple Desktop Bus and serial ports but were very newthe standard was not finalized until after the iMac's releaseand unsupported by any third-party Mac peripheral. Jobs wagered USB would solve the problem of accessory makers abandoning the shrinking Mac market with its special connectors. The iMac does not officially have an expansion slot, but early versions include a \"mezzanine slot\" intended for internal use but which a few third parties produced expansion cards for, such as video card upgrades and SCSI ports. Early models have an IrDA infrared port that wirelessly connects personal digital assistants and other devices. Jobs was furious the initial iMac model came with a tray-loading CD-ROM drive rather than a more-modern slot-loading drive, and nearly canceled the product launch over it. According to Jon Rubinstein, Jobs had always known about the CD tray. Jobs continued with the launch after he was assured subsequent models would include a slot-loading CD-ROM drive as soon as possible.",
        "target": "In early 1998, representatives from the advertising agency TBWA\\Chiat\\Day were shown the new computer, codenamed \"C1\". Creative director Ken Segall said the agency's first impression was that the product might be too shocking to be successful. Jobs was proud to show off Apple's work, saying \"the back of our computer looks better than the front of [our competitors'] computers\". Jobs informed Segall the internal name was \"MacMan\", contributed by Apple's marketing executive Phil Schiller, and solicited a study for a better name. Apple stipulated the name must contain \"Mac\", it must evoke easy Internet connectivity, and it must not sound portable or toy-like. TBWA spent a week developing other names; Segall's pick was \"iMac\"; it was short, it said the product was a Macintosh computer, and the i prefix suggested the internet. Jobs disliked all of the suggested names and gave the agency another week to generate more possibilities. At the next presentation, Segall once again ended with \"iMac\"; Jobs said he no longer hated the name but still preferred \"MacMan\". Segall thought he had failed, but the next day he learned Jobs had suggested the name to other employees and gotten a positive response. The product was thus named the iMac."
    },
    {
        "source": "Jobs wanted the new computer to be a modern, legacy-free PC without old or proprietary technology. Engineers adapted the Common Hardware Reference Platform specification to speed development. This included standard SO-DIMM RAM of Windows-based PCs, and an Open Firmware read-only memory (ROM). Previous Macintosh computers had complex, machine-specific ROMs but the new computer's instructions were loaded from memory, shortening production time. The iMac has no serial ports, Apple Desktop Bus, or floppy disk drive. To replace the removed ports, the iMac has Universal Serial Bus (USB) ports, which were faster and cheaper than Apple Desktop Bus and serial ports but were very newthe standard was not finalized until after the iMac's releaseand unsupported by any third-party Mac peripheral. Jobs wagered USB would solve the problem of accessory makers abandoning the shrinking Mac market with its special connectors. The iMac does not officially have an expansion slot, but early versions include a \"mezzanine slot\" intended for internal use but which a few third parties produced expansion cards for, such as video card upgrades and SCSI ports. Early models have an IrDA infrared port that wirelessly connects personal digital assistants and other devices. Jobs was furious the initial iMac model came with a tray-loading CD-ROM drive rather than a more-modern slot-loading drive, and nearly canceled the product launch over it. According to Jon Rubinstein, Jobs had always known about the CD tray. Jobs continued with the launch after he was assured subsequent models would include a slot-loading CD-ROM drive as soon as possible. In early 1998, representatives from the advertising agency TBWA\\Chiat\\Day were shown the new computer, codenamed \"C1\". Creative director Ken Segall said the agency's first impression was that the product might be too shocking to be successful. Jobs was proud to show off Apple's work, saying \"the back of our computer looks better than the front of [our competitors'] computers\". Jobs informed Segall the internal name was \"MacMan\", contributed by Apple's marketing executive Phil Schiller, and solicited a study for a better name. Apple stipulated the name must contain \"Mac\", it must evoke easy Internet connectivity, and it must not sound portable or toy-like. TBWA spent a week developing other names; Segall's pick was \"iMac\"; it was short, it said the product was a Macintosh computer, and the i prefix suggested the internet. Jobs disliked all of the suggested names and gave the agency another week to generate more possibilities. At the next presentation, Segall once again ended with \"iMac\"; Jobs said he no longer hated the name but still preferred \"MacMan\". Segall thought he had failed, but the next day he learned Jobs had suggested the name to other employees and gotten a positive response. The product was thus named the iMac.",
        "target": "Steve Jobs unveiled the iMac on May 6, 1998. The product launch echoed that of the original Macintosh 128K in 1984. It was staged in the same location, the Flint Center for the Performing Arts at De Anza College. Jobs invited Apple founding members Steve Wozniak, Mike Markkula, and Michael Scott, as well as members of the original Macintosh team. After demonstrating the look of traditional computers, Jobs revealed the iMac from under a tablecloth. The computer displayed \"Hello (again)\" on its screen, hearkening back to the Macintosh's whimsical \"Hello\" introduction."
    },
    {
        "source": "In early 1998, representatives from the advertising agency TBWA\\Chiat\\Day were shown the new computer, codenamed \"C1\". Creative director Ken Segall said the agency's first impression was that the product might be too shocking to be successful. Jobs was proud to show off Apple's work, saying \"the back of our computer looks better than the front of [our competitors'] computers\". Jobs informed Segall the internal name was \"MacMan\", contributed by Apple's marketing executive Phil Schiller, and solicited a study for a better name. Apple stipulated the name must contain \"Mac\", it must evoke easy Internet connectivity, and it must not sound portable or toy-like. TBWA spent a week developing other names; Segall's pick was \"iMac\"; it was short, it said the product was a Macintosh computer, and the i prefix suggested the internet. Jobs disliked all of the suggested names and gave the agency another week to generate more possibilities. At the next presentation, Segall once again ended with \"iMac\"; Jobs said he no longer hated the name but still preferred \"MacMan\". Segall thought he had failed, but the next day he learned Jobs had suggested the name to other employees and gotten a positive response. The product was thus named the iMac. Steve Jobs unveiled the iMac on May 6, 1998. The product launch echoed that of the original Macintosh 128K in 1984. It was staged in the same location, the Flint Center for the Performing Arts at De Anza College. Jobs invited Apple founding members Steve Wozniak, Mike Markkula, and Michael Scott, as well as members of the original Macintosh team. After demonstrating the look of traditional computers, Jobs revealed the iMac from under a tablecloth. The computer displayed \"Hello (again)\" on its screen, hearkening back to the Macintosh's whimsical \"Hello\" introduction.",
        "target": "Apple began shipping the iMac on August 15, 1998. The computer was supported by a $100million advertising campaign that stressed the iMac's ease of use, internet connectivity, and striking contrast from competitors' products. Actor Jeff Goldblum narrated television advertisements that rhetorically asked if computer companies had been in \"thinking jail\" making only beige products. Other promotions included radio giveaways, midnight launch events, and \"golden tickets\" hidden in select iMacs that could be redeemed for a tour of an Apple factory. To make sure Apple was able to ship as many Macs as possible, operations executive Tim Cook prebooked $100million in air freight. Apple was able to meet demand while at the same time causing shipping delays for their competitors during the holiday season."
    },
    {
        "source": "Steve Jobs unveiled the iMac on May 6, 1998. The product launch echoed that of the original Macintosh 128K in 1984. It was staged in the same location, the Flint Center for the Performing Arts at De Anza College. Jobs invited Apple founding members Steve Wozniak, Mike Markkula, and Michael Scott, as well as members of the original Macintosh team. After demonstrating the look of traditional computers, Jobs revealed the iMac from under a tablecloth. The computer displayed \"Hello (again)\" on its screen, hearkening back to the Macintosh's whimsical \"Hello\" introduction. Apple began shipping the iMac on August 15, 1998. The computer was supported by a $100million advertising campaign that stressed the iMac's ease of use, internet connectivity, and striking contrast from competitors' products. Actor Jeff Goldblum narrated television advertisements that rhetorically asked if computer companies had been in \"thinking jail\" making only beige products. Other promotions included radio giveaways, midnight launch events, and \"golden tickets\" hidden in select iMacs that could be redeemed for a tour of an Apple factory. To make sure Apple was able to ship as many Macs as possible, operations executive Tim Cook prebooked $100million in air freight. Apple was able to meet demand while at the same time causing shipping delays for their competitors during the holiday season.",
        "target": "The first release of the iMac G3 had a 233MHz PowerPC G3 processor, ATI Rage IIc graphics, 4GB hard drive, a tray-loading CD-ROM drive, two USB ports, networking, an infrared port, built-in stereo speakers, and headphone ports. Its casing was Bondi bluecolored and it shipped with MacOS 8.1. On October 17, the iMac was updated with faster ATI Rage Pro Turbo graphics options and MacOS 8.5. A more substantial revision to the iMac lineup came in January 1999. These new models came in five colors: blueberry, strawberry, tangerine, grape, and lime. They had a 266MHz processor and a 6GB hard drive. The infrared port and mezzanine slot were removed."
    },
    {
        "source": "Apple began shipping the iMac on August 15, 1998. The computer was supported by a $100million advertising campaign that stressed the iMac's ease of use, internet connectivity, and striking contrast from competitors' products. Actor Jeff Goldblum narrated television advertisements that rhetorically asked if computer companies had been in \"thinking jail\" making only beige products. Other promotions included radio giveaways, midnight launch events, and \"golden tickets\" hidden in select iMacs that could be redeemed for a tour of an Apple factory. To make sure Apple was able to ship as many Macs as possible, operations executive Tim Cook prebooked $100million in air freight. Apple was able to meet demand while at the same time causing shipping delays for their competitors during the holiday season. The first release of the iMac G3 had a 233MHz PowerPC G3 processor, ATI Rage IIc graphics, 4GB hard drive, a tray-loading CD-ROM drive, two USB ports, networking, an infrared port, built-in stereo speakers, and headphone ports. Its casing was Bondi bluecolored and it shipped with MacOS 8.1. On October 17, the iMac was updated with faster ATI Rage Pro Turbo graphics options and MacOS 8.5. A more substantial revision to the iMac lineup came in January 1999. These new models came in five colors: blueberry, strawberry, tangerine, grape, and lime. They had a 266MHz processor and a 6GB hard drive. The infrared port and mezzanine slot were removed.",
        "target": "Apple released a new series of iMacs on October 5, 1999, focused on the emerging digital video (DV) market. The new models were similar in appearance to the previous models but had a slightly smaller enclosure; the steel casing shrouding many of the components in the previous model was removed, the colors were lighter, and the plastics clearer. The tray-loading CD-ROM drive was replaced with a slot-loading drive and a rear door was fitted so users could easily add  RAM, and a slot for an AirPort wireless networking card was added. The computer's components were cooled fanlessly by convection, with hot air exhausted through vents around the top handle. Three new models were offered, and some colors and features were restricted to certain models. The cheapest model, now at $999, was available in only one color. It shipped with a 350MHz processor, 64MB of RAM, a new graphics chipset, and a larger hard drive. The iMac DV came in five colors and shipped with the video-editing software iMovie. It also had a 400MHz processor, two FireWire ports for high-speed connectivity, a larger hard drive, and DVD-ROM optical drive. The iMac DV Special Edition came in a new color named graphite, and shipped with more RAM and a 13GB hard drivethe largest capacity in the line-up. The iMac DV models also included a VGA video-out port for mirroring the iMac's display on another monitor."
    },
    {
        "source": "The first release of the iMac G3 had a 233MHz PowerPC G3 processor, ATI Rage IIc graphics, 4GB hard drive, a tray-loading CD-ROM drive, two USB ports, networking, an infrared port, built-in stereo speakers, and headphone ports. Its casing was Bondi bluecolored and it shipped with MacOS 8.1. On October 17, the iMac was updated with faster ATI Rage Pro Turbo graphics options and MacOS 8.5. A more substantial revision to the iMac lineup came in January 1999. These new models came in five colors: blueberry, strawberry, tangerine, grape, and lime. They had a 266MHz processor and a 6GB hard drive. The infrared port and mezzanine slot were removed. Apple released a new series of iMacs on October 5, 1999, focused on the emerging digital video (DV) market. The new models were similar in appearance to the previous models but had a slightly smaller enclosure; the steel casing shrouding many of the components in the previous model was removed, the colors were lighter, and the plastics clearer. The tray-loading CD-ROM drive was replaced with a slot-loading drive and a rear door was fitted so users could easily add  RAM, and a slot for an AirPort wireless networking card was added. The computer's components were cooled fanlessly by convection, with hot air exhausted through vents around the top handle. Three new models were offered, and some colors and features were restricted to certain models. The cheapest model, now at $999, was available in only one color. It shipped with a 350MHz processor, 64MB of RAM, a new graphics chipset, and a larger hard drive. The iMac DV came in five colors and shipped with the video-editing software iMovie. It also had a 400MHz processor, two FireWire ports for high-speed connectivity, a larger hard drive, and DVD-ROM optical drive. The iMac DV Special Edition came in a new color named graphite, and shipped with more RAM and a 13GB hard drivethe largest capacity in the line-up. The iMac DV models also included a VGA video-out port for mirroring the iMac's display on another monitor.",
        "target": "On July 19, 2000, Apple released a new iMac lineup with four configurations in five colors. The base model had no FireWire port or video-out socket, came in an indigo casing, and retailed for $799. It had the same processor and memory as the previous iMac with a larger hard drive. The iMac DV and DV+ models had 400MHz and 450MHz processors, respectively, and larger hard drives; and the DV+ model had a DVD-ROM drive. The most expensive model was the iMac DV Special Edition, which had a 500MHz processor, 128MB of RAM, a larger hard drive, and an exclusive snow color."
    },
    {
        "source": "Apple released a new series of iMacs on October 5, 1999, focused on the emerging digital video (DV) market. The new models were similar in appearance to the previous models but had a slightly smaller enclosure; the steel casing shrouding many of the components in the previous model was removed, the colors were lighter, and the plastics clearer. The tray-loading CD-ROM drive was replaced with a slot-loading drive and a rear door was fitted so users could easily add  RAM, and a slot for an AirPort wireless networking card was added. The computer's components were cooled fanlessly by convection, with hot air exhausted through vents around the top handle. Three new models were offered, and some colors and features were restricted to certain models. The cheapest model, now at $999, was available in only one color. It shipped with a 350MHz processor, 64MB of RAM, a new graphics chipset, and a larger hard drive. The iMac DV came in five colors and shipped with the video-editing software iMovie. It also had a 400MHz processor, two FireWire ports for high-speed connectivity, a larger hard drive, and DVD-ROM optical drive. The iMac DV Special Edition came in a new color named graphite, and shipped with more RAM and a 13GB hard drivethe largest capacity in the line-up. The iMac DV models also included a VGA video-out port for mirroring the iMac's display on another monitor. On July 19, 2000, Apple released a new iMac lineup with four configurations in five colors. The base model had no FireWire port or video-out socket, came in an indigo casing, and retailed for $799. It had the same processor and memory as the previous iMac with a larger hard drive. The iMac DV and DV+ models had 400MHz and 450MHz processors, respectively, and larger hard drives; and the DV+ model had a DVD-ROM drive. The most expensive model was the iMac DV Special Edition, which had a 500MHz processor, 128MB of RAM, a larger hard drive, and an exclusive snow color.",
        "target": "Apple's next iMac revision was released on February 22, 2001. The new machines came with CD-RW drives and iTunes software as Apple shifted to digital music consumption. The iMac and iMac Special Edition shipped with 400to 600MHz processors and FireWire became standard alongside a faster graphics chipset and larger hard drives. Apple supplemented the existing indigo and graphite colors with two new patterns, \"Flower Power\" and \"Blue Dalmatian\", which were intended as visual representations of music."
    },
    {
        "source": "On July 19, 2000, Apple released a new iMac lineup with four configurations in five colors. The base model had no FireWire port or video-out socket, came in an indigo casing, and retailed for $799. It had the same processor and memory as the previous iMac with a larger hard drive. The iMac DV and DV+ models had 400MHz and 450MHz processors, respectively, and larger hard drives; and the DV+ model had a DVD-ROM drive. The most expensive model was the iMac DV Special Edition, which had a 500MHz processor, 128MB of RAM, a larger hard drive, and an exclusive snow color. Apple's next iMac revision was released on February 22, 2001. The new machines came with CD-RW drives and iTunes software as Apple shifted to digital music consumption. The iMac and iMac Special Edition shipped with 400to 600MHz processors and FireWire became standard alongside a faster graphics chipset and larger hard drives. Apple supplemented the existing indigo and graphite colors with two new patterns, \"Flower Power\" and \"Blue Dalmatian\", which were intended as visual representations of music.",
        "target": "A final revision in July 2001 returned to more sedate colorsindigo, graphite, and snow. These models shipped with Mac OS X, 500, 600, or 700MHz processors, up to 256MB of RAM, and a 60GB hard drive on the Special Edition. Following the introduction of the iMac G4 in January 2002, Apple continued selling some G3-based iMac models, with 500 and 600MHz models in indigo, snow, and graphite. The indigo and graphite models were discontinued first, and the snow model was discontinued in March 2003."
    },
    {
        "source": "Apple's next iMac revision was released on February 22, 2001. The new machines came with CD-RW drives and iTunes software as Apple shifted to digital music consumption. The iMac and iMac Special Edition shipped with 400to 600MHz processors and FireWire became standard alongside a faster graphics chipset and larger hard drives. Apple supplemented the existing indigo and graphite colors with two new patterns, \"Flower Power\" and \"Blue Dalmatian\", which were intended as visual representations of music. A final revision in July 2001 returned to more sedate colorsindigo, graphite, and snow. These models shipped with Mac OS X, 500, 600, or 700MHz processors, up to 256MB of RAM, and a 60GB hard drive on the Special Edition. Following the introduction of the iMac G4 in January 2002, Apple continued selling some G3-based iMac models, with 500 and 600MHz models in indigo, snow, and graphite. The indigo and graphite models were discontinued first, and the snow model was discontinued in March 2003.",
        "target": "The iMac G3 received mixed reviews on release. Tech reviewers were often negative about the machine. Hiawatha Bray said the choices Jobs had made with the iMac doomed the product. In comparison, Macworld's Andrew Gore said the iMac G3 might be as important as the original Macintosh in shifting the computing paradigm, and that Apple's \"Think different\" marketing campaign was not just empty talk. Reporters including Newsweek's Barbara Kantrowitz and the San Francisco Chronicle's David Einstein considered it the first promising step in Apple's possible resurgence."
    },
    {
        "source": "A final revision in July 2001 returned to more sedate colorsindigo, graphite, and snow. These models shipped with Mac OS X, 500, 600, or 700MHz processors, up to 256MB of RAM, and a 60GB hard drive on the Special Edition. Following the introduction of the iMac G4 in January 2002, Apple continued selling some G3-based iMac models, with 500 and 600MHz models in indigo, snow, and graphite. The indigo and graphite models were discontinued first, and the snow model was discontinued in March 2003. The iMac G3 received mixed reviews on release. Tech reviewers were often negative about the machine. Hiawatha Bray said the choices Jobs had made with the iMac doomed the product. In comparison, Macworld's Andrew Gore said the iMac G3 might be as important as the original Macintosh in shifting the computing paradigm, and that Apple's \"Think different\" marketing campaign was not just empty talk. Reporters including Newsweek's Barbara Kantrowitz and the San Francisco Chronicle's David Einstein considered it the first promising step in Apple's possible resurgence.",
        "target": "The look of the iMac was generally praised. Many reviewers compared its curved look to the recently released Volkswagen New Beetle,  journalist Rob Morse likened it to a \"huggable\", futuristic machine like R2-D2 or a toy from The Jetsons. Less-positive reviews compared the iMac to an AMC Gremlin."
    },
    {
        "source": "The iMac G3 received mixed reviews on release. Tech reviewers were often negative about the machine. Hiawatha Bray said the choices Jobs had made with the iMac doomed the product. In comparison, Macworld's Andrew Gore said the iMac G3 might be as important as the original Macintosh in shifting the computing paradigm, and that Apple's \"Think different\" marketing campaign was not just empty talk. Reporters including Newsweek's Barbara Kantrowitz and the San Francisco Chronicle's David Einstein considered it the first promising step in Apple's possible resurgence. The look of the iMac was generally praised. Many reviewers compared its curved look to the recently released Volkswagen New Beetle,  journalist Rob Morse likened it to a \"huggable\", futuristic machine like R2-D2 or a toy from The Jetsons. Less-positive reviews compared the iMac to an AMC Gremlin.",
        "target": "Positive reviews highlighted the computer's ease of use for setup and operation; According to Morse, the iMac felt \"almost human\" and approachable for a non-tech consumer. Publications including CNN and PC Week considered the iMac's performance fast, but others felt the machine was underpowered, and PC World's testing showed that the machine generally performed less well than Windows PC competitors. Although reviewers noted that general consumers and new computer buyers would be well-served by the machine, they were less sure that it could fit into an office environment, especially if it was not networked."
    },
    {
        "source": "The look of the iMac was generally praised. Many reviewers compared its curved look to the recently released Volkswagen New Beetle,  journalist Rob Morse likened it to a \"huggable\", futuristic machine like R2-D2 or a toy from The Jetsons. Less-positive reviews compared the iMac to an AMC Gremlin. Positive reviews highlighted the computer's ease of use for setup and operation; According to Morse, the iMac felt \"almost human\" and approachable for a non-tech consumer. Publications including CNN and PC Week considered the iMac's performance fast, but others felt the machine was underpowered, and PC World's testing showed that the machine generally performed less well than Windows PC competitors. Although reviewers noted that general consumers and new computer buyers would be well-served by the machine, they were less sure that it could fit into an office environment, especially if it was not networked.",
        "target": "Criticism focused on the iMac's lack of legacy ports. Bray wrote that the lack of a floppy drive essentially wrote off most potential buyers in favor of \"'elites' [who will] pay more for less\". Gore considered the loss of the floppy drive acceptable but wished that the CD-ROM module, which was identical to that of the PowerBook notebook, could be swapped. He said the lack of expansion slots limited the computer's future potential. The Washington Post's John Breeden highlighted the lack of SCSI as making the iMac unsuitable for office work. Other reviewers bemoaned the high cost of external replacements for the internal floppy disk drive, low amount of installed memory, and its tinny speakers."
    },
    {
        "source": "Positive reviews highlighted the computer's ease of use for setup and operation; According to Morse, the iMac felt \"almost human\" and approachable for a non-tech consumer. Publications including CNN and PC Week considered the iMac's performance fast, but others felt the machine was underpowered, and PC World's testing showed that the machine generally performed less well than Windows PC competitors. Although reviewers noted that general consumers and new computer buyers would be well-served by the machine, they were less sure that it could fit into an office environment, especially if it was not networked. Criticism focused on the iMac's lack of legacy ports. Bray wrote that the lack of a floppy drive essentially wrote off most potential buyers in favor of \"'elites' [who will] pay more for less\". Gore considered the loss of the floppy drive acceptable but wished that the CD-ROM module, which was identical to that of the PowerBook notebook, could be swapped. He said the lack of expansion slots limited the computer's future potential. The Washington Post's John Breeden highlighted the lack of SCSI as making the iMac unsuitable for office work. Other reviewers bemoaned the high cost of external replacements for the internal floppy disk drive, low amount of installed memory, and its tinny speakers.",
        "target": "Another major complaint with the iMac was its original mouse and keyboard, which reviewers said were small and difficult to use comfortably, calling them an example of style over substance. The shape of the mouse was derisively compared to a hockey puck, and its reviewers considered the cable too short. The mouse's round shape made it difficult for users to discern its correct orientation. The mouse and keyboard were replaced with the Apple Pro Mouse and Apple Pro Keyboard for the 2000-revision iMacs. Other complaints included the lack of software and USB accessories, incompatibility with Microsoft Windows, and price. Later iMac G3 models addressed some of the product's perceived shortcomings. As the product line aged, reviews noted the new models offered few advancements over previous versions."
    },
    {
        "source": "Criticism focused on the iMac's lack of legacy ports. Bray wrote that the lack of a floppy drive essentially wrote off most potential buyers in favor of \"'elites' [who will] pay more for less\". Gore considered the loss of the floppy drive acceptable but wished that the CD-ROM module, which was identical to that of the PowerBook notebook, could be swapped. He said the lack of expansion slots limited the computer's future potential. The Washington Post's John Breeden highlighted the lack of SCSI as making the iMac unsuitable for office work. Other reviewers bemoaned the high cost of external replacements for the internal floppy disk drive, low amount of installed memory, and its tinny speakers. Another major complaint with the iMac was its original mouse and keyboard, which reviewers said were small and difficult to use comfortably, calling them an example of style over substance. The shape of the mouse was derisively compared to a hockey puck, and its reviewers considered the cable too short. The mouse's round shape made it difficult for users to discern its correct orientation. The mouse and keyboard were replaced with the Apple Pro Mouse and Apple Pro Keyboard for the 2000-revision iMacs. Other complaints included the lack of software and USB accessories, incompatibility with Microsoft Windows, and price. Later iMac G3 models addressed some of the product's perceived shortcomings. As the product line aged, reviews noted the new models offered few advancements over previous versions.",
        "target": "The iMac won several design competitions and awards, including Gold at the 1999 D&AD Design Awards in the UK, and \"Object of the Year\" by The Face. iMac G3 models are held in the collections of museums including the Henry Ford, the Victoria and Albert Museum, the Powerhouse Museum, and the Museum of Modern Art."
    },
    {
        "source": "Another major complaint with the iMac was its original mouse and keyboard, which reviewers said were small and difficult to use comfortably, calling them an example of style over substance. The shape of the mouse was derisively compared to a hockey puck, and its reviewers considered the cable too short. The mouse's round shape made it difficult for users to discern its correct orientation. The mouse and keyboard were replaced with the Apple Pro Mouse and Apple Pro Keyboard for the 2000-revision iMacs. Other complaints included the lack of software and USB accessories, incompatibility with Microsoft Windows, and price. Later iMac G3 models addressed some of the product's perceived shortcomings. As the product line aged, reviews noted the new models offered few advancements over previous versions. The iMac won several design competitions and awards, including Gold at the 1999 D&AD Design Awards in the UK, and \"Object of the Year\" by The Face. iMac G3 models are held in the collections of museums including the Henry Ford, the Victoria and Albert Museum, the Powerhouse Museum, and the Museum of Modern Art.",
        "target": "The iMac G3 was an immediate hit with consumers, with 278,000 units sold in the first six weeks, and 800,000 units after 20 weeks. It was the top-selling desktop computer in US stores the first three months of its release. Nearly half of iMac sales were to first-time computer buyers, and nearly 20 percent were Microsoft Windows users who switched to the Mac. In the quarter the iMac shipped, Macintosh computer sales grew year-on-year for the first time since late 1995, and saw the Mac grow its worldwide market share from 3 to 5 percent. Apple went from losing $878million in 1997 to making $414million in 1998, its first profit in three years. The iMac continued to be a strong seller for Apple, with 3.7million units sold by July 2000, and shipping the five-millionth iMac in April 2001. In announcing the computer's successor in January 2002, Jobs said that the iMac had sold 6 million units."
    },
    {
        "source": "The iMac won several design competitions and awards, including Gold at the 1999 D&AD Design Awards in the UK, and \"Object of the Year\" by The Face. iMac G3 models are held in the collections of museums including the Henry Ford, the Victoria and Albert Museum, the Powerhouse Museum, and the Museum of Modern Art. The iMac G3 was an immediate hit with consumers, with 278,000 units sold in the first six weeks, and 800,000 units after 20 weeks. It was the top-selling desktop computer in US stores the first three months of its release. Nearly half of iMac sales were to first-time computer buyers, and nearly 20 percent were Microsoft Windows users who switched to the Mac. In the quarter the iMac shipped, Macintosh computer sales grew year-on-year for the first time since late 1995, and saw the Mac grow its worldwide market share from 3 to 5 percent. Apple went from losing $878million in 1997 to making $414million in 1998, its first profit in three years. The iMac continued to be a strong seller for Apple, with 3.7million units sold by July 2000, and shipping the five-millionth iMac in April 2001. In announcing the computer's successor in January 2002, Jobs said that the iMac had sold 6 million units.",
        "target": "The iMac G3 became a computing icon. Paul Atkinson wrote that the original Macintosh made a huge impact on computing, but it had not affected the look of computers; for decades, personal computers were defined by unimaginative, beige boxes. The iMac, in contrast, did not affect the way consumers used computers but its design changed the idea of the appearance of computers. Apple defined itself in opposition to its competitors, who rushed to produce computers that followed the iMac's design language, adding similar translucent or colored plastic to their designs. The iMac mirrored contemporary design trends in its use of streamlining and curves; one designer said the focus on rounding helped make objects more approachable and personal."
    },
    {
        "source": "The iMac G3 was an immediate hit with consumers, with 278,000 units sold in the first six weeks, and 800,000 units after 20 weeks. It was the top-selling desktop computer in US stores the first three months of its release. Nearly half of iMac sales were to first-time computer buyers, and nearly 20 percent were Microsoft Windows users who switched to the Mac. In the quarter the iMac shipped, Macintosh computer sales grew year-on-year for the first time since late 1995, and saw the Mac grow its worldwide market share from 3 to 5 percent. Apple went from losing $878million in 1997 to making $414million in 1998, its first profit in three years. The iMac continued to be a strong seller for Apple, with 3.7million units sold by July 2000, and shipping the five-millionth iMac in April 2001. In announcing the computer's successor in January 2002, Jobs said that the iMac had sold 6 million units. The iMac G3 became a computing icon. Paul Atkinson wrote that the original Macintosh made a huge impact on computing, but it had not affected the look of computers; for decades, personal computers were defined by unimaginative, beige boxes. The iMac, in contrast, did not affect the way consumers used computers but its design changed the idea of the appearance of computers. Apple defined itself in opposition to its competitors, who rushed to produce computers that followed the iMac's design language, adding similar translucent or colored plastic to their designs. The iMac mirrored contemporary design trends in its use of streamlining and curves; one designer said the focus on rounding helped make objects more approachable and personal.",
        "target": "Apple protected the distinctive iMac design with legal action against competing computer makers who attempted to imitate the iMac, such as eMachines' eOne. The iMac made computers fashionable rather than utilitarian, and helped popularize USB and hasten the demise of the floppy disk. Following Apple's lead, other computer makers focused on \"legacy-free\" personal computers."
    },
    {
        "source": "The iMac G3 became a computing icon. Paul Atkinson wrote that the original Macintosh made a huge impact on computing, but it had not affected the look of computers; for decades, personal computers were defined by unimaginative, beige boxes. The iMac, in contrast, did not affect the way consumers used computers but its design changed the idea of the appearance of computers. Apple defined itself in opposition to its competitors, who rushed to produce computers that followed the iMac's design language, adding similar translucent or colored plastic to their designs. The iMac mirrored contemporary design trends in its use of streamlining and curves; one designer said the focus on rounding helped make objects more approachable and personal. Apple protected the distinctive iMac design with legal action against competing computer makers who attempted to imitate the iMac, such as eMachines' eOne. The iMac made computers fashionable rather than utilitarian, and helped popularize USB and hasten the demise of the floppy disk. Following Apple's lead, other computer makers focused on \"legacy-free\" personal computers.",
        "target": "The iMac's sales helped buoy Apple while it released a modern operating system and refreshed the rest of the Mac lineup. The computer's success positioned the company to focus on emerging digital media trends. It also established a formula of quickly polishing a new Apple product through rapid iterative updates. Macworld noted the iMac saved Apple financially and proved Apple could still produce exciting, innovative products. The iMac also served as the public's introduction to Jony Ive, making him one of the world's most-celebrated designers. The product's name influenced many of Apple's later productssuch as iPod, iLife, and iPhoneand for a time defined Apple's consumer-focused product lines. Apple's consumer laptop the iBook followed the iMac's lead in a lack of legacy technology and use of colorful, translucent plastic. The iMac was so successful in schools Apple created a G4-powered successor named the eMac, initially sold only to the education market."
    },
    {
        "source": "Apple protected the distinctive iMac design with legal action against competing computer makers who attempted to imitate the iMac, such as eMachines' eOne. The iMac made computers fashionable rather than utilitarian, and helped popularize USB and hasten the demise of the floppy disk. Following Apple's lead, other computer makers focused on \"legacy-free\" personal computers. The iMac's sales helped buoy Apple while it released a modern operating system and refreshed the rest of the Mac lineup. The computer's success positioned the company to focus on emerging digital media trends. It also established a formula of quickly polishing a new Apple product through rapid iterative updates. Macworld noted the iMac saved Apple financially and proved Apple could still produce exciting, innovative products. The iMac also served as the public's introduction to Jony Ive, making him one of the world's most-celebrated designers. The product's name influenced many of Apple's later productssuch as iPod, iLife, and iPhoneand for a time defined Apple's consumer-focused product lines. Apple's consumer laptop the iBook followed the iMac's lead in a lack of legacy technology and use of colorful, translucent plastic. The iMac was so successful in schools Apple created a G4-powered successor named the eMac, initially sold only to the education market.",
        "target": "The design influence of the iMac G3 was not limited to personal computers; by the early 2000s, multicolored, translucent plastic designs had become common among consumer designs, including microwave ovens and George Foreman grills. USA Today called the translucence trend \"electronics voyeurism\". Apple would follow the bulbous, candy-colored iMac G3 with the flat-panel, white iMac G4 in 2002. Apple's desktop lineup remained relatively monochrome in the following years; the 2021 release of Apple silicon-based iMacs were sold in seven colors and were considered to hearken back to the iMac's colorful roots."
    },
    {
        "source": " The Macintosh Classic is a personal computer designed, manufactured and sold by Apple Computer from October 1990 to September 1992. It was the first Macintosh to sell for less than US$1,000.",
        "target": "Production of the Classic was prompted by the success of the original Macintosh 128K, then the Macintosh Plus, and finally the Macintosh SE. The system specifications of the Classic are very similar to those of its predecessors, with the same 9-inch (23cm) monochrome CRT display, 512  342pixel resolution, and 4megabyte (MB) memory limit of the older Macintosh computers. Apple's decision to not update the Classic with newer technology such as a newer CPU, higher RAM capacity or color display resulted in criticism from reviewers, with Macworld describing it as having \"nothing to gloat about beyond its low price\" and \"unexceptional\". However, it ensured compatibility with the Mac's by-then healthy software base, as well as enabled it to sell for the lower price, as planned. The Classic also featured several improvements over the aging Macintosh Plus, which it replaced as Apple's low-end Mac computer. It is up to 25percent faster than the Plus and included an Apple SuperDrive 3.5-inch (9cm) floppy disk drive as standard. Unlike the Macintosh SE/30 and other compact Macs before it, the Classic did not have an internal Processor Direct Slot, making it the first non-expandable desktop Macintosh since the Macintosh Plus. Instead, it had a memory expansion slot."
    },
    {
        "source": "The Macintosh Classic is a personal computer designed, manufactured and sold by Apple Computer from October 1990 to September 1992. It was the first Macintosh to sell for less than US$1,000. Production of the Classic was prompted by the success of the original Macintosh 128K, then the Macintosh Plus, and finally the Macintosh SE. The system specifications of the Classic are very similar to those of its predecessors, with the same 9-inch (23cm) monochrome CRT display, 512  342pixel resolution, and 4megabyte (MB) memory limit of the older Macintosh computers. Apple's decision to not update the Classic with newer technology such as a newer CPU, higher RAM capacity or color display resulted in criticism from reviewers, with Macworld describing it as having \"nothing to gloat about beyond its low price\" and \"unexceptional\". However, it ensured compatibility with the Mac's by-then healthy software base, as well as enabled it to sell for the lower price, as planned. The Classic also featured several improvements over the aging Macintosh Plus, which it replaced as Apple's low-end Mac computer. It is up to 25percent faster than the Plus and included an Apple SuperDrive 3.5-inch (9cm) floppy disk drive as standard. Unlike the Macintosh SE/30 and other compact Macs before it, the Classic did not have an internal Processor Direct Slot, making it the first non-expandable desktop Macintosh since the Macintosh Plus. Instead, it had a memory expansion slot.",
        "target": "The Classic is an adaptation of Jerry Manock's and Terry Oyama's 1984 Macintosh 128K industrial design, as had been the earlier Macintosh SE. Apple released two versions. The price and the availability of education software led to the Classic's popularity in education. It was sold alongside the more powerful Macintosh Classic II in 1991 until its discontinuation the next year."
    },
    {
        "source": "Production of the Classic was prompted by the success of the original Macintosh 128K, then the Macintosh Plus, and finally the Macintosh SE. The system specifications of the Classic are very similar to those of its predecessors, with the same 9-inch (23cm) monochrome CRT display, 512  342pixel resolution, and 4megabyte (MB) memory limit of the older Macintosh computers. Apple's decision to not update the Classic with newer technology such as a newer CPU, higher RAM capacity or color display resulted in criticism from reviewers, with Macworld describing it as having \"nothing to gloat about beyond its low price\" and \"unexceptional\". However, it ensured compatibility with the Mac's by-then healthy software base, as well as enabled it to sell for the lower price, as planned. The Classic also featured several improvements over the aging Macintosh Plus, which it replaced as Apple's low-end Mac computer. It is up to 25percent faster than the Plus and included an Apple SuperDrive 3.5-inch (9cm) floppy disk drive as standard. Unlike the Macintosh SE/30 and other compact Macs before it, the Classic did not have an internal Processor Direct Slot, making it the first non-expandable desktop Macintosh since the Macintosh Plus. Instead, it had a memory expansion slot. The Classic is an adaptation of Jerry Manock's and Terry Oyama's 1984 Macintosh 128K industrial design, as had been the earlier Macintosh SE. Apple released two versions. The price and the availability of education software led to the Classic's popularity in education. It was sold alongside the more powerful Macintosh Classic II in 1991 until its discontinuation the next year.",
        "target": "After Apple's co-founder Steve Jobs left Apple in 1985, product development was handed to Jean-Louis Gassee, formerly the manager of Apple France. Gassee consistently pushed the Apple product line in two directions, towards more \"openness\" in terms of expandability and interoperability, and towards higher price. Gassee long argued that Apple should not aim for the low end of the computer market, where profits were thin, but instead concentrate on the high end and higher profit margins. He illustrated the concept using a graph showing the price-performance ratio of computers with low-power, low-cost machines in the lower left and high-power high-cost machines in the upper right. The \"high-right\" goal became a mantra among the upper management, who said \"fifty-five or die\", referring to Gassee's goal of a 55 percent profit margin."
    },
    {
        "source": "The Classic is an adaptation of Jerry Manock's and Terry Oyama's 1984 Macintosh 128K industrial design, as had been the earlier Macintosh SE. Apple released two versions. The price and the availability of education software led to the Classic's popularity in education. It was sold alongside the more powerful Macintosh Classic II in 1991 until its discontinuation the next year. After Apple's co-founder Steve Jobs left Apple in 1985, product development was handed to Jean-Louis Gassee, formerly the manager of Apple France. Gassee consistently pushed the Apple product line in two directions, towards more \"openness\" in terms of expandability and interoperability, and towards higher price. Gassee long argued that Apple should not aim for the low end of the computer market, where profits were thin, but instead concentrate on the high end and higher profit margins. He illustrated the concept using a graph showing the price-performance ratio of computers with low-power, low-cost machines in the lower left and high-power high-cost machines in the upper right. The \"high-right\" goal became a mantra among the upper management, who said \"fifty-five or die\", referring to Gassee's goal of a 55 percent profit margin.",
        "target": "The high-right policy led to a series of machines with ever-increasing prices. The original Macintosh plans called for a system around $1,000, but by the time it had morphed from Jef Raskin's original vision of an easy-to-use machine for composing text documents to Jobs's concept incorporating ideas gleaned during a trip to Xerox PARC, the Mac's list price had ballooned to $2,495."
    },
    {
        "source": "After Apple's co-founder Steve Jobs left Apple in 1985, product development was handed to Jean-Louis Gassee, formerly the manager of Apple France. Gassee consistently pushed the Apple product line in two directions, towards more \"openness\" in terms of expandability and interoperability, and towards higher price. Gassee long argued that Apple should not aim for the low end of the computer market, where profits were thin, but instead concentrate on the high end and higher profit margins. He illustrated the concept using a graph showing the price-performance ratio of computers with low-power, low-cost machines in the lower left and high-power high-cost machines in the upper right. The \"high-right\" goal became a mantra among the upper management, who said \"fifty-five or die\", referring to Gassee's goal of a 55 percent profit margin. The high-right policy led to a series of machines with ever-increasing prices. The original Macintosh plans called for a system around $1,000, but by the time it had morphed from Jef Raskin's original vision of an easy-to-use machine for composing text documents to Jobs's concept incorporating ideas gleaned during a trip to Xerox PARC, the Mac's list price had ballooned to $2,495.",
        "target": "With the \"low-left\" of the market it had abandoned years earlier booming with Turbo XTs, and being ignored on the high end for UNIX workstations from the likes of Sun Microsystems and SGI, Apple's fortunes of the 1980s quickly reversed. The Christmas season of 1989 drove this point home, with the first decrease in sales in years, and an accompanying 20 percent drop in Apple's stock price for the quarter."
    },
    {
        "source": "The high-right policy led to a series of machines with ever-increasing prices. The original Macintosh plans called for a system around $1,000, but by the time it had morphed from Jef Raskin's original vision of an easy-to-use machine for composing text documents to Jobs's concept incorporating ideas gleaned during a trip to Xerox PARC, the Mac's list price had ballooned to $2,495. With the \"low-left\" of the market it had abandoned years earlier booming with Turbo XTs, and being ignored on the high end for UNIX workstations from the likes of Sun Microsystems and SGI, Apple's fortunes of the 1980s quickly reversed. The Christmas season of 1989 drove this point home, with the first decrease in sales in years, and an accompanying 20 percent drop in Apple's stock price for the quarter.",
        "target": "In January 1990, Gassee resigned and his authority over product development was divided among several successors. Many Apple engineers had long been pressing for lower-cost options in order to build market share and increase demand across the entire price spectrum. With Gassee out, a rush started to quickly introduce a series of low-cost machines. Three market points were identified: a very low-cost machine with a target price of $1,000, a low-cost machine with color graphics, and a more upscale color machine for small business use. In time, these would develop as the Classic, Macintosh LC, and Macintosh IIsi, respectively."
    },
    {
        "source": "With the \"low-left\" of the market it had abandoned years earlier booming with Turbo XTs, and being ignored on the high end for UNIX workstations from the likes of Sun Microsystems and SGI, Apple's fortunes of the 1980s quickly reversed. The Christmas season of 1989 drove this point home, with the first decrease in sales in years, and an accompanying 20 percent drop in Apple's stock price for the quarter. In January 1990, Gassee resigned and his authority over product development was divided among several successors. Many Apple engineers had long been pressing for lower-cost options in order to build market share and increase demand across the entire price spectrum. With Gassee out, a rush started to quickly introduce a series of low-cost machines. Three market points were identified: a very low-cost machine with a target price of $1,000, a low-cost machine with color graphics, and a more upscale color machine for small business use. In time, these would develop as the Classic, Macintosh LC, and Macintosh IIsi, respectively.",
        "target": "MacWEEK magazine reported on July 10, 1990, that Apple had paid $1 million to Modular Computer Systems Inc., a subsidiary of Daimler-Benz AG, for the right to use the \"Classic\" name as part of a five-year contract. Apple did not renew the contract when it ended. MacWEEK speculated the Macintosh Classic would use the same 8MHz Motorola 68000 microprocessor and 9-inch (23cm) display as its predecessors and that the Classic would be priced from $1,500 to 2,150."
    },
    {
        "source": "In January 1990, Gassee resigned and his authority over product development was divided among several successors. Many Apple engineers had long been pressing for lower-cost options in order to build market share and increase demand across the entire price spectrum. With Gassee out, a rush started to quickly introduce a series of low-cost machines. Three market points were identified: a very low-cost machine with a target price of $1,000, a low-cost machine with color graphics, and a more upscale color machine for small business use. In time, these would develop as the Classic, Macintosh LC, and Macintosh IIsi, respectively. MacWEEK magazine reported on July 10, 1990, that Apple had paid $1 million to Modular Computer Systems Inc., a subsidiary of Daimler-Benz AG, for the right to use the \"Classic\" name as part of a five-year contract. Apple did not renew the contract when it ended. MacWEEK speculated the Macintosh Classic would use the same 8MHz Motorola 68000 microprocessor and 9-inch (23cm) display as its predecessors and that the Classic would be priced from $1,500 to 2,150.",
        "target": "On October 15, 1990, John Sculley (then Apple CEO) introduced the Classic at a press conference, announcing that pricing would start at $1,000 and saying, \"To reach new customers, we didn't just lower the prices of our existing products. We redesigned these computers from the ground up with the features customers have told us they value most.\" Apple's new pricing strategy caused concern among investors, who thought it would reduce profit margins. Brodie Keast, an Apple product marketing manager, said, \"We are prepared to do whatever it takes to reach more people with Macintosh[...] The plan is to get as aggressive on price as we need to be.\" After the release of the Classic, Apple's share price closed at $27.75 per share, down $0.50 from October 12, 1990, and far below its previous 12-month high of $50.37."
    },
    {
        "source": "MacWEEK magazine reported on July 10, 1990, that Apple had paid $1 million to Modular Computer Systems Inc., a subsidiary of Daimler-Benz AG, for the right to use the \"Classic\" name as part of a five-year contract. Apple did not renew the contract when it ended. MacWEEK speculated the Macintosh Classic would use the same 8MHz Motorola 68000 microprocessor and 9-inch (23cm) display as its predecessors and that the Classic would be priced from $1,500 to 2,150. On October 15, 1990, John Sculley (then Apple CEO) introduced the Classic at a press conference, announcing that pricing would start at $1,000 and saying, \"To reach new customers, we didn't just lower the prices of our existing products. We redesigned these computers from the ground up with the features customers have told us they value most.\" Apple's new pricing strategy caused concern among investors, who thought it would reduce profit margins. Brodie Keast, an Apple product marketing manager, said, \"We are prepared to do whatever it takes to reach more people with Macintosh[...] The plan is to get as aggressive on price as we need to be.\" After the release of the Classic, Apple's share price closed at $27.75 per share, down $0.50 from October 12, 1990, and far below its previous 12-month high of $50.37.",
        "target": "The Classic was released in Europe and Japan concurrently with the United States release. In Japan, the Classic retailed for 198,000 ($1,523), more than in the US but matching the price of the Toshiba Dynabook laptop computer."
    },
    {
        "source": "On October 15, 1990, John Sculley (then Apple CEO) introduced the Classic at a press conference, announcing that pricing would start at $1,000 and saying, \"To reach new customers, we didn't just lower the prices of our existing products. We redesigned these computers from the ground up with the features customers have told us they value most.\" Apple's new pricing strategy caused concern among investors, who thought it would reduce profit margins. Brodie Keast, an Apple product marketing manager, said, \"We are prepared to do whatever it takes to reach more people with Macintosh[...] The plan is to get as aggressive on price as we need to be.\" After the release of the Classic, Apple's share price closed at $27.75 per share, down $0.50 from October 12, 1990, and far below its previous 12-month high of $50.37. The Classic was released in Europe and Japan concurrently with the United States release. In Japan, the Classic retailed for 198,000 ($1,523), more than in the US but matching the price of the Toshiba Dynabook laptop computer.",
        "target": "After spending $40 million marketing the Classic to first-time buyers, Apple had difficulty meeting the high demand. Apple doubled its manufacturing space in 1990 by expanding its Singapore and Cork, Ireland factories, where the Classic was assembled. Air freight, rather than sea shipping, was used to speed delivery. The shortage caused concern among dealers, who blamed Apple's poor business planning."
    },
    {
        "source": "The Classic was released in Europe and Japan concurrently with the United States release. In Japan, the Classic retailed for 198,000 ($1,523), more than in the US but matching the price of the Toshiba Dynabook laptop computer. After spending $40 million marketing the Classic to first-time buyers, Apple had difficulty meeting the high demand. Apple doubled its manufacturing space in 1990 by expanding its Singapore and Cork, Ireland factories, where the Classic was assembled. Air freight, rather than sea shipping, was used to speed delivery. The shortage caused concern among dealers, who blamed Apple's poor business planning.",
        "target": "Macintosh Classics and LCs had been given to Scholastic Software 12weeks before they were officially announced, and Scholastic planned to release 16new Macintosh products in 1991. Peter Kelman, Scholastic's publisher, predicted that the Macintosh would become \"the school machine of the nineties.\" The Classic was sold to schools for $800. This, and the availability of educational software, led to the Classic's popularity in the education sector."
    },
    {
        "source": "After spending $40 million marketing the Classic to first-time buyers, Apple had difficulty meeting the high demand. Apple doubled its manufacturing space in 1990 by expanding its Singapore and Cork, Ireland factories, where the Classic was assembled. Air freight, rather than sea shipping, was used to speed delivery. The shortage caused concern among dealers, who blamed Apple's poor business planning. Macintosh Classics and LCs had been given to Scholastic Software 12weeks before they were officially announced, and Scholastic planned to release 16new Macintosh products in 1991. Peter Kelman, Scholastic's publisher, predicted that the Macintosh would become \"the school machine of the nineties.\" The Classic was sold to schools for $800. This, and the availability of educational software, led to the Classic's popularity in the education sector.",
        "target": "The low-end model was sold with 1MB of memory, a 1.44 MB floppy drive, no hard disk, and included a keyboard for $999. The $1,500 model had 2 MB of memory and a 40 MB hard disk. The Classic features several improvements over the Macintosh Plus, which it replaced as Apple's low-end Mac computer: it is up to 25percent faster than the Plus, about as fast as the SE, and includes an Apple SuperDrive 3.5\" floppy disk drive as standard. The SuperDrive can read and write to Macintosh, MS-DOS, OS/2, and ProDOS disks. The Classic also has an memory expansion slot(up to 4 MB)."
    },
    {
        "source": "Macintosh Classics and LCs had been given to Scholastic Software 12weeks before they were officially announced, and Scholastic planned to release 16new Macintosh products in 1991. Peter Kelman, Scholastic's publisher, predicted that the Macintosh would become \"the school machine of the nineties.\" The Classic was sold to schools for $800. This, and the availability of educational software, led to the Classic's popularity in the education sector. The low-end model was sold with 1MB of memory, a 1.44 MB floppy drive, no hard disk, and included a keyboard for $999. The $1,500 model had 2 MB of memory and a 40 MB hard disk. The Classic features several improvements over the Macintosh Plus, which it replaced as Apple's low-end Mac computer: it is up to 25percent faster than the Plus, about as fast as the SE, and includes an Apple SuperDrive 3.5\" floppy disk drive as standard. The SuperDrive can read and write to Macintosh, MS-DOS, OS/2, and ProDOS disks. The Classic also has an memory expansion slot(up to 4 MB).",
        "target": "The Classic uses the System 6.0.7 operating system with support for all versions up to System 7.5.5. A hidden Hierarchical File System (HFS) disk volume contained in the read-only memory (ROM) includes System 6.0.3. The Mac Classic can be booted into System 6.0.3 by holding down the  Command+ Option+X+O keys during boot."
    },
    {
        "source": "The low-end model was sold with 1MB of memory, a 1.44 MB floppy drive, no hard disk, and included a keyboard for $999. The $1,500 model had 2 MB of memory and a 40 MB hard disk. The Classic features several improvements over the Macintosh Plus, which it replaced as Apple's low-end Mac computer: it is up to 25percent faster than the Plus, about as fast as the SE, and includes an Apple SuperDrive 3.5\" floppy disk drive as standard. The SuperDrive can read and write to Macintosh, MS-DOS, OS/2, and ProDOS disks. The Classic also has an memory expansion slot(up to 4 MB). The Classic uses the System 6.0.7 operating system with support for all versions up to System 7.5.5. A hidden Hierarchical File System (HFS) disk volume contained in the read-only memory (ROM) includes System 6.0.3. The Mac Classic can be booted into System 6.0.3 by holding down the  Command+ Option+X+O keys during boot.",
        "target": "Some dealers included a software bundle called Smartbundle with the Classic. Also sold separately for $349, this includes T/Maker's WriteNow word processor, Ashton-Tate's Full Impact spreadsheet program, RecordHolderPlus database, and Silicon Beach Software's SuperPaint 2.0 paint and draw program."
    },
    {
        "source": "The Classic uses the System 6.0.7 operating system with support for all versions up to System 7.5.5. A hidden Hierarchical File System (HFS) disk volume contained in the read-only memory (ROM) includes System 6.0.3. The Mac Classic can be booted into System 6.0.3 by holding down the  Command+ Option+X+O keys during boot. Some dealers included a software bundle called Smartbundle with the Classic. Also sold separately for $349, this includes T/Maker's WriteNow word processor, Ashton-Tate's Full Impact spreadsheet program, RecordHolderPlus database, and Silicon Beach Software's SuperPaint 2.0 paint and draw program.",
        "target": "The Macintosh Classic is the final adaptation of Jerry Manock's and Terry Oyama's Macintosh 128K industrial design, bringing back some elements of the original while retaining little of the Snow White design language used in the Macintosh SE's design. The only remnant of the SE is the stripe across the front panel (bezel) for the floppy drive; the distinctive front bezel lines of the SE were not used on the Classic, and the vertical lines around its base are replaced by four horizontal vent lines, more reminiscent of the original design. Also, the curve of the front bezel was increased to the same 50-inch (1.3m) radial curve as on the front of both the Macintosh LC and Macintosh IIsi. The screen brightness dial on this bezel was also removed in favor of a software control. This broad, curved front bezel became a signature of Apple product design for much of the 1990s."
    },
    {
        "source": "Some dealers included a software bundle called Smartbundle with the Classic. Also sold separately for $349, this includes T/Maker's WriteNow word processor, Ashton-Tate's Full Impact spreadsheet program, RecordHolderPlus database, and Silicon Beach Software's SuperPaint 2.0 paint and draw program. The Macintosh Classic is the final adaptation of Jerry Manock's and Terry Oyama's Macintosh 128K industrial design, bringing back some elements of the original while retaining little of the Snow White design language used in the Macintosh SE's design. The only remnant of the SE is the stripe across the front panel (bezel) for the floppy drive; the distinctive front bezel lines of the SE were not used on the Classic, and the vertical lines around its base are replaced by four horizontal vent lines, more reminiscent of the original design. Also, the curve of the front bezel was increased to the same 50-inch (1.3m) radial curve as on the front of both the Macintosh LC and Macintosh IIsi. The screen brightness dial on this bezel was also removed in favor of a software control. This broad, curved front bezel became a signature of Apple product design for much of the 1990s.",
        "target": "The logic board, the central circuit board of the computer, is based on the Macintosh SE design. Its size, however, was reduced using surface-mount technology to 9  5inches (23  13cm), half the size of the SE board. This redesign, and the absence of expansion slots, kept manufacturing costs low. This lack of expansion abilities, along with the small screen size and Macintosh's popularity in desktop publishing, led to such oddities as video displays that connected through the SCSI port by users seeking to connect a larger full- or dual-page display to their Mac. The Classic design was used once more in 1991 for the Classic II, which succeeded the Classic."
    },
    {
        "source": "The Macintosh Classic is the final adaptation of Jerry Manock's and Terry Oyama's Macintosh 128K industrial design, bringing back some elements of the original while retaining little of the Snow White design language used in the Macintosh SE's design. The only remnant of the SE is the stripe across the front panel (bezel) for the floppy drive; the distinctive front bezel lines of the SE were not used on the Classic, and the vertical lines around its base are replaced by four horizontal vent lines, more reminiscent of the original design. Also, the curve of the front bezel was increased to the same 50-inch (1.3m) radial curve as on the front of both the Macintosh LC and Macintosh IIsi. The screen brightness dial on this bezel was also removed in favor of a software control. This broad, curved front bezel became a signature of Apple product design for much of the 1990s. The logic board, the central circuit board of the computer, is based on the Macintosh SE design. Its size, however, was reduced using surface-mount technology to 9  5inches (23  13cm), half the size of the SE board. This redesign, and the absence of expansion slots, kept manufacturing costs low. This lack of expansion abilities, along with the small screen size and Macintosh's popularity in desktop publishing, led to such oddities as video displays that connected through the SCSI port by users seeking to connect a larger full- or dual-page display to their Mac. The Classic design was used once more in 1991 for the Classic II, which succeeded the Classic.",
        "target": "Some reviewers of the Macintosh Classic focused on the processor performance and lack of expansion slots. Liza Schafer of Home Office Computing praised the Classic's ease of use and price, but criticized the 9-inch (230mm) display because a full US letter page (8.5 by 11 inches; 220mm 280mm) would not fit at full size, and warned those who required high-end graphics and desktop publishing capabilities against buying the Classic. Schafer concluded: \"The Classic's value is more impressive than its performance, but its performance will get you working on that novel, database, or spreadsheet.\" PC Week criticized the lack of a faster processor, stating, \"The 7.8MHz speed is adequate for text applications and limited graphics work, but it is not suitable for power users. As such, the Classic is appropriate as a home computer or for limited computing on the road.\" Similarly, PC User's review concluded, \"The slow processor and lack of expansion slots on the Macintosh Classic offset the low prices\". MacWEEK described it as a \"fine, inexpensive replacement for the Macintosh Plus that best embodies the original Macintosh vision six and a half years later\". Computer Gaming World was more skeptical, doubting that consumers would purchase a black-and-white computer with no hard drive that was only slightly faster than the Mac Plus."
    },
    {
        "source": "The logic board, the central circuit board of the computer, is based on the Macintosh SE design. Its size, however, was reduced using surface-mount technology to 9  5inches (23  13cm), half the size of the SE board. This redesign, and the absence of expansion slots, kept manufacturing costs low. This lack of expansion abilities, along with the small screen size and Macintosh's popularity in desktop publishing, led to such oddities as video displays that connected through the SCSI port by users seeking to connect a larger full- or dual-page display to their Mac. The Classic design was used once more in 1991 for the Classic II, which succeeded the Classic. Some reviewers of the Macintosh Classic focused on the processor performance and lack of expansion slots. Liza Schafer of Home Office Computing praised the Classic's ease of use and price, but criticized the 9-inch (230mm) display because a full US letter page (8.5 by 11 inches; 220mm 280mm) would not fit at full size, and warned those who required high-end graphics and desktop publishing capabilities against buying the Classic. Schafer concluded: \"The Classic's value is more impressive than its performance, but its performance will get you working on that novel, database, or spreadsheet.\" PC Week criticized the lack of a faster processor, stating, \"The 7.8MHz speed is adequate for text applications and limited graphics work, but it is not suitable for power users. As such, the Classic is appropriate as a home computer or for limited computing on the road.\" Similarly, PC User's review concluded, \"The slow processor and lack of expansion slots on the Macintosh Classic offset the low prices\". MacWEEK described it as a \"fine, inexpensive replacement for the Macintosh Plus that best embodies the original Macintosh vision six and a half years later\". Computer Gaming World was more skeptical, doubting that consumers would purchase a black-and-white computer with no hard drive that was only slightly faster than the Mac Plus.",
        "target": "In the February 1991 edition of Electronic Learning, Robert McCarthy wrote: \"Teachers, educational administrators, and software developers are enthusiastic about the new, lower-cost Apple Macintosh computers\". Steve Taffe, manager of instructional strategy at MECC, a developer and publisher of educational software, explained his excitement about the Classic: \"[it] is terrific  both because it's a Mac and because of that low price. Everyone can now afford a Macintosh.\" Scholastic, an educational software developer, was also confident of Apple's ability to compete with MS-DOS machines, stating: \"They are just as cost-effective and as powerful as MS-DOS computers, but the Apples will have a superior comfort level.\" Sue Talley, Apple's manager of strategic planning in education, said of the Classic: \"we see it going into applications where you need a fair number of powerful stations, but where color is not a big issue.\" Talley mentioned that it was most suited for writing labs and other basic productivity uses. Many schools decided not to buy the Macintosh Classic because of the lack of a color monitor, an option that the higher-priced Macintosh LC had. The popular Apple IIe Card also increased the LC's appeal to schools. Although the Classic was more popular at first, by May 1992 the LC (560,000 sold) was outselling the Classic (1.2 million sold)."
    },
    {
        "source": " The Manchester Baby, also called the Small-Scale Experimental Machine (SSEM), was the first electronic stored-program computer. It was built at the University of Manchester by Frederic C. Williams, Tom Kilburn, and Geoff Tootill, and ran its first program on 21 June 1948.",
        "target": "The Baby was not intended to be a practical computing engine, but was instead designed as a testbed for the Williams tube, the first truly random-access memory. Described as \"small and primitive\" 50 years after its creation, it was the first working machine to contain all the elements essential to a modern electronic digital computer. As soon as the Baby had demonstrated the feasibility of its design, a project was initiated at the university to develop it into a full-scale operational machine, the Manchester Mark 1. The Mark 1 in turn quickly became the prototype for the Ferranti Mark 1, the world's first commercially available general-purpose computer."
    },
    {
        "source": "The Manchester Baby, also called the Small-Scale Experimental Machine (SSEM), was the first electronic stored-program computer. It was built at the University of Manchester by Frederic C. Williams, Tom Kilburn, and Geoff Tootill, and ran its first program on 21 June 1948. The Baby was not intended to be a practical computing engine, but was instead designed as a testbed for the Williams tube, the first truly random-access memory. Described as \"small and primitive\" 50 years after its creation, it was the first working machine to contain all the elements essential to a modern electronic digital computer. As soon as the Baby had demonstrated the feasibility of its design, a project was initiated at the university to develop it into a full-scale operational machine, the Manchester Mark 1. The Mark 1 in turn quickly became the prototype for the Ferranti Mark 1, the world's first commercially available general-purpose computer.",
        "target": "The Baby had a 32-bit word length and a memory of 32words (1 kilobit, 1,024 bits). As it was designed to be the simplest possible stored-program computer, the only arithmetic operations implemented in hardware were subtraction and negation; other arithmetic operations were implemented in software. The first of three programs written for the machine calculated the highest proper divisor of 218 (262,144), by testing every integer from 218 downwards. This algorithm would take a long time to executeand so prove the computer's reliability, as division was implemented by repeated subtraction of the divisor. The program consisted of 17instructions and ran for about 52minutes before reaching the correct answer of 131,072, after the Baby had performed about 3.5million operations (for an effective CPU speed of about 1100 instructions per second)."
    },
    {
        "source": "The Baby was not intended to be a practical computing engine, but was instead designed as a testbed for the Williams tube, the first truly random-access memory. Described as \"small and primitive\" 50 years after its creation, it was the first working machine to contain all the elements essential to a modern electronic digital computer. As soon as the Baby had demonstrated the feasibility of its design, a project was initiated at the university to develop it into a full-scale operational machine, the Manchester Mark 1. The Mark 1 in turn quickly became the prototype for the Ferranti Mark 1, the world's first commercially available general-purpose computer. The Baby had a 32-bit word length and a memory of 32words (1 kilobit, 1,024 bits). As it was designed to be the simplest possible stored-program computer, the only arithmetic operations implemented in hardware were subtraction and negation; other arithmetic operations were implemented in software. The first of three programs written for the machine calculated the highest proper divisor of 218 (262,144), by testing every integer from 218 downwards. This algorithm would take a long time to executeand so prove the computer's reliability, as division was implemented by repeated subtraction of the divisor. The program consisted of 17instructions and ran for about 52minutes before reaching the correct answer of 131,072, after the Baby had performed about 3.5million operations (for an effective CPU speed of about 1100 instructions per second).",
        "target": "The first design for a program-controlled computer was Charles Babbage's Analytical Engine in the 1830s, with Ada Lovelace conceiving the idea of the first theoretical program to calculate Bernoulli numbers. A century later, in 1936, mathematician Alan Turing published his description of what became known as a Turing machine, a theoretical concept intended to explore the limits of mechanical computation. Turing was not imagining a physical machine, but a person he called a \"computer\", who acted according to the instructions provided by a tape on which symbols could be read and written sequentially as the tape moved under a tape head. Turing proved that if an algorithm can be written to solve a mathematical problem, then a Turing machine can execute that algorithm."
    },
    {
        "source": "The Baby had a 32-bit word length and a memory of 32words (1 kilobit, 1,024 bits). As it was designed to be the simplest possible stored-program computer, the only arithmetic operations implemented in hardware were subtraction and negation; other arithmetic operations were implemented in software. The first of three programs written for the machine calculated the highest proper divisor of 218 (262,144), by testing every integer from 218 downwards. This algorithm would take a long time to executeand so prove the computer's reliability, as division was implemented by repeated subtraction of the divisor. The program consisted of 17instructions and ran for about 52minutes before reaching the correct answer of 131,072, after the Baby had performed about 3.5million operations (for an effective CPU speed of about 1100 instructions per second). The first design for a program-controlled computer was Charles Babbage's Analytical Engine in the 1830s, with Ada Lovelace conceiving the idea of the first theoretical program to calculate Bernoulli numbers. A century later, in 1936, mathematician Alan Turing published his description of what became known as a Turing machine, a theoretical concept intended to explore the limits of mechanical computation. Turing was not imagining a physical machine, but a person he called a \"computer\", who acted according to the instructions provided by a tape on which symbols could be read and written sequentially as the tape moved under a tape head. Turing proved that if an algorithm can be written to solve a mathematical problem, then a Turing machine can execute that algorithm.",
        "target": "Konrad Zuse's Z3 was the world's first working programmable, fully automatic computer, with binary digital arithmetic logic, but it lacked the conditional branching of a Turing machine. On 12 May 1941, the Z3 was successfully presented to an audience of scientists of the Deutsche Versuchsanstalt fr Luftfahrt (\"German Laboratory for Aviation\") in Berlin. The Z3 stored its program on an external tape, but it was electromechanical rather than electronic. The earliest electronic computing devices were the AtanasoffBerry computer (ABC), which was successfully tested in 1942, and the Colossus of 1943, but neither was a stored-program machine."
    },
    {
        "source": "The first design for a program-controlled computer was Charles Babbage's Analytical Engine in the 1830s, with Ada Lovelace conceiving the idea of the first theoretical program to calculate Bernoulli numbers. A century later, in 1936, mathematician Alan Turing published his description of what became known as a Turing machine, a theoretical concept intended to explore the limits of mechanical computation. Turing was not imagining a physical machine, but a person he called a \"computer\", who acted according to the instructions provided by a tape on which symbols could be read and written sequentially as the tape moved under a tape head. Turing proved that if an algorithm can be written to solve a mathematical problem, then a Turing machine can execute that algorithm. Konrad Zuse's Z3 was the world's first working programmable, fully automatic computer, with binary digital arithmetic logic, but it lacked the conditional branching of a Turing machine. On 12 May 1941, the Z3 was successfully presented to an audience of scientists of the Deutsche Versuchsanstalt fr Luftfahrt (\"German Laboratory for Aviation\") in Berlin. The Z3 stored its program on an external tape, but it was electromechanical rather than electronic. The earliest electronic computing devices were the AtanasoffBerry computer (ABC), which was successfully tested in 1942, and the Colossus of 1943, but neither was a stored-program machine.",
        "target": "The ENIAC (1946) was the first automatic computer that was both electronic and general-purpose. It was Turing complete, with conditional branching, and programmable to solve a wide range of problems, but its program was held in the state of switches in patch cords, rather than machine-changeable memory, and it could take several days to reprogram. Researchers such as Turing and Zuse investigated the idea of using the computer's memory to hold the program as well as the data it was working on, and it was mathematician John von Neumann who wrote a widely distributed paper describing that computer architecture, still used in almost all computers."
    },
    {
        "source": "Konrad Zuse's Z3 was the world's first working programmable, fully automatic computer, with binary digital arithmetic logic, but it lacked the conditional branching of a Turing machine. On 12 May 1941, the Z3 was successfully presented to an audience of scientists of the Deutsche Versuchsanstalt fr Luftfahrt (\"German Laboratory for Aviation\") in Berlin. The Z3 stored its program on an external tape, but it was electromechanical rather than electronic. The earliest electronic computing devices were the AtanasoffBerry computer (ABC), which was successfully tested in 1942, and the Colossus of 1943, but neither was a stored-program machine. The ENIAC (1946) was the first automatic computer that was both electronic and general-purpose. It was Turing complete, with conditional branching, and programmable to solve a wide range of problems, but its program was held in the state of switches in patch cords, rather than machine-changeable memory, and it could take several days to reprogram. Researchers such as Turing and Zuse investigated the idea of using the computer's memory to hold the program as well as the data it was working on, and it was mathematician John von Neumann who wrote a widely distributed paper describing that computer architecture, still used in almost all computers.",
        "target": "The construction of a von Neumann computer depended on the availability of a suitable memory device on which to store the program. During the Second World War researchers working on the problem of removing the clutter from radar signals had developed a form of delay-line memory, the first practical application of which was the mercury delay line, developed by J.Presper Eckert. Radar transmitters send out regular brief pulses of radio energy, the reflections from which are displayed on a CRT screen. As operators are usually interested only in moving targets, it was desirable to filter out any distracting reflections from stationary objects. The filtering was achieved by comparing each received pulse with the previous pulse, and rejecting both if they were identical, leaving a signal containing only the images of any moving objects. To store each received pulse for later comparison it was passed through a transmission line, delaying it by exactly the time between transmitted pulses."
    },
    {
        "source": "The ENIAC (1946) was the first automatic computer that was both electronic and general-purpose. It was Turing complete, with conditional branching, and programmable to solve a wide range of problems, but its program was held in the state of switches in patch cords, rather than machine-changeable memory, and it could take several days to reprogram. Researchers such as Turing and Zuse investigated the idea of using the computer's memory to hold the program as well as the data it was working on, and it was mathematician John von Neumann who wrote a widely distributed paper describing that computer architecture, still used in almost all computers. The construction of a von Neumann computer depended on the availability of a suitable memory device on which to store the program. During the Second World War researchers working on the problem of removing the clutter from radar signals had developed a form of delay-line memory, the first practical application of which was the mercury delay line, developed by J.Presper Eckert. Radar transmitters send out regular brief pulses of radio energy, the reflections from which are displayed on a CRT screen. As operators are usually interested only in moving targets, it was desirable to filter out any distracting reflections from stationary objects. The filtering was achieved by comparing each received pulse with the previous pulse, and rejecting both if they were identical, leaving a signal containing only the images of any moving objects. To store each received pulse for later comparison it was passed through a transmission line, delaying it by exactly the time between transmitted pulses.",
        "target": "Turing joined the National Physical Laboratory (NPL) in October 1945, by which time scientists within the Ministry of Supply had concluded that Britain needed a National Mathematical Laboratory to co-ordinate machine-aided computation. A Mathematics Division was set up at the NPL, and on 19 February 1946 Turing presented a paper outlining his design for an electronic stored-program computer to be known as the Automatic Computing Engine (ACE). This was one of several projects set up in the years following the Second World War with the aim of constructing a stored-program computer. At about the same time, EDVAC was under development at the University of Pennsylvania's Moore School of Electrical Engineering, and the University of Cambridge Mathematical Laboratory was working on EDSAC."
    },
    {
        "source": "The construction of a von Neumann computer depended on the availability of a suitable memory device on which to store the program. During the Second World War researchers working on the problem of removing the clutter from radar signals had developed a form of delay-line memory, the first practical application of which was the mercury delay line, developed by J.Presper Eckert. Radar transmitters send out regular brief pulses of radio energy, the reflections from which are displayed on a CRT screen. As operators are usually interested only in moving targets, it was desirable to filter out any distracting reflections from stationary objects. The filtering was achieved by comparing each received pulse with the previous pulse, and rejecting both if they were identical, leaving a signal containing only the images of any moving objects. To store each received pulse for later comparison it was passed through a transmission line, delaying it by exactly the time between transmitted pulses. Turing joined the National Physical Laboratory (NPL) in October 1945, by which time scientists within the Ministry of Supply had concluded that Britain needed a National Mathematical Laboratory to co-ordinate machine-aided computation. A Mathematics Division was set up at the NPL, and on 19 February 1946 Turing presented a paper outlining his design for an electronic stored-program computer to be known as the Automatic Computing Engine (ACE). This was one of several projects set up in the years following the Second World War with the aim of constructing a stored-program computer. At about the same time, EDVAC was under development at the University of Pennsylvania's Moore School of Electrical Engineering, and the University of Cambridge Mathematical Laboratory was working on EDSAC.",
        "target": "The NPL did not have the expertise to build a machine like ACE, so they contacted Tommy Flowers at the General Post Office's (GPO) Dollis Hill Research Laboratory. Flowers, the designer of Colossus, the world's first programmable electronic computer, was committed elsewhere and was unable to take part in the project, although his team did build some mercury delay lines for ACE. The Telecommunications Research Establishment (TRE) was also approached for assistance, as was Maurice Wilkes at the University of Cambridge Mathematical Laboratory."
    },
    {
        "source": "Turing joined the National Physical Laboratory (NPL) in October 1945, by which time scientists within the Ministry of Supply had concluded that Britain needed a National Mathematical Laboratory to co-ordinate machine-aided computation. A Mathematics Division was set up at the NPL, and on 19 February 1946 Turing presented a paper outlining his design for an electronic stored-program computer to be known as the Automatic Computing Engine (ACE). This was one of several projects set up in the years following the Second World War with the aim of constructing a stored-program computer. At about the same time, EDVAC was under development at the University of Pennsylvania's Moore School of Electrical Engineering, and the University of Cambridge Mathematical Laboratory was working on EDSAC. The NPL did not have the expertise to build a machine like ACE, so they contacted Tommy Flowers at the General Post Office's (GPO) Dollis Hill Research Laboratory. Flowers, the designer of Colossus, the world's first programmable electronic computer, was committed elsewhere and was unable to take part in the project, although his team did build some mercury delay lines for ACE. The Telecommunications Research Establishment (TRE) was also approached for assistance, as was Maurice Wilkes at the University of Cambridge Mathematical Laboratory.",
        "target": "The government department responsible for the NPL decided that, of all the work being carried out by the TRE on its behalf, ACE was to be given the top priority. NPL's decision led to a visit by the superintendent of the TRE's Physics Division on 22 November 1946, accompanied by Frederic C. Williams and A.M.Uttley, also from the TRE. Williams led a TRE development group working on CRT stores for radar applications, as an alternative to delay lines. Williams was not available to work on the ACE because he had already accepted a professorship at the University of Manchester, and most of his circuit technicians were in the process of being transferred to the Department of Atomic Energy. The TRE agreed to second a small number of technicians to work under Williams' direction at the university, and to support another small group working with Uttley at the TRE."
    },
    {
        "source": "The NPL did not have the expertise to build a machine like ACE, so they contacted Tommy Flowers at the General Post Office's (GPO) Dollis Hill Research Laboratory. Flowers, the designer of Colossus, the world's first programmable electronic computer, was committed elsewhere and was unable to take part in the project, although his team did build some mercury delay lines for ACE. The Telecommunications Research Establishment (TRE) was also approached for assistance, as was Maurice Wilkes at the University of Cambridge Mathematical Laboratory. The government department responsible for the NPL decided that, of all the work being carried out by the TRE on its behalf, ACE was to be given the top priority. NPL's decision led to a visit by the superintendent of the TRE's Physics Division on 22 November 1946, accompanied by Frederic C. Williams and A.M.Uttley, also from the TRE. Williams led a TRE development group working on CRT stores for radar applications, as an alternative to delay lines. Williams was not available to work on the ACE because he had already accepted a professorship at the University of Manchester, and most of his circuit technicians were in the process of being transferred to the Department of Atomic Energy. The TRE agreed to second a small number of technicians to work under Williams' direction at the university, and to support another small group working with Uttley at the TRE.",
        "target": "Although some early computers such as EDSAC, inspired by the design of EDVAC, later made successful use of mercury delay-line memory, the technology had several drawbacks: it was heavy, it was expensive, and it did not allow data to be accessed randomly. In addition, because data was stored as a sequence of acoustic waves propagated through a mercury column, the device's temperature had to be very carefully controlled, as the velocity of sound through a medium varies with its temperature. Williams had seen an experiment at Bell Labs demonstrating the effectiveness of cathode-ray tubes (CRT) as an alternative to the delay line for removing ground echoes from radar signals. While working at the TRE, shortly before he joined the University of Manchester in December 1946, he and Tom Kilburn had developed a form of electronic memory known as the Williams tube or WilliamsKilburn tube, based on a standard CRT: the first electronic random-access digital storage device. The Baby was designed to show that it was a practical storage device by demonstrating that data held within it could be read and written reliably at a speed suitable for use in a computer."
    },
    {
        "source": "The government department responsible for the NPL decided that, of all the work being carried out by the TRE on its behalf, ACE was to be given the top priority. NPL's decision led to a visit by the superintendent of the TRE's Physics Division on 22 November 1946, accompanied by Frederic C. Williams and A.M.Uttley, also from the TRE. Williams led a TRE development group working on CRT stores for radar applications, as an alternative to delay lines. Williams was not available to work on the ACE because he had already accepted a professorship at the University of Manchester, and most of his circuit technicians were in the process of being transferred to the Department of Atomic Energy. The TRE agreed to second a small number of technicians to work under Williams' direction at the university, and to support another small group working with Uttley at the TRE. Although some early computers such as EDSAC, inspired by the design of EDVAC, later made successful use of mercury delay-line memory, the technology had several drawbacks: it was heavy, it was expensive, and it did not allow data to be accessed randomly. In addition, because data was stored as a sequence of acoustic waves propagated through a mercury column, the device's temperature had to be very carefully controlled, as the velocity of sound through a medium varies with its temperature. Williams had seen an experiment at Bell Labs demonstrating the effectiveness of cathode-ray tubes (CRT) as an alternative to the delay line for removing ground echoes from radar signals. While working at the TRE, shortly before he joined the University of Manchester in December 1946, he and Tom Kilburn had developed a form of electronic memory known as the Williams tube or WilliamsKilburn tube, based on a standard CRT: the first electronic random-access digital storage device. The Baby was designed to show that it was a practical storage device by demonstrating that data held within it could be read and written reliably at a speed suitable for use in a computer.",
        "target": "For use in a binary digital computer, the tube had to be capable of storing either one of two states at each of its memory locations, corresponding to the binary digits (bits) 0 and1. It exploited the positive or negative electric charge generated by displaying either a dash or a dot at any position on the CRT screen, a phenomenon known as secondary emission. A dash generated a positive charge, and a dot a negative charge, either of which could be picked up by a detector plate in front of the screen; a negative charge represented 0, and a positive charge1. The charge dissipated in about 0.2seconds, but it could be automatically refreshed from the data picked up by the detector."
    },
    {
        "source": "Although some early computers such as EDSAC, inspired by the design of EDVAC, later made successful use of mercury delay-line memory, the technology had several drawbacks: it was heavy, it was expensive, and it did not allow data to be accessed randomly. In addition, because data was stored as a sequence of acoustic waves propagated through a mercury column, the device's temperature had to be very carefully controlled, as the velocity of sound through a medium varies with its temperature. Williams had seen an experiment at Bell Labs demonstrating the effectiveness of cathode-ray tubes (CRT) as an alternative to the delay line for removing ground echoes from radar signals. While working at the TRE, shortly before he joined the University of Manchester in December 1946, he and Tom Kilburn had developed a form of electronic memory known as the Williams tube or WilliamsKilburn tube, based on a standard CRT: the first electronic random-access digital storage device. The Baby was designed to show that it was a practical storage device by demonstrating that data held within it could be read and written reliably at a speed suitable for use in a computer. For use in a binary digital computer, the tube had to be capable of storing either one of two states at each of its memory locations, corresponding to the binary digits (bits) 0 and1. It exploited the positive or negative electric charge generated by displaying either a dash or a dot at any position on the CRT screen, a phenomenon known as secondary emission. A dash generated a positive charge, and a dot a negative charge, either of which could be picked up by a detector plate in front of the screen; a negative charge represented 0, and a positive charge1. The charge dissipated in about 0.2seconds, but it could be automatically refreshed from the data picked up by the detector.",
        "target": "The Williams tube used in Baby was based on the CV1131, a commercially available 12-inch (300mm) diameter CRT, but a smaller 6-inch (150mm) tube, the CV1097, was used in the Mark I."
    },
    {
        "source": "For use in a binary digital computer, the tube had to be capable of storing either one of two states at each of its memory locations, corresponding to the binary digits (bits) 0 and1. It exploited the positive or negative electric charge generated by displaying either a dash or a dot at any position on the CRT screen, a phenomenon known as secondary emission. A dash generated a positive charge, and a dot a negative charge, either of which could be picked up by a detector plate in front of the screen; a negative charge represented 0, and a positive charge1. The charge dissipated in about 0.2seconds, but it could be automatically refreshed from the data picked up by the detector. The Williams tube used in Baby was based on the CV1131, a commercially available 12-inch (300mm) diameter CRT, but a smaller 6-inch (150mm) tube, the CV1097, was used in the Mark I.",
        "target": "After developing the Colossus computer for code breaking at Bletchley Park during World War II, Max Newman was committed to the development of a computer incorporating both Alan Turing's mathematical concepts and the stored-program concept that had been described by John von Neumann. In 1945, he was appointed to the Fielden Chair of Pure Mathematics at Manchester University; he took his Colossus-project colleagues Jack Good and David Rees to Manchester with him, and there they recruited F. C. Williams to be the \"circuit man\" for a new computer project for which he had secured funding from the Royal Society."
    },
    {
        "source": "The Williams tube used in Baby was based on the CV1131, a commercially available 12-inch (300mm) diameter CRT, but a smaller 6-inch (150mm) tube, the CV1097, was used in the Mark I. After developing the Colossus computer for code breaking at Bletchley Park during World War II, Max Newman was committed to the development of a computer incorporating both Alan Turing's mathematical concepts and the stored-program concept that had been described by John von Neumann. In 1945, he was appointed to the Fielden Chair of Pure Mathematics at Manchester University; he took his Colossus-project colleagues Jack Good and David Rees to Manchester with him, and there they recruited F. C. Williams to be the \"circuit man\" for a new computer project for which he had secured funding from the Royal Society.",
        "target": "Having secured the support of the university, obtained funding from the Royal Society, and assembled a first-rate team of mathematicians and engineers, Newman now had all elements of his computer-building plan in place. Adopting the approach he had used so effectively at Bletchley Park, Newman set his people loose on the detailed work while he concentrated on orchestrating the endeavor."
    },
    {
        "source": "After developing the Colossus computer for code breaking at Bletchley Park during World War II, Max Newman was committed to the development of a computer incorporating both Alan Turing's mathematical concepts and the stored-program concept that had been described by John von Neumann. In 1945, he was appointed to the Fielden Chair of Pure Mathematics at Manchester University; he took his Colossus-project colleagues Jack Good and David Rees to Manchester with him, and there they recruited F. C. Williams to be the \"circuit man\" for a new computer project for which he had secured funding from the Royal Society. Having secured the support of the university, obtained funding from the Royal Society, and assembled a first-rate team of mathematicians and engineers, Newman now had all elements of his computer-building plan in place. Adopting the approach he had used so effectively at Bletchley Park, Newman set his people loose on the detailed work while he concentrated on orchestrating the endeavor.",
        "target": "Following his appointment to the Chair of Electrical Engineering at Manchester University, Williams recruited his TRE colleague Tom Kilburn on secondment. By the autumn of 1947 the pair had increased the storage capacity of the Williams tube from one bit to 2,048, arranged in a 64 by 32-bit array, and demonstrated that it was able to store those bits for four hours. Engineer Geoff Tootill joined the team on loan from TRE in September 1947, and remained on secondment until April 1949."
    },
    {
        "source": "Having secured the support of the university, obtained funding from the Royal Society, and assembled a first-rate team of mathematicians and engineers, Newman now had all elements of his computer-building plan in place. Adopting the approach he had used so effectively at Bletchley Park, Newman set his people loose on the detailed work while he concentrated on orchestrating the endeavor. Following his appointment to the Chair of Electrical Engineering at Manchester University, Williams recruited his TRE colleague Tom Kilburn on secondment. By the autumn of 1947 the pair had increased the storage capacity of the Williams tube from one bit to 2,048, arranged in a 64 by 32-bit array, and demonstrated that it was able to store those bits for four hours. Engineer Geoff Tootill joined the team on loan from TRE in September 1947, and remained on secondment until April 1949.",
        "target": "Now let's be clear before we go any further that neither Tom Kilburn nor I knew the first thing about computers when we arrived at Manchester University... Newman explained the whole business of how a computer works to us.\""
    },
    {
        "source": "Following his appointment to the Chair of Electrical Engineering at Manchester University, Williams recruited his TRE colleague Tom Kilburn on secondment. By the autumn of 1947 the pair had increased the storage capacity of the Williams tube from one bit to 2,048, arranged in a 64 by 32-bit array, and demonstrated that it was able to store those bits for four hours. Engineer Geoff Tootill joined the team on loan from TRE in September 1947, and remained on secondment until April 1949. Now let's be clear before we go any further that neither Tom Kilburn nor I knew the first thing about computers when we arrived at Manchester University... Newman explained the whole business of how a computer works to us.\"",
        "target": "Kilburn had a hard time recalling the influences on his machine design:"
    },
    {
        "source": "Now let's be clear before we go any further that neither Tom Kilburn nor I knew the first thing about computers when we arrived at Manchester University... Newman explained the whole business of how a computer works to us.\" Kilburn had a hard time recalling the influences on his machine design:",
        "target": "[I]n that period, somehow or other I knew what a digital computer was ... Where I got this knowledge from I've no idea."
    },
    {
        "source": "Kilburn had a hard time recalling the influences on his machine design: [I]n that period, somehow or other I knew what a digital computer was ... Where I got this knowledge from I've no idea.",
        "target": "Jack Copeland explains that Kilburn's first (pre-Baby) accumulator-free (decentralized, in Jack Good's nomenclature) design was based on inputs from Turing, but that he later switched to an accumulator-based (centralized) machine of the sort advocated by von Neumann, as written up and taught to him by Jack Good and Max Newman."
    },
    {
        "source": "[I]n that period, somehow or other I knew what a digital computer was ... Where I got this knowledge from I've no idea. Jack Copeland explains that Kilburn's first (pre-Baby) accumulator-free (decentralized, in Jack Good's nomenclature) design was based on inputs from Turing, but that he later switched to an accumulator-based (centralized) machine of the sort advocated by von Neumann, as written up and taught to him by Jack Good and Max Newman.",
        "target": "The Baby's seven operation instruction set was approximately a subset of the twelve operation instruction set proposed in 1947 by Jack Good, in the first known document to use the term \"Baby\" for this machine. Good did not include a \"halt\" instruction, and his proposed conditional jump instruction was more complicated than what the Baby implemented."
    },
    {
        "source": "Jack Copeland explains that Kilburn's first (pre-Baby) accumulator-free (decentralized, in Jack Good's nomenclature) design was based on inputs from Turing, but that he later switched to an accumulator-based (centralized) machine of the sort advocated by von Neumann, as written up and taught to him by Jack Good and Max Newman. The Baby's seven operation instruction set was approximately a subset of the twelve operation instruction set proposed in 1947 by Jack Good, in the first known document to use the term \"Baby\" for this machine. Good did not include a \"halt\" instruction, and his proposed conditional jump instruction was more complicated than what the Baby implemented.",
        "target": "Although Newman played no engineering role in the development of the Baby, or any of the subsequent Manchester computers, he was generally supportive and enthusiastic about the project, and arranged for the acquisition of war-surplus supplies for its construction, including GPO metal racks and \"the material of two complete Colossi\" from Bletchley."
    },
    {
        "source": "The Baby's seven operation instruction set was approximately a subset of the twelve operation instruction set proposed in 1947 by Jack Good, in the first known document to use the term \"Baby\" for this machine. Good did not include a \"halt\" instruction, and his proposed conditional jump instruction was more complicated than what the Baby implemented. Although Newman played no engineering role in the development of the Baby, or any of the subsequent Manchester computers, he was generally supportive and enthusiastic about the project, and arranged for the acquisition of war-surplus supplies for its construction, including GPO metal racks and \"the material of two complete Colossi\" from Bletchley.",
        "target": "By June 1948 the Baby had been built and was working. It was 17 feet (5.2m) in length, 7feet 4inches (2.24m) tall, and weighed almost 1 long ton (1.0t). The machine contained 550valves (vacuum tubes)300diodes and 250pentodesand had a power consumption of 3500watts. The arithmetic unit was built using EF50 pentode valves, which had been widely used during wartime. The Baby used one Williams tube to provide 32 by 32-bit words of random-access memory (RAM), a second to hold a 32-bit accumulator in which the intermediate results of a calculation could be stored temporarily, and a third to hold the current program instruction along with its address in memory. A fourth CRT, without the storage electronics of the other three, was used as the output device, able to display the bit pattern of any selected storage tube."
    },
    {
        "source": "Although Newman played no engineering role in the development of the Baby, or any of the subsequent Manchester computers, he was generally supportive and enthusiastic about the project, and arranged for the acquisition of war-surplus supplies for its construction, including GPO metal racks and \"the material of two complete Colossi\" from Bletchley. By June 1948 the Baby had been built and was working. It was 17 feet (5.2m) in length, 7feet 4inches (2.24m) tall, and weighed almost 1 long ton (1.0t). The machine contained 550valves (vacuum tubes)300diodes and 250pentodesand had a power consumption of 3500watts. The arithmetic unit was built using EF50 pentode valves, which had been widely used during wartime. The Baby used one Williams tube to provide 32 by 32-bit words of random-access memory (RAM), a second to hold a 32-bit accumulator in which the intermediate results of a calculation could be stored temporarily, and a third to hold the current program instruction along with its address in memory. A fourth CRT, without the storage electronics of the other three, was used as the output device, able to display the bit pattern of any selected storage tube.",
        "target": "Each 32-bit word of RAM could contain either a program instruction or data. In a program instruction, bits 012 represented the memory address of the operand to be used, and bits 1315 specified the operation to be executed, such as storing a number in memory; the remaining 16bits were unused. The Baby's single operand architecture meant that the second operand of any operation was implicit: the accumulator or the program counter (instruction address); program instructions specified only the address of the data in memory."
    },
    {
        "source": "By June 1948 the Baby had been built and was working. It was 17 feet (5.2m) in length, 7feet 4inches (2.24m) tall, and weighed almost 1 long ton (1.0t). The machine contained 550valves (vacuum tubes)300diodes and 250pentodesand had a power consumption of 3500watts. The arithmetic unit was built using EF50 pentode valves, which had been widely used during wartime. The Baby used one Williams tube to provide 32 by 32-bit words of random-access memory (RAM), a second to hold a 32-bit accumulator in which the intermediate results of a calculation could be stored temporarily, and a third to hold the current program instruction along with its address in memory. A fourth CRT, without the storage electronics of the other three, was used as the output device, able to display the bit pattern of any selected storage tube. Each 32-bit word of RAM could contain either a program instruction or data. In a program instruction, bits 012 represented the memory address of the operand to be used, and bits 1315 specified the operation to be executed, such as storing a number in memory; the remaining 16bits were unused. The Baby's single operand architecture meant that the second operand of any operation was implicit: the accumulator or the program counter (instruction address); program instructions specified only the address of the data in memory.",
        "target": "A word in the computer's memory could be read, written, or refreshed, in 360microseconds. An instruction took four times as long to execute as accessing a word from memory, giving an instruction execution rate of about 700 per second. The main store was refreshed continuously, a process that took 20milliseconds to complete, as each of the Baby's 32words had to be read and then refreshed in sequence."
    },
    {
        "source": "Each 32-bit word of RAM could contain either a program instruction or data. In a program instruction, bits 012 represented the memory address of the operand to be used, and bits 1315 specified the operation to be executed, such as storing a number in memory; the remaining 16bits were unused. The Baby's single operand architecture meant that the second operand of any operation was implicit: the accumulator or the program counter (instruction address); program instructions specified only the address of the data in memory. A word in the computer's memory could be read, written, or refreshed, in 360microseconds. An instruction took four times as long to execute as accessing a word from memory, giving an instruction execution rate of about 700 per second. The main store was refreshed continuously, a process that took 20milliseconds to complete, as each of the Baby's 32words had to be read and then refreshed in sequence.",
        "target": "The Baby represented negative numbers using two's complement, as most computers still do. In that representation, the value of the most significant bit denotes the sign of a number; positive numbers have a zero in that position and negative numbers a one. Thus, the range of numbers that could be held in each 32-bit word was 231 to +2311 (decimal: 2,147,483,648 to +2,147,483,647)."
    },
    {
        "source": "A word in the computer's memory could be read, written, or refreshed, in 360microseconds. An instruction took four times as long to execute as accessing a word from memory, giving an instruction execution rate of about 700 per second. The main store was refreshed continuously, a process that took 20milliseconds to complete, as each of the Baby's 32words had to be read and then refreshed in sequence. The Baby represented negative numbers using two's complement, as most computers still do. In that representation, the value of the most significant bit denotes the sign of a number; positive numbers have a zero in that position and negative numbers a one. Thus, the range of numbers that could be held in each 32-bit word was 231 to +2311 (decimal: 2,147,483,648 to +2,147,483,647).",
        "target": "The Baby's instruction format had a three-bit operation code field, which allowed a maximum of eight (23) different instructions. In contrast to the modern convention, the machine's storage was described with the least significant digits to the left; thus a one was represented in three bits as \"100\", rather than the more conventional \"001\"."
    },
    {
        "source": "The Baby represented negative numbers using two's complement, as most computers still do. In that representation, the value of the most significant bit denotes the sign of a number; positive numbers have a zero in that position and negative numbers a one. Thus, the range of numbers that could be held in each 32-bit word was 231 to +2311 (decimal: 2,147,483,648 to +2,147,483,647). The Baby's instruction format had a three-bit operation code field, which allowed a maximum of eight (23) different instructions. In contrast to the modern convention, the machine's storage was described with the least significant digits to the left; thus a one was represented in three bits as \"100\", rather than the more conventional \"001\".",
        "target": "The awkward negative operations were a consequence of the Baby's lack of hardware to perform any arithmetic operations except subtraction and negation. It was considered unnecessary to build an adder before testing could begin as addition can easily be implemented by subtraction, i.e. x+y can be computed as (xy). Therefore, adding two numbers together, X and Y, required four instructions:"
    },
    {
        "source": "The Baby's instruction format had a three-bit operation code field, which allowed a maximum of eight (23) different instructions. In contrast to the modern convention, the machine's storage was described with the least significant digits to the left; thus a one was represented in three bits as \"100\", rather than the more conventional \"001\". The awkward negative operations were a consequence of the Baby's lack of hardware to perform any arithmetic operations except subtraction and negation. It was considered unnecessary to build an adder before testing could begin as addition can easily be implemented by subtraction, i.e. x+y can be computed as (xy). Therefore, adding two numbers together, X and Y, required four instructions:",
        "target": "Programs were entered in binary form by stepping through each word of memory in turn, and using a set of 32buttons and switches known as the input device to set the value of each bit of each word to either 0 or 1. The Baby had no paper-tape reader or punch."
    },
    {
        "source": "The awkward negative operations were a consequence of the Baby's lack of hardware to perform any arithmetic operations except subtraction and negation. It was considered unnecessary to build an adder before testing could begin as addition can easily be implemented by subtraction, i.e. x+y can be computed as (xy). Therefore, adding two numbers together, X and Y, required four instructions: Programs were entered in binary form by stepping through each word of memory in turn, and using a set of 32buttons and switches known as the input device to set the value of each bit of each word to either 0 or 1. The Baby had no paper-tape reader or punch.",
        "target": "Three programs were written for the computer. The first, consisting of 17instructions, was written by Kilburn, and so far as can be ascertained first ran on 21 June 1948. It was designed to find the highest proper factor of 218 (262,144) by trying every integer from 2181 downwards. The divisions were implemented by repeated subtractions of the divisor. The Baby took 3.5million operations and 52minutes to produce the answer (131,072). The program used eight words of working storage in addition to its 17words of instructions, giving a program size of 25words."
    },
    {
        "source": "Programs were entered in binary form by stepping through each word of memory in turn, and using a set of 32buttons and switches known as the input device to set the value of each bit of each word to either 0 or 1. The Baby had no paper-tape reader or punch. Three programs were written for the computer. The first, consisting of 17instructions, was written by Kilburn, and so far as can be ascertained first ran on 21 June 1948. It was designed to find the highest proper factor of 218 (262,144) by trying every integer from 2181 downwards. The divisions were implemented by repeated subtractions of the divisor. The Baby took 3.5million operations and 52minutes to produce the answer (131,072). The program used eight words of working storage in addition to its 17words of instructions, giving a program size of 25words.",
        "target": "Geoff Tootill wrote an amended version of the program the following month, and in mid-July Alan Turing who had been appointed as a reader in the mathematics department at Manchester University in September 1948 submitted the third program, to carry out long division. Turing had by then been appointed to the nominal post of Deputy Director of the Computing Machine Laboratory at the university, although the laboratory did not become a physical reality until 1951."
    },
    {
        "source": "Three programs were written for the computer. The first, consisting of 17instructions, was written by Kilburn, and so far as can be ascertained first ran on 21 June 1948. It was designed to find the highest proper factor of 218 (262,144) by trying every integer from 2181 downwards. The divisions were implemented by repeated subtractions of the divisor. The Baby took 3.5million operations and 52minutes to produce the answer (131,072). The program used eight words of working storage in addition to its 17words of instructions, giving a program size of 25words. Geoff Tootill wrote an amended version of the program the following month, and in mid-July Alan Turing who had been appointed as a reader in the mathematics department at Manchester University in September 1948 submitted the third program, to carry out long division. Turing had by then been appointed to the nominal post of Deputy Director of the Computing Machine Laboratory at the university, although the laboratory did not become a physical reality until 1951.",
        "target": "Williams and Kilburn reported on the Baby in a letter to the Journal Nature, published in September 1948. The machine's successful demonstration quickly led to the construction of a more practical computer, the Manchester Mark 1, work on which began in August 1948. The first version was operational by April 1949, and it in turn led directly to the development of the Ferranti Mark 1, the world's first commercially available general-purpose computer."
    },
    {
        "source": "Geoff Tootill wrote an amended version of the program the following month, and in mid-July Alan Turing who had been appointed as a reader in the mathematics department at Manchester University in September 1948 submitted the third program, to carry out long division. Turing had by then been appointed to the nominal post of Deputy Director of the Computing Machine Laboratory at the university, although the laboratory did not become a physical reality until 1951. Williams and Kilburn reported on the Baby in a letter to the Journal Nature, published in September 1948. The machine's successful demonstration quickly led to the construction of a more practical computer, the Manchester Mark 1, work on which began in August 1948. The first version was operational by April 1949, and it in turn led directly to the development of the Ferranti Mark 1, the world's first commercially available general-purpose computer.",
        "target": "In 1998, a working replica of the Baby, now on display at the Museum of Science and Industry in Manchester, was built to celebrate the 50th anniversary of the running of its first program. Demonstrations of the machine in operation are held regularly at the museum."
    },
    {
        "source": "Williams and Kilburn reported on the Baby in a letter to the Journal Nature, published in September 1948. The machine's successful demonstration quickly led to the construction of a more practical computer, the Manchester Mark 1, work on which began in August 1948. The first version was operational by April 1949, and it in turn led directly to the development of the Ferranti Mark 1, the world's first commercially available general-purpose computer. In 1998, a working replica of the Baby, now on display at the Museum of Science and Industry in Manchester, was built to celebrate the 50th anniversary of the running of its first program. Demonstrations of the machine in operation are held regularly at the museum.",
        "target": "In 2008, an original panoramic photograph of the entire machine was discovered at the University of Manchester. The photograph, taken on 15 December 1948 by a research student, Alec Robinson, had been reproduced in The Illustrated London News in June 1949."
    },
    {
        "source": " The Manchester Mark 1 was one of the earliest stored-program computers, developed at the Victoria University of Manchester, England from the Manchester Baby (operational in June 1948). Work began in August 1948, and the first version was operational by April 1949; a program written to search for Mersenne primes ran error-free for nine hours on the night of 16/17 June 1949.",
        "target": "The machine's successful operation was widely reported in the British press, which used the phrase \"electronic brain\" in describing it to their readers. That description provoked a reaction from the head of the University of Manchester's Department of Neurosurgery, the start of a long-running debate as to whether an electronic computer could ever be truly creative."
    },
    {
        "source": "The Manchester Mark 1 was one of the earliest stored-program computers, developed at the Victoria University of Manchester, England from the Manchester Baby (operational in June 1948). Work began in August 1948, and the first version was operational by April 1949; a program written to search for Mersenne primes ran error-free for nine hours on the night of 16/17 June 1949. The machine's successful operation was widely reported in the British press, which used the phrase \"electronic brain\" in describing it to their readers. That description provoked a reaction from the head of the University of Manchester's Department of Neurosurgery, the start of a long-running debate as to whether an electronic computer could ever be truly creative.",
        "target": "The Mark 1 was to provide a computing resource within the university, to allow researchers to gain experience in the practical use of computers, but it very quickly also became a prototype on which the design of Ferranti's commercial version could be based. Development ceased at the end of 1949, and the machine was scrapped towards the end of 1950, replaced in February 1951 by a Ferranti Mark 1, the world's first commercially available general-purpose electronic computer."
    },
    {
        "source": "The machine's successful operation was widely reported in the British press, which used the phrase \"electronic brain\" in describing it to their readers. That description provoked a reaction from the head of the University of Manchester's Department of Neurosurgery, the start of a long-running debate as to whether an electronic computer could ever be truly creative. The Mark 1 was to provide a computing resource within the university, to allow researchers to gain experience in the practical use of computers, but it very quickly also became a prototype on which the design of Ferranti's commercial version could be based. Development ceased at the end of 1949, and the machine was scrapped towards the end of 1950, replaced in February 1951 by a Ferranti Mark 1, the world's first commercially available general-purpose electronic computer.",
        "target": "The computer is especially historically significant because of its pioneering inclusion of index registers, an innovation which made it easier for a program to read sequentially through an array of words in memory. Thirty-four patents resulted from the machine's development, and many of the ideas behind its design were incorporated in subsequent commercial products such as the IBM 701 and 702 as well as the Ferranti Mark 1. The chief designers, Frederic C. Williams and Tom Kilburn, concluded from their experiences with the Mark1 that computers would be used more in scientific roles than in pure mathematics. In 1951, they started development work on Meg, the Mark1's successor, which would include a floating point unit."
    },
    {
        "source": "The Mark 1 was to provide a computing resource within the university, to allow researchers to gain experience in the practical use of computers, but it very quickly also became a prototype on which the design of Ferranti's commercial version could be based. Development ceased at the end of 1949, and the machine was scrapped towards the end of 1950, replaced in February 1951 by a Ferranti Mark 1, the world's first commercially available general-purpose electronic computer. The computer is especially historically significant because of its pioneering inclusion of index registers, an innovation which made it easier for a program to read sequentially through an array of words in memory. Thirty-four patents resulted from the machine's development, and many of the ideas behind its design were incorporated in subsequent commercial products such as the IBM 701 and 702 as well as the Ferranti Mark 1. The chief designers, Frederic C. Williams and Tom Kilburn, concluded from their experiences with the Mark1 that computers would be used more in scientific roles than in pure mathematics. In 1951, they started development work on Meg, the Mark1's successor, which would include a floating point unit.",
        "target": "It was also called the Manchester Automatic Digital Machine, or MADM."
    },
    {
        "source": "The computer is especially historically significant because of its pioneering inclusion of index registers, an innovation which made it easier for a program to read sequentially through an array of words in memory. Thirty-four patents resulted from the machine's development, and many of the ideas behind its design were incorporated in subsequent commercial products such as the IBM 701 and 702 as well as the Ferranti Mark 1. The chief designers, Frederic C. Williams and Tom Kilburn, concluded from their experiences with the Mark1 that computers would be used more in scientific roles than in pure mathematics. In 1951, they started development work on Meg, the Mark1's successor, which would include a floating point unit. It was also called the Manchester Automatic Digital Machine, or MADM.",
        "target": "In 1936, mathematician Alan Turing published a definition of a theoretical \"universal computing machine\", a computer which held its program on tape, along with the data being worked on. Turing proved that such a machine was capable of solving any conceivable mathematical problem for which an algorithm could be written. During the 1940s, Turing and others such as Konrad Zuse developed the idea of using the computer's own memory to hold both the program and data, instead of tape, but it was mathematician John von Neumann who became widely credited with defining that stored-program computer architecture, on which the Manchester Mark 1 was based."
    },
    {
        "source": "It was also called the Manchester Automatic Digital Machine, or MADM. In 1936, mathematician Alan Turing published a definition of a theoretical \"universal computing machine\", a computer which held its program on tape, along with the data being worked on. Turing proved that such a machine was capable of solving any conceivable mathematical problem for which an algorithm could be written. During the 1940s, Turing and others such as Konrad Zuse developed the idea of using the computer's own memory to hold both the program and data, instead of tape, but it was mathematician John von Neumann who became widely credited with defining that stored-program computer architecture, on which the Manchester Mark 1 was based.",
        "target": "The practical construction of a von Neumann computer depended on the availability of a suitable memory device. The University of Manchester's Baby, the world's first electronic stored-program computer, had successfully demonstrated the practicality of the stored-program approach and of the Williams tube, an early form of computer memory based on a standard cathode-ray tube (CRT), by running its first program on 21 June 1948. Early electronic computers were generally programmed by being rewired, or via plugs and patch panels; there was no separate program stored in memory, as in a modern computer. It could take several days to reprogram ENIAC, for instance. Stored-program computers were also being developed by other researchers, notably the National Physical Laboratory's Pilot ACE, Cambridge University's EDSAC, and the US Army's EDVAC. The Baby and the Mark 1 differed primarily in their use of Williams tubes as memory devices, instead of mercury delay lines."
    },
    {
        "source": "In 1936, mathematician Alan Turing published a definition of a theoretical \"universal computing machine\", a computer which held its program on tape, along with the data being worked on. Turing proved that such a machine was capable of solving any conceivable mathematical problem for which an algorithm could be written. During the 1940s, Turing and others such as Konrad Zuse developed the idea of using the computer's own memory to hold both the program and data, instead of tape, but it was mathematician John von Neumann who became widely credited with defining that stored-program computer architecture, on which the Manchester Mark 1 was based. The practical construction of a von Neumann computer depended on the availability of a suitable memory device. The University of Manchester's Baby, the world's first electronic stored-program computer, had successfully demonstrated the practicality of the stored-program approach and of the Williams tube, an early form of computer memory based on a standard cathode-ray tube (CRT), by running its first program on 21 June 1948. Early electronic computers were generally programmed by being rewired, or via plugs and patch panels; there was no separate program stored in memory, as in a modern computer. It could take several days to reprogram ENIAC, for instance. Stored-program computers were also being developed by other researchers, notably the National Physical Laboratory's Pilot ACE, Cambridge University's EDSAC, and the US Army's EDVAC. The Baby and the Mark 1 differed primarily in their use of Williams tubes as memory devices, instead of mercury delay lines.",
        "target": "From about August 1948, the Baby was intensively developed as a prototype for the Manchester Mark 1, initially with the aim of providing the university with a more realistic computing facility. In October 1948, UK Government Chief Scientist Ben Lockspeiser was given a demonstration of the prototype Mark 1 while on a visit to the University of Manchester. Lockspeiser was so impressed by what he saw that he immediately initiated a government contract with the local firm of Ferranti to make a commercial version of the machine, the Ferranti Mark 1. In his letter to the company, dated 26October 1948, Lockspeiser authorised the company to \"proceed on the lines we discussed, namely, to construct an electronic calculating machine to the instructions of Professor F. C. Williams\". From that point on, development of the Mark 1 had the additional purpose of supplying Ferranti with a design on which to base their commercial machine. The government's contract with Ferranti ran for five years from November 1948, and involved an estimated 35,000 per year (equivalent to 1.38million per year in 2023).[a]"
    },
    {
        "source": "The practical construction of a von Neumann computer depended on the availability of a suitable memory device. The University of Manchester's Baby, the world's first electronic stored-program computer, had successfully demonstrated the practicality of the stored-program approach and of the Williams tube, an early form of computer memory based on a standard cathode-ray tube (CRT), by running its first program on 21 June 1948. Early electronic computers were generally programmed by being rewired, or via plugs and patch panels; there was no separate program stored in memory, as in a modern computer. It could take several days to reprogram ENIAC, for instance. Stored-program computers were also being developed by other researchers, notably the National Physical Laboratory's Pilot ACE, Cambridge University's EDSAC, and the US Army's EDVAC. The Baby and the Mark 1 differed primarily in their use of Williams tubes as memory devices, instead of mercury delay lines. From about August 1948, the Baby was intensively developed as a prototype for the Manchester Mark 1, initially with the aim of providing the university with a more realistic computing facility. In October 1948, UK Government Chief Scientist Ben Lockspeiser was given a demonstration of the prototype Mark 1 while on a visit to the University of Manchester. Lockspeiser was so impressed by what he saw that he immediately initiated a government contract with the local firm of Ferranti to make a commercial version of the machine, the Ferranti Mark 1. In his letter to the company, dated 26October 1948, Lockspeiser authorised the company to \"proceed on the lines we discussed, namely, to construct an electronic calculating machine to the instructions of Professor F. C. Williams\". From that point on, development of the Mark 1 had the additional purpose of supplying Ferranti with a design on which to base their commercial machine. The government's contract with Ferranti ran for five years from November 1948, and involved an estimated 35,000 per year (equivalent to 1.38million per year in 2023).[a]",
        "target": "The Baby had been designed by the team of Frederic C. Williams, Tom Kilburn and Geoff Tootill. To develop the Mark 1 they were joined by two research students, D.B.G.Edwards and G. E. Thomas; work began in earnest in August 1948. The project soon had the dual purpose of supplying Ferranti with a working design on which they could base a commercial machine, the Ferranti Mark 1, and of building a computer that would allow researchers to gain experience of how such a machine could be used in practice. The first of the two versions of the Manchester Mark 1 known as the Intermediary Version was operational by April 1949. However, this first version lacked features such as the instructions necessary to programmatically transfer data between the main store and its newly developed magnetic backing store, which had to be done by halting the machine and manually initiating the transfer. These missing features were incorporated in the Final Specification version, which was fully working by October 1949. The machine contained 4,050 valves and had a power consumption of 25 kilowatts. To increase reliability, purpose-built CRTs made by GEC were used in the machine instead of the standard devices used in the Baby."
    },
    {
        "source": "From about August 1948, the Baby was intensively developed as a prototype for the Manchester Mark 1, initially with the aim of providing the university with a more realistic computing facility. In October 1948, UK Government Chief Scientist Ben Lockspeiser was given a demonstration of the prototype Mark 1 while on a visit to the University of Manchester. Lockspeiser was so impressed by what he saw that he immediately initiated a government contract with the local firm of Ferranti to make a commercial version of the machine, the Ferranti Mark 1. In his letter to the company, dated 26October 1948, Lockspeiser authorised the company to \"proceed on the lines we discussed, namely, to construct an electronic calculating machine to the instructions of Professor F. C. Williams\". From that point on, development of the Mark 1 had the additional purpose of supplying Ferranti with a design on which to base their commercial machine. The government's contract with Ferranti ran for five years from November 1948, and involved an estimated 35,000 per year (equivalent to 1.38million per year in 2023).[a] The Baby had been designed by the team of Frederic C. Williams, Tom Kilburn and Geoff Tootill. To develop the Mark 1 they were joined by two research students, D.B.G.Edwards and G. E. Thomas; work began in earnest in August 1948. The project soon had the dual purpose of supplying Ferranti with a working design on which they could base a commercial machine, the Ferranti Mark 1, and of building a computer that would allow researchers to gain experience of how such a machine could be used in practice. The first of the two versions of the Manchester Mark 1 known as the Intermediary Version was operational by April 1949. However, this first version lacked features such as the instructions necessary to programmatically transfer data between the main store and its newly developed magnetic backing store, which had to be done by halting the machine and manually initiating the transfer. These missing features were incorporated in the Final Specification version, which was fully working by October 1949. The machine contained 4,050 valves and had a power consumption of 25 kilowatts. To increase reliability, purpose-built CRTs made by GEC were used in the machine instead of the standard devices used in the Baby.",
        "target": "The Baby's 32-bit word length was increased to 40 bits. Each word could hold either one 40-bit number or two 20-bit program instructions. The main store initially consisted of two double-density Williams tubes, each holding two arrays of 32 x 40-bit words known as pages backed up by a magnetic drum capable of storing an additional 32 pages.  The capacity was increased in the Final Specification version to eight pages of main store on four Williams tubes and 128 magnetic drum pages of backing store. The 12-inch (300mm) diameter drum, initially known as a magnetic wheel, contained a series of parallel magnetic tracks around its surface, each with its own read/write head. Each track held 2,560bits, corresponding to twopages (23240bits). One revolution of the drum took 30milliseconds, during which time both pages could be transferred to the CRT main memory, although the actual data transfer time depended on the latency, the time it took for a page to arrive under the read/write head. Writing pages to the drum took about twice as long as reading. The drum's rotational speed was synchronised to the main central processor clock, which allowed for additional drums to be added. Data was recorded onto the drum using a phase modulation technique still known today as Manchester coding."
    },
    {
        "source": "The Baby had been designed by the team of Frederic C. Williams, Tom Kilburn and Geoff Tootill. To develop the Mark 1 they were joined by two research students, D.B.G.Edwards and G. E. Thomas; work began in earnest in August 1948. The project soon had the dual purpose of supplying Ferranti with a working design on which they could base a commercial machine, the Ferranti Mark 1, and of building a computer that would allow researchers to gain experience of how such a machine could be used in practice. The first of the two versions of the Manchester Mark 1 known as the Intermediary Version was operational by April 1949. However, this first version lacked features such as the instructions necessary to programmatically transfer data between the main store and its newly developed magnetic backing store, which had to be done by halting the machine and manually initiating the transfer. These missing features were incorporated in the Final Specification version, which was fully working by October 1949. The machine contained 4,050 valves and had a power consumption of 25 kilowatts. To increase reliability, purpose-built CRTs made by GEC were used in the machine instead of the standard devices used in the Baby. The Baby's 32-bit word length was increased to 40 bits. Each word could hold either one 40-bit number or two 20-bit program instructions. The main store initially consisted of two double-density Williams tubes, each holding two arrays of 32 x 40-bit words known as pages backed up by a magnetic drum capable of storing an additional 32 pages.  The capacity was increased in the Final Specification version to eight pages of main store on four Williams tubes and 128 magnetic drum pages of backing store. The 12-inch (300mm) diameter drum, initially known as a magnetic wheel, contained a series of parallel magnetic tracks around its surface, each with its own read/write head. Each track held 2,560bits, corresponding to twopages (23240bits). One revolution of the drum took 30milliseconds, during which time both pages could be transferred to the CRT main memory, although the actual data transfer time depended on the latency, the time it took for a page to arrive under the read/write head. Writing pages to the drum took about twice as long as reading. The drum's rotational speed was synchronised to the main central processor clock, which allowed for additional drums to be added. Data was recorded onto the drum using a phase modulation technique still known today as Manchester coding.",
        "target": "The machine's instruction set was increased from the 7 of the Baby to 26 initially, including multiplication done in hardware. This increased to 30instructions in the Final Specification version. Ten bits of each word were allocated to hold the instruction code. The standard instruction time was 1.8 milliseconds, but multiplication was much slower, depending on the size of the operand."
    },
    {
        "source": "The Baby's 32-bit word length was increased to 40 bits. Each word could hold either one 40-bit number or two 20-bit program instructions. The main store initially consisted of two double-density Williams tubes, each holding two arrays of 32 x 40-bit words known as pages backed up by a magnetic drum capable of storing an additional 32 pages.  The capacity was increased in the Final Specification version to eight pages of main store on four Williams tubes and 128 magnetic drum pages of backing store. The 12-inch (300mm) diameter drum, initially known as a magnetic wheel, contained a series of parallel magnetic tracks around its surface, each with its own read/write head. Each track held 2,560bits, corresponding to twopages (23240bits). One revolution of the drum took 30milliseconds, during which time both pages could be transferred to the CRT main memory, although the actual data transfer time depended on the latency, the time it took for a page to arrive under the read/write head. Writing pages to the drum took about twice as long as reading. The drum's rotational speed was synchronised to the main central processor clock, which allowed for additional drums to be added. Data was recorded onto the drum using a phase modulation technique still known today as Manchester coding. The machine's instruction set was increased from the 7 of the Baby to 26 initially, including multiplication done in hardware. This increased to 30instructions in the Final Specification version. Ten bits of each word were allocated to hold the instruction code. The standard instruction time was 1.8 milliseconds, but multiplication was much slower, depending on the size of the operand.",
        "target": "The machine's most significant innovation is generally considered to be its incorporation of index registers, commonplace on modern computers. The Baby had included two registers, implemented as Williams tubes: the accumulator (A) and the program counter (C). As A and C had already been assigned, the tube holding the two index registers, originally known as B-lines, was given the name B. The contents of the registers could be used to modify program instructions, allowing convenient iteration through an array of numbers stored in memory. The Mark 1 also had a fourth tube, (M), to hold the multiplicand and multiplier for a multiplication operation."
    },
    {
        "source": "The machine's instruction set was increased from the 7 of the Baby to 26 initially, including multiplication done in hardware. This increased to 30instructions in the Final Specification version. Ten bits of each word were allocated to hold the instruction code. The standard instruction time was 1.8 milliseconds, but multiplication was much slower, depending on the size of the operand. The machine's most significant innovation is generally considered to be its incorporation of index registers, commonplace on modern computers. The Baby had included two registers, implemented as Williams tubes: the accumulator (A) and the program counter (C). As A and C had already been assigned, the tube holding the two index registers, originally known as B-lines, was given the name B. The contents of the registers could be used to modify program instructions, allowing convenient iteration through an array of numbers stored in memory. The Mark 1 also had a fourth tube, (M), to hold the multiplicand and multiplier for a multiplication operation.",
        "target": "Of the 20 bits allocated for each program instruction, 10 were used to hold the instruction code, which allowed for 1,024 (210) different instructions. The machine had 26 initially, increasing to 30 when the function codes to programmatically control the data transfer between the magnetic drum and the cathode-ray tube (CRT) main store were added. On the Intermediary Version programs were input by key switches, and the output was displayed as a series of dots and dashes on a cathode-ray tube known as the output device, just as on the Baby from which the Mark 1 had been developed. However, the Final Specification machine, completed in October 1949, benefitted from the addition of a teleprinter with a five-hole paper-tape reader and punch."
    },
    {
        "source": "The machine's most significant innovation is generally considered to be its incorporation of index registers, commonplace on modern computers. The Baby had included two registers, implemented as Williams tubes: the accumulator (A) and the program counter (C). As A and C had already been assigned, the tube holding the two index registers, originally known as B-lines, was given the name B. The contents of the registers could be used to modify program instructions, allowing convenient iteration through an array of numbers stored in memory. The Mark 1 also had a fourth tube, (M), to hold the multiplicand and multiplier for a multiplication operation. Of the 20 bits allocated for each program instruction, 10 were used to hold the instruction code, which allowed for 1,024 (210) different instructions. The machine had 26 initially, increasing to 30 when the function codes to programmatically control the data transfer between the magnetic drum and the cathode-ray tube (CRT) main store were added. On the Intermediary Version programs were input by key switches, and the output was displayed as a series of dots and dashes on a cathode-ray tube known as the output device, just as on the Baby from which the Mark 1 had been developed. However, the Final Specification machine, completed in October 1949, benefitted from the addition of a teleprinter with a five-hole paper-tape reader and punch.",
        "target": "Mathematician Alan Turing, who had been appointed to the nominal post of Deputy Director of the Computing Machine Laboratory at the University of Manchester in September 1948, devised a base 32 encoding scheme based on the standard ITA2 5-bit teleprinter code, which allowed programs and data to be written to and read from paper tape. The ITA2 system maps each of the possible 32 binary values that can be represented in 5 bits (25) to a single character. Thus \"10010\" represents \"D\", \"10001\" represents \"Z\", and so forth. Turing changed only a few of the standard encodings; for instance, 00000 and 01000, which mean \"no effect\" and \"linefeed\" in the teleprinter code, were represented by the characters \"/\" and \"@\" respectively. Binary zero, represented by the forward slash, was the most common character in programs and data, leading to sequences written as \"///////////////\". One early user suggested that Turing's choice of a forward slash was a subconscious choice on his part, a representation of rain seen through a dirty window, reflecting Manchester's \"famously dismal\" weather."
    },
    {
        "source": "Of the 20 bits allocated for each program instruction, 10 were used to hold the instruction code, which allowed for 1,024 (210) different instructions. The machine had 26 initially, increasing to 30 when the function codes to programmatically control the data transfer between the magnetic drum and the cathode-ray tube (CRT) main store were added. On the Intermediary Version programs were input by key switches, and the output was displayed as a series of dots and dashes on a cathode-ray tube known as the output device, just as on the Baby from which the Mark 1 had been developed. However, the Final Specification machine, completed in October 1949, benefitted from the addition of a teleprinter with a five-hole paper-tape reader and punch. Mathematician Alan Turing, who had been appointed to the nominal post of Deputy Director of the Computing Machine Laboratory at the University of Manchester in September 1948, devised a base 32 encoding scheme based on the standard ITA2 5-bit teleprinter code, which allowed programs and data to be written to and read from paper tape. The ITA2 system maps each of the possible 32 binary values that can be represented in 5 bits (25) to a single character. Thus \"10010\" represents \"D\", \"10001\" represents \"Z\", and so forth. Turing changed only a few of the standard encodings; for instance, 00000 and 01000, which mean \"no effect\" and \"linefeed\" in the teleprinter code, were represented by the characters \"/\" and \"@\" respectively. Binary zero, represented by the forward slash, was the most common character in programs and data, leading to sequences written as \"///////////////\". One early user suggested that Turing's choice of a forward slash was a subconscious choice on his part, a representation of rain seen through a dirty window, reflecting Manchester's \"famously dismal\" weather.",
        "target": "Because the Mark 1 had a 40-bit word length, eight 5-bit teleprinter characters were required to encode each word. Thus for example the binary word:"
    },
    {
        "source": "Mathematician Alan Turing, who had been appointed to the nominal post of Deputy Director of the Computing Machine Laboratory at the University of Manchester in September 1948, devised a base 32 encoding scheme based on the standard ITA2 5-bit teleprinter code, which allowed programs and data to be written to and read from paper tape. The ITA2 system maps each of the possible 32 binary values that can be represented in 5 bits (25) to a single character. Thus \"10010\" represents \"D\", \"10001\" represents \"Z\", and so forth. Turing changed only a few of the standard encodings; for instance, 00000 and 01000, which mean \"no effect\" and \"linefeed\" in the teleprinter code, were represented by the characters \"/\" and \"@\" respectively. Binary zero, represented by the forward slash, was the most common character in programs and data, leading to sequences written as \"///////////////\". One early user suggested that Turing's choice of a forward slash was a subconscious choice on his part, a representation of rain seen through a dirty window, reflecting Manchester's \"famously dismal\" weather. Because the Mark 1 had a 40-bit word length, eight 5-bit teleprinter characters were required to encode each word. Thus for example the binary word:",
        "target": "would be represented on paper tape as ZDSLZWRF. The contents of any word in store could also be set via the teleprinter's keyboard, and output onto its printer. The machine worked internally in binary, but it was able to carry out the necessary decimal to binary and binary to decimal conversions for its input and output respectively."
    },
    {
        "source": "Because the Mark 1 had a 40-bit word length, eight 5-bit teleprinter characters were required to encode each word. Thus for example the binary word: would be represented on paper tape as ZDSLZWRF. The contents of any word in store could also be set via the teleprinter's keyboard, and output onto its printer. The machine worked internally in binary, but it was able to carry out the necessary decimal to binary and binary to decimal conversions for its input and output respectively.",
        "target": "There was no assembly language defined for the Mark 1. Programs had to be written and submitted in binary form, encoded as eight 5-bit characters for each 40-bit word; programmers were encouraged to memorize the modified ITA2 coding scheme to make their job easier. Data was read and written from the papertape punch under program control. The Mark 1 had no system of hardware interrupts; the program continued after a read or write operation had been initiated until another input/output instruction was encountered, at which point the machine waited for the first to complete."
    },
    {
        "source": "would be represented on paper tape as ZDSLZWRF. The contents of any word in store could also be set via the teleprinter's keyboard, and output onto its printer. The machine worked internally in binary, but it was able to carry out the necessary decimal to binary and binary to decimal conversions for its input and output respectively. There was no assembly language defined for the Mark 1. Programs had to be written and submitted in binary form, encoded as eight 5-bit characters for each 40-bit word; programmers were encouraged to memorize the modified ITA2 coding scheme to make their job easier. Data was read and written from the papertape punch under program control. The Mark 1 had no system of hardware interrupts; the program continued after a read or write operation had been initiated until another input/output instruction was encountered, at which point the machine waited for the first to complete.",
        "target": "The Mark 1 had no operating system; its only system software was a few basic routines for input and output. As in the Baby from which it was developed, and in contrast to the established mathematical convention, the machine's storage was arranged with the least significant digits to the left; thus a one was represented in five bits as \"10000\", rather than the more conventional \"00001\". Negative numbers were represented using two's complement, as most computers still do today. In that representation, the value of the most significant bit denotes the sign of a number; positive numbers have a zero in that position and negative numbers a one. Thus the range of numbers that could be held in each 40-bit word was 239 to +2391 (decimal: -549,755,813,888 to +549,755,813,887)."
    },
    {
        "source": "There was no assembly language defined for the Mark 1. Programs had to be written and submitted in binary form, encoded as eight 5-bit characters for each 40-bit word; programmers were encouraged to memorize the modified ITA2 coding scheme to make their job easier. Data was read and written from the papertape punch under program control. The Mark 1 had no system of hardware interrupts; the program continued after a read or write operation had been initiated until another input/output instruction was encountered, at which point the machine waited for the first to complete. The Mark 1 had no operating system; its only system software was a few basic routines for input and output. As in the Baby from which it was developed, and in contrast to the established mathematical convention, the machine's storage was arranged with the least significant digits to the left; thus a one was represented in five bits as \"10000\", rather than the more conventional \"00001\". Negative numbers were represented using two's complement, as most computers still do today. In that representation, the value of the most significant bit denotes the sign of a number; positive numbers have a zero in that position and negative numbers a one. Thus the range of numbers that could be held in each 40-bit word was 239 to +2391 (decimal: -549,755,813,888 to +549,755,813,887).",
        "target": "The first realistic program to be run on the Mark 1 was a search for Mersenne primes, in early April 1949, which ran error free for nine hours on the night of 16/17 June 1949."
    },
    {
        "source": "The Mark 1 had no operating system; its only system software was a few basic routines for input and output. As in the Baby from which it was developed, and in contrast to the established mathematical convention, the machine's storage was arranged with the least significant digits to the left; thus a one was represented in five bits as \"10000\", rather than the more conventional \"00001\". Negative numbers were represented using two's complement, as most computers still do today. In that representation, the value of the most significant bit denotes the sign of a number; positive numbers have a zero in that position and negative numbers a one. Thus the range of numbers that could be held in each 40-bit word was 239 to +2391 (decimal: -549,755,813,888 to +549,755,813,887). The first realistic program to be run on the Mark 1 was a search for Mersenne primes, in early April 1949, which ran error free for nine hours on the night of 16/17 June 1949.",
        "target": "The algorithm was specified by Max Newman, head of the Mathematics Department at the University of Manchester, and the program was written by Kilburn and Tootill. Alan Turing later wrote an optimised version of the program, dubbed the Mersenne Express."
    },
    {
        "source": "The first realistic program to be run on the Mark 1 was a search for Mersenne primes, in early April 1949, which ran error free for nine hours on the night of 16/17 June 1949. The algorithm was specified by Max Newman, head of the Mathematics Department at the University of Manchester, and the program was written by Kilburn and Tootill. Alan Turing later wrote an optimised version of the program, dubbed the Mersenne Express.",
        "target": "The Manchester Mark 1 continued to do useful mathematical work until 1950, including an investigation of the Riemann hypothesis and calculations in optics."
    },
    {
        "source": "The algorithm was specified by Max Newman, head of the Mathematics Department at the University of Manchester, and the program was written by Kilburn and Tootill. Alan Turing later wrote an optimised version of the program, dubbed the Mersenne Express. The Manchester Mark 1 continued to do useful mathematical work until 1950, including an investigation of the Riemann hypothesis and calculations in optics.",
        "target": "Tootill was temporarily transferred from the University of Manchester to Ferranti in August 1949, to continue work on the Ferranti Mark 1's design, and spent four months working with the company. The Manchester Mark 1 was dismantled and scrapped in August 1950, replaced a few months later by the first Ferranti Mark 1, the world's first commercially available general-purpose computer."
    },
    {
        "source": "The Manchester Mark 1 continued to do useful mathematical work until 1950, including an investigation of the Riemann hypothesis and calculations in optics. Tootill was temporarily transferred from the University of Manchester to Ferranti in August 1949, to continue work on the Ferranti Mark 1's design, and spent four months working with the company. The Manchester Mark 1 was dismantled and scrapped in August 1950, replaced a few months later by the first Ferranti Mark 1, the world's first commercially available general-purpose computer.",
        "target": "Between 1946 and 1949, the average size of the design team working on the Mark 1 and its predecessor, the Baby, had been about four people. During that time 34patents were taken out based on the team's work, either by the Ministry of Supply or by its successor, the National Research Development Corporation. In July 1949, IBM invited Williams to the United States on an all-expenses-paid trip to discuss the Mark 1's design. The company subsequently licensed several of the patented ideas developed for the machine, including the Williams tube, in the design of its own 701 and 702 computers. The most significant design legacy of the Manchester Mark 1 was perhaps its incorporation of index registers, the patent for which was taken out in the names of Williams, Kilburn, Tootill, and Newman."
    },
    {
        "source": "Tootill was temporarily transferred from the University of Manchester to Ferranti in August 1949, to continue work on the Ferranti Mark 1's design, and spent four months working with the company. The Manchester Mark 1 was dismantled and scrapped in August 1950, replaced a few months later by the first Ferranti Mark 1, the world's first commercially available general-purpose computer. Between 1946 and 1949, the average size of the design team working on the Mark 1 and its predecessor, the Baby, had been about four people. During that time 34patents were taken out based on the team's work, either by the Ministry of Supply or by its successor, the National Research Development Corporation. In July 1949, IBM invited Williams to the United States on an all-expenses-paid trip to discuss the Mark 1's design. The company subsequently licensed several of the patented ideas developed for the machine, including the Williams tube, in the design of its own 701 and 702 computers. The most significant design legacy of the Manchester Mark 1 was perhaps its incorporation of index registers, the patent for which was taken out in the names of Williams, Kilburn, Tootill, and Newman.",
        "target": "Kilburn and Williams concluded that computers would be used more in scientific roles than pure maths, and decided to develop a new machine that would include a floating point unit. Work began in 1951, and the resulting machine, which ran its first program in May 1954, was known as Meg, or the megacycle machine. It was smaller and simpler than the Mark 1, and much faster for maths problems. Ferranti produced a version of Meg with the Williams tubes replaced by the more reliable core memory, marketed as the Ferranti Mercury."
    },
    {
        "source": "Between 1946 and 1949, the average size of the design team working on the Mark 1 and its predecessor, the Baby, had been about four people. During that time 34patents were taken out based on the team's work, either by the Ministry of Supply or by its successor, the National Research Development Corporation. In July 1949, IBM invited Williams to the United States on an all-expenses-paid trip to discuss the Mark 1's design. The company subsequently licensed several of the patented ideas developed for the machine, including the Williams tube, in the design of its own 701 and 702 computers. The most significant design legacy of the Manchester Mark 1 was perhaps its incorporation of index registers, the patent for which was taken out in the names of Williams, Kilburn, Tootill, and Newman. Kilburn and Williams concluded that computers would be used more in scientific roles than pure maths, and decided to develop a new machine that would include a floating point unit. Work began in 1951, and the resulting machine, which ran its first program in May 1954, was known as Meg, or the megacycle machine. It was smaller and simpler than the Mark 1, and much faster for maths problems. Ferranti produced a version of Meg with the Williams tubes replaced by the more reliable core memory, marketed as the Ferranti Mercury.",
        "target": "The successful operation of the Manchester Mark 1 and its predecessor, the Baby, was widely reported in the British press, which used the phrase \"electronic brain\" to describe the machines. Lord Louis Mountbatten had earlier introduced that term in a speech delivered to the British Institution of Radio Engineers on 31 October 1946, in which he speculated about how the primitive computers then available might evolve. The excitement surrounding the reporting in 1949 of what was the first recognisably modern computer provoked a reaction unexpected by its developers; Sir Geoffrey Jefferson, professor of neurosurgery at the University of Manchester, on being asked to deliver the Lister Oration on 9June 1949 chose \"The Mind of Mechanical Man\" as his subject. His purpose was to \"debunk\" the Manchester project. In his address he said:"
    },
    {
        "source": "Kilburn and Williams concluded that computers would be used more in scientific roles than pure maths, and decided to develop a new machine that would include a floating point unit. Work began in 1951, and the resulting machine, which ran its first program in May 1954, was known as Meg, or the megacycle machine. It was smaller and simpler than the Mark 1, and much faster for maths problems. Ferranti produced a version of Meg with the Williams tubes replaced by the more reliable core memory, marketed as the Ferranti Mercury. The successful operation of the Manchester Mark 1 and its predecessor, the Baby, was widely reported in the British press, which used the phrase \"electronic brain\" to describe the machines. Lord Louis Mountbatten had earlier introduced that term in a speech delivered to the British Institution of Radio Engineers on 31 October 1946, in which he speculated about how the primitive computers then available might evolve. The excitement surrounding the reporting in 1949 of what was the first recognisably modern computer provoked a reaction unexpected by its developers; Sir Geoffrey Jefferson, professor of neurosurgery at the University of Manchester, on being asked to deliver the Lister Oration on 9June 1949 chose \"The Mind of Mechanical Man\" as his subject. His purpose was to \"debunk\" the Manchester project. In his address he said:",
        "target": "Not until a machine can write a sonnet or compose a concerto because of thoughts and emotions felt, and not by the chance fall of symbols, could we agree that machine equals brain that is, not only write it but know that it had written it. No machinecould feel pleasure at its success, grief when its valves fuse, be warmed by flattery, be made miserable by its mistakes, be charmed by sex, be angry or miserable when it cannot get what it wants."
    },
    {
        "source": "The successful operation of the Manchester Mark 1 and its predecessor, the Baby, was widely reported in the British press, which used the phrase \"electronic brain\" to describe the machines. Lord Louis Mountbatten had earlier introduced that term in a speech delivered to the British Institution of Radio Engineers on 31 October 1946, in which he speculated about how the primitive computers then available might evolve. The excitement surrounding the reporting in 1949 of what was the first recognisably modern computer provoked a reaction unexpected by its developers; Sir Geoffrey Jefferson, professor of neurosurgery at the University of Manchester, on being asked to deliver the Lister Oration on 9June 1949 chose \"The Mind of Mechanical Man\" as his subject. His purpose was to \"debunk\" the Manchester project. In his address he said: Not until a machine can write a sonnet or compose a concerto because of thoughts and emotions felt, and not by the chance fall of symbols, could we agree that machine equals brain that is, not only write it but know that it had written it. No machinecould feel pleasure at its success, grief when its valves fuse, be warmed by flattery, be made miserable by its mistakes, be charmed by sex, be angry or miserable when it cannot get what it wants.",
        "target": "The Times reported on Jefferson's speech the following day, adding that Jefferson forecast that \"the day would never dawn when the gracious rooms of the Royal Society would be converted into garages to house these new fellows\". This was interpreted as a deliberate slight to Newman, who had secured a grant from the society to continue the work of the Manchester team. In response Newman wrote a follow-up article for The Times, in which he claimed that there was a close analogy between the structure of the Mark 1 and the human brain. His article included an interview with Turing, who added:"
    },
    {
        "source": "Not until a machine can write a sonnet or compose a concerto because of thoughts and emotions felt, and not by the chance fall of symbols, could we agree that machine equals brain that is, not only write it but know that it had written it. No machinecould feel pleasure at its success, grief when its valves fuse, be warmed by flattery, be made miserable by its mistakes, be charmed by sex, be angry or miserable when it cannot get what it wants. The Times reported on Jefferson's speech the following day, adding that Jefferson forecast that \"the day would never dawn when the gracious rooms of the Royal Society would be converted into garages to house these new fellows\". This was interpreted as a deliberate slight to Newman, who had secured a grant from the society to continue the work of the Manchester team. In response Newman wrote a follow-up article for The Times, in which he claimed that there was a close analogy between the structure of the Mark 1 and the human brain. His article included an interview with Turing, who added:",
        "target": "This is only a foretaste of what is to come, and only the shadow of what is going to be. We have to have some experience with the machine before we really know its capabilities. It may take years before we settle down to the new possibilities, but I do not see why it should not enter any of the fields normally covered by the human intellect and eventually compete on equal terms."
    },
    {
        "source": " The Million Dollar Homepage is a website conceived in 2005 by Alex Tew, a student from Wiltshire, England, to raise money for his university education. The home page consists of a million pixels arranged in a 1000  1000 pixel grid; the image-based links on it were sold for $1 per pixel in  10  10 blocks. The purchasers of these pixel blocks provided tiny images to be displayed on them, a URL to which the images were linked, and a slogan to be displayed when hovering a cursor over the link. The aim of the website was to sell all the pixels in the image, thus generating a million dollars of income for the creator. The Wall Street Journal has commented that the site inspired other websites that sell pixels.",
        "target": "Launched on 26 August 2005, the website became an Internet phenomenon, with copycat websites emerging in response. The Alexa ranking of web traffic peaked at around 127; As of 9May2009[update], it was 40,044. On 1 January 2006, the final 1,000 pixels were put up for auction on eBay. The auction closed on 11 January with a winning bid of $38,100 that brought the final tally to $1,037,100 in gross."
    },
    {
        "source": "The Million Dollar Homepage is a website conceived in 2005 by Alex Tew, a student from Wiltshire, England, to raise money for his university education. The home page consists of a million pixels arranged in a 1000  1000 pixel grid; the image-based links on it were sold for $1 per pixel in  10  10 blocks. The purchasers of these pixel blocks provided tiny images to be displayed on them, a URL to which the images were linked, and a slogan to be displayed when hovering a cursor over the link. The aim of the website was to sell all the pixels in the image, thus generating a million dollars of income for the creator. The Wall Street Journal has commented that the site inspired other websites that sell pixels. Launched on 26 August 2005, the website became an Internet phenomenon, with copycat websites emerging in response. The Alexa ranking of web traffic peaked at around 127; As of 9May2009[update], it was 40,044. On 1 January 2006, the final 1,000 pixels were put up for auction on eBay. The auction closed on 11 January with a winning bid of $38,100 that brought the final tally to $1,037,100 in gross.",
        "target": "During the January 2006 auction, the website was subject to a distributed denial-of-service attack (DDoS) and ransom demand, which left it inaccessible to visitors for a week while its security system was upgraded. The Federal Bureau of Investigation and Wiltshire Constabulary investigated the attack and extortion attempt."
    },
    {
        "source": "Launched on 26 August 2005, the website became an Internet phenomenon, with copycat websites emerging in response. The Alexa ranking of web traffic peaked at around 127; As of 9May2009[update], it was 40,044. On 1 January 2006, the final 1,000 pixels were put up for auction on eBay. The auction closed on 11 January with a winning bid of $38,100 that brought the final tally to $1,037,100 in gross. During the January 2006 auction, the website was subject to a distributed denial-of-service attack (DDoS) and ransom demand, which left it inaccessible to visitors for a week while its security system was upgraded. The Federal Bureau of Investigation and Wiltshire Constabulary investigated the attack and extortion attempt.",
        "target": "After a short time, Tew decided to drop out of the business degree program for which he had created the site in the first place. As of 2019, The Million Dollar Homepage was still receiving thousands of daily viewers; however, by 2017, many of the website's links suffered from link rot,  causing the URLs to no longer function as originally intended."
    },
    {
        "source": "During the January 2006 auction, the website was subject to a distributed denial-of-service attack (DDoS) and ransom demand, which left it inaccessible to visitors for a week while its security system was upgraded. The Federal Bureau of Investigation and Wiltshire Constabulary investigated the attack and extortion attempt. After a short time, Tew decided to drop out of the business degree program for which he had created the site in the first place. As of 2019, The Million Dollar Homepage was still receiving thousands of daily viewers; however, by 2017, many of the website's links suffered from link rot,  causing the URLs to no longer function as originally intended.",
        "target": "From the outset I knew the idea had potential, but it was one of those things that could have gone either way. My thinking was I had nothing to lose (apart from the 50 Euros or so it cost to register the domain and setup the hosting). I knew that the idea was quirky enough to create interest... The Internet is a very powerful medium."
    },
    {
        "source": "From the outset I knew the idea had potential, but it was one of those things that could have gone either way. My thinking was I had nothing to lose (apart from the 50 Euros or so it cost to register the domain and setup the hosting). I knew that the idea was quirky enough to create interest... The Internet is a very powerful medium. Alex Tew, 22 February 2006.",
        "target": "Alex Tew, a student from Cricklade in Wiltshire, England, conceived The Million Dollar Homepage in August 2005 when he was 21 years old. He was about to begin a three-year Business Management course at the University of Nottingham, and was concerned that he would be left with a student loan that could take years to repay. As a money-raising idea, Tew decided to sell a million pixels on a website for $1 each; purchasers would add their own image, logo or advertisement, and have the option of including a hyperlink to their website. Pixels were sold for US dollars rather than UK pounds; the US has a larger online population than the UK, and Tew believed more people would relate to the concept if the pixels were sold in US currency. In 2005, the pound was strong against the dollar: 1 was worth approximately $1.80, and that cost per pixel may have been too expensive for many potential buyers. Tew's setup costs were 50, which paid for the registration of the domain name and a basic web-hosting package. The website went live on 26 August 2005."
    },
    {
        "source": "Alex Tew, 22 February 2006. Alex Tew, a student from Cricklade in Wiltshire, England, conceived The Million Dollar Homepage in August 2005 when he was 21 years old. He was about to begin a three-year Business Management course at the University of Nottingham, and was concerned that he would be left with a student loan that could take years to repay. As a money-raising idea, Tew decided to sell a million pixels on a website for $1 each; purchasers would add their own image, logo or advertisement, and have the option of including a hyperlink to their website. Pixels were sold for US dollars rather than UK pounds; the US has a larger online population than the UK, and Tew believed more people would relate to the concept if the pixels were sold in US currency. In 2005, the pound was strong against the dollar: 1 was worth approximately $1.80, and that cost per pixel may have been too expensive for many potential buyers. Tew's setup costs were 50, which paid for the registration of the domain name and a basic web-hosting package. The website went live on 26 August 2005.",
        "target": "The homepage featured a Web banner with the site's name and a pixel counter displaying the number of pixels sold, a navigation bar containing nine small links to the site's internal web pages, and an empty square grid of 1,000,000 pixels divided into 10,000 100-pixel blocks. Tew promised customers that the site would remain online for at least five years  that is, until at least 26 August 2010."
    },
    {
        "source": "Alex Tew, a student from Cricklade in Wiltshire, England, conceived The Million Dollar Homepage in August 2005 when he was 21 years old. He was about to begin a three-year Business Management course at the University of Nottingham, and was concerned that he would be left with a student loan that could take years to repay. As a money-raising idea, Tew decided to sell a million pixels on a website for $1 each; purchasers would add their own image, logo or advertisement, and have the option of including a hyperlink to their website. Pixels were sold for US dollars rather than UK pounds; the US has a larger online population than the UK, and Tew believed more people would relate to the concept if the pixels were sold in US currency. In 2005, the pound was strong against the dollar: 1 was worth approximately $1.80, and that cost per pixel may have been too expensive for many potential buyers. Tew's setup costs were 50, which paid for the registration of the domain name and a basic web-hosting package. The website went live on 26 August 2005. The homepage featured a Web banner with the site's name and a pixel counter displaying the number of pixels sold, a navigation bar containing nine small links to the site's internal web pages, and an empty square grid of 1,000,000 pixels divided into 10,000 100-pixel blocks. Tew promised customers that the site would remain online for at least five years  that is, until at least 26 August 2010.",
        "target": "Because individual pixels are too small to be seen easily, pixels were sold in 100-pixel \"blocks\" measuring 10  10 pixels; the minimum price was thus $100. The first sale, three days after the site began operating, was to an online music website operated by a friend of Tew's. He bought 400 pixels in a 20  20 block. After two weeks, Tew's friends and family members had purchased a total of 4,700 pixels. The site was initially marketed only through word of mouth; however, after the site had made $1,000, a press release was sent out that was picked up by the BBC. The technology news website The Register featured two articles on The Million Dollar Homepage in September. By the end of the month, The Million Dollar Homepage had received $250,000 and was ranked Number 3 on Alexa Internet's list of \"Movers and Shakers\" behind the websites for Britney Spears and Photo District News. On 6 October, Tew reported the site received 65,000 unique visitors; it received 1465 Diggs, becoming one of the most Dugg links that week. Eleven days later, the number had increased to 100,000 unique visitors. On 26 October, two months after The Million Dollar Homepage was launched, more than 500,900 pixels had been sold to 1,400 customers. By New Year's Eve, Tew reported that the site was receiving hits from 25,000 unique visitors every hour and had an Alexa Rank of 127, and that 999,000 of the 1,000,000 pixels had been sold."
    },
    {
        "source": "The homepage featured a Web banner with the site's name and a pixel counter displaying the number of pixels sold, a navigation bar containing nine small links to the site's internal web pages, and an empty square grid of 1,000,000 pixels divided into 10,000 100-pixel blocks. Tew promised customers that the site would remain online for at least five years  that is, until at least 26 August 2010. Because individual pixels are too small to be seen easily, pixels were sold in 100-pixel \"blocks\" measuring 10  10 pixels; the minimum price was thus $100. The first sale, three days after the site began operating, was to an online music website operated by a friend of Tew's. He bought 400 pixels in a 20  20 block. After two weeks, Tew's friends and family members had purchased a total of 4,700 pixels. The site was initially marketed only through word of mouth; however, after the site had made $1,000, a press release was sent out that was picked up by the BBC. The technology news website The Register featured two articles on The Million Dollar Homepage in September. By the end of the month, The Million Dollar Homepage had received $250,000 and was ranked Number 3 on Alexa Internet's list of \"Movers and Shakers\" behind the websites for Britney Spears and Photo District News. On 6 October, Tew reported the site received 65,000 unique visitors; it received 1465 Diggs, becoming one of the most Dugg links that week. Eleven days later, the number had increased to 100,000 unique visitors. On 26 October, two months after The Million Dollar Homepage was launched, more than 500,900 pixels had been sold to 1,400 customers. By New Year's Eve, Tew reported that the site was receiving hits from 25,000 unique visitors every hour and had an Alexa Rank of 127, and that 999,000 of the 1,000,000 pixels had been sold.",
        "target": "On 1 January 2006, Tew announced that because the demand was so great for the last 1,000 pixels, \"the most fair and logical thing\" to do was auction them on eBay rather than lose \"the integrity and degree of exclusivity intrinsic to the million-pixel concept\" by launching a second Million Dollar Homepage. The auction lasted ten days and received 99 legitimate bids. Although bids were received for amounts as high as $160,109.99, many were either retracted by the bidders or cancelled as hoaxes. \"I actually contacted the people by phone and turns out they weren't serious, which is fairly frustrating, so I removed those bidders at the last minute\", said Tew. The winning bid was $38,100, placed by MillionDollarWeightLoss.com, an online store selling diet-related products. Tew remarked that he had expected the final bid amount to be higher due to the media attention. The Million Dollar Homepage made a gross total of $1,037,100 in five months. After costs, taxes and a donation to The Prince's Trust, a charity for young people, Tew expected his net income to be $650,000$700,000."
    },
    {
        "source": "Because individual pixels are too small to be seen easily, pixels were sold in 100-pixel \"blocks\" measuring 10  10 pixels; the minimum price was thus $100. The first sale, three days after the site began operating, was to an online music website operated by a friend of Tew's. He bought 400 pixels in a 20  20 block. After two weeks, Tew's friends and family members had purchased a total of 4,700 pixels. The site was initially marketed only through word of mouth; however, after the site had made $1,000, a press release was sent out that was picked up by the BBC. The technology news website The Register featured two articles on The Million Dollar Homepage in September. By the end of the month, The Million Dollar Homepage had received $250,000 and was ranked Number 3 on Alexa Internet's list of \"Movers and Shakers\" behind the websites for Britney Spears and Photo District News. On 6 October, Tew reported the site received 65,000 unique visitors; it received 1465 Diggs, becoming one of the most Dugg links that week. Eleven days later, the number had increased to 100,000 unique visitors. On 26 October, two months after The Million Dollar Homepage was launched, more than 500,900 pixels had been sold to 1,400 customers. By New Year's Eve, Tew reported that the site was receiving hits from 25,000 unique visitors every hour and had an Alexa Rank of 127, and that 999,000 of the 1,000,000 pixels had been sold. On 1 January 2006, Tew announced that because the demand was so great for the last 1,000 pixels, \"the most fair and logical thing\" to do was auction them on eBay rather than lose \"the integrity and degree of exclusivity intrinsic to the million-pixel concept\" by launching a second Million Dollar Homepage. The auction lasted ten days and received 99 legitimate bids. Although bids were received for amounts as high as $160,109.99, many were either retracted by the bidders or cancelled as hoaxes. \"I actually contacted the people by phone and turns out they weren't serious, which is fairly frustrating, so I removed those bidders at the last minute\", said Tew. The winning bid was $38,100, placed by MillionDollarWeightLoss.com, an online store selling diet-related products. Tew remarked that he had expected the final bid amount to be higher due to the media attention. The Million Dollar Homepage made a gross total of $1,037,100 in five months. After costs, taxes and a donation to The Prince's Trust, a charity for young people, Tew expected his net income to be $650,000$700,000.",
        "target": "Pixel purchasers included Bonanza Gift Shop, Panda Software, the producers of Wal-Mart: The High Cost of Low Price, British Schools Karting Championship, Book of Cool, Orange, The Times, Cheapflights.com, Schiffer Publishing, Rhapsody, Tenacious D, GoldenPalace.com, 888.com and other online casinos, Independiente Records, Yahoo!, small privately owned businesses, and companies offering get-rich-quick schemes, online dating services, personal loans, free samples, website designs and holidays."
    },
    {
        "source": "On 1 January 2006, Tew announced that because the demand was so great for the last 1,000 pixels, \"the most fair and logical thing\" to do was auction them on eBay rather than lose \"the integrity and degree of exclusivity intrinsic to the million-pixel concept\" by launching a second Million Dollar Homepage. The auction lasted ten days and received 99 legitimate bids. Although bids were received for amounts as high as $160,109.99, many were either retracted by the bidders or cancelled as hoaxes. \"I actually contacted the people by phone and turns out they weren't serious, which is fairly frustrating, so I removed those bidders at the last minute\", said Tew. The winning bid was $38,100, placed by MillionDollarWeightLoss.com, an online store selling diet-related products. Tew remarked that he had expected the final bid amount to be higher due to the media attention. The Million Dollar Homepage made a gross total of $1,037,100 in five months. After costs, taxes and a donation to The Prince's Trust, a charity for young people, Tew expected his net income to be $650,000$700,000. Pixel purchasers included Bonanza Gift Shop, Panda Software, the producers of Wal-Mart: The High Cost of Low Price, British Schools Karting Championship, Book of Cool, Orange, The Times, Cheapflights.com, Schiffer Publishing, Rhapsody, Tenacious D, GoldenPalace.com, 888.com and other online casinos, Independiente Records, Yahoo!, small privately owned businesses, and companies offering get-rich-quick schemes, online dating services, personal loans, free samples, website designs and holidays.",
        "target": "On 7 January 2006, three days before the auction of the final 1,000 pixels was due to end, Tew received an e-mail from an organisation called \"The Dark Group\", and was told The Million Dollar Homepage would become the victim of a distributed denial-of-service attack (DDoS) if a ransom of $5,000 was not paid by 10 January. Believing the threat to be a hoax, he ignored it, but a week later received a second e-mail threat: \"Hello u website is under us atack to stop the DDoS send us 50000$.\" Again, he ignored the threat, and the website was flooded with extra traffic and e-mails, causing it to crash. \"I haven't replied to any of them as I don't want to give them the satisfaction and I certainly don't intend to pay them any money. What is happening to my website is like terrorism. If you pay them, new attacks will start,\" Tew said."
    },
    {
        "source": "Pixel purchasers included Bonanza Gift Shop, Panda Software, the producers of Wal-Mart: The High Cost of Low Price, British Schools Karting Championship, Book of Cool, Orange, The Times, Cheapflights.com, Schiffer Publishing, Rhapsody, Tenacious D, GoldenPalace.com, 888.com and other online casinos, Independiente Records, Yahoo!, small privately owned businesses, and companies offering get-rich-quick schemes, online dating services, personal loans, free samples, website designs and holidays. On 7 January 2006, three days before the auction of the final 1,000 pixels was due to end, Tew received an e-mail from an organisation called \"The Dark Group\", and was told The Million Dollar Homepage would become the victim of a distributed denial-of-service attack (DDoS) if a ransom of $5,000 was not paid by 10 January. Believing the threat to be a hoax, he ignored it, but a week later received a second e-mail threat: \"Hello u website is under us atack to stop the DDoS send us 50000$.\" Again, he ignored the threat, and the website was flooded with extra traffic and e-mails, causing it to crash. \"I haven't replied to any of them as I don't want to give them the satisfaction and I certainly don't intend to pay them any money. What is happening to my website is like terrorism. If you pay them, new attacks will start,\" Tew said.",
        "target": "The website was inaccessible to visitors for a week until the host server upgraded the security system, and filtered traffic through anti-DDoS software. Wiltshire Constabulary's Hi-Tech Crime Unit and the Federal Bureau of Investigation (FBI) were called to investigate the extortion and attack; they believed it originated in Russia."
    },
    {
        "source": "On 7 January 2006, three days before the auction of the final 1,000 pixels was due to end, Tew received an e-mail from an organisation called \"The Dark Group\", and was told The Million Dollar Homepage would become the victim of a distributed denial-of-service attack (DDoS) if a ransom of $5,000 was not paid by 10 January. Believing the threat to be a hoax, he ignored it, but a week later received a second e-mail threat: \"Hello u website is under us atack to stop the DDoS send us 50000$.\" Again, he ignored the threat, and the website was flooded with extra traffic and e-mails, causing it to crash. \"I haven't replied to any of them as I don't want to give them the satisfaction and I certainly don't intend to pay them any money. What is happening to my website is like terrorism. If you pay them, new attacks will start,\" Tew said. The website was inaccessible to visitors for a week until the host server upgraded the security system, and filtered traffic through anti-DDoS software. Wiltshire Constabulary's Hi-Tech Crime Unit and the Federal Bureau of Investigation (FBI) were called to investigate the extortion and attack; they believed it originated in Russia.",
        "target": "The crucial thing in creating the media interest was the idea itself: it was unique and quirky enough to stand out. I only had to push the idea a bit in the first few days by sending out a press release which essentially acted as a catalyst. This interest coupled with traditional word-of-mouth created a real buzz about the homepage, which in turn created more interest."
    },
    {
        "source": "The crucial thing in creating the media interest was the idea itself: it was unique and quirky enough to stand out. I only had to push the idea a bit in the first few days by sending out a press release which essentially acted as a catalyst. This interest coupled with traditional word-of-mouth created a real buzz about the homepage, which in turn created more interest. Alex Tew, 22 February 2006.",
        "target": "Following the September press release that first brought attention to the site, The Million Dollar Homepage was featured in numerous British media articles and programmes. By November 2005, the website had received attention from The Wall Street Journal and media around the world. During a week-long trip to the US, Tew gave several media interviews."
    },
    {
        "source": "Alex Tew, 22 February 2006. Following the September press release that first brought attention to the site, The Million Dollar Homepage was featured in numerous British media articles and programmes. By November 2005, the website had received attention from The Wall Street Journal and media around the world. During a week-long trip to the US, Tew gave several media interviews.",
        "target": "The concept was described as \"simple and brilliant\", \"clever\", \"ingenious\", and \"a unique platform [for advertising] which is also a bit of fun\". Professor Martin Binks, director of the Nottingham University Institute for Entrepreneurial Innovation, said, \"It is brilliant in its simplicity... advertisers have been attracted to it by its novelty... the site has become a phenomenon.\" Popular Mechanics said: \"There's no content. No cool graphics, giveaways or steamy Paris Hilton videos for viewers to salivate over. Imagine a TV channel that shows nothing but commercials, a magazine with nothing but ads. That's The Million Dollar Homepage. An astonishing example of the power of viral marketing.\" Don Oldenburg of The Washington Post was one of the few without praise for the site, calling it a \"cheap, mind-bogglingly lucrative marketing monstrosity, an advertising badlands of spam, banner ads and pop-ups.\" Oldenburg continues, \"it looks like a bulletin board on designer steroids, an advertising train wreck you can't not look at. It's like getting every pop-up ad you ever got in your life, at once. It's the Internet equivalent of suddenly feeling like you want to take a shower.\""
    },
    {
        "source": "Following the September press release that first brought attention to the site, The Million Dollar Homepage was featured in numerous British media articles and programmes. By November 2005, the website had received attention from The Wall Street Journal and media around the world. During a week-long trip to the US, Tew gave several media interviews. The concept was described as \"simple and brilliant\", \"clever\", \"ingenious\", and \"a unique platform [for advertising] which is also a bit of fun\". Professor Martin Binks, director of the Nottingham University Institute for Entrepreneurial Innovation, said, \"It is brilliant in its simplicity... advertisers have been attracted to it by its novelty... the site has become a phenomenon.\" Popular Mechanics said: \"There's no content. No cool graphics, giveaways or steamy Paris Hilton videos for viewers to salivate over. Imagine a TV channel that shows nothing but commercials, a magazine with nothing but ads. That's The Million Dollar Homepage. An astonishing example of the power of viral marketing.\" Don Oldenburg of The Washington Post was one of the few without praise for the site, calling it a \"cheap, mind-bogglingly lucrative marketing monstrosity, an advertising badlands of spam, banner ads and pop-ups.\" Oldenburg continues, \"it looks like a bulletin board on designer steroids, an advertising train wreck you can't not look at. It's like getting every pop-up ad you ever got in your life, at once. It's the Internet equivalent of suddenly feeling like you want to take a shower.\"",
        "target": "As the final pixels were being auctioned, Tew was interviewed on Richard & Judy, and profiled in the online BBC News Magazine. The Wall Street Journal wrote about The Million Dollar Homepage and its impact on the Internet community. \"Mr. Tew himself has taken on celebrity status in the Internet community... the creative juice... paints an interesting picture of online entrepreneurship\"."
    },
    {
        "source": "The concept was described as \"simple and brilliant\", \"clever\", \"ingenious\", and \"a unique platform [for advertising] which is also a bit of fun\". Professor Martin Binks, director of the Nottingham University Institute for Entrepreneurial Innovation, said, \"It is brilliant in its simplicity... advertisers have been attracted to it by its novelty... the site has become a phenomenon.\" Popular Mechanics said: \"There's no content. No cool graphics, giveaways or steamy Paris Hilton videos for viewers to salivate over. Imagine a TV channel that shows nothing but commercials, a magazine with nothing but ads. That's The Million Dollar Homepage. An astonishing example of the power of viral marketing.\" Don Oldenburg of The Washington Post was one of the few without praise for the site, calling it a \"cheap, mind-bogglingly lucrative marketing monstrosity, an advertising badlands of spam, banner ads and pop-ups.\" Oldenburg continues, \"it looks like a bulletin board on designer steroids, an advertising train wreck you can't not look at. It's like getting every pop-up ad you ever got in your life, at once. It's the Internet equivalent of suddenly feeling like you want to take a shower.\" As the final pixels were being auctioned, Tew was interviewed on Richard & Judy, and profiled in the online BBC News Magazine. The Wall Street Journal wrote about The Million Dollar Homepage and its impact on the Internet community. \"Mr. Tew himself has taken on celebrity status in the Internet community... the creative juice... paints an interesting picture of online entrepreneurship\".",
        "target": "Tew dropped out of the business degree the site was set up to fund after one term. In 2008, Tew founded Popjam, an Internet aggregation and social networking business. On May 4, 2012, Tew co-founded software company Calm with Michael Acton Smith. As of 2016, Tew was working as an entrepreneur in San Francisco."
    },
    {
        "source": "As the final pixels were being auctioned, Tew was interviewed on Richard & Judy, and profiled in the online BBC News Magazine. The Wall Street Journal wrote about The Million Dollar Homepage and its impact on the Internet community. \"Mr. Tew himself has taken on celebrity status in the Internet community... the creative juice... paints an interesting picture of online entrepreneurship\". Tew dropped out of the business degree the site was set up to fund after one term. In 2008, Tew founded Popjam, an Internet aggregation and social networking business. On May 4, 2012, Tew co-founded software company Calm with Michael Acton Smith. As of 2016, Tew was working as an entrepreneur in San Francisco.",
        "target": "As of 2017, only the main page of the website was available, with all sub pages returning a 404 Not Found message. By 2017, the links on the still-live main page of the site demonstrated a considerable degree of link rot. Of the 2,816 original links, 547 (342,000 pixels, sold for $342,000) were dead, and 489 (145,000 pixels, sold for $145,000) redirected to a different domain. The report stated that, of the remaining links, that \"the majority do not seem to reflect their original purpose\". By April 2019, according to the BBC, approximately 40% of the site's links were suffering from link rot. The site was still receiving several thousands of viewers per day."
    },
    {
        "source": "Tew dropped out of the business degree the site was set up to fund after one term. In 2008, Tew founded Popjam, an Internet aggregation and social networking business. On May 4, 2012, Tew co-founded software company Calm with Michael Acton Smith. As of 2016, Tew was working as an entrepreneur in San Francisco. As of 2017, only the main page of the website was available, with all sub pages returning a 404 Not Found message. By 2017, the links on the still-live main page of the site demonstrated a considerable degree of link rot. Of the 2,816 original links, 547 (342,000 pixels, sold for $342,000) were dead, and 489 (145,000 pixels, sold for $145,000) redirected to a different domain. The report stated that, of the remaining links, that \"the majority do not seem to reflect their original purpose\". By April 2019, according to the BBC, approximately 40% of the site's links were suffering from link rot. The site was still receiving several thousands of viewers per day.",
        "target": "Many other sites sold advertising by pixels. Tew said of the sites, \"[they] popped up almost immediately; now there are hundreds of Web sites selling pixels. The copycats are all competing with each other.\" \"...they have very little ads, therefore I guess it's not going too well for them. The idea only works once and relies on novelty ... any copy-cat sites will only have pure comedy value, whereas mine possibly has a bit of comedy PLUS some actual pull in advertising dollars ... so I say good luck to the imitators!\""
    },
    {
        "source": "Parallel computing is a type of computation in which many calculations or processes are carried out simultaneously. Large problems can often be divided into smaller ones, which can then be solved at the same time. There are several different forms of parallel computing: bit-level, instruction-level, data, and task parallelism. Parallelism has long been employed in high-performance computing, but has gained broader interest due to the physical constraints preventing frequency scaling. As power consumption (and consequently heat generation) by computers has become a concern in recent years, parallel computing has become the dominant paradigm in computer architecture, mainly in the form of multi-core processors. In computer science, parallelism and concurrency are two different things: a parallel program uses multiple CPU cores, each core performing a task independently. On the other hand, concurrency enables a program to deal with multiple tasks even on a single CPU core; the core switches between tasks (i.e. threads) without necessarily completing each one. A program can have both, neither or a combination of parallelism and concurrency characteristics.",
        "target": "Parallel computers can be roughly classified according to the level at which the hardware supports parallelism, with multi-core and multi-processor computers having multiple processing elements within a single machine, while clusters, MPPs, and grids use multiple computers to work on the same task. Specialized parallel computer architectures are sometimes used alongside traditional processors, for accelerating specific tasks."
    },
    {
        "source": "In computer science, parallelism and concurrency are two different things: a parallel program uses multiple CPU cores, each core performing a task independently. On the other hand, concurrency enables a program to deal with multiple tasks even on a single CPU core; the core switches between tasks (i.e. threads) without necessarily completing each one. A program can have both, neither or a combination of parallelism and concurrency characteristics. Parallel computers can be roughly classified according to the level at which the hardware supports parallelism, with multi-core and multi-processor computers having multiple processing elements within a single machine, while clusters, MPPs, and grids use multiple computers to work on the same task. Specialized parallel computer architectures are sometimes used alongside traditional processors, for accelerating specific tasks.",
        "target": "In some cases parallelism is transparent to the programmer, such as in bit-level or instruction-level parallelism, but explicitly parallel algorithms, particularly those that use concurrency, are more difficult to write than sequential ones, because concurrency introduces several new classes of potential software bugs, of which race conditions are the most common. Communication and synchronization between the different subtasks are typically some of the greatest obstacles to getting optimal parallel program performance."
    },
    {
        "source": "Parallel computers can be roughly classified according to the level at which the hardware supports parallelism, with multi-core and multi-processor computers having multiple processing elements within a single machine, while clusters, MPPs, and grids use multiple computers to work on the same task. Specialized parallel computer architectures are sometimes used alongside traditional processors, for accelerating specific tasks. In some cases parallelism is transparent to the programmer, such as in bit-level or instruction-level parallelism, but explicitly parallel algorithms, particularly those that use concurrency, are more difficult to write than sequential ones, because concurrency introduces several new classes of potential software bugs, of which race conditions are the most common. Communication and synchronization between the different subtasks are typically some of the greatest obstacles to getting optimal parallel program performance.",
        "target": "A theoretical upper bound on the speed-up of a single program as a result of parallelization is given by Amdahl's law, which states that it is limited by the fraction of time for which the parallelization can be utilised."
    },
    {
        "source": "In some cases parallelism is transparent to the programmer, such as in bit-level or instruction-level parallelism, but explicitly parallel algorithms, particularly those that use concurrency, are more difficult to write than sequential ones, because concurrency introduces several new classes of potential software bugs, of which race conditions are the most common. Communication and synchronization between the different subtasks are typically some of the greatest obstacles to getting optimal parallel program performance. A theoretical upper bound on the speed-up of a single program as a result of parallelization is given by Amdahl's law, which states that it is limited by the fraction of time for which the parallelization can be utilised.",
        "target": "Traditionally, computer software has been written for serial computation. To solve a problem, an algorithm is constructed and implemented as a serial stream of instructions. These instructions are executed on a central processing unit on one computer. Only one instruction may execute at a timeafter that instruction is finished, the next one is executed."
    },
    {
        "source": "A theoretical upper bound on the speed-up of a single program as a result of parallelization is given by Amdahl's law, which states that it is limited by the fraction of time for which the parallelization can be utilised. Traditionally, computer software has been written for serial computation. To solve a problem, an algorithm is constructed and implemented as a serial stream of instructions. These instructions are executed on a central processing unit on one computer. Only one instruction may execute at a timeafter that instruction is finished, the next one is executed.",
        "target": "Parallel computing, on the other hand, uses multiple processing elements simultaneously to solve a problem. This is accomplished by breaking the problem into independent parts so that each processing element can execute its part of the algorithm simultaneously with the others. The processing elements can be diverse and include resources such as a single computer with multiple processors, several networked computers, specialized hardware, or any combination of the above. Historically parallel computing was used for scientific computing and the simulation of scientific problems, particularly in the natural and engineering sciences, such as meteorology. This led to the design of parallel hardware and software, as well as high performance computing."
    },
    {
        "source": "Traditionally, computer software has been written for serial computation. To solve a problem, an algorithm is constructed and implemented as a serial stream of instructions. These instructions are executed on a central processing unit on one computer. Only one instruction may execute at a timeafter that instruction is finished, the next one is executed. Parallel computing, on the other hand, uses multiple processing elements simultaneously to solve a problem. This is accomplished by breaking the problem into independent parts so that each processing element can execute its part of the algorithm simultaneously with the others. The processing elements can be diverse and include resources such as a single computer with multiple processors, several networked computers, specialized hardware, or any combination of the above. Historically parallel computing was used for scientific computing and the simulation of scientific problems, particularly in the natural and engineering sciences, such as meteorology. This led to the design of parallel hardware and software, as well as high performance computing.",
        "target": "Frequency scaling was the dominant reason for improvements in computer performance from the mid-1980s until 2004. The runtime of a program is equal to the number of instructions multiplied by the average time per instruction. Maintaining everything else constant, increasing the clock frequency decreases the average time it takes to execute an instruction. An increase in frequency thus decreases runtime for all compute-bound programs. However, power consumption P by a chip is given by the equation P = C  V 2  F, where C is the capacitance being switched per clock cycle (proportional to the number of transistors whose inputs change), V is voltage, and F is the processor frequency (cycles per second). Increases in frequency increase the amount of power used in a processor. Increasing processor power consumption led ultimately to Intel's May 8, 2004 cancellation of its Tejas and Jayhawk processors, which is generally cited as the end of frequency scaling as the dominant computer architecture paradigm."
    },
    {
        "source": "Parallel computing, on the other hand, uses multiple processing elements simultaneously to solve a problem. This is accomplished by breaking the problem into independent parts so that each processing element can execute its part of the algorithm simultaneously with the others. The processing elements can be diverse and include resources such as a single computer with multiple processors, several networked computers, specialized hardware, or any combination of the above. Historically parallel computing was used for scientific computing and the simulation of scientific problems, particularly in the natural and engineering sciences, such as meteorology. This led to the design of parallel hardware and software, as well as high performance computing. Frequency scaling was the dominant reason for improvements in computer performance from the mid-1980s until 2004. The runtime of a program is equal to the number of instructions multiplied by the average time per instruction. Maintaining everything else constant, increasing the clock frequency decreases the average time it takes to execute an instruction. An increase in frequency thus decreases runtime for all compute-bound programs. However, power consumption P by a chip is given by the equation P = C  V 2  F, where C is the capacitance being switched per clock cycle (proportional to the number of transistors whose inputs change), V is voltage, and F is the processor frequency (cycles per second). Increases in frequency increase the amount of power used in a processor. Increasing processor power consumption led ultimately to Intel's May 8, 2004 cancellation of its Tejas and Jayhawk processors, which is generally cited as the end of frequency scaling as the dominant computer architecture paradigm.",
        "target": "To deal with the problem of power consumption and overheating the major central processing unit (CPU or processor) manufacturers started to produce power efficient processors with multiple cores. The core is the computing unit of the processor and in multi-core processors each core is independent and can access the same memory concurrently. Multi-core processors have brought parallel computing to desktop computers. Thus parallelization of serial programs has become a mainstream programming task. In 2012 quad-core processors became standard for desktop computers, while servers have 10+ core processors. From Moore's law it can be predicted that the number of cores per processor will double every 1824 months. This could mean that after 2020 a typical processor will have dozens or hundreds of cores, however in reality the standard is somewhere in the region of 4 to 16 cores, with some designs having a mix of performance and efficiency cores (such as ARM's big.LITTLE design) due to thermal and design constraints.[citation needed]"
    },
    {
        "source": "Frequency scaling was the dominant reason for improvements in computer performance from the mid-1980s until 2004. The runtime of a program is equal to the number of instructions multiplied by the average time per instruction. Maintaining everything else constant, increasing the clock frequency decreases the average time it takes to execute an instruction. An increase in frequency thus decreases runtime for all compute-bound programs. However, power consumption P by a chip is given by the equation P = C  V 2  F, where C is the capacitance being switched per clock cycle (proportional to the number of transistors whose inputs change), V is voltage, and F is the processor frequency (cycles per second). Increases in frequency increase the amount of power used in a processor. Increasing processor power consumption led ultimately to Intel's May 8, 2004 cancellation of its Tejas and Jayhawk processors, which is generally cited as the end of frequency scaling as the dominant computer architecture paradigm. To deal with the problem of power consumption and overheating the major central processing unit (CPU or processor) manufacturers started to produce power efficient processors with multiple cores. The core is the computing unit of the processor and in multi-core processors each core is independent and can access the same memory concurrently. Multi-core processors have brought parallel computing to desktop computers. Thus parallelization of serial programs has become a mainstream programming task. In 2012 quad-core processors became standard for desktop computers, while servers have 10+ core processors. From Moore's law it can be predicted that the number of cores per processor will double every 1824 months. This could mean that after 2020 a typical processor will have dozens or hundreds of cores, however in reality the standard is somewhere in the region of 4 to 16 cores, with some designs having a mix of performance and efficiency cores (such as ARM's big.LITTLE design) due to thermal and design constraints.[citation needed]",
        "target": "An operating system can ensure that different tasks and user programs are run in parallel on the available cores. However, for a serial software program to take full advantage of the multi-core architecture the programmer needs to restructure and parallelize the code. A speed-up of application software runtime will no longer be achieved through frequency scaling, instead programmers will need to parallelize their software code to take advantage of the increasing computing power of multicore architectures."
    },
    {
        "source": "To deal with the problem of power consumption and overheating the major central processing unit (CPU or processor) manufacturers started to produce power efficient processors with multiple cores. The core is the computing unit of the processor and in multi-core processors each core is independent and can access the same memory concurrently. Multi-core processors have brought parallel computing to desktop computers. Thus parallelization of serial programs has become a mainstream programming task. In 2012 quad-core processors became standard for desktop computers, while servers have 10+ core processors. From Moore's law it can be predicted that the number of cores per processor will double every 1824 months. This could mean that after 2020 a typical processor will have dozens or hundreds of cores, however in reality the standard is somewhere in the region of 4 to 16 cores, with some designs having a mix of performance and efficiency cores (such as ARM's big.LITTLE design) due to thermal and design constraints.[citation needed] An operating system can ensure that different tasks and user programs are run in parallel on the available cores. However, for a serial software program to take full advantage of the multi-core architecture the programmer needs to restructure and parallelize the code. A speed-up of application software runtime will no longer be achieved through frequency scaling, instead programmers will need to parallelize their software code to take advantage of the increasing computing power of multicore architectures.",
        "target": "Optimally, the speedup from parallelization would be lineardoubling the number of processing elements should halve the runtime, and doubling it a second time should again halve the runtime. However, very few parallel algorithms achieve optimal speedup. Most of them have a near-linear speedup for small numbers of processing elements, which flattens out into a constant value for large numbers of processing elements."
    },
    {
        "source": "An operating system can ensure that different tasks and user programs are run in parallel on the available cores. However, for a serial software program to take full advantage of the multi-core architecture the programmer needs to restructure and parallelize the code. A speed-up of application software runtime will no longer be achieved through frequency scaling, instead programmers will need to parallelize their software code to take advantage of the increasing computing power of multicore architectures. Optimally, the speedup from parallelization would be lineardoubling the number of processing elements should halve the runtime, and doubling it a second time should again halve the runtime. However, very few parallel algorithms achieve optimal speedup. Most of them have a near-linear speedup for small numbers of processing elements, which flattens out into a constant value for large numbers of processing elements.",
        "target": "The potential speedup of an algorithm on a parallel computing platform is given by Amdahl's law"
    },
    {
        "source": "The potential speedup of an algorithm on a parallel computing platform is given by Amdahl's law where",
        "target": "Since Slatency < 1/(1 - p), it shows that a small part of the program which cannot be parallelized will limit the overall speedup available from parallelization. A program solving a large mathematical or engineering problem will typically consist of several parallelizable parts and several non-parallelizable (serial) parts. If the non-parallelizable part of a program accounts for 10% of the runtime (p = 0.9), we can get no more than a 10 times speedup, regardless of how many processors are added. This puts an upper limit on the usefulness of adding more parallel execution units. \"When a task cannot be partitioned because of sequential constraints, the application of more effort has no effect on the schedule. The bearing of a child takes nine months, no matter how many women are assigned.\""
    },
    {
        "source": "where Since Slatency < 1/(1 - p), it shows that a small part of the program which cannot be parallelized will limit the overall speedup available from parallelization. A program solving a large mathematical or engineering problem will typically consist of several parallelizable parts and several non-parallelizable (serial) parts. If the non-parallelizable part of a program accounts for 10% of the runtime (p = 0.9), we can get no more than a 10 times speedup, regardless of how many processors are added. This puts an upper limit on the usefulness of adding more parallel execution units. \"When a task cannot be partitioned because of sequential constraints, the application of more effort has no effect on the schedule. The bearing of a child takes nine months, no matter how many women are assigned.\"",
        "target": "Amdahl's law only applies to cases where the problem size is fixed. In practice, as more computing resources become available, they tend to get used on larger problems (larger datasets), and the time spent in the parallelizable part often grows much faster than the inherently serial work. In this case, Gustafson's law gives a less pessimistic and more realistic assessment of parallel performance:"
    },
    {
        "source": "Since Slatency < 1/(1 - p), it shows that a small part of the program which cannot be parallelized will limit the overall speedup available from parallelization. A program solving a large mathematical or engineering problem will typically consist of several parallelizable parts and several non-parallelizable (serial) parts. If the non-parallelizable part of a program accounts for 10% of the runtime (p = 0.9), we can get no more than a 10 times speedup, regardless of how many processors are added. This puts an upper limit on the usefulness of adding more parallel execution units. \"When a task cannot be partitioned because of sequential constraints, the application of more effort has no effect on the schedule. The bearing of a child takes nine months, no matter how many women are assigned.\" Amdahl's law only applies to cases where the problem size is fixed. In practice, as more computing resources become available, they tend to get used on larger problems (larger datasets), and the time spent in the parallelizable part often grows much faster than the inherently serial work. In this case, Gustafson's law gives a less pessimistic and more realistic assessment of parallel performance:",
        "target": "Both Amdahl's law and Gustafson's law assume that the running time of the serial part of the program is independent of the number of processors. Amdahl's law assumes that the entire problem is of fixed size so that the total amount of work to be done in parallel is also independent of the number of processors, whereas Gustafson's law assumes that the total amount of work to be done in parallel varies linearly with the number of processors."
    },
    {
        "source": "Amdahl's law only applies to cases where the problem size is fixed. In practice, as more computing resources become available, they tend to get used on larger problems (larger datasets), and the time spent in the parallelizable part often grows much faster than the inherently serial work. In this case, Gustafson's law gives a less pessimistic and more realistic assessment of parallel performance: Both Amdahl's law and Gustafson's law assume that the running time of the serial part of the program is independent of the number of processors. Amdahl's law assumes that the entire problem is of fixed size so that the total amount of work to be done in parallel is also independent of the number of processors, whereas Gustafson's law assumes that the total amount of work to be done in parallel varies linearly with the number of processors.",
        "target": "Understanding data dependencies is fundamental in implementing parallel algorithms. No program can run more quickly than the longest chain of dependent calculations (known as the critical path), since calculations that depend upon prior calculations in the chain must be executed in order. However, most algorithms do not consist of just a long chain of dependent calculations; there are usually opportunities to execute independent calculations in parallel."
    },
    {
        "source": "Both Amdahl's law and Gustafson's law assume that the running time of the serial part of the program is independent of the number of processors. Amdahl's law assumes that the entire problem is of fixed size so that the total amount of work to be done in parallel is also independent of the number of processors, whereas Gustafson's law assumes that the total amount of work to be done in parallel varies linearly with the number of processors. Understanding data dependencies is fundamental in implementing parallel algorithms. No program can run more quickly than the longest chain of dependent calculations (known as the critical path), since calculations that depend upon prior calculations in the chain must be executed in order. However, most algorithms do not consist of just a long chain of dependent calculations; there are usually opportunities to execute independent calculations in parallel.",
        "target": "Let Pi and Pj be two program segments. Bernstein's conditions describe when the two are independent and can be executed in parallel. For Pi, let Ii be all of the input variables and Oi the output variables, and likewise for Pj. Pi and Pj are independent if they satisfy"
    },
    {
        "source": "Understanding data dependencies is fundamental in implementing parallel algorithms. No program can run more quickly than the longest chain of dependent calculations (known as the critical path), since calculations that depend upon prior calculations in the chain must be executed in order. However, most algorithms do not consist of just a long chain of dependent calculations; there are usually opportunities to execute independent calculations in parallel. Let Pi and Pj be two program segments. Bernstein's conditions describe when the two are independent and can be executed in parallel. For Pi, let Ii be all of the input variables and Oi the output variables, and likewise for Pj. Pi and Pj are independent if they satisfy",
        "target": "Violation of the first condition introduces a flow dependency, corresponding to the first segment producing a result used by the second segment. The second condition represents an anti-dependency, when the second segment produces a variable needed by the first segment. The third and final condition represents an output dependency: when two segments write to the same location, the result comes from the logically last executed segment."
    },
    {
        "source": "Let Pi and Pj be two program segments. Bernstein's conditions describe when the two are independent and can be executed in parallel. For Pi, let Ii be all of the input variables and Oi the output variables, and likewise for Pj. Pi and Pj are independent if they satisfy Violation of the first condition introduces a flow dependency, corresponding to the first segment producing a result used by the second segment. The second condition represents an anti-dependency, when the second segment produces a variable needed by the first segment. The third and final condition represents an output dependency: when two segments write to the same location, the result comes from the logically last executed segment.",
        "target": "Consider the following functions, which demonstrate several kinds of dependencies:"
    },
    {
        "source": "Violation of the first condition introduces a flow dependency, corresponding to the first segment producing a result used by the second segment. The second condition represents an anti-dependency, when the second segment produces a variable needed by the first segment. The third and final condition represents an output dependency: when two segments write to the same location, the result comes from the logically last executed segment. Consider the following functions, which demonstrate several kinds of dependencies:",
        "target": "In this example, instruction 3 cannot be executed before (or even in parallel with) instruction 2, because instruction 3 uses a result from instruction 2. It violates condition 1, and thus introduces a flow dependency."
    },
    {
        "source": "Consider the following functions, which demonstrate several kinds of dependencies: In this example, instruction 3 cannot be executed before (or even in parallel with) instruction 2, because instruction 3 uses a result from instruction 2. It violates condition 1, and thus introduces a flow dependency.",
        "target": "In this example, there are no dependencies between the instructions, so they can all be run in parallel."
    },
    {
        "source": "In this example, instruction 3 cannot be executed before (or even in parallel with) instruction 2, because instruction 3 uses a result from instruction 2. It violates condition 1, and thus introduces a flow dependency. In this example, there are no dependencies between the instructions, so they can all be run in parallel.",
        "target": "Bernstein's conditions do not allow memory to be shared between different processes. For that, some means of enforcing an ordering between accesses is necessary, such as semaphores, barriers or some other synchronization method."
    },
    {
        "source": "In this example, there are no dependencies between the instructions, so they can all be run in parallel. Bernstein's conditions do not allow memory to be shared between different processes. For that, some means of enforcing an ordering between accesses is necessary, such as semaphores, barriers or some other synchronization method.",
        "target": "Subtasks in a parallel program are often called threads. Some parallel computer architectures use smaller, lightweight versions of threads known as fibers, while others use bigger versions known as processes. However, \"threads\" is generally accepted as a generic term for subtasks. Threads will often need synchronized access to an object or other resource, for example when they must update a variable that is shared between them. Without synchronization, the instructions between the two threads may be interleaved in any order. For example, consider the following program:"
    },
    {
        "source": "Bernstein's conditions do not allow memory to be shared between different processes. For that, some means of enforcing an ordering between accesses is necessary, such as semaphores, barriers or some other synchronization method. Subtasks in a parallel program are often called threads. Some parallel computer architectures use smaller, lightweight versions of threads known as fibers, while others use bigger versions known as processes. However, \"threads\" is generally accepted as a generic term for subtasks. Threads will often need synchronized access to an object or other resource, for example when they must update a variable that is shared between them. Without synchronization, the instructions between the two threads may be interleaved in any order. For example, consider the following program:",
        "target": "If instruction 1B is executed between 1A and 3A, or if instruction 1A is executed between 1B and 3B, the program will produce incorrect data. This is known as a race condition. The programmer must use a lock to provide mutual exclusion. A lock is a programming language construct that allows one thread to take control of a variable and prevent other threads from reading or writing it, until that variable is unlocked. The thread holding the lock is free to execute its critical section (the section of a program that requires exclusive access to some variable), and to unlock the data when it is finished. Therefore, to guarantee correct program execution, the above program can be rewritten to use locks:"
    },
    {
        "source": "Subtasks in a parallel program are often called threads. Some parallel computer architectures use smaller, lightweight versions of threads known as fibers, while others use bigger versions known as processes. However, \"threads\" is generally accepted as a generic term for subtasks. Threads will often need synchronized access to an object or other resource, for example when they must update a variable that is shared between them. Without synchronization, the instructions between the two threads may be interleaved in any order. For example, consider the following program: If instruction 1B is executed between 1A and 3A, or if instruction 1A is executed between 1B and 3B, the program will produce incorrect data. This is known as a race condition. The programmer must use a lock to provide mutual exclusion. A lock is a programming language construct that allows one thread to take control of a variable and prevent other threads from reading or writing it, until that variable is unlocked. The thread holding the lock is free to execute its critical section (the section of a program that requires exclusive access to some variable), and to unlock the data when it is finished. Therefore, to guarantee correct program execution, the above program can be rewritten to use locks:",
        "target": "One thread will successfully lock variable V, while the other thread will be locked outunable to proceed until V is unlocked again. This guarantees correct execution of the program. Locks may be necessary to ensure correct program execution when threads must serialize access to resources, but their use can greatly slow a program and may affect its reliability."
    },
    {
        "source": "If instruction 1B is executed between 1A and 3A, or if instruction 1A is executed between 1B and 3B, the program will produce incorrect data. This is known as a race condition. The programmer must use a lock to provide mutual exclusion. A lock is a programming language construct that allows one thread to take control of a variable and prevent other threads from reading or writing it, until that variable is unlocked. The thread holding the lock is free to execute its critical section (the section of a program that requires exclusive access to some variable), and to unlock the data when it is finished. Therefore, to guarantee correct program execution, the above program can be rewritten to use locks: One thread will successfully lock variable V, while the other thread will be locked outunable to proceed until V is unlocked again. This guarantees correct execution of the program. Locks may be necessary to ensure correct program execution when threads must serialize access to resources, but their use can greatly slow a program and may affect its reliability.",
        "target": "Locking multiple variables using non-atomic locks introduces the possibility of program deadlock. An atomic lock locks multiple variables all at once. If it cannot lock all of them, it does not lock any of them. If two threads each need to lock the same two variables using non-atomic locks, it is possible that one thread will lock one of them and the second thread will lock the second variable. In such a case, neither thread can complete, and deadlock results."
    },
    {
        "source": "One thread will successfully lock variable V, while the other thread will be locked outunable to proceed until V is unlocked again. This guarantees correct execution of the program. Locks may be necessary to ensure correct program execution when threads must serialize access to resources, but their use can greatly slow a program and may affect its reliability. Locking multiple variables using non-atomic locks introduces the possibility of program deadlock. An atomic lock locks multiple variables all at once. If it cannot lock all of them, it does not lock any of them. If two threads each need to lock the same two variables using non-atomic locks, it is possible that one thread will lock one of them and the second thread will lock the second variable. In such a case, neither thread can complete, and deadlock results.",
        "target": "Many parallel programs require that their subtasks act in synchrony. This requires the use of a barrier. Barriers are typically implemented using a lock or a semaphore. One class of algorithms, known as lock-free and wait-free algorithms, altogether avoids the use of locks and barriers. However, this approach is generally difficult to implement and requires correctly designed data structures."
    },
    {
        "source": "Locking multiple variables using non-atomic locks introduces the possibility of program deadlock. An atomic lock locks multiple variables all at once. If it cannot lock all of them, it does not lock any of them. If two threads each need to lock the same two variables using non-atomic locks, it is possible that one thread will lock one of them and the second thread will lock the second variable. In such a case, neither thread can complete, and deadlock results. Many parallel programs require that their subtasks act in synchrony. This requires the use of a barrier. Barriers are typically implemented using a lock or a semaphore. One class of algorithms, known as lock-free and wait-free algorithms, altogether avoids the use of locks and barriers. However, this approach is generally difficult to implement and requires correctly designed data structures.",
        "target": "Not all parallelization results in speed-up. Generally, as a task is split up into more and more threads, those threads spend an ever-increasing portion of their time communicating with each other or waiting on each other for access to resources. Once the overhead from resource contention or communication dominates the time spent on other computation, further parallelization (that is, splitting the workload over even more threads) increases rather than decreases the amount of time required to finish. This problem, known as parallel slowdown, can be improved in some cases by software analysis and redesign."
    },
    {
        "source": "Many parallel programs require that their subtasks act in synchrony. This requires the use of a barrier. Barriers are typically implemented using a lock or a semaphore. One class of algorithms, known as lock-free and wait-free algorithms, altogether avoids the use of locks and barriers. However, this approach is generally difficult to implement and requires correctly designed data structures. Not all parallelization results in speed-up. Generally, as a task is split up into more and more threads, those threads spend an ever-increasing portion of their time communicating with each other or waiting on each other for access to resources. Once the overhead from resource contention or communication dominates the time spent on other computation, further parallelization (that is, splitting the workload over even more threads) increases rather than decreases the amount of time required to finish. This problem, known as parallel slowdown, can be improved in some cases by software analysis and redesign.",
        "target": "Applications are often classified according to how often their subtasks need to synchronize or communicate with each other. An application exhibits fine-grained parallelism if its subtasks must communicate many times per second; it exhibits coarse-grained parallelism if they do not communicate many times per second, and it exhibits embarrassing parallelism if they rarely or never have to communicate. Embarrassingly parallel applications are considered the easiest to parallelize."
    },
    {
        "source": "Not all parallelization results in speed-up. Generally, as a task is split up into more and more threads, those threads spend an ever-increasing portion of their time communicating with each other or waiting on each other for access to resources. Once the overhead from resource contention or communication dominates the time spent on other computation, further parallelization (that is, splitting the workload over even more threads) increases rather than decreases the amount of time required to finish. This problem, known as parallel slowdown, can be improved in some cases by software analysis and redesign. Applications are often classified according to how often their subtasks need to synchronize or communicate with each other. An application exhibits fine-grained parallelism if its subtasks must communicate many times per second; it exhibits coarse-grained parallelism if they do not communicate many times per second, and it exhibits embarrassing parallelism if they rarely or never have to communicate. Embarrassingly parallel applications are considered the easiest to parallelize.",
        "target": "Michael J. Flynn created one of the earliest classification systems for parallel (and sequential) computers and programs, now known as Flynn's taxonomy. Flynn classified programs and computers by whether they were operating using a single set or multiple sets of instructions, and whether or not those instructions were using a single set or multiple sets of data."
    },
    {
        "source": "Applications are often classified according to how often their subtasks need to synchronize or communicate with each other. An application exhibits fine-grained parallelism if its subtasks must communicate many times per second; it exhibits coarse-grained parallelism if they do not communicate many times per second, and it exhibits embarrassing parallelism if they rarely or never have to communicate. Embarrassingly parallel applications are considered the easiest to parallelize. Michael J. Flynn created one of the earliest classification systems for parallel (and sequential) computers and programs, now known as Flynn's taxonomy. Flynn classified programs and computers by whether they were operating using a single set or multiple sets of instructions, and whether or not those instructions were using a single set or multiple sets of data.",
        "target": "The single-instruction-single-data (SISD) classification is equivalent to an entirely sequential program. The single-instruction-multiple-data (SIMD) classification is analogous to doing the same operation repeatedly over a large data set. This is commonly done in signal processing applications. Multiple-instruction-single-data (MISD) is a rarely used classification. While computer architectures to deal with this were devised (such as systolic arrays), few applications that fit this class materialized. Multiple-instruction-multiple-data (MIMD) programs are by far the most common type of parallel programs."
    },
    {
        "source": "Michael J. Flynn created one of the earliest classification systems for parallel (and sequential) computers and programs, now known as Flynn's taxonomy. Flynn classified programs and computers by whether they were operating using a single set or multiple sets of instructions, and whether or not those instructions were using a single set or multiple sets of data. The single-instruction-single-data (SISD) classification is equivalent to an entirely sequential program. The single-instruction-multiple-data (SIMD) classification is analogous to doing the same operation repeatedly over a large data set. This is commonly done in signal processing applications. Multiple-instruction-single-data (MISD) is a rarely used classification. While computer architectures to deal with this were devised (such as systolic arrays), few applications that fit this class materialized. Multiple-instruction-multiple-data (MIMD) programs are by far the most common type of parallel programs.",
        "target": "According to David A. Patterson and John L. Hennessy, \"Some machines are hybrids of these categories, of course, but this classic model has survived because it is simple, easy to understand, and gives a good first approximation. It is alsoperhaps because of its understandabilitythe most widely used scheme.\""
    },
    {
        "source": "The single-instruction-single-data (SISD) classification is equivalent to an entirely sequential program. The single-instruction-multiple-data (SIMD) classification is analogous to doing the same operation repeatedly over a large data set. This is commonly done in signal processing applications. Multiple-instruction-single-data (MISD) is a rarely used classification. While computer architectures to deal with this were devised (such as systolic arrays), few applications that fit this class materialized. Multiple-instruction-multiple-data (MIMD) programs are by far the most common type of parallel programs. According to David A. Patterson and John L. Hennessy, \"Some machines are hybrids of these categories, of course, but this classic model has survived because it is simple, easy to understand, and gives a good first approximation. It is alsoperhaps because of its understandabilitythe most widely used scheme.\"",
        "target": "From the advent of very-large-scale integration (VLSI) computer-chip fabrication technology in the 1970s until about 1986, speed-up in computer architecture was driven by doubling computer word sizethe amount of information the processor can manipulate per cycle. Increasing the word size reduces the number of instructions the processor must execute to perform an operation on variables whose sizes are greater than the length of the word. For example, where an 8-bit processor must add two 16-bit integers, the processor must first add the 8lower-order bits from each integer using the standard addition instruction, then add the 8higher-order bits using an add-with-carry instruction and the carry bit from the lower order addition; thus, an 8-bit processor requires two instructions to complete a single operation, where a 16-bit processor would be able to complete the operation with a single instruction."
    },
    {
        "source": "According to David A. Patterson and John L. Hennessy, \"Some machines are hybrids of these categories, of course, but this classic model has survived because it is simple, easy to understand, and gives a good first approximation. It is alsoperhaps because of its understandabilitythe most widely used scheme.\" From the advent of very-large-scale integration (VLSI) computer-chip fabrication technology in the 1970s until about 1986, speed-up in computer architecture was driven by doubling computer word sizethe amount of information the processor can manipulate per cycle. Increasing the word size reduces the number of instructions the processor must execute to perform an operation on variables whose sizes are greater than the length of the word. For example, where an 8-bit processor must add two 16-bit integers, the processor must first add the 8lower-order bits from each integer using the standard addition instruction, then add the 8higher-order bits using an add-with-carry instruction and the carry bit from the lower order addition; thus, an 8-bit processor requires two instructions to complete a single operation, where a 16-bit processor would be able to complete the operation with a single instruction.",
        "target": "Historically, 4-bit microprocessors were replaced with 8-bit, then 16-bit, then 32-bit microprocessors. This trend generally came to an end with the introduction of 32-bit processors, which has been a standard in general-purpose computing for two decades. Not until the early 2000s, with the advent of x86-64 architectures, did 64-bit processors become commonplace."
    },
    {
        "source": "From the advent of very-large-scale integration (VLSI) computer-chip fabrication technology in the 1970s until about 1986, speed-up in computer architecture was driven by doubling computer word sizethe amount of information the processor can manipulate per cycle. Increasing the word size reduces the number of instructions the processor must execute to perform an operation on variables whose sizes are greater than the length of the word. For example, where an 8-bit processor must add two 16-bit integers, the processor must first add the 8lower-order bits from each integer using the standard addition instruction, then add the 8higher-order bits using an add-with-carry instruction and the carry bit from the lower order addition; thus, an 8-bit processor requires two instructions to complete a single operation, where a 16-bit processor would be able to complete the operation with a single instruction. Historically, 4-bit microprocessors were replaced with 8-bit, then 16-bit, then 32-bit microprocessors. This trend generally came to an end with the introduction of 32-bit processors, which has been a standard in general-purpose computing for two decades. Not until the early 2000s, with the advent of x86-64 architectures, did 64-bit processors become commonplace.",
        "target": "A computer program is, in essence, a stream of instructions executed by a processor. Without instruction-level parallelism, a processor can only issue less than one instruction per clock cycle (IPC < 1). These processors are known as subscalar processors. These instructions can be re-ordered and combined into groups which are then executed in parallel without changing the result of the program. This is known as instruction-level parallelism. Advances in instruction-level parallelism dominated computer architecture from the mid-1980s until the mid-1990s."
    },
    {
        "source": "Historically, 4-bit microprocessors were replaced with 8-bit, then 16-bit, then 32-bit microprocessors. This trend generally came to an end with the introduction of 32-bit processors, which has been a standard in general-purpose computing for two decades. Not until the early 2000s, with the advent of x86-64 architectures, did 64-bit processors become commonplace. A computer program is, in essence, a stream of instructions executed by a processor. Without instruction-level parallelism, a processor can only issue less than one instruction per clock cycle (IPC < 1). These processors are known as subscalar processors. These instructions can be re-ordered and combined into groups which are then executed in parallel without changing the result of the program. This is known as instruction-level parallelism. Advances in instruction-level parallelism dominated computer architecture from the mid-1980s until the mid-1990s.",
        "target": "All modern processors have multi-stage instruction pipelines. Each stage in the pipeline corresponds to a different action the processor performs on that instruction in that stage; a processor with an N-stage pipeline can have up to N different instructions at different stages of completion and thus can issue one instruction per clock cycle (IPC = 1). These processors are known as scalar processors. The canonical example of a pipelined processor is a RISC processor, with five stages: instruction fetch (IF), instruction decode (ID), execute (EX), memory access (MEM), and register write back (WB). The Pentium 4 processor had a 35-stage pipeline."
    },
    {
        "source": "A computer program is, in essence, a stream of instructions executed by a processor. Without instruction-level parallelism, a processor can only issue less than one instruction per clock cycle (IPC < 1). These processors are known as subscalar processors. These instructions can be re-ordered and combined into groups which are then executed in parallel without changing the result of the program. This is known as instruction-level parallelism. Advances in instruction-level parallelism dominated computer architecture from the mid-1980s until the mid-1990s. All modern processors have multi-stage instruction pipelines. Each stage in the pipeline corresponds to a different action the processor performs on that instruction in that stage; a processor with an N-stage pipeline can have up to N different instructions at different stages of completion and thus can issue one instruction per clock cycle (IPC = 1). These processors are known as scalar processors. The canonical example of a pipelined processor is a RISC processor, with five stages: instruction fetch (IF), instruction decode (ID), execute (EX), memory access (MEM), and register write back (WB). The Pentium 4 processor had a 35-stage pipeline.",
        "target": "Most modern processors also have multiple execution units. They usually combine this feature with pipelining and thus can issue more than one instruction per clock cycle (IPC > 1). These processors are known as superscalar processors. Superscalar processors differ from multi-core processors in that the several execution units are not entire processors (i.e. processing units). Instructions can be grouped together only if there is no data dependency between them. Scoreboarding and the Tomasulo algorithm (which is similar to scoreboarding but makes use of register renaming) are two of the most common techniques for implementing out-of-order execution and instruction-level parallelism."
    },
    {
        "source": "All modern processors have multi-stage instruction pipelines. Each stage in the pipeline corresponds to a different action the processor performs on that instruction in that stage; a processor with an N-stage pipeline can have up to N different instructions at different stages of completion and thus can issue one instruction per clock cycle (IPC = 1). These processors are known as scalar processors. The canonical example of a pipelined processor is a RISC processor, with five stages: instruction fetch (IF), instruction decode (ID), execute (EX), memory access (MEM), and register write back (WB). The Pentium 4 processor had a 35-stage pipeline. Most modern processors also have multiple execution units. They usually combine this feature with pipelining and thus can issue more than one instruction per clock cycle (IPC > 1). These processors are known as superscalar processors. Superscalar processors differ from multi-core processors in that the several execution units are not entire processors (i.e. processing units). Instructions can be grouped together only if there is no data dependency between them. Scoreboarding and the Tomasulo algorithm (which is similar to scoreboarding but makes use of register renaming) are two of the most common techniques for implementing out-of-order execution and instruction-level parallelism.",
        "target": "Task parallelisms is the characteristic of a parallel program that \"entirely different calculations can be performed on either the same or different sets of data\". This contrasts with data parallelism, where the same calculation is performed on the same or different sets of data. Task parallelism involves the decomposition of a task into sub-tasks and then allocating each sub-task to a processor for execution. The processors would then execute these sub-tasks concurrently and often cooperatively. Task parallelism does not usually scale with the size of a problem."
    },
    {
        "source": "Most modern processors also have multiple execution units. They usually combine this feature with pipelining and thus can issue more than one instruction per clock cycle (IPC > 1). These processors are known as superscalar processors. Superscalar processors differ from multi-core processors in that the several execution units are not entire processors (i.e. processing units). Instructions can be grouped together only if there is no data dependency between them. Scoreboarding and the Tomasulo algorithm (which is similar to scoreboarding but makes use of register renaming) are two of the most common techniques for implementing out-of-order execution and instruction-level parallelism. Task parallelisms is the characteristic of a parallel program that \"entirely different calculations can be performed on either the same or different sets of data\". This contrasts with data parallelism, where the same calculation is performed on the same or different sets of data. Task parallelism involves the decomposition of a task into sub-tasks and then allocating each sub-task to a processor for execution. The processors would then execute these sub-tasks concurrently and often cooperatively. Task parallelism does not usually scale with the size of a problem.",
        "target": "Superword level parallelism is a vectorization technique based on loop unrolling and basic block vectorization. It is distinct from loop vectorization algorithms in that it can exploit parallelism of inline code, such as manipulating coordinates, color channels or in loops unrolled by hand."
    },
    {
        "source": "Task parallelisms is the characteristic of a parallel program that \"entirely different calculations can be performed on either the same or different sets of data\". This contrasts with data parallelism, where the same calculation is performed on the same or different sets of data. Task parallelism involves the decomposition of a task into sub-tasks and then allocating each sub-task to a processor for execution. The processors would then execute these sub-tasks concurrently and often cooperatively. Task parallelism does not usually scale with the size of a problem. Superword level parallelism is a vectorization technique based on loop unrolling and basic block vectorization. It is distinct from loop vectorization algorithms in that it can exploit parallelism of inline code, such as manipulating coordinates, color channels or in loops unrolled by hand.",
        "target": "Main memory in a parallel computer is either shared memory (shared between all processing elements in a single address space), or distributed memory (in which each processing element has its own local address space). Distributed memory refers to the fact that the memory is logically distributed, but often implies that it is physically distributed as well. Distributed shared memory and memory virtualization combine the two approaches, where the processing element has its own local memory and access to the memory on non-local processors. Accesses to local memory are typically faster than accesses to non-local memory. On the supercomputers, distributed shared memory space can be implemented using the programming model such as PGAS.  This model allows processes on one compute node to transparently access the remote memory of another compute node. All compute nodes are also connected to an external shared memory system via high-speed interconnect, such as Infiniband, this external shared memory system is known as burst buffer, which is typically built from arrays of non-volatile memory physically distributed across multiple I/O nodes."
    },
    {
        "source": "Superword level parallelism is a vectorization technique based on loop unrolling and basic block vectorization. It is distinct from loop vectorization algorithms in that it can exploit parallelism of inline code, such as manipulating coordinates, color channels or in loops unrolled by hand. Main memory in a parallel computer is either shared memory (shared between all processing elements in a single address space), or distributed memory (in which each processing element has its own local address space). Distributed memory refers to the fact that the memory is logically distributed, but often implies that it is physically distributed as well. Distributed shared memory and memory virtualization combine the two approaches, where the processing element has its own local memory and access to the memory on non-local processors. Accesses to local memory are typically faster than accesses to non-local memory. On the supercomputers, distributed shared memory space can be implemented using the programming model such as PGAS.  This model allows processes on one compute node to transparently access the remote memory of another compute node. All compute nodes are also connected to an external shared memory system via high-speed interconnect, such as Infiniband, this external shared memory system is known as burst buffer, which is typically built from arrays of non-volatile memory physically distributed across multiple I/O nodes.",
        "target": "Computer architectures in which each element of main memory can be accessed with equal latency and bandwidth are known as uniform memory access (UMA) systems. Typically, that can be achieved only by a shared memory system, in which the memory is not physically distributed. A system that does not have this property is known as a non-uniform memory access (NUMA) architecture. Distributed memory systems have non-uniform memory access."
    },
    {
        "source": "Main memory in a parallel computer is either shared memory (shared between all processing elements in a single address space), or distributed memory (in which each processing element has its own local address space). Distributed memory refers to the fact that the memory is logically distributed, but often implies that it is physically distributed as well. Distributed shared memory and memory virtualization combine the two approaches, where the processing element has its own local memory and access to the memory on non-local processors. Accesses to local memory are typically faster than accesses to non-local memory. On the supercomputers, distributed shared memory space can be implemented using the programming model such as PGAS.  This model allows processes on one compute node to transparently access the remote memory of another compute node. All compute nodes are also connected to an external shared memory system via high-speed interconnect, such as Infiniband, this external shared memory system is known as burst buffer, which is typically built from arrays of non-volatile memory physically distributed across multiple I/O nodes. Computer architectures in which each element of main memory can be accessed with equal latency and bandwidth are known as uniform memory access (UMA) systems. Typically, that can be achieved only by a shared memory system, in which the memory is not physically distributed. A system that does not have this property is known as a non-uniform memory access (NUMA) architecture. Distributed memory systems have non-uniform memory access.",
        "target": "Computer systems make use of cachessmall and fast memories located close to the processor which store temporary copies of memory values (nearby in both the physical and logical sense). Parallel computer systems have difficulties with caches that may store the same value in more than one location, with the possibility of incorrect program execution. These computers require a cache coherency system, which keeps track of cached values and strategically purges them, thus ensuring correct program execution. Bus snooping is one of the most common methods for keeping track of which values are being accessed (and thus should be purged). Designing large, high-performance cache coherence systems is a very difficult problem in computer architecture. As a result, shared memory computer architectures do not scale as well as distributed memory systems do."
    },
    {
        "source": "Computer architectures in which each element of main memory can be accessed with equal latency and bandwidth are known as uniform memory access (UMA) systems. Typically, that can be achieved only by a shared memory system, in which the memory is not physically distributed. A system that does not have this property is known as a non-uniform memory access (NUMA) architecture. Distributed memory systems have non-uniform memory access. Computer systems make use of cachessmall and fast memories located close to the processor which store temporary copies of memory values (nearby in both the physical and logical sense). Parallel computer systems have difficulties with caches that may store the same value in more than one location, with the possibility of incorrect program execution. These computers require a cache coherency system, which keeps track of cached values and strategically purges them, thus ensuring correct program execution. Bus snooping is one of the most common methods for keeping track of which values are being accessed (and thus should be purged). Designing large, high-performance cache coherence systems is a very difficult problem in computer architecture. As a result, shared memory computer architectures do not scale as well as distributed memory systems do.",
        "target": "Processorprocessor and processormemory communication can be implemented in hardware in several ways, including via shared (either multiported or multiplexed) memory, a crossbar switch, a shared bus or an interconnect network of a myriad of topologies including star, ring, tree, hypercube, fat hypercube (a hypercube with more than one processor at a node), or n-dimensional mesh."
    },
    {
        "source": "Computer systems make use of cachessmall and fast memories located close to the processor which store temporary copies of memory values (nearby in both the physical and logical sense). Parallel computer systems have difficulties with caches that may store the same value in more than one location, with the possibility of incorrect program execution. These computers require a cache coherency system, which keeps track of cached values and strategically purges them, thus ensuring correct program execution. Bus snooping is one of the most common methods for keeping track of which values are being accessed (and thus should be purged). Designing large, high-performance cache coherence systems is a very difficult problem in computer architecture. As a result, shared memory computer architectures do not scale as well as distributed memory systems do. Processorprocessor and processormemory communication can be implemented in hardware in several ways, including via shared (either multiported or multiplexed) memory, a crossbar switch, a shared bus or an interconnect network of a myriad of topologies including star, ring, tree, hypercube, fat hypercube (a hypercube with more than one processor at a node), or n-dimensional mesh.",
        "target": "Parallel computers based on interconnected networks need to have some kind of routing to enable the passing of messages between nodes that are not directly connected. The medium used for communication between the processors is likely to be hierarchical in large multiprocessor machines."
    },
    {
        "source": "Processorprocessor and processormemory communication can be implemented in hardware in several ways, including via shared (either multiported or multiplexed) memory, a crossbar switch, a shared bus or an interconnect network of a myriad of topologies including star, ring, tree, hypercube, fat hypercube (a hypercube with more than one processor at a node), or n-dimensional mesh. Parallel computers based on interconnected networks need to have some kind of routing to enable the passing of messages between nodes that are not directly connected. The medium used for communication between the processors is likely to be hierarchical in large multiprocessor machines.",
        "target": "Parallel computers can be roughly classified according to the level at which the hardware supports parallelism. This classification is broadly analogous to the distance between basic computing nodes. These are not mutually exclusive; for example, clusters of symmetric multiprocessors are relatively common."
    },
    {
        "source": "Parallel computers based on interconnected networks need to have some kind of routing to enable the passing of messages between nodes that are not directly connected. The medium used for communication between the processors is likely to be hierarchical in large multiprocessor machines. Parallel computers can be roughly classified according to the level at which the hardware supports parallelism. This classification is broadly analogous to the distance between basic computing nodes. These are not mutually exclusive; for example, clusters of symmetric multiprocessors are relatively common.",
        "target": "A multi-core processor is a processor that includes multiple processing units (called \"cores\") on the same chip. This processor differs from a superscalar processor, which includes multiple execution units and can issue multiple instructions per clock cycle from one instruction stream (thread); in contrast, a multi-core processor can issue multiple instructions per clock cycle from multiple instruction streams. IBM's Cell microprocessor, designed for use in the Sony PlayStation 3, is a prominent multi-core processor. Each core in a multi-core processor can potentially be superscalar as wellthat is, on every clock cycle, each core can issue multiple instructions from one thread."
    },
    {
        "source": "Parallel computers can be roughly classified according to the level at which the hardware supports parallelism. This classification is broadly analogous to the distance between basic computing nodes. These are not mutually exclusive; for example, clusters of symmetric multiprocessors are relatively common. A multi-core processor is a processor that includes multiple processing units (called \"cores\") on the same chip. This processor differs from a superscalar processor, which includes multiple execution units and can issue multiple instructions per clock cycle from one instruction stream (thread); in contrast, a multi-core processor can issue multiple instructions per clock cycle from multiple instruction streams. IBM's Cell microprocessor, designed for use in the Sony PlayStation 3, is a prominent multi-core processor. Each core in a multi-core processor can potentially be superscalar as wellthat is, on every clock cycle, each core can issue multiple instructions from one thread.",
        "target": "Simultaneous multithreading  (of which Intel's Hyper-Threading is the best known) was an early form of pseudo-multi-coreism. A processor capable of concurrent multithreading includes multiple execution units in the same processing unitthat is it has a superscalar architectureand can issue multiple instructions per clock cycle from multiple threads. Temporal multithreading on the other hand includes a single execution unit in the same processing unit and can issue one instruction at a time from multiple threads."
    },
    {
        "source": "A multi-core processor is a processor that includes multiple processing units (called \"cores\") on the same chip. This processor differs from a superscalar processor, which includes multiple execution units and can issue multiple instructions per clock cycle from one instruction stream (thread); in contrast, a multi-core processor can issue multiple instructions per clock cycle from multiple instruction streams. IBM's Cell microprocessor, designed for use in the Sony PlayStation 3, is a prominent multi-core processor. Each core in a multi-core processor can potentially be superscalar as wellthat is, on every clock cycle, each core can issue multiple instructions from one thread. Simultaneous multithreading  (of which Intel's Hyper-Threading is the best known) was an early form of pseudo-multi-coreism. A processor capable of concurrent multithreading includes multiple execution units in the same processing unitthat is it has a superscalar architectureand can issue multiple instructions per clock cycle from multiple threads. Temporal multithreading on the other hand includes a single execution unit in the same processing unit and can issue one instruction at a time from multiple threads.",
        "target": "A symmetric multiprocessor (SMP) is a computer system with multiple identical processors that share memory and connect via a bus. Bus contention prevents bus architectures from scaling. As a result, SMPs generally do not comprise more than 32processors. Because of the small size of the processors and the significant reduction in the requirements for bus bandwidth achieved by large caches, such symmetric multiprocessors are extremely cost-effective, provided that a sufficient amount of memory bandwidth exists."
    },
    {
        "source": "Simultaneous multithreading  (of which Intel's Hyper-Threading is the best known) was an early form of pseudo-multi-coreism. A processor capable of concurrent multithreading includes multiple execution units in the same processing unitthat is it has a superscalar architectureand can issue multiple instructions per clock cycle from multiple threads. Temporal multithreading on the other hand includes a single execution unit in the same processing unit and can issue one instruction at a time from multiple threads. A symmetric multiprocessor (SMP) is a computer system with multiple identical processors that share memory and connect via a bus. Bus contention prevents bus architectures from scaling. As a result, SMPs generally do not comprise more than 32processors. Because of the small size of the processors and the significant reduction in the requirements for bus bandwidth achieved by large caches, such symmetric multiprocessors are extremely cost-effective, provided that a sufficient amount of memory bandwidth exists.",
        "target": "A distributed computer (also known as a distributed memory multiprocessor) is a distributed memory computer system in which the processing elements are connected by a network. Distributed computers are highly scalable. The terms \"concurrent computing\", \"parallel computing\", and \"distributed computing\" have a lot of overlap, and no clear distinction exists between them. The same system may be characterized both as \"parallel\" and \"distributed\"; the processors in a typical distributed system run concurrently in parallel."
    },
    {
        "source": "A symmetric multiprocessor (SMP) is a computer system with multiple identical processors that share memory and connect via a bus. Bus contention prevents bus architectures from scaling. As a result, SMPs generally do not comprise more than 32processors. Because of the small size of the processors and the significant reduction in the requirements for bus bandwidth achieved by large caches, such symmetric multiprocessors are extremely cost-effective, provided that a sufficient amount of memory bandwidth exists. A distributed computer (also known as a distributed memory multiprocessor) is a distributed memory computer system in which the processing elements are connected by a network. Distributed computers are highly scalable. The terms \"concurrent computing\", \"parallel computing\", and \"distributed computing\" have a lot of overlap, and no clear distinction exists between them. The same system may be characterized both as \"parallel\" and \"distributed\"; the processors in a typical distributed system run concurrently in parallel.",
        "target": "A cluster is a group of loosely coupled computers that work together closely, so that in some respects they can be regarded as a single computer. Clusters are composed of multiple standalone machines connected by a network. While machines in a cluster do not have to be symmetric, load balancing is more difficult if they are not. The most common type of cluster is the Beowulf cluster, which is a cluster implemented on multiple identical commercial off-the-shelf computers connected with a TCP/IP Ethernet local area network. Beowulf technology was originally developed by Thomas Sterling and Donald Becker. 87% of all Top500 supercomputers are clusters. The remaining are Massively Parallel Processors, explained below."
    },
    {
        "source": "A distributed computer (also known as a distributed memory multiprocessor) is a distributed memory computer system in which the processing elements are connected by a network. Distributed computers are highly scalable. The terms \"concurrent computing\", \"parallel computing\", and \"distributed computing\" have a lot of overlap, and no clear distinction exists between them. The same system may be characterized both as \"parallel\" and \"distributed\"; the processors in a typical distributed system run concurrently in parallel. A cluster is a group of loosely coupled computers that work together closely, so that in some respects they can be regarded as a single computer. Clusters are composed of multiple standalone machines connected by a network. While machines in a cluster do not have to be symmetric, load balancing is more difficult if they are not. The most common type of cluster is the Beowulf cluster, which is a cluster implemented on multiple identical commercial off-the-shelf computers connected with a TCP/IP Ethernet local area network. Beowulf technology was originally developed by Thomas Sterling and Donald Becker. 87% of all Top500 supercomputers are clusters. The remaining are Massively Parallel Processors, explained below.",
        "target": "Because grid computing systems (described below) can easily handle embarrassingly parallel problems, modern clusters are typically designed to handle more difficult problemsproblems that require nodes to share intermediate results with each other more often. This requires a high bandwidth and, more importantly, a low-latency interconnection network. Many historic and current supercomputers use customized high-performance network hardware specifically designed for cluster computing, such as the Cray Gemini network. As of 2014, most current supercomputers use some off-the-shelf standard network hardware, often Myrinet, InfiniBand, or Gigabit Ethernet."
    },
    {
        "source": "A cluster is a group of loosely coupled computers that work together closely, so that in some respects they can be regarded as a single computer. Clusters are composed of multiple standalone machines connected by a network. While machines in a cluster do not have to be symmetric, load balancing is more difficult if they are not. The most common type of cluster is the Beowulf cluster, which is a cluster implemented on multiple identical commercial off-the-shelf computers connected with a TCP/IP Ethernet local area network. Beowulf technology was originally developed by Thomas Sterling and Donald Becker. 87% of all Top500 supercomputers are clusters. The remaining are Massively Parallel Processors, explained below. Because grid computing systems (described below) can easily handle embarrassingly parallel problems, modern clusters are typically designed to handle more difficult problemsproblems that require nodes to share intermediate results with each other more often. This requires a high bandwidth and, more importantly, a low-latency interconnection network. Many historic and current supercomputers use customized high-performance network hardware specifically designed for cluster computing, such as the Cray Gemini network. As of 2014, most current supercomputers use some off-the-shelf standard network hardware, often Myrinet, InfiniBand, or Gigabit Ethernet.",
        "target": "A massively parallel processor (MPP) is a single computer with many networked processors. MPPs have many of the same characteristics as clusters, but MPPs have specialized interconnect networks (whereas clusters use commodity hardware for networking). MPPs also tend to be larger than clusters, typically having \"far more\" than 100processors. In an MPP, \"each CPU contains its own memory and copy of the operating system and application. Each subsystem communicates with the others via a high-speed interconnect.\""
    },
    {
        "source": "Because grid computing systems (described below) can easily handle embarrassingly parallel problems, modern clusters are typically designed to handle more difficult problemsproblems that require nodes to share intermediate results with each other more often. This requires a high bandwidth and, more importantly, a low-latency interconnection network. Many historic and current supercomputers use customized high-performance network hardware specifically designed for cluster computing, such as the Cray Gemini network. As of 2014, most current supercomputers use some off-the-shelf standard network hardware, often Myrinet, InfiniBand, or Gigabit Ethernet. A massively parallel processor (MPP) is a single computer with many networked processors. MPPs have many of the same characteristics as clusters, but MPPs have specialized interconnect networks (whereas clusters use commodity hardware for networking). MPPs also tend to be larger than clusters, typically having \"far more\" than 100processors. In an MPP, \"each CPU contains its own memory and copy of the operating system and application. Each subsystem communicates with the others via a high-speed interconnect.\"",
        "target": "IBM's Blue Gene/L, the fifth fastest supercomputer in the world according to the June 2009 TOP500 ranking, is an MPP."
    },
    {
        "source": "A massively parallel processor (MPP) is a single computer with many networked processors. MPPs have many of the same characteristics as clusters, but MPPs have specialized interconnect networks (whereas clusters use commodity hardware for networking). MPPs also tend to be larger than clusters, typically having \"far more\" than 100processors. In an MPP, \"each CPU contains its own memory and copy of the operating system and application. Each subsystem communicates with the others via a high-speed interconnect.\" IBM's Blue Gene/L, the fifth fastest supercomputer in the world according to the June 2009 TOP500 ranking, is an MPP.",
        "target": "Grid computing is the most distributed form of parallel computing. It makes use of computers communicating over the Internet to work on a given problem. Because of the low bandwidth and extremely high latency available on the Internet, distributed computing typically deals only with embarrassingly parallel problems."
    },
    {
        "source": "IBM's Blue Gene/L, the fifth fastest supercomputer in the world according to the June 2009 TOP500 ranking, is an MPP. Grid computing is the most distributed form of parallel computing. It makes use of computers communicating over the Internet to work on a given problem. Because of the low bandwidth and extremely high latency available on the Internet, distributed computing typically deals only with embarrassingly parallel problems.",
        "target": "Most grid computing applications use middleware (software that sits between the operating system and the application to manage network resources and standardize the software interface). The most common grid computing middleware is the Berkeley Open Infrastructure for Network Computing (BOINC). Often volunteer computing software makes use of \"spare cycles\", performing computations at times when a computer is idling."
    },
    {
        "source": "Grid computing is the most distributed form of parallel computing. It makes use of computers communicating over the Internet to work on a given problem. Because of the low bandwidth and extremely high latency available on the Internet, distributed computing typically deals only with embarrassingly parallel problems. Most grid computing applications use middleware (software that sits between the operating system and the application to manage network resources and standardize the software interface). The most common grid computing middleware is the Berkeley Open Infrastructure for Network Computing (BOINC). Often volunteer computing software makes use of \"spare cycles\", performing computations at times when a computer is idling.",
        "target": "The ubiquity of Internet brought the possibility of large-scale cloud computing."
    },
    {
        "source": "Most grid computing applications use middleware (software that sits between the operating system and the application to manage network resources and standardize the software interface). The most common grid computing middleware is the Berkeley Open Infrastructure for Network Computing (BOINC). Often volunteer computing software makes use of \"spare cycles\", performing computations at times when a computer is idling. The ubiquity of Internet brought the possibility of large-scale cloud computing.",
        "target": "Within parallel computing, there are specialized parallel devices that remain niche areas of interest. While not domain-specific, they tend to be applicable to only a few classes of parallel problems."
    },
    {
        "source": "The ubiquity of Internet brought the possibility of large-scale cloud computing. Within parallel computing, there are specialized parallel devices that remain niche areas of interest. While not domain-specific, they tend to be applicable to only a few classes of parallel problems.",
        "target": "Reconfigurable computing is the use of a field-programmable gate array (FPGA) as a co-processor to a general-purpose computer. An FPGA is, in essence, a computer chip that can rewire itself for a given task."
    },
    {
        "source": "Within parallel computing, there are specialized parallel devices that remain niche areas of interest. While not domain-specific, they tend to be applicable to only a few classes of parallel problems. Reconfigurable computing is the use of a field-programmable gate array (FPGA) as a co-processor to a general-purpose computer. An FPGA is, in essence, a computer chip that can rewire itself for a given task.",
        "target": "FPGAs can be programmed with hardware description languages such as VHDL or Verilog. Several vendors have created C to HDL languages that attempt to emulate the syntax and semantics of the C programming language, with which most programmers are familiar. The best known C to HDL languages are Mitrion-C, Impulse C, and Handel-C. Specific subsets of SystemC based on C++ can also be used for this purpose."
    },
    {
        "source": "Reconfigurable computing is the use of a field-programmable gate array (FPGA) as a co-processor to a general-purpose computer. An FPGA is, in essence, a computer chip that can rewire itself for a given task. FPGAs can be programmed with hardware description languages such as VHDL or Verilog. Several vendors have created C to HDL languages that attempt to emulate the syntax and semantics of the C programming language, with which most programmers are familiar. The best known C to HDL languages are Mitrion-C, Impulse C, and Handel-C. Specific subsets of SystemC based on C++ can also be used for this purpose.",
        "target": "AMD's decision to open its HyperTransport technology to third-party vendors has become the enabling technology for high-performance reconfigurable computing. According to Michael R. D'Amour, Chief Operating Officer of DRC Computer Corporation, \"when we first walked into AMD, they called us 'the socket stealers.' Now they call us their partners.\""
    },
    {
        "source": "FPGAs can be programmed with hardware description languages such as VHDL or Verilog. Several vendors have created C to HDL languages that attempt to emulate the syntax and semantics of the C programming language, with which most programmers are familiar. The best known C to HDL languages are Mitrion-C, Impulse C, and Handel-C. Specific subsets of SystemC based on C++ can also be used for this purpose. AMD's decision to open its HyperTransport technology to third-party vendors has become the enabling technology for high-performance reconfigurable computing. According to Michael R. D'Amour, Chief Operating Officer of DRC Computer Corporation, \"when we first walked into AMD, they called us 'the socket stealers.' Now they call us their partners.\"",
        "target": "General-purpose computing on graphics processing units (GPGPU) is a fairly recent trend in computer engineering research. GPUs are co-processors that have been heavily optimized for computer graphics processing. Computer graphics processing is a field dominated by data parallel operationsparticularly linear algebra matrix operations."
    },
    {
        "source": "AMD's decision to open its HyperTransport technology to third-party vendors has become the enabling technology for high-performance reconfigurable computing. According to Michael R. D'Amour, Chief Operating Officer of DRC Computer Corporation, \"when we first walked into AMD, they called us 'the socket stealers.' Now they call us their partners.\" General-purpose computing on graphics processing units (GPGPU) is a fairly recent trend in computer engineering research. GPUs are co-processors that have been heavily optimized for computer graphics processing. Computer graphics processing is a field dominated by data parallel operationsparticularly linear algebra matrix operations.",
        "target": "In the early days, GPGPU programs used the normal graphics APIs for executing programs. However, several new programming languages and platforms have been built to do general purpose computation on GPUs with both Nvidia and AMD releasing programming environments with CUDA and Stream SDK respectively. Other GPU programming languages include BrookGPU, PeakStream, and RapidMind. Nvidia has also released specific products for computation in their Tesla series. The technology consortium Khronos Group has released the OpenCL specification, which is a framework for writing programs that execute across platforms consisting of CPUs and GPUs. AMD, Apple, Intel, Nvidia and others are supporting OpenCL."
    },
    {
        "source": "General-purpose computing on graphics processing units (GPGPU) is a fairly recent trend in computer engineering research. GPUs are co-processors that have been heavily optimized for computer graphics processing. Computer graphics processing is a field dominated by data parallel operationsparticularly linear algebra matrix operations. In the early days, GPGPU programs used the normal graphics APIs for executing programs. However, several new programming languages and platforms have been built to do general purpose computation on GPUs with both Nvidia and AMD releasing programming environments with CUDA and Stream SDK respectively. Other GPU programming languages include BrookGPU, PeakStream, and RapidMind. Nvidia has also released specific products for computation in their Tesla series. The technology consortium Khronos Group has released the OpenCL specification, which is a framework for writing programs that execute across platforms consisting of CPUs and GPUs. AMD, Apple, Intel, Nvidia and others are supporting OpenCL.",
        "target": "Several application-specific integrated circuit (ASIC) approaches have been devised for dealing with parallel applications."
    },
    {
        "source": "In the early days, GPGPU programs used the normal graphics APIs for executing programs. However, several new programming languages and platforms have been built to do general purpose computation on GPUs with both Nvidia and AMD releasing programming environments with CUDA and Stream SDK respectively. Other GPU programming languages include BrookGPU, PeakStream, and RapidMind. Nvidia has also released specific products for computation in their Tesla series. The technology consortium Khronos Group has released the OpenCL specification, which is a framework for writing programs that execute across platforms consisting of CPUs and GPUs. AMD, Apple, Intel, Nvidia and others are supporting OpenCL. Several application-specific integrated circuit (ASIC) approaches have been devised for dealing with parallel applications.",
        "target": "Because an ASIC is (by definition) specific to a given application, it can be fully optimized for that application. As a result, for a given application, an ASIC tends to outperform a general-purpose computer. However, ASICs are created by UV photolithography. This process requires a mask set, which can be extremely expensive. A mask set can cost over a million US dollars. (The smaller the transistors required for the chip, the more expensive the mask will be.) Meanwhile, performance increases in general-purpose computing over time (as described by Moore's law) tend to wipe out these gains in only one or two chip generations. High initial cost, and the tendency to be overtaken by Moore's-law-driven general-purpose computing, has rendered ASICs unfeasible for most parallel computing applications. However, some have been built. One example is the PFLOPS RIKEN MDGRAPE-3 machine which uses custom ASICs for molecular dynamics simulation."
    },
    {
        "source": "Several application-specific integrated circuit (ASIC) approaches have been devised for dealing with parallel applications. Because an ASIC is (by definition) specific to a given application, it can be fully optimized for that application. As a result, for a given application, an ASIC tends to outperform a general-purpose computer. However, ASICs are created by UV photolithography. This process requires a mask set, which can be extremely expensive. A mask set can cost over a million US dollars. (The smaller the transistors required for the chip, the more expensive the mask will be.) Meanwhile, performance increases in general-purpose computing over time (as described by Moore's law) tend to wipe out these gains in only one or two chip generations. High initial cost, and the tendency to be overtaken by Moore's-law-driven general-purpose computing, has rendered ASICs unfeasible for most parallel computing applications. However, some have been built. One example is the PFLOPS RIKEN MDGRAPE-3 machine which uses custom ASICs for molecular dynamics simulation.",
        "target": "A vector processor is a CPU or computer system that can execute the same instruction on large sets of data. Vector processors have high-level operations that work on linear arrays of numbers or vectors. An example vector operation is A = B  C, where A, B, and C are each 64-element vectors of 64-bit floating-point numbers. They are closely related to Flynn's SIMD classification."
    },
    {
        "source": "Because an ASIC is (by definition) specific to a given application, it can be fully optimized for that application. As a result, for a given application, an ASIC tends to outperform a general-purpose computer. However, ASICs are created by UV photolithography. This process requires a mask set, which can be extremely expensive. A mask set can cost over a million US dollars. (The smaller the transistors required for the chip, the more expensive the mask will be.) Meanwhile, performance increases in general-purpose computing over time (as described by Moore's law) tend to wipe out these gains in only one or two chip generations. High initial cost, and the tendency to be overtaken by Moore's-law-driven general-purpose computing, has rendered ASICs unfeasible for most parallel computing applications. However, some have been built. One example is the PFLOPS RIKEN MDGRAPE-3 machine which uses custom ASICs for molecular dynamics simulation. A vector processor is a CPU or computer system that can execute the same instruction on large sets of data. Vector processors have high-level operations that work on linear arrays of numbers or vectors. An example vector operation is A = B  C, where A, B, and C are each 64-element vectors of 64-bit floating-point numbers. They are closely related to Flynn's SIMD classification.",
        "target": "Cray computers became famous for their vector-processing computers in the 1970s and 1980s. However, vector processorsboth as CPUs and as full computer systemshave generally disappeared. Modern processor instruction sets do include some vector processing instructions, such as with Freescale Semiconductor's AltiVec and Intel's Streaming SIMD Extensions (SSE)."
    },
    {
        "source": "A vector processor is a CPU or computer system that can execute the same instruction on large sets of data. Vector processors have high-level operations that work on linear arrays of numbers or vectors. An example vector operation is A = B  C, where A, B, and C are each 64-element vectors of 64-bit floating-point numbers. They are closely related to Flynn's SIMD classification. Cray computers became famous for their vector-processing computers in the 1970s and 1980s. However, vector processorsboth as CPUs and as full computer systemshave generally disappeared. Modern processor instruction sets do include some vector processing instructions, such as with Freescale Semiconductor's AltiVec and Intel's Streaming SIMD Extensions (SSE).",
        "target": "Concurrent programming languages, libraries, APIs, and parallel programming models (such as algorithmic skeletons) have been created for programming parallel computers. These can generally be divided into classes based on the assumptions they make about the underlying memory architectureshared memory, distributed memory, or shared distributed memory. Shared memory programming languages communicate by manipulating shared memory variables. Distributed memory uses message passing. POSIX Threads and OpenMP are two of the most widely used shared memory APIs, whereas Message Passing Interface (MPI) is the most widely used message-passing system API. One concept used in programming parallel programs is the future concept, where one part of a program promises to deliver a required datum to another part of a program at some future time."
    },
    {
        "source": "Cray computers became famous for their vector-processing computers in the 1970s and 1980s. However, vector processorsboth as CPUs and as full computer systemshave generally disappeared. Modern processor instruction sets do include some vector processing instructions, such as with Freescale Semiconductor's AltiVec and Intel's Streaming SIMD Extensions (SSE). Concurrent programming languages, libraries, APIs, and parallel programming models (such as algorithmic skeletons) have been created for programming parallel computers. These can generally be divided into classes based on the assumptions they make about the underlying memory architectureshared memory, distributed memory, or shared distributed memory. Shared memory programming languages communicate by manipulating shared memory variables. Distributed memory uses message passing. POSIX Threads and OpenMP are two of the most widely used shared memory APIs, whereas Message Passing Interface (MPI) is the most widely used message-passing system API. One concept used in programming parallel programs is the future concept, where one part of a program promises to deliver a required datum to another part of a program at some future time.",
        "target": "Efforts to standardize parallel programming include an open standard called OpenHMPP for hybrid multi-core parallel programming. The OpenHMPP directive-based programming model offers a syntax to efficiently offload computations on hardware accelerators and to optimize data movement to/from the hardware memory using remote procedure calls."
    },
    {
        "source": "Concurrent programming languages, libraries, APIs, and parallel programming models (such as algorithmic skeletons) have been created for programming parallel computers. These can generally be divided into classes based on the assumptions they make about the underlying memory architectureshared memory, distributed memory, or shared distributed memory. Shared memory programming languages communicate by manipulating shared memory variables. Distributed memory uses message passing. POSIX Threads and OpenMP are two of the most widely used shared memory APIs, whereas Message Passing Interface (MPI) is the most widely used message-passing system API. One concept used in programming parallel programs is the future concept, where one part of a program promises to deliver a required datum to another part of a program at some future time. Efforts to standardize parallel programming include an open standard called OpenHMPP for hybrid multi-core parallel programming. The OpenHMPP directive-based programming model offers a syntax to efficiently offload computations on hardware accelerators and to optimize data movement to/from the hardware memory using remote procedure calls.",
        "target": "The rise of consumer GPUs has led to support for compute kernels, either in graphics  APIs (referred to as compute shaders), in dedicated APIs (such as OpenCL), or in other language extensions."
    },
    {
        "source": "Efforts to standardize parallel programming include an open standard called OpenHMPP for hybrid multi-core parallel programming. The OpenHMPP directive-based programming model offers a syntax to efficiently offload computations on hardware accelerators and to optimize data movement to/from the hardware memory using remote procedure calls. The rise of consumer GPUs has led to support for compute kernels, either in graphics  APIs (referred to as compute shaders), in dedicated APIs (such as OpenCL), or in other language extensions.",
        "target": "Automatic parallelization of a sequential program by a compiler is the \"holy grail\" of parallel computing, especially with the aforementioned limit of processor frequency. Despite decades of work by compiler researchers, automatic parallelization has had only limited success."
    },
    {
        "source": "The rise of consumer GPUs has led to support for compute kernels, either in graphics  APIs (referred to as compute shaders), in dedicated APIs (such as OpenCL), or in other language extensions. Automatic parallelization of a sequential program by a compiler is the \"holy grail\" of parallel computing, especially with the aforementioned limit of processor frequency. Despite decades of work by compiler researchers, automatic parallelization has had only limited success.",
        "target": "Mainstream parallel programming languages remain either explicitly parallel or (at best) partially implicit, in which a programmer gives the compiler directives for parallelization. A few fully implicit parallel programming languages existSISAL, Parallel Haskell, SequenceL, System C (for FPGAs), Mitrion-C, VHDL, and Verilog."
    },
    {
        "source": "Automatic parallelization of a sequential program by a compiler is the \"holy grail\" of parallel computing, especially with the aforementioned limit of processor frequency. Despite decades of work by compiler researchers, automatic parallelization has had only limited success. Mainstream parallel programming languages remain either explicitly parallel or (at best) partially implicit, in which a programmer gives the compiler directives for parallelization. A few fully implicit parallel programming languages existSISAL, Parallel Haskell, SequenceL, System C (for FPGAs), Mitrion-C, VHDL, and Verilog.",
        "target": "As a computer system grows in complexity, the mean time between failures usually decreases. Application checkpointing is a technique whereby the computer system takes a \"snapshot\" of the applicationa record of all current resource allocations and variable states, akin to a core dump; this information can be used to restore the program if the computer should fail. Application checkpointing means that the program has to restart from only its last checkpoint rather than the beginning. While checkpointing provides benefits in a variety of situations, it is especially useful in highly parallel systems with a large number of processors used in high performance computing."
    },
    {
        "source": "Mainstream parallel programming languages remain either explicitly parallel or (at best) partially implicit, in which a programmer gives the compiler directives for parallelization. A few fully implicit parallel programming languages existSISAL, Parallel Haskell, SequenceL, System C (for FPGAs), Mitrion-C, VHDL, and Verilog. As a computer system grows in complexity, the mean time between failures usually decreases. Application checkpointing is a technique whereby the computer system takes a \"snapshot\" of the applicationa record of all current resource allocations and variable states, akin to a core dump; this information can be used to restore the program if the computer should fail. Application checkpointing means that the program has to restart from only its last checkpoint rather than the beginning. While checkpointing provides benefits in a variety of situations, it is especially useful in highly parallel systems with a large number of processors used in high performance computing.",
        "target": "As parallel computers become larger and faster, we are now able to solve problems that had previously taken too long to run. Fields as varied as bioinformatics (for protein folding and sequence analysis) and economics have taken advantage of parallel computing. Common types of problems in parallel computing applications include:"
    },
    {
        "source": "As a computer system grows in complexity, the mean time between failures usually decreases. Application checkpointing is a technique whereby the computer system takes a \"snapshot\" of the applicationa record of all current resource allocations and variable states, akin to a core dump; this information can be used to restore the program if the computer should fail. Application checkpointing means that the program has to restart from only its last checkpoint rather than the beginning. While checkpointing provides benefits in a variety of situations, it is especially useful in highly parallel systems with a large number of processors used in high performance computing. As parallel computers become larger and faster, we are now able to solve problems that had previously taken too long to run. Fields as varied as bioinformatics (for protein folding and sequence analysis) and economics have taken advantage of parallel computing. Common types of problems in parallel computing applications include:",
        "target": "Parallel computing can also be applied to the design of fault-tolerant computer systems, particularly via lockstep systems performing the same operation in parallel. This provides redundancy in case one component fails, and also allows automatic error detection and error correction if the results differ. These methods can be used to help prevent single-event upsets caused by transient errors. Although additional measures may be required in embedded or specialized systems, this method can provide a cost-effective approach to achieve n-modular redundancy in commercial off-the-shelf systems."
    },
    {
        "source": "As parallel computers become larger and faster, we are now able to solve problems that had previously taken too long to run. Fields as varied as bioinformatics (for protein folding and sequence analysis) and economics have taken advantage of parallel computing. Common types of problems in parallel computing applications include: Parallel computing can also be applied to the design of fault-tolerant computer systems, particularly via lockstep systems performing the same operation in parallel. This provides redundancy in case one component fails, and also allows automatic error detection and error correction if the results differ. These methods can be used to help prevent single-event upsets caused by transient errors. Although additional measures may be required in embedded or specialized systems, this method can provide a cost-effective approach to achieve n-modular redundancy in commercial off-the-shelf systems.",
        "target": "The origins of true (MIMD) parallelism go back to Luigi Federico Menabrea and his Sketch of the Analytic Engine Invented by Charles Babbage."
    },
    {
        "source": "Parallel computing can also be applied to the design of fault-tolerant computer systems, particularly via lockstep systems performing the same operation in parallel. This provides redundancy in case one component fails, and also allows automatic error detection and error correction if the results differ. These methods can be used to help prevent single-event upsets caused by transient errors. Although additional measures may be required in embedded or specialized systems, this method can provide a cost-effective approach to achieve n-modular redundancy in commercial off-the-shelf systems. The origins of true (MIMD) parallelism go back to Luigi Federico Menabrea and his Sketch of the Analytic Engine Invented by Charles Babbage.",
        "target": "In 1957, Compagnie des Machines Bull announced the first computer architecture specifically designed for parallelism, the Gamma 60. It utilized a fork-join model and a \"Program Distributor\" to dispatch and collect data to and from independent processing units connected to a central memory."
    },
    {
        "source": "The origins of true (MIMD) parallelism go back to Luigi Federico Menabrea and his Sketch of the Analytic Engine Invented by Charles Babbage. In 1957, Compagnie des Machines Bull announced the first computer architecture specifically designed for parallelism, the Gamma 60. It utilized a fork-join model and a \"Program Distributor\" to dispatch and collect data to and from independent processing units connected to a central memory.",
        "target": "In April 1958, Stanley Gill (Ferranti) discussed parallel programming and the need for branching and waiting. Also in 1958, IBM researchers John Cocke and Daniel Slotnick discussed the use of parallelism in numerical calculations for the first time. Burroughs Corporation introduced the D825 in 1962, a four-processor computer that accessed up to 16 memory modules through a crossbar switch. In 1967, Amdahl and Slotnick published a debate about the feasibility of parallel processing at American Federation of Information Processing Societies Conference. It was during this debate that Amdahl's law was coined to define the limit of speed-up due to parallelism."
    },
    {
        "source": "In 1957, Compagnie des Machines Bull announced the first computer architecture specifically designed for parallelism, the Gamma 60. It utilized a fork-join model and a \"Program Distributor\" to dispatch and collect data to and from independent processing units connected to a central memory. In April 1958, Stanley Gill (Ferranti) discussed parallel programming and the need for branching and waiting. Also in 1958, IBM researchers John Cocke and Daniel Slotnick discussed the use of parallelism in numerical calculations for the first time. Burroughs Corporation introduced the D825 in 1962, a four-processor computer that accessed up to 16 memory modules through a crossbar switch. In 1967, Amdahl and Slotnick published a debate about the feasibility of parallel processing at American Federation of Information Processing Societies Conference. It was during this debate that Amdahl's law was coined to define the limit of speed-up due to parallelism.",
        "target": "In 1969, Honeywell introduced its first Multics system, a symmetric multiprocessor system capable of running up to eight processors in parallel. C.mmp, a multi-processor project at Carnegie Mellon University in the 1970s, was among the first multiprocessors with more than a few processors. The first bus-connected multiprocessor with snooping caches was the Synapse N+1 in 1984."
    },
    {
        "source": "In April 1958, Stanley Gill (Ferranti) discussed parallel programming and the need for branching and waiting. Also in 1958, IBM researchers John Cocke and Daniel Slotnick discussed the use of parallelism in numerical calculations for the first time. Burroughs Corporation introduced the D825 in 1962, a four-processor computer that accessed up to 16 memory modules through a crossbar switch. In 1967, Amdahl and Slotnick published a debate about the feasibility of parallel processing at American Federation of Information Processing Societies Conference. It was during this debate that Amdahl's law was coined to define the limit of speed-up due to parallelism. In 1969, Honeywell introduced its first Multics system, a symmetric multiprocessor system capable of running up to eight processors in parallel. C.mmp, a multi-processor project at Carnegie Mellon University in the 1970s, was among the first multiprocessors with more than a few processors. The first bus-connected multiprocessor with snooping caches was the Synapse N+1 in 1984.",
        "target": "SIMD parallel computers can be traced back to the 1970s. The motivation behind early SIMD computers was to amortize the gate delay of the processor's control unit over multiple instructions. In 1964, Slotnick had proposed building a massively parallel computer for the Lawrence Livermore National Laboratory. His design was funded by the US Air Force, which was the earliest SIMD parallel-computing effort, ILLIAC IV. The key to its design was a fairly high parallelism, with up to 256processors, which allowed the machine to work on large datasets in what would later be known as vector processing. However, ILLIAC IV was called \"the most infamous of supercomputers\", because the project was only one-fourth completed, but took 11years and cost almost four times the original estimate. When it was finally ready to run its first real application in 1976, it was outperformed by existing commercial supercomputers such as the Cray-1."
    },
    {
        "source": "In 1969, Honeywell introduced its first Multics system, a symmetric multiprocessor system capable of running up to eight processors in parallel. C.mmp, a multi-processor project at Carnegie Mellon University in the 1970s, was among the first multiprocessors with more than a few processors. The first bus-connected multiprocessor with snooping caches was the Synapse N+1 in 1984. SIMD parallel computers can be traced back to the 1970s. The motivation behind early SIMD computers was to amortize the gate delay of the processor's control unit over multiple instructions. In 1964, Slotnick had proposed building a massively parallel computer for the Lawrence Livermore National Laboratory. His design was funded by the US Air Force, which was the earliest SIMD parallel-computing effort, ILLIAC IV. The key to its design was a fairly high parallelism, with up to 256processors, which allowed the machine to work on large datasets in what would later be known as vector processing. However, ILLIAC IV was called \"the most infamous of supercomputers\", because the project was only one-fourth completed, but took 11years and cost almost four times the original estimate. When it was finally ready to run its first real application in 1976, it was outperformed by existing commercial supercomputers such as the Cray-1.",
        "target": "In the early 1970s, at the MIT Computer Science and Artificial Intelligence Laboratory, Marvin Minsky and Seymour Papert started developing the Society of Mind theory, which views the biological brain as massively parallel computer. In 1986, Minsky published The Society of Mind, which claims that \"mind is formed from many little agents, each mindless by itself\". The theory attempts to explain how what we call intelligence could be a product of the interaction of non-intelligent parts. Minsky says that the biggest source of ideas about the theory came from his work in trying to create a machine that uses a robotic arm, a video camera, and a computer to build with children's blocks."
    },
    {
        "source": "SIMD parallel computers can be traced back to the 1970s. The motivation behind early SIMD computers was to amortize the gate delay of the processor's control unit over multiple instructions. In 1964, Slotnick had proposed building a massively parallel computer for the Lawrence Livermore National Laboratory. His design was funded by the US Air Force, which was the earliest SIMD parallel-computing effort, ILLIAC IV. The key to its design was a fairly high parallelism, with up to 256processors, which allowed the machine to work on large datasets in what would later be known as vector processing. However, ILLIAC IV was called \"the most infamous of supercomputers\", because the project was only one-fourth completed, but took 11years and cost almost four times the original estimate. When it was finally ready to run its first real application in 1976, it was outperformed by existing commercial supercomputers such as the Cray-1. In the early 1970s, at the MIT Computer Science and Artificial Intelligence Laboratory, Marvin Minsky and Seymour Papert started developing the Society of Mind theory, which views the biological brain as massively parallel computer. In 1986, Minsky published The Society of Mind, which claims that \"mind is formed from many little agents, each mindless by itself\". The theory attempts to explain how what we call intelligence could be a product of the interaction of non-intelligent parts. Minsky says that the biggest source of ideas about the theory came from his work in trying to create a machine that uses a robotic arm, a video camera, and a computer to build with children's blocks.",
        "target": "Similar models (which also view the biological brain as a massively parallel computer, i.e., the brain is made up of a constellation of independent or semi-independent agents) were also described by:"
    },
    {
        "source": " The Power Mac G4 Cube is a Mac personal computer sold by Apple Computer, Inc. between July 2000 and 2001. The Cube was conceived as a miniaturized but powerful computer by Apple chief executive officer (CEO) Steve Jobs and designed by Jony Ive. Apple developed new technologies and manufacturing methods for the producta 7.7-inch (20cm) cubic computer housed in clear acrylic glass. Apple positioned it in the middle of its product range, between the consumer iMac G3 and the professional Power Mac G4. The Cube was announced at the Macworld Expo on July 19, 2000.",
        "target": "The Cube won awards and plaudits for its design upon release, but reviews noted its high cost compared to its power, its limited expandability, and cosmetic defects. The product was an immediate commercial failure, with only 150,000 units sold before production was suspended within one year of its announcement. The Cube is one of the rare failures for the company under Jobs, after having avoided bankruptcy. However, it influenced future Apple products, from the iPod to the Mac Mini. The Museum of Modern Art and other museums hold Cubes in their collections."
    },
    {
        "source": "The Power Mac G4 Cube is a Mac personal computer sold by Apple Computer, Inc. between July 2000 and 2001. The Cube was conceived as a miniaturized but powerful computer by Apple chief executive officer (CEO) Steve Jobs and designed by Jony Ive. Apple developed new technologies and manufacturing methods for the producta 7.7-inch (20cm) cubic computer housed in clear acrylic glass. Apple positioned it in the middle of its product range, between the consumer iMac G3 and the professional Power Mac G4. The Cube was announced at the Macworld Expo on July 19, 2000. The Cube won awards and plaudits for its design upon release, but reviews noted its high cost compared to its power, its limited expandability, and cosmetic defects. The product was an immediate commercial failure, with only 150,000 units sold before production was suspended within one year of its announcement. The Cube is one of the rare failures for the company under Jobs, after having avoided bankruptcy. However, it influenced future Apple products, from the iPod to the Mac Mini. The Museum of Modern Art and other museums hold Cubes in their collections.",
        "target": "The Power Mac G4 Cube is a small cubic computer, suspended in a 7.77.79.8in (202025cm) acrylic glass enclosure. The transparent plastic is intended to give the impression that the computer is floating. The enclosure houses the computer's vital functions, including a slot-loading optical disc drive. The Cube requires a separate monitor with either an Apple Display Connector (ADC) or a Video Graphics Array (VGA) connection. The machine has no fan to move air and heat through the case. Instead, it is passively cooled, with heat dissipated via a grille at the top of the case. The base model shipped with a 450MHz PowerPC G4 processor, 64MB of random-access memory (RAM), 20GB hard drive, and an ATI Rage 128 Pro video card. A higher-end model with a 500MHz processor, double the RAM, and a 30GB hard drive was sold only through Apple's online store."
    },
    {
        "source": "The Cube won awards and plaudits for its design upon release, but reviews noted its high cost compared to its power, its limited expandability, and cosmetic defects. The product was an immediate commercial failure, with only 150,000 units sold before production was suspended within one year of its announcement. The Cube is one of the rare failures for the company under Jobs, after having avoided bankruptcy. However, it influenced future Apple products, from the iPod to the Mac Mini. The Museum of Modern Art and other museums hold Cubes in their collections. The Power Mac G4 Cube is a small cubic computer, suspended in a 7.77.79.8in (202025cm) acrylic glass enclosure. The transparent plastic is intended to give the impression that the computer is floating. The enclosure houses the computer's vital functions, including a slot-loading optical disc drive. The Cube requires a separate monitor with either an Apple Display Connector (ADC) or a Video Graphics Array (VGA) connection. The machine has no fan to move air and heat through the case. Instead, it is passively cooled, with heat dissipated via a grille at the top of the case. The base model shipped with a 450MHz PowerPC G4 processor, 64MB of random-access memory (RAM), 20GB hard drive, and an ATI Rage 128 Pro video card. A higher-end model with a 500MHz processor, double the RAM, and a 30GB hard drive was sold only through Apple's online store.",
        "target": "The Cube's small size does not feature expansion slots; it has a video card in a standard Accelerated Graphics Port (AGP) slot, but cannot fit a full-length card. The power supply is located externally to save space, and the Cube features no audio jacks. Instead, the Cube shipped with round Harman Kardon speakers and digital amplifier, attached via Universal Serial Bus (USB). Despite its size, the Cube fits three RAM slots, two FireWire 400 ports, and two USB 1.1 ports for connecting peripherals in its frame. These ports and the power cable are located on the underside of the machine. Access to the machine's internal components is accomplished by inverting the unit and using a pop-out handle to slide the entire internal assembly out from the shell."
    },
    {
        "source": "The Power Mac G4 Cube is a small cubic computer, suspended in a 7.77.79.8in (202025cm) acrylic glass enclosure. The transparent plastic is intended to give the impression that the computer is floating. The enclosure houses the computer's vital functions, including a slot-loading optical disc drive. The Cube requires a separate monitor with either an Apple Display Connector (ADC) or a Video Graphics Array (VGA) connection. The machine has no fan to move air and heat through the case. Instead, it is passively cooled, with heat dissipated via a grille at the top of the case. The base model shipped with a 450MHz PowerPC G4 processor, 64MB of random-access memory (RAM), 20GB hard drive, and an ATI Rage 128 Pro video card. A higher-end model with a 500MHz processor, double the RAM, and a 30GB hard drive was sold only through Apple's online store. The Cube's small size does not feature expansion slots; it has a video card in a standard Accelerated Graphics Port (AGP) slot, but cannot fit a full-length card. The power supply is located externally to save space, and the Cube features no audio jacks. Instead, the Cube shipped with round Harman Kardon speakers and digital amplifier, attached via Universal Serial Bus (USB). Despite its size, the Cube fits three RAM slots, two FireWire 400 ports, and two USB 1.1 ports for connecting peripherals in its frame. These ports and the power cable are located on the underside of the machine. Access to the machine's internal components is accomplished by inverting the unit and using a pop-out handle to slide the entire internal assembly out from the shell.",
        "target": "The Cube was an important product to Apple, and especially to Apple CEO Steve Jobs, who said the idea for the product came from his own desires as a computer user for something between the iMac and Power Mac G4, saying, \"I wanted the [flat-panel] Cinema Display but I don't need the features of the Power Mac\". Jobs's minimalist aesthetic influenced the core components of the design, from the lack of a mechanical power button, to the trayless optical drive and quiet fanless operation. The design team at Apple, led by Jonathan Ive, shrunk a powerful desktop form factor, seeing traditional desktop tower computers as lazily designed around what was easiest for engineers. The Cube represented an internal shift in Apple, as the designers held increasing sway over product design. The New York Times called the Cube \"pure [...] industrial design\" harkening to Bauhaus concepts."
    },
    {
        "source": "The Cube's small size does not feature expansion slots; it has a video card in a standard Accelerated Graphics Port (AGP) slot, but cannot fit a full-length card. The power supply is located externally to save space, and the Cube features no audio jacks. Instead, the Cube shipped with round Harman Kardon speakers and digital amplifier, attached via Universal Serial Bus (USB). Despite its size, the Cube fits three RAM slots, two FireWire 400 ports, and two USB 1.1 ports for connecting peripherals in its frame. These ports and the power cable are located on the underside of the machine. Access to the machine's internal components is accomplished by inverting the unit and using a pop-out handle to slide the entire internal assembly out from the shell. The Cube was an important product to Apple, and especially to Apple CEO Steve Jobs, who said the idea for the product came from his own desires as a computer user for something between the iMac and Power Mac G4, saying, \"I wanted the [flat-panel] Cinema Display but I don't need the features of the Power Mac\". Jobs's minimalist aesthetic influenced the core components of the design, from the lack of a mechanical power button, to the trayless optical drive and quiet fanless operation. The design team at Apple, led by Jonathan Ive, shrunk a powerful desktop form factor, seeing traditional desktop tower computers as lazily designed around what was easiest for engineers. The Cube represented an internal shift in Apple, as the designers held increasing sway over product design. The New York Times called the Cube \"pure [...] industrial design\" harkening to Bauhaus concepts.",
        "target": "The Cube represented an effort by Apple to simplify the computer to its barest essentials. Journalist Jason Snell called the machine an example of Jobs and Ive's obsession with a \"Black Box\"dense, miniaturized computers hidden within a pleasing shell hiding the \"magic\" of its technology. As the Cube has no fan, the design started with the heat sink. The power button that turned on with a wave or touch was accomplished via the use of capacitive sensing. The proprietary plastics formula for the housing took Apple six months to develop. Effort spent developing the Cube would pioneer new uses and processes for materials at Apple that benefitted later products. Because of the technology included in the Cube, Apple's engineers had a tough time keeping the total cost low. Advertising director Ken Segall recalled that Jobs learned of the product's price shortly before an ad agency meeting, and was left \"visibly shaken\" by the news, realizing that the high price might cause the product's failure."
    },
    {
        "source": "The Cube was an important product to Apple, and especially to Apple CEO Steve Jobs, who said the idea for the product came from his own desires as a computer user for something between the iMac and Power Mac G4, saying, \"I wanted the [flat-panel] Cinema Display but I don't need the features of the Power Mac\". Jobs's minimalist aesthetic influenced the core components of the design, from the lack of a mechanical power button, to the trayless optical drive and quiet fanless operation. The design team at Apple, led by Jonathan Ive, shrunk a powerful desktop form factor, seeing traditional desktop tower computers as lazily designed around what was easiest for engineers. The Cube represented an internal shift in Apple, as the designers held increasing sway over product design. The New York Times called the Cube \"pure [...] industrial design\" harkening to Bauhaus concepts. The Cube represented an effort by Apple to simplify the computer to its barest essentials. Journalist Jason Snell called the machine an example of Jobs and Ive's obsession with a \"Black Box\"dense, miniaturized computers hidden within a pleasing shell hiding the \"magic\" of its technology. As the Cube has no fan, the design started with the heat sink. The power button that turned on with a wave or touch was accomplished via the use of capacitive sensing. The proprietary plastics formula for the housing took Apple six months to develop. Effort spent developing the Cube would pioneer new uses and processes for materials at Apple that benefitted later products. Because of the technology included in the Cube, Apple's engineers had a tough time keeping the total cost low. Advertising director Ken Segall recalled that Jobs learned of the product's price shortly before an ad agency meeting, and was left \"visibly shaken\" by the news, realizing that the high price might cause the product's failure.",
        "target": "Rumors of a cube-shaped Apple computer leaked weeks in advance, and some sites posted purported pictures. The G4 Cube was announced at Macworld Expo on July 19, 2000, as an end-of-show \"one more thing\". Jobs touted it as combining the power of the Power Mac G4 with a sleek design and miniaturization Apple learned from producing the iMac. Alongside the Cube, Apple introduced a new mouse, keyboard, and displays to complement the machine."
    },
    {
        "source": "The Cube represented an effort by Apple to simplify the computer to its barest essentials. Journalist Jason Snell called the machine an example of Jobs and Ive's obsession with a \"Black Box\"dense, miniaturized computers hidden within a pleasing shell hiding the \"magic\" of its technology. As the Cube has no fan, the design started with the heat sink. The power button that turned on with a wave or touch was accomplished via the use of capacitive sensing. The proprietary plastics formula for the housing took Apple six months to develop. Effort spent developing the Cube would pioneer new uses and processes for materials at Apple that benefitted later products. Because of the technology included in the Cube, Apple's engineers had a tough time keeping the total cost low. Advertising director Ken Segall recalled that Jobs learned of the product's price shortly before an ad agency meeting, and was left \"visibly shaken\" by the news, realizing that the high price might cause the product's failure. Rumors of a cube-shaped Apple computer leaked weeks in advance, and some sites posted purported pictures. The G4 Cube was announced at Macworld Expo on July 19, 2000, as an end-of-show \"one more thing\". Jobs touted it as combining the power of the Power Mac G4 with a sleek design and miniaturization Apple learned from producing the iMac. Alongside the Cube, Apple introduced a new mouse, keyboard, and displays to complement the machine.",
        "target": "The machine's size and looks were immediately divisive, which Macworld editor Andrew Gore took as an indication that Apple had succeeded in creating a cutting-edge product. The design was a point of praise and of jokes, compared to a Borg cube, toasters, or a box of Kleenex tissues. Others compared it to the NeXTcube. Ive and the design team were so amused by the comparison to a tissue box that they used spare Cube shells for that purpose in their studio."
    },
    {
        "source": "Rumors of a cube-shaped Apple computer leaked weeks in advance, and some sites posted purported pictures. The G4 Cube was announced at Macworld Expo on July 19, 2000, as an end-of-show \"one more thing\". Jobs touted it as combining the power of the Power Mac G4 with a sleek design and miniaturization Apple learned from producing the iMac. Alongside the Cube, Apple introduced a new mouse, keyboard, and displays to complement the machine. The machine's size and looks were immediately divisive, which Macworld editor Andrew Gore took as an indication that Apple had succeeded in creating a cutting-edge product. The design was a point of praise and of jokes, compared to a Borg cube, toasters, or a box of Kleenex tissues. Others compared it to the NeXTcube. Ive and the design team were so amused by the comparison to a tissue box that they used spare Cube shells for that purpose in their studio.",
        "target": "Reviews were generally positive. Peter H. Lewis, writing for The New York Times, called the computer the most attractive on the market, and that the machine, combined with Apple's displays and peripherals, created \"desk sculpture\". PC Magazine Australia said that after changing the look of computers with the iMac, the G4 Cube had raised the bar for competitors even further. Gore called the Cube a work of art that felt more like sculpture than a piece of technology, but noted that one had to live with compromises made in the service of art. Walt Mossberg, writing for The Wall Street Journal, called it the \"most gorgeous personal computer\" that he had ever seen."
    },
    {
        "source": "The machine's size and looks were immediately divisive, which Macworld editor Andrew Gore took as an indication that Apple had succeeded in creating a cutting-edge product. The design was a point of praise and of jokes, compared to a Borg cube, toasters, or a box of Kleenex tissues. Others compared it to the NeXTcube. Ive and the design team were so amused by the comparison to a tissue box that they used spare Cube shells for that purpose in their studio. Reviews were generally positive. Peter H. Lewis, writing for The New York Times, called the computer the most attractive on the market, and that the machine, combined with Apple's displays and peripherals, created \"desk sculpture\". PC Magazine Australia said that after changing the look of computers with the iMac, the G4 Cube had raised the bar for competitors even further. Gore called the Cube a work of art that felt more like sculpture than a piece of technology, but noted that one had to live with compromises made in the service of art. Walt Mossberg, writing for The Wall Street Journal, called it the \"most gorgeous personal computer\" that he had ever seen.",
        "target": "Critics noted that to get easy access to plug and unplug peripherals, users must tip the entire machinerisking accidental sleep activation or dropping the smooth plastic computer entirely. Macworld found the touch-sensitive power button too sensitive and they accidentally activated sleep mode regularly. They reported that the stock 5400-rpm hard drive and 64MB of RAM on the base model slowed the system considerably."
    },
    {
        "source": "Reviews were generally positive. Peter H. Lewis, writing for The New York Times, called the computer the most attractive on the market, and that the machine, combined with Apple's displays and peripherals, created \"desk sculpture\". PC Magazine Australia said that after changing the look of computers with the iMac, the G4 Cube had raised the bar for competitors even further. Gore called the Cube a work of art that felt more like sculpture than a piece of technology, but noted that one had to live with compromises made in the service of art. Walt Mossberg, writing for The Wall Street Journal, called it the \"most gorgeous personal computer\" that he had ever seen. Critics noted that to get easy access to plug and unplug peripherals, users must tip the entire machinerisking accidental sleep activation or dropping the smooth plastic computer entirely. Macworld found the touch-sensitive power button too sensitive and they accidentally activated sleep mode regularly. They reported that the stock 5400-rpm hard drive and 64MB of RAM on the base model slowed the system considerably.",
        "target": "The Cube won several international design awards on release, and PC Magazine's best desktop computer for its Technical Innovation Awards. The G4 Cube and its peripherals were acquired and showcased by The Museum of Modern Art alongside other Apple products, and a Cube is also held in the collections of the American Museum of Natural History and Powerhouse Museum."
    },
    {
        "source": "Critics noted that to get easy access to plug and unplug peripherals, users must tip the entire machinerisking accidental sleep activation or dropping the smooth plastic computer entirely. Macworld found the touch-sensitive power button too sensitive and they accidentally activated sleep mode regularly. They reported that the stock 5400-rpm hard drive and 64MB of RAM on the base model slowed the system considerably. The Cube won several international design awards on release, and PC Magazine's best desktop computer for its Technical Innovation Awards. The G4 Cube and its peripherals were acquired and showcased by The Museum of Modern Art alongside other Apple products, and a Cube is also held in the collections of the American Museum of Natural History and Powerhouse Museum.",
        "target": "The introduction of the Cube did not fit with the focused product lineup Jobs had introduced since his return to Apple, leaving it without a clear audience. It was as expensive as a similarly equipped Power Mac, but without extra room for more storage or PCI slots. It was likewise much more expensive than an upgraded consumer iMac. Jobs imagined that creative professionals and designers would want one, and that the product was so great that it would inform buying patterns."
    },
    {
        "source": "The Cube won several international design awards on release, and PC Magazine's best desktop computer for its Technical Innovation Awards. The G4 Cube and its peripherals were acquired and showcased by The Museum of Modern Art alongside other Apple products, and a Cube is also held in the collections of the American Museum of Natural History and Powerhouse Museum. The introduction of the Cube did not fit with the focused product lineup Jobs had introduced since his return to Apple, leaving it without a clear audience. It was as expensive as a similarly equipped Power Mac, but without extra room for more storage or PCI slots. It was likewise much more expensive than an upgraded consumer iMac. Jobs imagined that creative professionals and designers would want one, and that the product was so great that it would inform buying patterns.",
        "target": "Sales for the Cube were much lower than expected. Returning from the brink of bankruptcy, Apple had eleven profitable quarters before the Cube's announcement, but Apple's end-of-year financials for 2000 missed predicted revenues by $180million. Part of the drop in profit was attributed to the Cube, with only one third as many units sold as Apple had expected, creating a $90million shortfall in revenue targets. The Cube counted for 29,000 of the Macs Apple shipped in the quarter, compared to 308,000 iMacs. Retailers had excess product, leaving Apple with a large amount of unsold inventory heading into 2001 it had expected to last until March. The computer appealed to high-end customers who wanted a small and sleek design, but Jobs admitted that audience was smaller than expected. In February 2001, Apple lowered the price on the 500MHz model and added new memory, hard drive, and graphics options. These updates made little difference, and sales continued to decline. In the first quarter of 2001, only 12,000units were sold, representing just 1.6% of the company's total computer sales."
    },
    {
        "source": "The introduction of the Cube did not fit with the focused product lineup Jobs had introduced since his return to Apple, leaving it without a clear audience. It was as expensive as a similarly equipped Power Mac, but without extra room for more storage or PCI slots. It was likewise much more expensive than an upgraded consumer iMac. Jobs imagined that creative professionals and designers would want one, and that the product was so great that it would inform buying patterns. Sales for the Cube were much lower than expected. Returning from the brink of bankruptcy, Apple had eleven profitable quarters before the Cube's announcement, but Apple's end-of-year financials for 2000 missed predicted revenues by $180million. Part of the drop in profit was attributed to the Cube, with only one third as many units sold as Apple had expected, creating a $90million shortfall in revenue targets. The Cube counted for 29,000 of the Macs Apple shipped in the quarter, compared to 308,000 iMacs. Retailers had excess product, leaving Apple with a large amount of unsold inventory heading into 2001 it had expected to last until March. The computer appealed to high-end customers who wanted a small and sleek design, but Jobs admitted that audience was smaller than expected. In February 2001, Apple lowered the price on the 500MHz model and added new memory, hard drive, and graphics options. These updates made little difference, and sales continued to decline. In the first quarter of 2001, only 12,000units were sold, representing just 1.6% of the company's total computer sales.",
        "target": "In addition to the product's high price, the Cube suffered cosmetic issues. Early buyers noticed cracks caused by the injection-molded plastic process. The idea of a design-focused product having aesthetic flaws turned into a negative public relations story for Apple, and dissuaded potential buyers for whom the design was its main appeal. The Cube's radical departure from a conventional personal computer alienated potential buyers, and exacerbated Apple's struggles in the market competing with the performance of Windows PCs. Macworld's Benj Edwards wrote that consumers treated the Cube as \"an underpowered, over-expensive toy or [...] an emotionally inaccessible, ultra-geometric gray box suspended in an untouchable glass prison\". The lack of internal expansion and reliance on less-common USB and FireWire peripherals also hurt the computer's chances of success."
    },
    {
        "source": "Sales for the Cube were much lower than expected. Returning from the brink of bankruptcy, Apple had eleven profitable quarters before the Cube's announcement, but Apple's end-of-year financials for 2000 missed predicted revenues by $180million. Part of the drop in profit was attributed to the Cube, with only one third as many units sold as Apple had expected, creating a $90million shortfall in revenue targets. The Cube counted for 29,000 of the Macs Apple shipped in the quarter, compared to 308,000 iMacs. Retailers had excess product, leaving Apple with a large amount of unsold inventory heading into 2001 it had expected to last until March. The computer appealed to high-end customers who wanted a small and sleek design, but Jobs admitted that audience was smaller than expected. In February 2001, Apple lowered the price on the 500MHz model and added new memory, hard drive, and graphics options. These updates made little difference, and sales continued to decline. In the first quarter of 2001, only 12,000units were sold, representing just 1.6% of the company's total computer sales. In addition to the product's high price, the Cube suffered cosmetic issues. Early buyers noticed cracks caused by the injection-molded plastic process. The idea of a design-focused product having aesthetic flaws turned into a negative public relations story for Apple, and dissuaded potential buyers for whom the design was its main appeal. The Cube's radical departure from a conventional personal computer alienated potential buyers, and exacerbated Apple's struggles in the market competing with the performance of Windows PCs. Macworld's Benj Edwards wrote that consumers treated the Cube as \"an underpowered, over-expensive toy or [...] an emotionally inaccessible, ultra-geometric gray box suspended in an untouchable glass prison\". The lack of internal expansion and reliance on less-common USB and FireWire peripherals also hurt the computer's chances of success.",
        "target": "Jobs clearly loved the computer, but was quick to discontinue the underperforming product. On July 3, 2001, an Apple press release made the unusual statement that the computerrather than being canceled or discontinuedwas having its production \"suspended indefinitely\", due to low demand. Apple did not rule out an upgraded Cube model in the future, but considered it unlikely. Business journalist Karen Blumenthal called the Cube the first big failure by Jobs since his return to Apple. Jobs's ability to quickly move on the mistake left the Cube a \"blip\" in Apple's history, according to Segalla quickly forgotten failure among other successful innovations."
    },
    {
        "source": "In addition to the product's high price, the Cube suffered cosmetic issues. Early buyers noticed cracks caused by the injection-molded plastic process. The idea of a design-focused product having aesthetic flaws turned into a negative public relations story for Apple, and dissuaded potential buyers for whom the design was its main appeal. The Cube's radical departure from a conventional personal computer alienated potential buyers, and exacerbated Apple's struggles in the market competing with the performance of Windows PCs. Macworld's Benj Edwards wrote that consumers treated the Cube as \"an underpowered, over-expensive toy or [...] an emotionally inaccessible, ultra-geometric gray box suspended in an untouchable glass prison\". The lack of internal expansion and reliance on less-common USB and FireWire peripherals also hurt the computer's chances of success. Jobs clearly loved the computer, but was quick to discontinue the underperforming product. On July 3, 2001, an Apple press release made the unusual statement that the computerrather than being canceled or discontinuedwas having its production \"suspended indefinitely\", due to low demand. Apple did not rule out an upgraded Cube model in the future, but considered it unlikely. Business journalist Karen Blumenthal called the Cube the first big failure by Jobs since his return to Apple. Jobs's ability to quickly move on the mistake left the Cube a \"blip\" in Apple's history, according to Segalla quickly forgotten failure among other successful innovations.",
        "target": "Though Apple CEO Tim Cook called the Cube \"a spectacular failure\" and the product sold only 150,000 units before being discontinued, it became highly popular with a small but enthusiastic group of fans. Macworld's Benj Edwards wrote that the Cube was a product ahead of its time; its appeal to a dedicated group of fans years after it was discontinued was a testament to its vision. After its discontinuation the product fetched high prices from resellers, and a cottage industry developed selling upgrades and modifications to make the machine run faster or cooler. John Gruber wrote 20 years after its introduction that the Cube was a \"worthy failure [...] Powerful computers needed to get smaller, quieter, and more attractive. The Cube pushed the state of the art forward.\" CNET called the machine \"an iconic example of millennium-era design\". Its unconventional and futuristic appearance earned it a spot as a prop in several films and television shows, including Absolutely Fabulous, The Drew Carey Show, Orange County, and 24. Sixteen Cubes were also used to power the displays of the computer consoles in Star Trek: Enterprise."
    },
    {
        "source": "Jobs clearly loved the computer, but was quick to discontinue the underperforming product. On July 3, 2001, an Apple press release made the unusual statement that the computerrather than being canceled or discontinuedwas having its production \"suspended indefinitely\", due to low demand. Apple did not rule out an upgraded Cube model in the future, but considered it unlikely. Business journalist Karen Blumenthal called the Cube the first big failure by Jobs since his return to Apple. Jobs's ability to quickly move on the mistake left the Cube a \"blip\" in Apple's history, according to Segalla quickly forgotten failure among other successful innovations. Though Apple CEO Tim Cook called the Cube \"a spectacular failure\" and the product sold only 150,000 units before being discontinued, it became highly popular with a small but enthusiastic group of fans. Macworld's Benj Edwards wrote that the Cube was a product ahead of its time; its appeal to a dedicated group of fans years after it was discontinued was a testament to its vision. After its discontinuation the product fetched high prices from resellers, and a cottage industry developed selling upgrades and modifications to make the machine run faster or cooler. John Gruber wrote 20 years after its introduction that the Cube was a \"worthy failure [...] Powerful computers needed to get smaller, quieter, and more attractive. The Cube pushed the state of the art forward.\" CNET called the machine \"an iconic example of millennium-era design\". Its unconventional and futuristic appearance earned it a spot as a prop in several films and television shows, including Absolutely Fabulous, The Drew Carey Show, Orange County, and 24. Sixteen Cubes were also used to power the displays of the computer consoles in Star Trek: Enterprise.",
        "target": "Although the Cube failed commercially, it influenced future Apple products. The efforts at miniaturizing computer components would benefit future computers like the flatscreen iMac G4, while the efforts Apple spent learning how to precision machine parts of the Cube would be integral to the design of aluminum MacBooks.  The Mac mini fit an entire computer in a shell one-fifth the size of the Cube and retained some of the Cube's design philosophies. In comparison to the high price of the Cube, the Mini retailed for $499 and became a successful product that remains part of Apple's lineup. The translucent cube shape would return with the design for the flagship Apple Fifth Avenue store in New York City. Capacitive touch would reappear in the iPod and iPhone lines, and the Cube's vertical thermal design and lattice grille pattern were echoed by the 2013 and 2019 versions of the Mac Pro."
    },
    {
        "source": " The inaugural World Science Festival was held in New York City from May 28 to June 1, 2008. It consisted mainly of panel discussions and on-stage conversations, accompanied by multimedia presentations. A youth and family program presented topics such as sports from a scientific perspective and included an extensive street fair. A cultural program led by actor and writer Alan Alda focused on art inspired by science. The festival also included a World Science Summit, a meeting of high-level participants from the worlds of science, politics, administration, and business.",
        "target": "The festival was the brainchild of Columbia University physicist Brian Greene and his wife, Emmy Award-winning television journalist Tracy Day. It was held in partnership with major New York City cultural and academic institutions, including Columbia University, New York University and the Metropolitan Museum of Art."
    },
    {
        "source": "The inaugural World Science Festival was held in New York City from May 28 to June 1, 2008. It consisted mainly of panel discussions and on-stage conversations, accompanied by multimedia presentations. A youth and family program presented topics such as sports from a scientific perspective and included an extensive street fair. A cultural program led by actor and writer Alan Alda focused on art inspired by science. The festival also included a World Science Summit, a meeting of high-level participants from the worlds of science, politics, administration, and business. The festival was the brainchild of Columbia University physicist Brian Greene and his wife, Emmy Award-winning television journalist Tracy Day. It was held in partnership with major New York City cultural and academic institutions, including Columbia University, New York University and the Metropolitan Museum of Art.",
        "target": "The World Science Festival was founded by Brian Greene, a Columbia University physics professor and author of several popular-science books (such as The Elegant Universe), and his wife, Emmy Award-winning television journalist Tracy Day. Inspired by a visit to the 2005 Festival della Scienza in Genoa, where Greene had been invited to speak, the two decided that founding a similar festival in New York City would be a unique opportunity to bring science to the wider public. As they envisioned it, such a festival would allow them to combine Greene's skills as a scientist and science communicator with Day's as a journalist and producer: the events were meant to be rooted in science, but also to conform to the production standards of professional TV or theater productions."
    },
    {
        "source": "The festival was the brainchild of Columbia University physicist Brian Greene and his wife, Emmy Award-winning television journalist Tracy Day. It was held in partnership with major New York City cultural and academic institutions, including Columbia University, New York University and the Metropolitan Museum of Art. The World Science Festival was founded by Brian Greene, a Columbia University physics professor and author of several popular-science books (such as The Elegant Universe), and his wife, Emmy Award-winning television journalist Tracy Day. Inspired by a visit to the 2005 Festival della Scienza in Genoa, where Greene had been invited to speak, the two decided that founding a similar festival in New York City would be a unique opportunity to bring science to the wider public. As they envisioned it, such a festival would allow them to combine Greene's skills as a scientist and science communicator with Day's as a journalist and producer: the events were meant to be rooted in science, but also to conform to the production standards of professional TV or theater productions.",
        "target": "Day and Greene sounded out scientists and science communicators about their idea, enlisting many of their contacts as the festival's scientific advisors. They met with the presidents of the city's major universities and its cultural and scientific institutions, forging partnerships for the festival's organization. According to Greene, their idea fell on open ears wherever they went, and the most frequent reaction to their proposal was the expression of disbelief that a festival like this did not already exist in New York City. Early 2006 saw the founding of the Science Festival Foundation (SFF), a non-profit organization based in New York City, dedicated to organizing the festival and related events. Greene serves as the foundation's chairman, and is also on its board of directors. The other members of the board are Alan Alda, Columbia University president Lee Bollinger, the foundation's president Judith Cox, New York University president John Sexton, and Tracy Day, who also serves as the festival's executive director."
    },
    {
        "source": "The World Science Festival was founded by Brian Greene, a Columbia University physics professor and author of several popular-science books (such as The Elegant Universe), and his wife, Emmy Award-winning television journalist Tracy Day. Inspired by a visit to the 2005 Festival della Scienza in Genoa, where Greene had been invited to speak, the two decided that founding a similar festival in New York City would be a unique opportunity to bring science to the wider public. As they envisioned it, such a festival would allow them to combine Greene's skills as a scientist and science communicator with Day's as a journalist and producer: the events were meant to be rooted in science, but also to conform to the production standards of professional TV or theater productions. Day and Greene sounded out scientists and science communicators about their idea, enlisting many of their contacts as the festival's scientific advisors. They met with the presidents of the city's major universities and its cultural and scientific institutions, forging partnerships for the festival's organization. According to Greene, their idea fell on open ears wherever they went, and the most frequent reaction to their proposal was the expression of disbelief that a festival like this did not already exist in New York City. Early 2006 saw the founding of the Science Festival Foundation (SFF), a non-profit organization based in New York City, dedicated to organizing the festival and related events. Greene serves as the foundation's chairman, and is also on its board of directors. The other members of the board are Alan Alda, Columbia University president Lee Bollinger, the foundation's president Judith Cox, New York University president John Sexton, and Tracy Day, who also serves as the festival's executive director.",
        "target": "Next came the assembly of a team of producers who were to organize the festival's events. Notably Kyle Gibson, an Emmy Award-winning former producer of Nightline with Ted Koppel, joined the festival as senior program producer, while production of the Youth and Family Program was put into the hands of Robin Reardon, a former show producer for Walt Disney Imagineering and former vice president of Universal Studios Creative, who also became the festival's managing director. The task of raising the Festival's New York City profile went to Vice President Marketing Ben Austin, who previously worked for the New York City Department of Education doing Public Relations for Caroline Kennedy, but who had a scientific background appropriate to the new Festival."
    },
    {
        "source": "Day and Greene sounded out scientists and science communicators about their idea, enlisting many of their contacts as the festival's scientific advisors. They met with the presidents of the city's major universities and its cultural and scientific institutions, forging partnerships for the festival's organization. According to Greene, their idea fell on open ears wherever they went, and the most frequent reaction to their proposal was the expression of disbelief that a festival like this did not already exist in New York City. Early 2006 saw the founding of the Science Festival Foundation (SFF), a non-profit organization based in New York City, dedicated to organizing the festival and related events. Greene serves as the foundation's chairman, and is also on its board of directors. The other members of the board are Alan Alda, Columbia University president Lee Bollinger, the foundation's president Judith Cox, New York University president John Sexton, and Tracy Day, who also serves as the festival's executive director. Next came the assembly of a team of producers who were to organize the festival's events. Notably Kyle Gibson, an Emmy Award-winning former producer of Nightline with Ted Koppel, joined the festival as senior program producer, while production of the Youth and Family Program was put into the hands of Robin Reardon, a former show producer for Walt Disney Imagineering and former vice president of Universal Studios Creative, who also became the festival's managing director. The task of raising the Festival's New York City profile went to Vice President Marketing Ben Austin, who previously worked for the New York City Department of Education doing Public Relations for Caroline Kennedy, but who had a scientific background appropriate to the new Festival.",
        "target": "The foundation organizes the World Science Festival (WSF) in partnership with Columbia University, New York University, the City University of New York, Rockefeller University and the Cooper Union, as well as cultural institutions such as the Metropolitan Museum of Art, the Guggenheim Museum, and the Museum of Modern Art. Financial support comes from individuals, from numerous foundations, and from corporate sponsors which, for the 2008 festival, included the Sloan Foundation, the Simons Foundation, the Templeton Foundation, the Rockefeller Foundation, the Cullman Foundation, and Credit Suisse."
    },
    {
        "source": "Next came the assembly of a team of producers who were to organize the festival's events. Notably Kyle Gibson, an Emmy Award-winning former producer of Nightline with Ted Koppel, joined the festival as senior program producer, while production of the Youth and Family Program was put into the hands of Robin Reardon, a former show producer for Walt Disney Imagineering and former vice president of Universal Studios Creative, who also became the festival's managing director. The task of raising the Festival's New York City profile went to Vice President Marketing Ben Austin, who previously worked for the New York City Department of Education doing Public Relations for Caroline Kennedy, but who had a scientific background appropriate to the new Festival. The foundation organizes the World Science Festival (WSF) in partnership with Columbia University, New York University, the City University of New York, Rockefeller University and the Cooper Union, as well as cultural institutions such as the Metropolitan Museum of Art, the Guggenheim Museum, and the Museum of Modern Art. Financial support comes from individuals, from numerous foundations, and from corporate sponsors which, for the 2008 festival, included the Sloan Foundation, the Simons Foundation, the Templeton Foundation, the Rockefeller Foundation, the Cullman Foundation, and Credit Suisse.",
        "target": "The inaugural World Science Festival took place from May 28 to June 1, 2008, at 22venues throughout New York City. It included 46events, a street fair and, on its first day, the one-day World Science Summit at Columbia University. The Festival was attended by 120,000people. It featured several different kinds of presentations: science events for a general audience, a cultural program focusing on art inspired by science, and a youth and family program. Since then, it has been held annually in New York. In 2016, WSF launched its Brisbane edition, which is held annually as well."
    },
    {
        "source": "The foundation organizes the World Science Festival (WSF) in partnership with Columbia University, New York University, the City University of New York, Rockefeller University and the Cooper Union, as well as cultural institutions such as the Metropolitan Museum of Art, the Guggenheim Museum, and the Museum of Modern Art. Financial support comes from individuals, from numerous foundations, and from corporate sponsors which, for the 2008 festival, included the Sloan Foundation, the Simons Foundation, the Templeton Foundation, the Rockefeller Foundation, the Cullman Foundation, and Credit Suisse. The inaugural World Science Festival took place from May 28 to June 1, 2008, at 22venues throughout New York City. It included 46events, a street fair and, on its first day, the one-day World Science Summit at Columbia University. The Festival was attended by 120,000people. It featured several different kinds of presentations: science events for a general audience, a cultural program focusing on art inspired by science, and a youth and family program. Since then, it has been held annually in New York. In 2016, WSF launched its Brisbane edition, which is held annually as well.",
        "target": "Preceding the public events was the invitation-only World Science Summit on May 28, 2008; New York City Mayor Michael Bloomberg opened the Festival. At the summit, an invited audience interacted with eminent scientists in several panel discussions. Participants included Nina Fedoroff (Science and Technology Advisor to U. S. Secretary of State, Condoleezza Rice), biologist David Baltimore and cancer researcher Harold Varmus."
    },
    {
        "source": "The inaugural World Science Festival took place from May 28 to June 1, 2008, at 22venues throughout New York City. It included 46events, a street fair and, on its first day, the one-day World Science Summit at Columbia University. The Festival was attended by 120,000people. It featured several different kinds of presentations: science events for a general audience, a cultural program focusing on art inspired by science, and a youth and family program. Since then, it has been held annually in New York. In 2016, WSF launched its Brisbane edition, which is held annually as well. Preceding the public events was the invitation-only World Science Summit on May 28, 2008; New York City Mayor Michael Bloomberg opened the Festival. At the summit, an invited audience interacted with eminent scientists in several panel discussions. Participants included Nina Fedoroff (Science and Technology Advisor to U. S. Secretary of State, Condoleezza Rice), biologist David Baltimore and cancer researcher Harold Varmus.",
        "target": "As part of the summit, the winners of the first Kavli Prizes were announced in a simulcast linking New York City and Oslo. The first Kavli Prize for astrophysics was awarded to Maarten Schmidt and Donald Lynden-Bell for their pioneering work on quasars. Louis E. Brus and Sumio Iijima shared the nanoscience prize for their contributions to the science of quantum dots and carbon nanotubes, respectively. Pasko Rakic, Thomas Jessell and Sten Grillner were awarded the neuroscience prize for their research into how neuronal networks develop and communicate."
    },
    {
        "source": "Preceding the public events was the invitation-only World Science Summit on May 28, 2008; New York City Mayor Michael Bloomberg opened the Festival. At the summit, an invited audience interacted with eminent scientists in several panel discussions. Participants included Nina Fedoroff (Science and Technology Advisor to U. S. Secretary of State, Condoleezza Rice), biologist David Baltimore and cancer researcher Harold Varmus. As part of the summit, the winners of the first Kavli Prizes were announced in a simulcast linking New York City and Oslo. The first Kavli Prize for astrophysics was awarded to Maarten Schmidt and Donald Lynden-Bell for their pioneering work on quasars. Louis E. Brus and Sumio Iijima shared the nanoscience prize for their contributions to the science of quantum dots and carbon nanotubes, respectively. Pasko Rakic, Thomas Jessell and Sten Grillner were awarded the neuroscience prize for their research into how neuronal networks develop and communicate.",
        "target": "Events covered a wide variety of scientific topics, and combined talks, demonstrations, video presentations and panel discussions. A number of events addressed \"big questions\". For example, a roster of scientists including physicist William Phillips, philosopher Patricia Churchland, neuroscientist Antonio Damasio, philosopher Daniel Dennett, cognitive scientist Marvin Minsky, and cancer researcher Harold Varmus, debated \"What It Means to Be Human\" in a panel discussion moderated by Charlie Rose. A recurring theme was the wider implications of scientific results, as exemplified by a discussion on the promises and consequences of personal genomics involving biochemist Paul Nurse, sociologist Nikolas Rose, and human genome project leader Francis Collins. A number of events explored the interface between science and the arts; for instance, a panel including psychologist Nancy C. Andreasen, choreographer and dancer Bill T. Jones, and actor and writer Michael York focused on the scientific study of creativity. Other audiences saw physicists Lawrence Krauss and radio host Ira Flatow presenting modern cosmology, paleontologist Richard Leakey exploring the sixth extinction, soundscape ecologist Bernie Krause reflecting on the loss of biophony, and chemist F. Sherwood Rowland and Rensselaer Polytechnic president Shirley Ann Jackson discussing new ways of satisfying humanity's energy needs. A number of events were co-productions with the festival's partners, such as a discussion between Robert Krulwich and neurologist and author Oliver Sacks on perception, held at the Metropolitan Museum of Art, and musician Mark Oliver Everett's exploration of the scientific legacy of his father, Hugh Everett, at the Museum of Modern Art."
    },
    {
        "source": "As part of the summit, the winners of the first Kavli Prizes were announced in a simulcast linking New York City and Oslo. The first Kavli Prize for astrophysics was awarded to Maarten Schmidt and Donald Lynden-Bell for their pioneering work on quasars. Louis E. Brus and Sumio Iijima shared the nanoscience prize for their contributions to the science of quantum dots and carbon nanotubes, respectively. Pasko Rakic, Thomas Jessell and Sten Grillner were awarded the neuroscience prize for their research into how neuronal networks develop and communicate. Events covered a wide variety of scientific topics, and combined talks, demonstrations, video presentations and panel discussions. A number of events addressed \"big questions\". For example, a roster of scientists including physicist William Phillips, philosopher Patricia Churchland, neuroscientist Antonio Damasio, philosopher Daniel Dennett, cognitive scientist Marvin Minsky, and cancer researcher Harold Varmus, debated \"What It Means to Be Human\" in a panel discussion moderated by Charlie Rose. A recurring theme was the wider implications of scientific results, as exemplified by a discussion on the promises and consequences of personal genomics involving biochemist Paul Nurse, sociologist Nikolas Rose, and human genome project leader Francis Collins. A number of events explored the interface between science and the arts; for instance, a panel including psychologist Nancy C. Andreasen, choreographer and dancer Bill T. Jones, and actor and writer Michael York focused on the scientific study of creativity. Other audiences saw physicists Lawrence Krauss and radio host Ira Flatow presenting modern cosmology, paleontologist Richard Leakey exploring the sixth extinction, soundscape ecologist Bernie Krause reflecting on the loss of biophony, and chemist F. Sherwood Rowland and Rensselaer Polytechnic president Shirley Ann Jackson discussing new ways of satisfying humanity's energy needs. A number of events were co-productions with the festival's partners, such as a discussion between Robert Krulwich and neurologist and author Oliver Sacks on perception, held at the Metropolitan Museum of Art, and musician Mark Oliver Everett's exploration of the scientific legacy of his father, Hugh Everett, at the Museum of Modern Art.",
        "target": "The festival's cultural program ranged from a string theory-themed dance performance choreographed by Karole Armitage to a storytelling event in cooperation with The Moth, which featured journalist and writer Lucy Hawking, physicist Jim Gates and writer Sam Shepard, among others. Alan Alda revisited his role as Richard Feynman in Peter Parnell's play QED in a staged reading at Columbia University's Miller Theatre, and the choir of the Abyssinian Baptist Church joined Oliver Sacks in an exploration of music and science. The festival also saw the premire of Dear Albert, a reading for the stage written by Alda based on the letters of Albert Einstein, and starring Anthony LaPaglia as Einstein."
    },
    {
        "source": "Events covered a wide variety of scientific topics, and combined talks, demonstrations, video presentations and panel discussions. A number of events addressed \"big questions\". For example, a roster of scientists including physicist William Phillips, philosopher Patricia Churchland, neuroscientist Antonio Damasio, philosopher Daniel Dennett, cognitive scientist Marvin Minsky, and cancer researcher Harold Varmus, debated \"What It Means to Be Human\" in a panel discussion moderated by Charlie Rose. A recurring theme was the wider implications of scientific results, as exemplified by a discussion on the promises and consequences of personal genomics involving biochemist Paul Nurse, sociologist Nikolas Rose, and human genome project leader Francis Collins. A number of events explored the interface between science and the arts; for instance, a panel including psychologist Nancy C. Andreasen, choreographer and dancer Bill T. Jones, and actor and writer Michael York focused on the scientific study of creativity. Other audiences saw physicists Lawrence Krauss and radio host Ira Flatow presenting modern cosmology, paleontologist Richard Leakey exploring the sixth extinction, soundscape ecologist Bernie Krause reflecting on the loss of biophony, and chemist F. Sherwood Rowland and Rensselaer Polytechnic president Shirley Ann Jackson discussing new ways of satisfying humanity's energy needs. A number of events were co-productions with the festival's partners, such as a discussion between Robert Krulwich and neurologist and author Oliver Sacks on perception, held at the Metropolitan Museum of Art, and musician Mark Oliver Everett's exploration of the scientific legacy of his father, Hugh Everett, at the Museum of Modern Art. The festival's cultural program ranged from a string theory-themed dance performance choreographed by Karole Armitage to a storytelling event in cooperation with The Moth, which featured journalist and writer Lucy Hawking, physicist Jim Gates and writer Sam Shepard, among others. Alan Alda revisited his role as Richard Feynman in Peter Parnell's play QED in a staged reading at Columbia University's Miller Theatre, and the choir of the Abyssinian Baptist Church joined Oliver Sacks in an exploration of music and science. The festival also saw the premire of Dear Albert, a reading for the stage written by Alda based on the letters of Albert Einstein, and starring Anthony LaPaglia as Einstein.",
        "target": "Events for a younger audience included an examination of the science of sports (with sports scientist Tom Crawford, neuroscientist David Eagleman, and athletes such as Brevin Knight, Lisa Willis and Leilani Mitchell). For the festival's first event, New York City high-school students interviewed robotics expert Cynthia Breazeal and physicist Leon Lederman on-stage, moderated by MTV's SuChin Pak. Another event was presented by the Disney Imagineers, who explored the science of special effects and amusement park technology, from roller coasters and fireworks to motion capture and artificial fog."
    },
    {
        "source": "The festival's cultural program ranged from a string theory-themed dance performance choreographed by Karole Armitage to a storytelling event in cooperation with The Moth, which featured journalist and writer Lucy Hawking, physicist Jim Gates and writer Sam Shepard, among others. Alan Alda revisited his role as Richard Feynman in Peter Parnell's play QED in a staged reading at Columbia University's Miller Theatre, and the choir of the Abyssinian Baptist Church joined Oliver Sacks in an exploration of music and science. The festival also saw the premire of Dear Albert, a reading for the stage written by Alda based on the letters of Albert Einstein, and starring Anthony LaPaglia as Einstein. Events for a younger audience included an examination of the science of sports (with sports scientist Tom Crawford, neuroscientist David Eagleman, and athletes such as Brevin Knight, Lisa Willis and Leilani Mitchell). For the festival's first event, New York City high-school students interviewed robotics expert Cynthia Breazeal and physicist Leon Lederman on-stage, moderated by MTV's SuChin Pak. Another event was presented by the Disney Imagineers, who explored the science of special effects and amusement park technology, from roller coasters and fireworks to motion capture and artificial fog.",
        "target": "The WSF Street Fair took place in and around Washington Square Park, on the New York University campus, on Saturday, May 30, 2008. Although it was interrupted by a thunderstorm, the street fair was attended by 100,000 people, according to estimates from the New York Police Department."
    },
    {
        "source": "Events for a younger audience included an examination of the science of sports (with sports scientist Tom Crawford, neuroscientist David Eagleman, and athletes such as Brevin Knight, Lisa Willis and Leilani Mitchell). For the festival's first event, New York City high-school students interviewed robotics expert Cynthia Breazeal and physicist Leon Lederman on-stage, moderated by MTV's SuChin Pak. Another event was presented by the Disney Imagineers, who explored the science of special effects and amusement park technology, from roller coasters and fireworks to motion capture and artificial fog. The WSF Street Fair took place in and around Washington Square Park, on the New York University campus, on Saturday, May 30, 2008. Although it was interrupted by a thunderstorm, the street fair was attended by 100,000 people, according to estimates from the New York Police Department.",
        "target": "Stage events at the street fair included live performances by the \"Mathemagician\" Arthur T. Benjamin, \"science rapper\" Zach Powers of PCR RAP fame,[bettersourceneeded] and a band called \"The Mathematicians\", science demonstrations by teams from institutions such as the Liberty Science Center and the Franklin Institute, and presentations by journalist and author Lucy Hawking and visual artist Scott Draves, among others. The street fair featured appearances by Disney's animatronic dinosaur Lucky, by characters from science- and education-related TV shows such as Cyberchase, It's a Big Big World, Clifford the Big Red Dog and Zula Patrol, as well as demonstrations by teams participating in the New YorkNew Jersey FIRST Robotics Competition, and hands-on activities such as owl pellet dissections and miniature rocket launches. Also present were a movable museum from the American Museum of Natural History and the Magic School Bus."
    },
    {
        "source": "The WSF Street Fair took place in and around Washington Square Park, on the New York University campus, on Saturday, May 30, 2008. Although it was interrupted by a thunderstorm, the street fair was attended by 100,000 people, according to estimates from the New York Police Department. Stage events at the street fair included live performances by the \"Mathemagician\" Arthur T. Benjamin, \"science rapper\" Zach Powers of PCR RAP fame,[bettersourceneeded] and a band called \"The Mathematicians\", science demonstrations by teams from institutions such as the Liberty Science Center and the Franklin Institute, and presentations by journalist and author Lucy Hawking and visual artist Scott Draves, among others. The street fair featured appearances by Disney's animatronic dinosaur Lucky, by characters from science- and education-related TV shows such as Cyberchase, It's a Big Big World, Clifford the Big Red Dog and Zula Patrol, as well as demonstrations by teams participating in the New YorkNew Jersey FIRST Robotics Competition, and hands-on activities such as owl pellet dissections and miniature rocket launches. Also present were a movable museum from the American Museum of Natural History and the Magic School Bus.",
        "target": "Festival coverage leading up to the 2008 festival, which included articles in major newspapers and appearances by Alda and Greene on national shows such as Regis and Kelly and The Colbert Report, mostly focused on introducing the festival's concept, organizers and events, and on the promise of bringing an event of this type to New York. Aside from mention of small organizational glitches, coverage of festival events was generally positive. Both Good Morning America and Science News focused on the potential of the festival to inspire the next generation of scientists and \"make geek chic\". The New York Post described the festival's role in New York's cultural landscape as the geek counterpart of Fashion Week and the Tony Awards, while the Science Channel's coverage characterized the festival as \"wonderfully inspiring and informative\".\nThe New York Times noted that Greene and Day appeared to have succeeded in creating \"a new cultural institution\"; further Times articles declared the festival a critical and a box office success."
    },
    {
        "source": "Stage events at the street fair included live performances by the \"Mathemagician\" Arthur T. Benjamin, \"science rapper\" Zach Powers of PCR RAP fame,[bettersourceneeded] and a band called \"The Mathematicians\", science demonstrations by teams from institutions such as the Liberty Science Center and the Franklin Institute, and presentations by journalist and author Lucy Hawking and visual artist Scott Draves, among others. The street fair featured appearances by Disney's animatronic dinosaur Lucky, by characters from science- and education-related TV shows such as Cyberchase, It's a Big Big World, Clifford the Big Red Dog and Zula Patrol, as well as demonstrations by teams participating in the New YorkNew Jersey FIRST Robotics Competition, and hands-on activities such as owl pellet dissections and miniature rocket launches. Also present were a movable museum from the American Museum of Natural History and the Magic School Bus. Festival coverage leading up to the 2008 festival, which included articles in major newspapers and appearances by Alda and Greene on national shows such as Regis and Kelly and The Colbert Report, mostly focused on introducing the festival's concept, organizers and events, and on the promise of bringing an event of this type to New York. Aside from mention of small organizational glitches, coverage of festival events was generally positive. Both Good Morning America and Science News focused on the potential of the festival to inspire the next generation of scientists and \"make geek chic\". The New York Post described the festival's role in New York's cultural landscape as the geek counterpart of Fashion Week and the Tony Awards, while the Science Channel's coverage characterized the festival as \"wonderfully inspiring and informative\".\nThe New York Times noted that Greene and Day appeared to have succeeded in creating \"a new cultural institution\"; further Times articles declared the festival a critical and a box office success.",
        "target": "Online coverage typically focused on specific festival events. Notably, Science, Wired, The Science Channel and USA Today provided same-day or next-day accounts of events including \"What It Means to Be Human\", \"Ramachandran/Kurzweil: Humanity Now/Humanity Next\", \"Future Cities\", as well as the two events featuring Oliver Sacks."
    },
    {
        "source": "A gas explosion caused by a large gas leak occurred in a residential area of Rosario, the third-largest city in Argentina, on August 6, 2013. A nearby building collapsed, and others were at high risk of structural failure. Twenty-two people died, and sixty were injured. Several organizations helped secure the area, search for survivors and aid people who lost their homes. Shortly after the explosion, the time needed for reconstruction was estimated at six months. The provincial judiciary launched an investigation into the cause of the explosion. Primary suspects were Litoral Gas (the natural-gas provider for Rosario) and an employee who carried out maintenance work at the building that day. Several public figures sent condolences, and most of the candidates for the 2013 primary elections suspended their political campaigns.",
        "target": "The explosion occurred at 9:30a.m. near the intersection of Oroo and Salta Streets in central Rosario. Initial reports confirmed eight people dead, sixty injured and fifteen missing; eight more deaths were later confirmed. Searches the following day revealed twelve fatalities, ten of whom were identified. Of the people who were missing, some were found dead among the debris, while others were rescued. The search for survivors ended on August 13, with twenty-two people confirmed dead. A 65-year-old woman who had been injured died on October 8."
    },
    {
        "source": "The provincial judiciary launched an investigation into the cause of the explosion. Primary suspects were Litoral Gas (the natural-gas provider for Rosario) and an employee who carried out maintenance work at the building that day. Several public figures sent condolences, and most of the candidates for the 2013 primary elections suspended their political campaigns. The explosion occurred at 9:30a.m. near the intersection of Oroo and Salta Streets in central Rosario. Initial reports confirmed eight people dead, sixty injured and fifteen missing; eight more deaths were later confirmed. Searches the following day revealed twelve fatalities, ten of whom were identified. Of the people who were missing, some were found dead among the debris, while others were rescued. The search for survivors ended on August 13, with twenty-two people confirmed dead. A 65-year-old woman who had been injured died on October 8.",
        "target": "The explosion was caused by a gas leak in a 30-year-old building. It severely damaged a nearby nine-story apartment building, causing it to collapse. Mnica Fein, mayor of Rosario, asked residents to avoid the area because of the risk that more buildings might collapse, and to ease the work of disaster management personnel. The streets were covered with broken glass from damaged buildings. Gas and electricity were immediately disconnected, and the national government sent an Argentine Federal Police task force to the scene."
    },
    {
        "source": "The explosion occurred at 9:30a.m. near the intersection of Oroo and Salta Streets in central Rosario. Initial reports confirmed eight people dead, sixty injured and fifteen missing; eight more deaths were later confirmed. Searches the following day revealed twelve fatalities, ten of whom were identified. Of the people who were missing, some were found dead among the debris, while others were rescued. The search for survivors ended on August 13, with twenty-two people confirmed dead. A 65-year-old woman who had been injured died on October 8. The explosion was caused by a gas leak in a 30-year-old building. It severely damaged a nearby nine-story apartment building, causing it to collapse. Mnica Fein, mayor of Rosario, asked residents to avoid the area because of the risk that more buildings might collapse, and to ease the work of disaster management personnel. The streets were covered with broken glass from damaged buildings. Gas and electricity were immediately disconnected, and the national government sent an Argentine Federal Police task force to the scene.",
        "target": "The natural gas supplier, Litoral Gas, immediately began sealing the distribution pipe to the area. The Center for Ambulatory Medical Specialties of Rosario (Spanish: Centro de Especialidades Medicas Ambulatorias de Rosario) managed the information about the dead and injured, and tents were prepared for those left homeless. Firefighters and other workers found people trapped on the upper floors of buildings and evacuated them over adjacent roofs. Although the building was not destroyed by the explosion, a high risk of structural failure remained."
    },
    {
        "source": "The explosion was caused by a gas leak in a 30-year-old building. It severely damaged a nearby nine-story apartment building, causing it to collapse. Mnica Fein, mayor of Rosario, asked residents to avoid the area because of the risk that more buildings might collapse, and to ease the work of disaster management personnel. The streets were covered with broken glass from damaged buildings. Gas and electricity were immediately disconnected, and the national government sent an Argentine Federal Police task force to the scene. The natural gas supplier, Litoral Gas, immediately began sealing the distribution pipe to the area. The Center for Ambulatory Medical Specialties of Rosario (Spanish: Centro de Especialidades Medicas Ambulatorias de Rosario) managed the information about the dead and injured, and tents were prepared for those left homeless. Firefighters and other workers found people trapped on the upper floors of buildings and evacuated them over adjacent roofs. Although the building was not destroyed by the explosion, a high risk of structural failure remained.",
        "target": "Neighbors reported to the press that they had smelled a gas leak several hours before the explosion and had called Litoral Gas. Company director Jose Mara Gonzlez said that the company had received no such calls, and thought that callers might have dialed the 911 emergency number instead. Prosecutor Camporini reported at the trial that the building had experienced several gas leaks before the explosion."
    },
    {
        "source": "The natural gas supplier, Litoral Gas, immediately began sealing the distribution pipe to the area. The Center for Ambulatory Medical Specialties of Rosario (Spanish: Centro de Especialidades Medicas Ambulatorias de Rosario) managed the information about the dead and injured, and tents were prepared for those left homeless. Firefighters and other workers found people trapped on the upper floors of buildings and evacuated them over adjacent roofs. Although the building was not destroyed by the explosion, a high risk of structural failure remained. Neighbors reported to the press that they had smelled a gas leak several hours before the explosion and had called Litoral Gas. Company director Jose Mara Gonzlez said that the company had received no such calls, and thought that callers might have dialed the 911 emergency number instead. Prosecutor Camporini reported at the trial that the building had experienced several gas leaks before the explosion.",
        "target": "The provincial judiciary launched an investigation into the circumstances surrounding the explosion. The prosecution conducted a search and seizure at the offices of Litoral Gas to confirm the absence of customer complaints about the gas leak. Judge Juan Carlos Curto ordered the arrest of Carlos Osvaldo Garca, an employee of the department responsible for gas service to the area. He was captured during the night, and his assistant Pablo Mio surrendered to police the following day. According to witnesses, one employee fled in a van before the explosion, when he realized the severity of the gas leak, while another remained to try to evacuate people from the endangered area. The van belonged to Garca, who experienced an acute stress reaction during the trial. Curto checked the remnants of the gas employee's workshop to verify Garca's testimony."
    },
    {
        "source": "Neighbors reported to the press that they had smelled a gas leak several hours before the explosion and had called Litoral Gas. Company director Jose Mara Gonzlez said that the company had received no such calls, and thought that callers might have dialed the 911 emergency number instead. Prosecutor Camporini reported at the trial that the building had experienced several gas leaks before the explosion. The provincial judiciary launched an investigation into the circumstances surrounding the explosion. The prosecution conducted a search and seizure at the offices of Litoral Gas to confirm the absence of customer complaints about the gas leak. Judge Juan Carlos Curto ordered the arrest of Carlos Osvaldo Garca, an employee of the department responsible for gas service to the area. He was captured during the night, and his assistant Pablo Mio surrendered to police the following day. According to witnesses, one employee fled in a van before the explosion, when he realized the severity of the gas leak, while another remained to try to evacuate people from the endangered area. The van belonged to Garca, who experienced an acute stress reaction during the trial. Curto checked the remnants of the gas employee's workshop to verify Garca's testimony.",
        "target": "Prosecutor Graciela Argelles said that, according to the investigation, Litoral Gas ignored calls for help from Garca, who was not properly trained to manage such a situation. The judge suggested that documents seized from Litoral Gas might prove the existence of customer reports of a gas leak. Curto thought that the employees might not bear sole responsibility, and that the liability of Litoral Gas had to be investigated as well."
    },
    {
        "source": "The provincial judiciary launched an investigation into the circumstances surrounding the explosion. The prosecution conducted a search and seizure at the offices of Litoral Gas to confirm the absence of customer complaints about the gas leak. Judge Juan Carlos Curto ordered the arrest of Carlos Osvaldo Garca, an employee of the department responsible for gas service to the area. He was captured during the night, and his assistant Pablo Mio surrendered to police the following day. According to witnesses, one employee fled in a van before the explosion, when he realized the severity of the gas leak, while another remained to try to evacuate people from the endangered area. The van belonged to Garca, who experienced an acute stress reaction during the trial. Curto checked the remnants of the gas employee's workshop to verify Garca's testimony. Prosecutor Graciela Argelles said that, according to the investigation, Litoral Gas ignored calls for help from Garca, who was not properly trained to manage such a situation. The judge suggested that documents seized from Litoral Gas might prove the existence of customer reports of a gas leak. Curto thought that the employees might not bear sole responsibility, and that the liability of Litoral Gas had to be investigated as well.",
        "target": "Pablo Mio was released from prison, but Curto refused to release Garca, saying that Mio had extenuating circumstances which Garca did not. Mio's job was to give Garca the required tools, not to do the maintenance. He was in the street, watching over the van, which was not properly parked and locked, and did not see Garca's work before the explosion. Curto stopped short of pronouncing Mio innocent at that early stage."
    },
    {
        "source": "Prosecutor Graciela Argelles said that, according to the investigation, Litoral Gas ignored calls for help from Garca, who was not properly trained to manage such a situation. The judge suggested that documents seized from Litoral Gas might prove the existence of customer reports of a gas leak. Curto thought that the employees might not bear sole responsibility, and that the liability of Litoral Gas had to be investigated as well. Pablo Mio was released from prison, but Curto refused to release Garca, saying that Mio had extenuating circumstances which Garca did not. Mio's job was to give Garca the required tools, not to do the maintenance. He was in the street, watching over the van, which was not properly parked and locked, and did not see Garca's work before the explosion. Curto stopped short of pronouncing Mio innocent at that early stage.",
        "target": "As the case expanded beyond his jurisdiction, Curto recused himself from the trial and was replaced by Javier Beltramone, who released Garca from prison. Litoral Gas demanded Beltramone's recusal for expressing an opinion about the case to the press. The appeal court agreed in a 21 vote to remove Beltramone, and the case was transferred to Patricia Bilotta. Garca had claimed that he was following instructions received in the days before the explosion, so Bilotta summoned the technical officers of Litoral Gas to clarify that point. Litoral Gas said that Garca had not received any instructions prior to the explosion."
    },
    {
        "source": "Pablo Mio was released from prison, but Curto refused to release Garca, saying that Mio had extenuating circumstances which Garca did not. Mio's job was to give Garca the required tools, not to do the maintenance. He was in the street, watching over the van, which was not properly parked and locked, and did not see Garca's work before the explosion. Curto stopped short of pronouncing Mio innocent at that early stage. As the case expanded beyond his jurisdiction, Curto recused himself from the trial and was replaced by Javier Beltramone, who released Garca from prison. Litoral Gas demanded Beltramone's recusal for expressing an opinion about the case to the press. The appeal court agreed in a 21 vote to remove Beltramone, and the case was transferred to Patricia Bilotta. Garca had claimed that he was following instructions received in the days before the explosion, so Bilotta summoned the technical officers of Litoral Gas to clarify that point. Litoral Gas said that Garca had not received any instructions prior to the explosion.",
        "target": "Litoral Gas proposed an out-of-court settlement to the relatives of the victims, offering about 1200 US dollars per square meter of collapsed building, in addition to compensation for loss of life. Vice Governor Jorge Henn[es] rejected it as immoral, and most of the families also initially rejected the proposal. By May 2014, however, almost half of the families had accepted the settlement."
    },
    {
        "source": "As the case expanded beyond his jurisdiction, Curto recused himself from the trial and was replaced by Javier Beltramone, who released Garca from prison. Litoral Gas demanded Beltramone's recusal for expressing an opinion about the case to the press. The appeal court agreed in a 21 vote to remove Beltramone, and the case was transferred to Patricia Bilotta. Garca had claimed that he was following instructions received in the days before the explosion, so Bilotta summoned the technical officers of Litoral Gas to clarify that point. Litoral Gas said that Garca had not received any instructions prior to the explosion. Litoral Gas proposed an out-of-court settlement to the relatives of the victims, offering about 1200 US dollars per square meter of collapsed building, in addition to compensation for loss of life. Vice Governor Jorge Henn[es] rejected it as immoral, and most of the families also initially rejected the proposal. By May 2014, however, almost half of the families had accepted the settlement.",
        "target": "The explosion occurred shortly before the primary 2013 Argentine legislative elections on August 11. The governor of Santa Fe province, Antonio Bonfatti, asked the political parties to end their campaigns to allow mourning for the victims of the explosion. The Front for Victory and Progressive, Civic and Social Front candidates suspended their campaigns, and the national government declared two days of mourning. The period of mourning was observed by all candidates in Buenos Aires and most other provinces, who ended their political campaigns."
    },
    {
        "source": "Litoral Gas proposed an out-of-court settlement to the relatives of the victims, offering about 1200 US dollars per square meter of collapsed building, in addition to compensation for loss of life. Vice Governor Jorge Henn[es] rejected it as immoral, and most of the families also initially rejected the proposal. By May 2014, however, almost half of the families had accepted the settlement. The explosion occurred shortly before the primary 2013 Argentine legislative elections on August 11. The governor of Santa Fe province, Antonio Bonfatti, asked the political parties to end their campaigns to allow mourning for the victims of the explosion. The Front for Victory and Progressive, Civic and Social Front candidates suspended their campaigns, and the national government declared two days of mourning. The period of mourning was observed by all candidates in Buenos Aires and most other provinces, who ended their political campaigns.",
        "target": "President Cristina Fernndez de Kirchner, who had recently returned from a diplomatic visit to the United Nations, visited the site of the explosion on August 7. She was berated by local residents; some were angry because her surprise visit halted work at the site, and others thought her presence was politically motivated. The president stayed briefly, visited the CEMAR and met Bonfatti. Kirchner's entourage was surrounded by members of La Cmpora, who tried to prevent demonstrations against her and keep journalists and residents at bay."
    },
    {
        "source": "The explosion occurred shortly before the primary 2013 Argentine legislative elections on August 11. The governor of Santa Fe province, Antonio Bonfatti, asked the political parties to end their campaigns to allow mourning for the victims of the explosion. The Front for Victory and Progressive, Civic and Social Front candidates suspended their campaigns, and the national government declared two days of mourning. The period of mourning was observed by all candidates in Buenos Aires and most other provinces, who ended their political campaigns. President Cristina Fernndez de Kirchner, who had recently returned from a diplomatic visit to the United Nations, visited the site of the explosion on August 7. She was berated by local residents; some were angry because her surprise visit halted work at the site, and others thought her presence was politically motivated. The president stayed briefly, visited the CEMAR and met Bonfatti. Kirchner's entourage was surrounded by members of La Cmpora, who tried to prevent demonstrations against her and keep journalists and residents at bay.",
        "target": "Weeks before the explosion, several social networking sites had scheduled a country-wide cacerolazo (a pot-banging protest demonstration), known as 8A, against Kirchner for August 8. The websites had already conducted successful cacerolazos (8N and 18A). Despite the national mourning, the 8A protest went ahead as planned, with the added slogan \"No more pointless deaths\". Candidate Ricardo Gil Lavedra thought the cacerolazo should have been canceled, as the campaigning was, but fellow candidate Rodolfo Terragno supported it. It was attended by fewer people than previous ones in Buenos Aires and the rest of the country. The demonstration in Rosario was not a cacerolazo, but a silent candlelight vigil attended by nearly a hundred people. There was a second demonstration in Rosario on August 22, proceeding from the National Flag Memorial to the headquarters of Litoral Gas."
    },
    {
        "source": "President Cristina Fernndez de Kirchner, who had recently returned from a diplomatic visit to the United Nations, visited the site of the explosion on August 7. She was berated by local residents; some were angry because her surprise visit halted work at the site, and others thought her presence was politically motivated. The president stayed briefly, visited the CEMAR and met Bonfatti. Kirchner's entourage was surrounded by members of La Cmpora, who tried to prevent demonstrations against her and keep journalists and residents at bay. Weeks before the explosion, several social networking sites had scheduled a country-wide cacerolazo (a pot-banging protest demonstration), known as 8A, against Kirchner for August 8. The websites had already conducted successful cacerolazos (8N and 18A). Despite the national mourning, the 8A protest went ahead as planned, with the added slogan \"No more pointless deaths\". Candidate Ricardo Gil Lavedra thought the cacerolazo should have been canceled, as the campaigning was, but fellow candidate Rodolfo Terragno supported it. It was attended by fewer people than previous ones in Buenos Aires and the rest of the country. The demonstration in Rosario was not a cacerolazo, but a silent candlelight vigil attended by nearly a hundred people. There was a second demonstration in Rosario on August 22, proceeding from the National Flag Memorial to the headquarters of Litoral Gas.",
        "target": "Pope Francis sent a letter of condolence to Archbishop Jose Luis Mollaghan of Rosario, and it was read during a mass and procession for Saint Cajetan at Plaza 25 de Mayo. Newell's Old Boys and Rosario Central, two local soccer teams and rivals in the Rosario derby, organized a charity match for the victims at the Gabino Sosa Stadium, and Rosario-born Lionel Messi provided support through the \"Leo Messi\" charity. The charity match collected 120,000 pesos. Musicians Fito Pez, Vicentico, Babasnicos, Las Pelotas, Chaqueo Palavecino, Ciro Pertusi, Lisandro Aristimuo, Pablo Dacal and Coki Debernardi[es] performed concerts in several Argentine cities to raise money for the victims."
    },
    {
        "source": "Weeks before the explosion, several social networking sites had scheduled a country-wide cacerolazo (a pot-banging protest demonstration), known as 8A, against Kirchner for August 8. The websites had already conducted successful cacerolazos (8N and 18A). Despite the national mourning, the 8A protest went ahead as planned, with the added slogan \"No more pointless deaths\". Candidate Ricardo Gil Lavedra thought the cacerolazo should have been canceled, as the campaigning was, but fellow candidate Rodolfo Terragno supported it. It was attended by fewer people than previous ones in Buenos Aires and the rest of the country. The demonstration in Rosario was not a cacerolazo, but a silent candlelight vigil attended by nearly a hundred people. There was a second demonstration in Rosario on August 22, proceeding from the National Flag Memorial to the headquarters of Litoral Gas. Pope Francis sent a letter of condolence to Archbishop Jose Luis Mollaghan of Rosario, and it was read during a mass and procession for Saint Cajetan at Plaza 25 de Mayo. Newell's Old Boys and Rosario Central, two local soccer teams and rivals in the Rosario derby, organized a charity match for the victims at the Gabino Sosa Stadium, and Rosario-born Lionel Messi provided support through the \"Leo Messi\" charity. The charity match collected 120,000 pesos. Musicians Fito Pez, Vicentico, Babasnicos, Las Pelotas, Chaqueo Palavecino, Ciro Pertusi, Lisandro Aristimuo, Pablo Dacal and Coki Debernardi[es] performed concerts in several Argentine cities to raise money for the victims.",
        "target": "Bonfatti announced that Santa Fe province would provide financial help to the victims of the explosion. Since most houses in the vicinity were damaged, affected families would receive a subsidy of $20,000 to rent homes during reconstruction. They would receive $50,000 in credit to buy furniture and appliances, payable in 60 months with five percent interest. Rosario's real estate firms prepared a list of houses for rent without charging victims their regular fee. Some of the affected buildings may have had cheap insurances which would not cover the risk of an explosion. Some cars trapped in an underground parking lot could not be retrieved."
    },
    {
        "source": "Pope Francis sent a letter of condolence to Archbishop Jose Luis Mollaghan of Rosario, and it was read during a mass and procession for Saint Cajetan at Plaza 25 de Mayo. Newell's Old Boys and Rosario Central, two local soccer teams and rivals in the Rosario derby, organized a charity match for the victims at the Gabino Sosa Stadium, and Rosario-born Lionel Messi provided support through the \"Leo Messi\" charity. The charity match collected 120,000 pesos. Musicians Fito Pez, Vicentico, Babasnicos, Las Pelotas, Chaqueo Palavecino, Ciro Pertusi, Lisandro Aristimuo, Pablo Dacal and Coki Debernardi[es] performed concerts in several Argentine cities to raise money for the victims. Bonfatti announced that Santa Fe province would provide financial help to the victims of the explosion. Since most houses in the vicinity were damaged, affected families would receive a subsidy of $20,000 to rent homes during reconstruction. They would receive $50,000 in credit to buy furniture and appliances, payable in 60 months with five percent interest. Rosario's real estate firms prepared a list of houses for rent without charging victims their regular fee. Some of the affected buildings may have had cheap insurances which would not cover the risk of an explosion. Some cars trapped in an underground parking lot could not be retrieved.",
        "target": "When the search for survivors ended, authorities closed Salta Street. Engineers began checking the buildings at ground zero, trying to restore the original layout of the street and demolishing unstable structures. Secretary of Public Works Omar Saab said that the two remaining buildings were beyond repair and had to be demolished. As a sign of respect, the demolition would not be carried out with explosives. Secretary of Housing Gustavo Leone estimated that the work would take nearly six months. People were allowed to enter their destroyed houses in small groups at a time, starting on August 9. Nearby streets began to be reopened on August 13."
    },
    {
        "source": "Bonfatti announced that Santa Fe province would provide financial help to the victims of the explosion. Since most houses in the vicinity were damaged, affected families would receive a subsidy of $20,000 to rent homes during reconstruction. They would receive $50,000 in credit to buy furniture and appliances, payable in 60 months with five percent interest. Rosario's real estate firms prepared a list of houses for rent without charging victims their regular fee. Some of the affected buildings may have had cheap insurances which would not cover the risk of an explosion. Some cars trapped in an underground parking lot could not be retrieved. When the search for survivors ended, authorities closed Salta Street. Engineers began checking the buildings at ground zero, trying to restore the original layout of the street and demolishing unstable structures. Secretary of Public Works Omar Saab said that the two remaining buildings were beyond repair and had to be demolished. As a sign of respect, the demolition would not be carried out with explosives. Secretary of Housing Gustavo Leone estimated that the work would take nearly six months. People were allowed to enter their destroyed houses in small groups at a time, starting on August 9. Nearby streets began to be reopened on August 13.",
        "target": "The CGT union signed a deal with the association of factories of Rosario and the government of Rosario to make sure that all the victims of the explosions would keep their jobs."
    },
    {
        "source": " Apollo 4 (November 9, 1967), also known as SA-501, was the uncrewed first test flight of the SaturnV launch vehicle, the rocket that eventually took astronauts to the Moon. The space vehicle was assembled in the Vehicle Assembly Building, and was the first to be launched from Kennedy Space Center (KSC) in Florida, ascending from Launch Complex 39, where facilities built specially for the SaturnV had been constructed.",
        "target": "Apollo 4 was an \"all-up\" test, meaning all rocket stages and spacecraft were fully functional on the initial flight, a first for NASA. It was the first time the S-IC first stage and S-II second stage flew. It also demonstrated the S-IVB third stage's first in-flight restart. The mission used a BlockI command and service module modified to test several key BlockII revisions, including its heat shield at simulated lunar-return velocity and angle."
    },
    {
        "source": "Apollo 4 (November 9, 1967), also known as SA-501, was the uncrewed first test flight of the SaturnV launch vehicle, the rocket that eventually took astronauts to the Moon. The space vehicle was assembled in the Vehicle Assembly Building, and was the first to be launched from Kennedy Space Center (KSC) in Florida, ascending from Launch Complex 39, where facilities built specially for the SaturnV had been constructed. Apollo 4 was an \"all-up\" test, meaning all rocket stages and spacecraft were fully functional on the initial flight, a first for NASA. It was the first time the S-IC first stage and S-II second stage flew. It also demonstrated the S-IVB third stage's first in-flight restart. The mission used a BlockI command and service module modified to test several key BlockII revisions, including its heat shield at simulated lunar-return velocity and angle.",
        "target": "The launch was planned for early 1967, but delayed to November9 because of problems with various elements of the spacecraft and difficulties during pre-flight testing. Additional inspections were also required after a fire killed the Apollo1 crew in January 1967."
    },
    {
        "source": "Apollo 4 was an \"all-up\" test, meaning all rocket stages and spacecraft were fully functional on the initial flight, a first for NASA. It was the first time the S-IC first stage and S-II second stage flew. It also demonstrated the S-IVB third stage's first in-flight restart. The mission used a BlockI command and service module modified to test several key BlockII revisions, including its heat shield at simulated lunar-return velocity and angle. The launch was planned for early 1967, but delayed to November9 because of problems with various elements of the spacecraft and difficulties during pre-flight testing. Additional inspections were also required after a fire killed the Apollo1 crew in January 1967.",
        "target": "The mission splashed down in the Pacific Ocean slightly less than nine hours after launch, having achieved its objectives. NASA considered the mission a complete success, proving that the SaturnV worked, an important step towards achieving the main objective of landing astronauts on the Moon, and bringing them back safely, before the end of the 1960s."
    },
    {
        "source": "The launch was planned for early 1967, but delayed to November9 because of problems with various elements of the spacecraft and difficulties during pre-flight testing. Additional inspections were also required after a fire killed the Apollo1 crew in January 1967. The mission splashed down in the Pacific Ocean slightly less than nine hours after launch, having achieved its objectives. NASA considered the mission a complete success, proving that the SaturnV worked, an important step towards achieving the main objective of landing astronauts on the Moon, and bringing them back safely, before the end of the 1960s.",
        "target": "In 1961 U.S. President John F. Kennedy proposed that his nation land an astronaut on the Moon by the end of the decade, with a safe return to Earth. One of the early choices that had to be made to accomplish this goal was what launch vehicle to use. NASA decided on the SaturnC-5 rocket, a three-stage launch vehicle based on rockets already in development. In 1962 this was approved by NASA, which contemplated an initial test launch in 1965 and a first crewed flight by 1967, leaving plenty of time to accomplish Kennedy's goal. In early 1963, NASA redesignated the C-5 as the SaturnV."
    },
    {
        "source": "The mission splashed down in the Pacific Ocean slightly less than nine hours after launch, having achieved its objectives. NASA considered the mission a complete success, proving that the SaturnV worked, an important step towards achieving the main objective of landing astronauts on the Moon, and bringing them back safely, before the end of the 1960s. In 1961 U.S. President John F. Kennedy proposed that his nation land an astronaut on the Moon by the end of the decade, with a safe return to Earth. One of the early choices that had to be made to accomplish this goal was what launch vehicle to use. NASA decided on the SaturnC-5 rocket, a three-stage launch vehicle based on rockets already in development. In 1962 this was approved by NASA, which contemplated an initial test launch in 1965 and a first crewed flight by 1967, leaving plenty of time to accomplish Kennedy's goal. In early 1963, NASA redesignated the C-5 as the SaturnV.",
        "target": "After considerable debate within NASA, it was decided in late 1962 that lunar missions would have a \"lunar orbit rendezvous\" mode whereby the complete Apollo spacecraft would be propelled towards lunar orbit by the third stage of the launch vehicle, the S-IVB. Once in lunar orbit, the astronauts who would land would enter what was then known as the Lunar Excursion Module, which would separate from the rest of the spacecraft, land, and after taking off again be discarded once the crew had transferred back. The remainder of the vehicle would then return to Earth. The launch facilities under development would not be sufficient for the new launch vehicle, and in 1962, NASA announced plans for a new complex on the Florida coast from which the Apollo lunar missions could be launched. This was dubbed the Launch Operations Center, but after Kennedy's assassination in November 1963 was renamed the John F. Kennedy Space Center (KSC). Apollo4 was the first flight from KSC, and the first using Launch Complex 39 (LC-39) there, built to accommodate the SaturnV."
    },
    {
        "source": "In 1961 U.S. President John F. Kennedy proposed that his nation land an astronaut on the Moon by the end of the decade, with a safe return to Earth. One of the early choices that had to be made to accomplish this goal was what launch vehicle to use. NASA decided on the SaturnC-5 rocket, a three-stage launch vehicle based on rockets already in development. In 1962 this was approved by NASA, which contemplated an initial test launch in 1965 and a first crewed flight by 1967, leaving plenty of time to accomplish Kennedy's goal. In early 1963, NASA redesignated the C-5 as the SaturnV. After considerable debate within NASA, it was decided in late 1962 that lunar missions would have a \"lunar orbit rendezvous\" mode whereby the complete Apollo spacecraft would be propelled towards lunar orbit by the third stage of the launch vehicle, the S-IVB. Once in lunar orbit, the astronauts who would land would enter what was then known as the Lunar Excursion Module, which would separate from the rest of the spacecraft, land, and after taking off again be discarded once the crew had transferred back. The remainder of the vehicle would then return to Earth. The launch facilities under development would not be sufficient for the new launch vehicle, and in 1962, NASA announced plans for a new complex on the Florida coast from which the Apollo lunar missions could be launched. This was dubbed the Launch Operations Center, but after Kennedy's assassination in November 1963 was renamed the John F. Kennedy Space Center (KSC). Apollo4 was the first flight from KSC, and the first using Launch Complex 39 (LC-39) there, built to accommodate the SaturnV.",
        "target": "The first three flights carrying Apollo equipment were launched using SaturnIBs. This smaller launch vehicle did not use the facilities at KSC, but issues resolved by SaturnIB flights would be valid for those to be launched by the SaturnV. Both the SaturnIB and the SaturnV would use a S-IVB, though the IB would use it as its second, final stage, rather than the third stage as on the SaturnV. Thus, many of the flight qualifications for the payload the SaturnV would carry could be resolved without having to expend one of the large launch vehicles. In addition to flight-qualifying the hardware, it was necessary to prove that the ground systems at KSC could successfully launch a Saturn V before risking the lives of astronauts on one."
    },
    {
        "source": "After considerable debate within NASA, it was decided in late 1962 that lunar missions would have a \"lunar orbit rendezvous\" mode whereby the complete Apollo spacecraft would be propelled towards lunar orbit by the third stage of the launch vehicle, the S-IVB. Once in lunar orbit, the astronauts who would land would enter what was then known as the Lunar Excursion Module, which would separate from the rest of the spacecraft, land, and after taking off again be discarded once the crew had transferred back. The remainder of the vehicle would then return to Earth. The launch facilities under development would not be sufficient for the new launch vehicle, and in 1962, NASA announced plans for a new complex on the Florida coast from which the Apollo lunar missions could be launched. This was dubbed the Launch Operations Center, but after Kennedy's assassination in November 1963 was renamed the John F. Kennedy Space Center (KSC). Apollo4 was the first flight from KSC, and the first using Launch Complex 39 (LC-39) there, built to accommodate the SaturnV. The first three flights carrying Apollo equipment were launched using SaturnIBs. This smaller launch vehicle did not use the facilities at KSC, but issues resolved by SaturnIB flights would be valid for those to be launched by the SaturnV. Both the SaturnIB and the SaturnV would use a S-IVB, though the IB would use it as its second, final stage, rather than the third stage as on the SaturnV. Thus, many of the flight qualifications for the payload the SaturnV would carry could be resolved without having to expend one of the large launch vehicles. In addition to flight-qualifying the hardware, it was necessary to prove that the ground systems at KSC could successfully launch a Saturn V before risking the lives of astronauts on one.",
        "target": "Three Saturn IB launches (in order of launch, AS-201, AS-203 and AS-202) took place in 1966; all were successful. According to Charles D. Benson and William B. Flaherty in their history of KSC, \"The Apollo-SaturnIB launches of 1966 represented important gains for NASA's launch team. LC-34 and LC-37, testbeds for automated checkout, were found wanting. In the twenty months between AS-201 and SA-501 [Apollo4], KSC corrected the major automation problems. Without these trial and error advances, SA-501, the toughest launch in Apollo's history, would have been far more difficult.\""
    },
    {
        "source": "The first three flights carrying Apollo equipment were launched using SaturnIBs. This smaller launch vehicle did not use the facilities at KSC, but issues resolved by SaturnIB flights would be valid for those to be launched by the SaturnV. Both the SaturnIB and the SaturnV would use a S-IVB, though the IB would use it as its second, final stage, rather than the third stage as on the SaturnV. Thus, many of the flight qualifications for the payload the SaturnV would carry could be resolved without having to expend one of the large launch vehicles. In addition to flight-qualifying the hardware, it was necessary to prove that the ground systems at KSC could successfully launch a Saturn V before risking the lives of astronauts on one. Three Saturn IB launches (in order of launch, AS-201, AS-203 and AS-202) took place in 1966; all were successful. According to Charles D. Benson and William B. Flaherty in their history of KSC, \"The Apollo-SaturnIB launches of 1966 represented important gains for NASA's launch team. LC-34 and LC-37, testbeds for automated checkout, were found wanting. In the twenty months between AS-201 and SA-501 [Apollo4], KSC corrected the major automation problems. Without these trial and error advances, SA-501, the toughest launch in Apollo's history, would have been far more difficult.\"",
        "target": "In January 1965 Major General Samuel C. Phillips, the Apollo Program Director, scheduled SA-501, the first test flight of the SaturnV, for January 1967. This left little spare time for delay, especially since two additional SaturnV launches were planned to follow in 1967. Many Apollo officials lacked confidence in the proposed launch date, and these misgivings proved accurate. After an explosion involving a liquid oxygen line flowing to LC-39, from which SA-501 was to be launched, there was a potential for a delay of several weeks."
    },
    {
        "source": "Three Saturn IB launches (in order of launch, AS-201, AS-203 and AS-202) took place in 1966; all were successful. According to Charles D. Benson and William B. Flaherty in their history of KSC, \"The Apollo-SaturnIB launches of 1966 represented important gains for NASA's launch team. LC-34 and LC-37, testbeds for automated checkout, were found wanting. In the twenty months between AS-201 and SA-501 [Apollo4], KSC corrected the major automation problems. Without these trial and error advances, SA-501, the toughest launch in Apollo's history, would have been far more difficult.\" In January 1965 Major General Samuel C. Phillips, the Apollo Program Director, scheduled SA-501, the first test flight of the SaturnV, for January 1967. This left little spare time for delay, especially since two additional SaturnV launches were planned to follow in 1967. Many Apollo officials lacked confidence in the proposed launch date, and these misgivings proved accurate. After an explosion involving a liquid oxygen line flowing to LC-39, from which SA-501 was to be launched, there was a potential for a delay of several weeks.",
        "target": "North American Aviation was the contractor for both the S-II SaturnV second stage, and the Apollo command and service module (CSM) spacecraft. NASA had been experiencing problems with North American's schedule, cost, and quality performance on both programs, severe enough that Phillips led a team to North American's facility in California in November and December 1965 to investigate matters, and recommend solutions to the program management problems. He published his findings in a report to his supervisor, George Mueller. Technicians found cracks in the S-II, delaying its test firings prior to acceptance by NASA. As North American worked to fix the S-II, parts of the rocket began to arrive at KSC, beginning with the S-IVB on August 14, 1966, (by Pregnant Guppy aircraft) and followed closely by the first stage S-IC on September 12 (by barge). A spool-shaped \"spacer\" that took the place of the S-II allowed NASA to stack the vehicle as its checkout proceeded in the Vehicle Assembly Building (VAB). With the S-II still not arrived by November 1966 (it had originally been planned for July), NASA planned January 1967 for its arrival, with launch three months later. The CSM arrived on December 24, 1966, with the S-II arriving on January 21, 1967. Last to arrive was the aft interstage (the structure between the first and second stages), on January 31."
    },
    {
        "source": "In January 1965 Major General Samuel C. Phillips, the Apollo Program Director, scheduled SA-501, the first test flight of the SaturnV, for January 1967. This left little spare time for delay, especially since two additional SaturnV launches were planned to follow in 1967. Many Apollo officials lacked confidence in the proposed launch date, and these misgivings proved accurate. After an explosion involving a liquid oxygen line flowing to LC-39, from which SA-501 was to be launched, there was a potential for a delay of several weeks. North American Aviation was the contractor for both the S-II SaturnV second stage, and the Apollo command and service module (CSM) spacecraft. NASA had been experiencing problems with North American's schedule, cost, and quality performance on both programs, severe enough that Phillips led a team to North American's facility in California in November and December 1965 to investigate matters, and recommend solutions to the program management problems. He published his findings in a report to his supervisor, George Mueller. Technicians found cracks in the S-II, delaying its test firings prior to acceptance by NASA. As North American worked to fix the S-II, parts of the rocket began to arrive at KSC, beginning with the S-IVB on August 14, 1966, (by Pregnant Guppy aircraft) and followed closely by the first stage S-IC on September 12 (by barge). A spool-shaped \"spacer\" that took the place of the S-II allowed NASA to stack the vehicle as its checkout proceeded in the Vehicle Assembly Building (VAB). With the S-II still not arrived by November 1966 (it had originally been planned for July), NASA planned January 1967 for its arrival, with launch three months later. The CSM arrived on December 24, 1966, with the S-II arriving on January 21, 1967. Last to arrive was the aft interstage (the structure between the first and second stages), on January 31.",
        "target": "The Apollo 1 fire on January 27, 1967, which killed three astronauts during a launch pad test, threw NASA's schedules into further question even though SA-501 was uncrewed, NASA officials wanted to closely examine its CSM. NASA had planned to restack the vehicle once this was done, but instead the inspections that took place found a total of 1,407 errors in the spacecraft. Inspectors found many haphazardly routed and skinned wires, prime material for short circuits."
    },
    {
        "source": "North American Aviation was the contractor for both the S-II SaturnV second stage, and the Apollo command and service module (CSM) spacecraft. NASA had been experiencing problems with North American's schedule, cost, and quality performance on both programs, severe enough that Phillips led a team to North American's facility in California in November and December 1965 to investigate matters, and recommend solutions to the program management problems. He published his findings in a report to his supervisor, George Mueller. Technicians found cracks in the S-II, delaying its test firings prior to acceptance by NASA. As North American worked to fix the S-II, parts of the rocket began to arrive at KSC, beginning with the S-IVB on August 14, 1966, (by Pregnant Guppy aircraft) and followed closely by the first stage S-IC on September 12 (by barge). A spool-shaped \"spacer\" that took the place of the S-II allowed NASA to stack the vehicle as its checkout proceeded in the Vehicle Assembly Building (VAB). With the S-II still not arrived by November 1966 (it had originally been planned for July), NASA planned January 1967 for its arrival, with launch three months later. The CSM arrived on December 24, 1966, with the S-II arriving on January 21, 1967. Last to arrive was the aft interstage (the structure between the first and second stages), on January 31. The Apollo 1 fire on January 27, 1967, which killed three astronauts during a launch pad test, threw NASA's schedules into further question even though SA-501 was uncrewed, NASA officials wanted to closely examine its CSM. NASA had planned to restack the vehicle once this was done, but instead the inspections that took place found a total of 1,407 errors in the spacecraft. Inspectors found many haphazardly routed and skinned wires, prime material for short circuits.",
        "target": "Other problems were discovered, such as an extra, out-of-place bolt in one of the J-2 engines; NASA was concerned not only with retrieving the surplus hardware, but also with discovering how it got there. A meeting in March 1967, with Phillips in attendance, disclosed twelve hundred problems with the SaturnV, which the technicians proposed to deal with at the rate of eighty per day. While the CSM was undergoing repairs, the spacer was removed from the vehicle stack, and the S-II positioned. On May 24 it was announced that the S-II would be removed for inspection following the discovery of hairline cracks in another S-II then being constructed, this work being completed by mid-June, after which the CSM was also returned to the stack, the first time the launch vehicle and spacecraft had been fully assembled. It was rolled out to LC-39 on August 26, 1967, where it was joined by the Mobile Servicing Structure that allowed access to the launch vehicle and spacecraft two days later, also transported by crawler. This was the first time a NASA spacecraft had been assembled away from its launch site, something allowing protection from Florida's hot and humid climate for equipment and personnel."
    },
    {
        "source": "The Apollo 1 fire on January 27, 1967, which killed three astronauts during a launch pad test, threw NASA's schedules into further question even though SA-501 was uncrewed, NASA officials wanted to closely examine its CSM. NASA had planned to restack the vehicle once this was done, but instead the inspections that took place found a total of 1,407 errors in the spacecraft. Inspectors found many haphazardly routed and skinned wires, prime material for short circuits. Other problems were discovered, such as an extra, out-of-place bolt in one of the J-2 engines; NASA was concerned not only with retrieving the surplus hardware, but also with discovering how it got there. A meeting in March 1967, with Phillips in attendance, disclosed twelve hundred problems with the SaturnV, which the technicians proposed to deal with at the rate of eighty per day. While the CSM was undergoing repairs, the spacer was removed from the vehicle stack, and the S-II positioned. On May 24 it was announced that the S-II would be removed for inspection following the discovery of hairline cracks in another S-II then being constructed, this work being completed by mid-June, after which the CSM was also returned to the stack, the first time the launch vehicle and spacecraft had been fully assembled. It was rolled out to LC-39 on August 26, 1967, where it was joined by the Mobile Servicing Structure that allowed access to the launch vehicle and spacecraft two days later, also transported by crawler. This was the first time a NASA spacecraft had been assembled away from its launch site, something allowing protection from Florida's hot and humid climate for equipment and personnel.",
        "target": "The countdown demonstration test had been scheduled for September 20 but was soon rescheduled for the 25th and did not begin until the evening of the 27th. By October2 another two days had been lost to delays, but by October4 it reached launch minus 45 minutes. Then a computer failed, and the count, reset to minus 13 hours before launch, resumed on October 9. More computer and equipment problems appeared. By then, the launch team was exhausted and a two-day break was declared. The test was completed on October 13, meaning that it took three weeks rather than the expectation of a week or slightly over. With world attention on the launch, NASA public relations head Julian Scheer brought the skeptical questions from the media as to whether Apollo4 would ever fly to the attention of NASA Administrator James E. Webb, leading to a heated meeting in which Webb said he would announce the launch date when he wanted to."
    },
    {
        "source": "Other problems were discovered, such as an extra, out-of-place bolt in one of the J-2 engines; NASA was concerned not only with retrieving the surplus hardware, but also with discovering how it got there. A meeting in March 1967, with Phillips in attendance, disclosed twelve hundred problems with the SaturnV, which the technicians proposed to deal with at the rate of eighty per day. While the CSM was undergoing repairs, the spacer was removed from the vehicle stack, and the S-II positioned. On May 24 it was announced that the S-II would be removed for inspection following the discovery of hairline cracks in another S-II then being constructed, this work being completed by mid-June, after which the CSM was also returned to the stack, the first time the launch vehicle and spacecraft had been fully assembled. It was rolled out to LC-39 on August 26, 1967, where it was joined by the Mobile Servicing Structure that allowed access to the launch vehicle and spacecraft two days later, also transported by crawler. This was the first time a NASA spacecraft had been assembled away from its launch site, something allowing protection from Florida's hot and humid climate for equipment and personnel. The countdown demonstration test had been scheduled for September 20 but was soon rescheduled for the 25th and did not begin until the evening of the 27th. By October2 another two days had been lost to delays, but by October4 it reached launch minus 45 minutes. Then a computer failed, and the count, reset to minus 13 hours before launch, resumed on October 9. More computer and equipment problems appeared. By then, the launch team was exhausted and a two-day break was declared. The test was completed on October 13, meaning that it took three weeks rather than the expectation of a week or slightly over. With world attention on the launch, NASA public relations head Julian Scheer brought the skeptical questions from the media as to whether Apollo4 would ever fly to the attention of NASA Administrator James E. Webb, leading to a heated meeting in which Webb said he would announce the launch date when he wanted to.",
        "target": "These difficulties provided the launch crew with valuable experience, but meant that Apollo4 could not be launched at the earliest until November 7. A flight readiness review on October 19 cleared Apollo4 for launch, assuming the remaining tests and modifications were satisfactorily completed. Concerned about the potential for leaks in the Teflon seal rings and drain valves of the liquid oxygen tanks on board the vehicle due to the long time it had been sitting on the launch pad in the Florida sun, on November2 Phillips postponed the launch until November9."
    },
    {
        "source": "The countdown demonstration test had been scheduled for September 20 but was soon rescheduled for the 25th and did not begin until the evening of the 27th. By October2 another two days had been lost to delays, but by October4 it reached launch minus 45 minutes. Then a computer failed, and the count, reset to minus 13 hours before launch, resumed on October 9. More computer and equipment problems appeared. By then, the launch team was exhausted and a two-day break was declared. The test was completed on October 13, meaning that it took three weeks rather than the expectation of a week or slightly over. With world attention on the launch, NASA public relations head Julian Scheer brought the skeptical questions from the media as to whether Apollo4 would ever fly to the attention of NASA Administrator James E. Webb, leading to a heated meeting in which Webb said he would announce the launch date when he wanted to. These difficulties provided the launch crew with valuable experience, but meant that Apollo4 could not be launched at the earliest until November 7. A flight readiness review on October 19 cleared Apollo4 for launch, assuming the remaining tests and modifications were satisfactorily completed. Concerned about the potential for leaks in the Teflon seal rings and drain valves of the liquid oxygen tanks on board the vehicle due to the long time it had been sitting on the launch pad in the Florida sun, on November2 Phillips postponed the launch until November9.",
        "target": "The purpose of Apollo 4 (together with the SaturnV's other uncrewed test flight, Apollo6) was to qualify the launch vehicle, the Apollo spacecraft, and the ground systems, for the crewed lunar landing missions that would follow. In addition to being the first flight of the SaturnV, Apollo4 marked the first flight for two of its stages: the S-IC first stage and the S-II second stage (the S-IVB had flown as part of the SaturnIB)."
    },
    {
        "source": "These difficulties provided the launch crew with valuable experience, but meant that Apollo4 could not be launched at the earliest until November 7. A flight readiness review on October 19 cleared Apollo4 for launch, assuming the remaining tests and modifications were satisfactorily completed. Concerned about the potential for leaks in the Teflon seal rings and drain valves of the liquid oxygen tanks on board the vehicle due to the long time it had been sitting on the launch pad in the Florida sun, on November2 Phillips postponed the launch until November9. The purpose of Apollo 4 (together with the SaturnV's other uncrewed test flight, Apollo6) was to qualify the launch vehicle, the Apollo spacecraft, and the ground systems, for the crewed lunar landing missions that would follow. In addition to being the first flight of the SaturnV, Apollo4 marked the first flight for two of its stages: the S-IC first stage and the S-II second stage (the S-IVB had flown as part of the SaturnIB).",
        "target": "Objectives for the Apollo 4 mission were to gain flight data on the SaturnV and spacecraft structural integrity and mutual compatibility, including on flight loads and during the separations as each SaturnV stage was exhausted and was discarded. NASA also wanted data on subsystem operations, including the emergency detection subsystem, and sought to evaluate the Apollo CM's heat shield under conditions simulating a return from a lunar mission. NASA was also seeking to test the restart capability of the S-IVB in space. These objectives would all be achieved."
    },
    {
        "source": "The purpose of Apollo 4 (together with the SaturnV's other uncrewed test flight, Apollo6) was to qualify the launch vehicle, the Apollo spacecraft, and the ground systems, for the crewed lunar landing missions that would follow. In addition to being the first flight of the SaturnV, Apollo4 marked the first flight for two of its stages: the S-IC first stage and the S-II second stage (the S-IVB had flown as part of the SaturnIB). Objectives for the Apollo 4 mission were to gain flight data on the SaturnV and spacecraft structural integrity and mutual compatibility, including on flight loads and during the separations as each SaturnV stage was exhausted and was discarded. NASA also wanted data on subsystem operations, including the emergency detection subsystem, and sought to evaluate the Apollo CM's heat shield under conditions simulating a return from a lunar mission. NASA was also seeking to test the restart capability of the S-IVB in space. These objectives would all be achieved.",
        "target": "Apollo 4 carried CSM-017, a BlockI design of the command and service modules meant for testing and for Apollo's early Earth orbit flights. Unlike the BlockII spacecraft which would go to the Moon, it lacked the capability to dock with a lunar module (LM). CSM-017 was made up of command module CM-017 and service module SM-020. CM-017 was the second fully-functional CM to be delivered to NASA; the first, CM-012, was designated for Apollo1, and was severely damaged in the fire. SM-020 was originally to be used in CSM-020, slated for the second SaturnV test, but this changed after SM-017, which was intended to be part of CSM-017, was damaged in an explosion and was scrapped."
    },
    {
        "source": "Objectives for the Apollo 4 mission were to gain flight data on the SaturnV and spacecraft structural integrity and mutual compatibility, including on flight loads and during the separations as each SaturnV stage was exhausted and was discarded. NASA also wanted data on subsystem operations, including the emergency detection subsystem, and sought to evaluate the Apollo CM's heat shield under conditions simulating a return from a lunar mission. NASA was also seeking to test the restart capability of the S-IVB in space. These objectives would all be achieved. Apollo 4 carried CSM-017, a BlockI design of the command and service modules meant for testing and for Apollo's early Earth orbit flights. Unlike the BlockII spacecraft which would go to the Moon, it lacked the capability to dock with a lunar module (LM). CSM-017 was made up of command module CM-017 and service module SM-020. CM-017 was the second fully-functional CM to be delivered to NASA; the first, CM-012, was designated for Apollo1, and was severely damaged in the fire. SM-020 was originally to be used in CSM-020, slated for the second SaturnV test, but this changed after SM-017, which was intended to be part of CSM-017, was damaged in an explosion and was scrapped.",
        "target": "Several significant Block II modifications were made to CSM-017 for certification purposes, since no BlockII spacecraft would fly without a crew. These included upgrading the heat shield to BlockII standards, using a BlockII CM-to-SM umbilical connector, and installing BlockII-style VHF and S-band antennae. Additionally, there were modifications to the CM's hatch. The fact that the spacecraft hatch could not be readily opened in case of emergency had trapped the Apollo1 astronauts in the fire that took their lives, and led to a redesign of the hatch. The new hatch was not scheduled to fly until the second SaturnV test (Apollo6), but its seals were to be flight-qualified on Apollo4 the hatch window was replaced with a test panel simulating the seals and exterior heat shield. The heat shield was upgraded to BlockII standards since Apollo4's high-speed re-entry into Earth's atmosphere was intended to simulate a return from the Moon. Special equipment had been installed to allow Mission Control to operate the CSM's systems remotely, and there was a camera that would automatically take pictures out of one of the CM's windows on its final orbit. Since Apollo4 carried no crew the CM lacked couches, controls and displays."
    },
    {
        "source": "Apollo 4 carried CSM-017, a BlockI design of the command and service modules meant for testing and for Apollo's early Earth orbit flights. Unlike the BlockII spacecraft which would go to the Moon, it lacked the capability to dock with a lunar module (LM). CSM-017 was made up of command module CM-017 and service module SM-020. CM-017 was the second fully-functional CM to be delivered to NASA; the first, CM-012, was designated for Apollo1, and was severely damaged in the fire. SM-020 was originally to be used in CSM-020, slated for the second SaturnV test, but this changed after SM-017, which was intended to be part of CSM-017, was damaged in an explosion and was scrapped. Several significant Block II modifications were made to CSM-017 for certification purposes, since no BlockII spacecraft would fly without a crew. These included upgrading the heat shield to BlockII standards, using a BlockII CM-to-SM umbilical connector, and installing BlockII-style VHF and S-band antennae. Additionally, there were modifications to the CM's hatch. The fact that the spacecraft hatch could not be readily opened in case of emergency had trapped the Apollo1 astronauts in the fire that took their lives, and led to a redesign of the hatch. The new hatch was not scheduled to fly until the second SaturnV test (Apollo6), but its seals were to be flight-qualified on Apollo4 the hatch window was replaced with a test panel simulating the seals and exterior heat shield. The heat shield was upgraded to BlockII standards since Apollo4's high-speed re-entry into Earth's atmosphere was intended to simulate a return from the Moon. Special equipment had been installed to allow Mission Control to operate the CSM's systems remotely, and there was a camera that would automatically take pictures out of one of the CM's windows on its final orbit. Since Apollo4 carried no crew the CM lacked couches, controls and displays.",
        "target": "A Lunar Module Test Article, LTA-10R, was carried, and remained inside the SpacecraftLM Adapter, numbered as SLA-8, on the third stage of the SaturnV throughout its flight. The LTA consisted of a flight-type descent stage lacking landing gear, with its fuel and oxidizer tanks containing a mixture of water, glycol, and freon. There was an ascent stage mockup atop it, made of aluminum with ballast, and having no flight systems. The SLA and LTA were instrumented to measure stress on them as the SaturnV made its way to orbit. LTA-10R would be destroyed when the S-IVB re-entered the atmosphere."
    },
    {
        "source": "Several significant Block II modifications were made to CSM-017 for certification purposes, since no BlockII spacecraft would fly without a crew. These included upgrading the heat shield to BlockII standards, using a BlockII CM-to-SM umbilical connector, and installing BlockII-style VHF and S-band antennae. Additionally, there were modifications to the CM's hatch. The fact that the spacecraft hatch could not be readily opened in case of emergency had trapped the Apollo1 astronauts in the fire that took their lives, and led to a redesign of the hatch. The new hatch was not scheduled to fly until the second SaturnV test (Apollo6), but its seals were to be flight-qualified on Apollo4 the hatch window was replaced with a test panel simulating the seals and exterior heat shield. The heat shield was upgraded to BlockII standards since Apollo4's high-speed re-entry into Earth's atmosphere was intended to simulate a return from the Moon. Special equipment had been installed to allow Mission Control to operate the CSM's systems remotely, and there was a camera that would automatically take pictures out of one of the CM's windows on its final orbit. Since Apollo4 carried no crew the CM lacked couches, controls and displays. A Lunar Module Test Article, LTA-10R, was carried, and remained inside the SpacecraftLM Adapter, numbered as SLA-8, on the third stage of the SaturnV throughout its flight. The LTA consisted of a flight-type descent stage lacking landing gear, with its fuel and oxidizer tanks containing a mixture of water, glycol, and freon. There was an ascent stage mockup atop it, made of aluminum with ballast, and having no flight systems. The SLA and LTA were instrumented to measure stress on them as the SaturnV made its way to orbit. LTA-10R would be destroyed when the S-IVB re-entered the atmosphere.",
        "target": "Apollo 4 was the first flight of a SaturnV. At the time, it was the largest launch vehicle to ever attempt a flight. This mission was the first time NASA used \"all-up\" testing, requiring that each stage of the launch vehicle work and that the vehicle carry a working spacecraft; a decision that goes back to late 1963. Mueller, the head of the NASA Office of Manned Space Flight at that time, was a systems engineer who previously worked on military missile projects. He had recognized that all-up testing was successfully used to rapidly develop the Air Force's Minuteman ICBM program, and thought it could be used to meet Apollo's schedule. In a 1963 memo he ordered that both the first SaturnIB flight and the first SaturnV flight be uncrewed, that each stage be fully functional, and that each carry a working spacecraft. The second flight of each type of rocket would also be an uncrewed test flight, and the third flight would be crewed. Previously, the way Wernher von Braun's team at the Marshall Space Flight Center tested new rockets was by testing each stage incrementally. The SaturnV would be tested all at once, with all stages live and fully flight-worthy, including an Apollo CSM. This decision dramatically streamlined the program's test flight phase, eliminating four missions, but it required everything to work properly the first time. Apollo program managers had misgivings about all-up testing but agreed to it with some reluctance since incremental component tests would inevitably push the lunar landing mission past the 1970 goal."
    },
    {
        "source": "A Lunar Module Test Article, LTA-10R, was carried, and remained inside the SpacecraftLM Adapter, numbered as SLA-8, on the third stage of the SaturnV throughout its flight. The LTA consisted of a flight-type descent stage lacking landing gear, with its fuel and oxidizer tanks containing a mixture of water, glycol, and freon. There was an ascent stage mockup atop it, made of aluminum with ballast, and having no flight systems. The SLA and LTA were instrumented to measure stress on them as the SaturnV made its way to orbit. LTA-10R would be destroyed when the S-IVB re-entered the atmosphere. Apollo 4 was the first flight of a SaturnV. At the time, it was the largest launch vehicle to ever attempt a flight. This mission was the first time NASA used \"all-up\" testing, requiring that each stage of the launch vehicle work and that the vehicle carry a working spacecraft; a decision that goes back to late 1963. Mueller, the head of the NASA Office of Manned Space Flight at that time, was a systems engineer who previously worked on military missile projects. He had recognized that all-up testing was successfully used to rapidly develop the Air Force's Minuteman ICBM program, and thought it could be used to meet Apollo's schedule. In a 1963 memo he ordered that both the first SaturnIB flight and the first SaturnV flight be uncrewed, that each stage be fully functional, and that each carry a working spacecraft. The second flight of each type of rocket would also be an uncrewed test flight, and the third flight would be crewed. Previously, the way Wernher von Braun's team at the Marshall Space Flight Center tested new rockets was by testing each stage incrementally. The SaturnV would be tested all at once, with all stages live and fully flight-worthy, including an Apollo CSM. This decision dramatically streamlined the program's test flight phase, eliminating four missions, but it required everything to work properly the first time. Apollo program managers had misgivings about all-up testing but agreed to it with some reluctance since incremental component tests would inevitably push the lunar landing mission past the 1970 goal.",
        "target": "Apollo 4 was the first mission to fly under the official Apollo mission numbering scheme approved by Mueller on April 24, 1967; the planned first crewed flight, in preparation for which three astronauts had died, was retroactively designated Apollo1 as the widows of the crew members had requested. Although three uncrewed SaturnIB flights had already occurred, only two had contained an Apollo spacecraft (AS-203 carried only the aerodynamic nose cone). Mueller resumed the numbering sequence at Apollo4, without designating an Apollo 2 or3."
    },
    {
        "source": "Apollo 4 was the first flight of a SaturnV. At the time, it was the largest launch vehicle to ever attempt a flight. This mission was the first time NASA used \"all-up\" testing, requiring that each stage of the launch vehicle work and that the vehicle carry a working spacecraft; a decision that goes back to late 1963. Mueller, the head of the NASA Office of Manned Space Flight at that time, was a systems engineer who previously worked on military missile projects. He had recognized that all-up testing was successfully used to rapidly develop the Air Force's Minuteman ICBM program, and thought it could be used to meet Apollo's schedule. In a 1963 memo he ordered that both the first SaturnIB flight and the first SaturnV flight be uncrewed, that each stage be fully functional, and that each carry a working spacecraft. The second flight of each type of rocket would also be an uncrewed test flight, and the third flight would be crewed. Previously, the way Wernher von Braun's team at the Marshall Space Flight Center tested new rockets was by testing each stage incrementally. The SaturnV would be tested all at once, with all stages live and fully flight-worthy, including an Apollo CSM. This decision dramatically streamlined the program's test flight phase, eliminating four missions, but it required everything to work properly the first time. Apollo program managers had misgivings about all-up testing but agreed to it with some reluctance since incremental component tests would inevitably push the lunar landing mission past the 1970 goal. Apollo 4 was the first mission to fly under the official Apollo mission numbering scheme approved by Mueller on April 24, 1967; the planned first crewed flight, in preparation for which three astronauts had died, was retroactively designated Apollo1 as the widows of the crew members had requested. Although three uncrewed SaturnIB flights had already occurred, only two had contained an Apollo spacecraft (AS-203 carried only the aerodynamic nose cone). Mueller resumed the numbering sequence at Apollo4, without designating an Apollo 2 or3.",
        "target": "VIPs swarmed to KSC in the days before the launch. Von Braun arrived on November 6, scheduled for an exclusive executive dinner and conference that evening. NASA executives, figures from industry, Congressional leaders and diplomats also came for the launch. Each NASA center involved had a list of VIP guests, as did NASA headquarters in Washington, and duplications were sorted out so each center's director could invite guests personally. They watched the launch from uncovered bleachers near the VAB. NASA set up press headquarters in Cocoa Beach, where media representatives were accredited, and offered tours of KSC to visiting journalists, as well as a half-hourly shuttle service. NASA provided extensive telephone facilities for the media at the press site near LC-39, at their expense. KSC workers and their dependents watched the launch from near their work assignments. In addition, 43 employees of contractors who had performed in an exemplary manner were selected as \"Manned Flight Awareness\" honorees, given a VIP tour of KSC, a social evening in which six astronauts participated, and a view of the launch."
    },
    {
        "source": "Apollo 4 was the first mission to fly under the official Apollo mission numbering scheme approved by Mueller on April 24, 1967; the planned first crewed flight, in preparation for which three astronauts had died, was retroactively designated Apollo1 as the widows of the crew members had requested. Although three uncrewed SaturnIB flights had already occurred, only two had contained an Apollo spacecraft (AS-203 carried only the aerodynamic nose cone). Mueller resumed the numbering sequence at Apollo4, without designating an Apollo 2 or3. VIPs swarmed to KSC in the days before the launch. Von Braun arrived on November 6, scheduled for an exclusive executive dinner and conference that evening. NASA executives, figures from industry, Congressional leaders and diplomats also came for the launch. Each NASA center involved had a list of VIP guests, as did NASA headquarters in Washington, and duplications were sorted out so each center's director could invite guests personally. They watched the launch from uncovered bleachers near the VAB. NASA set up press headquarters in Cocoa Beach, where media representatives were accredited, and offered tours of KSC to visiting journalists, as well as a half-hourly shuttle service. NASA provided extensive telephone facilities for the media at the press site near LC-39, at their expense. KSC workers and their dependents watched the launch from near their work assignments. In addition, 43 employees of contractors who had performed in an exemplary manner were selected as \"Manned Flight Awareness\" honorees, given a VIP tour of KSC, a social evening in which six astronauts participated, and a view of the launch.",
        "target": "Apollo 4, being the first flight of the SaturnV, gained intense media coverage, and writers struggled to convey to the public the size of the launch vehicle, stating that it would tower well over the Statue of Liberty and be thirteen times as heavy. North American, in a handout to the media, noted that the 3000-ton SaturnV comfortably outweighed a \"good-sized navy destroyer\". On the day before launch, Mueller, Phillips, von Braun, Deputy Administrator Robert C. Seamans and Kennedy Space Center Director Kurt Debus held an outdoor press conference for more than a thousand journalists, including some from the Soviet Union, with the SaturnV in the background."
    },
    {
        "source": "VIPs swarmed to KSC in the days before the launch. Von Braun arrived on November 6, scheduled for an exclusive executive dinner and conference that evening. NASA executives, figures from industry, Congressional leaders and diplomats also came for the launch. Each NASA center involved had a list of VIP guests, as did NASA headquarters in Washington, and duplications were sorted out so each center's director could invite guests personally. They watched the launch from uncovered bleachers near the VAB. NASA set up press headquarters in Cocoa Beach, where media representatives were accredited, and offered tours of KSC to visiting journalists, as well as a half-hourly shuttle service. NASA provided extensive telephone facilities for the media at the press site near LC-39, at their expense. KSC workers and their dependents watched the launch from near their work assignments. In addition, 43 employees of contractors who had performed in an exemplary manner were selected as \"Manned Flight Awareness\" honorees, given a VIP tour of KSC, a social evening in which six astronauts participated, and a view of the launch. Apollo 4, being the first flight of the SaturnV, gained intense media coverage, and writers struggled to convey to the public the size of the launch vehicle, stating that it would tower well over the Statue of Liberty and be thirteen times as heavy. North American, in a handout to the media, noted that the 3000-ton SaturnV comfortably outweighed a \"good-sized navy destroyer\". On the day before launch, Mueller, Phillips, von Braun, Deputy Administrator Robert C. Seamans and Kennedy Space Center Director Kurt Debus held an outdoor press conference for more than a thousand journalists, including some from the Soviet Union, with the SaturnV in the background.",
        "target": "Our building's shaking! The roar is terrific! The building's shaking! This big glass window is shaking. We're holding it with our hands! Look at that rocket go! Into the clouds at 3,000 feet! The roar is terrific! Look at it going! You can see it. Part of our roof has come in here."
    },
    {
        "source": "Our building's shaking! The roar is terrific! The building's shaking! This big glass window is shaking. We're holding it with our hands! Look at that rocket go! Into the clouds at 3,000 feet! The roar is terrific! Look at it going! You can see it. Part of our roof has come in here. Walter Cronkite, November 9, 1967",
        "target": "On November 6, 1967, at 10:30pm EST (03:30 November7 UTC), the 56+12-hour countdown sequence began with propellant loading. In total there were 89 trailer-truck loads of liquid oxygen, 28 trailer loads of LH2 (liquid hydrogen), and 27 rail cars of RP-1 (highly refined kerosene). This time the problems encountered were few and minor, and did not delay the launch due to the use of built-in holds in the countdown, during which time accumulated delays were made good."
    },
    {
        "source": "Walter Cronkite, November 9, 1967 On November 6, 1967, at 10:30pm EST (03:30 November7 UTC), the 56+12-hour countdown sequence began with propellant loading. In total there were 89 trailer-truck loads of liquid oxygen, 28 trailer loads of LH2 (liquid hydrogen), and 27 rail cars of RP-1 (highly refined kerosene). This time the problems encountered were few and minor, and did not delay the launch due to the use of built-in holds in the countdown, during which time accumulated delays were made good.",
        "target": "Apollo 4 launched on November9 at 7:00am EST (noon UTC). Eight seconds before liftoff, the five F-1 engines ignited, sending tremendous amounts of noise across Kennedy Space Center. Even though the launch pads at LC-39 were more than five kilometers (three miles) from the Vehicle Assembly Building, the sound pressure was much stronger than expected and buffeted the VAB, Launch Control Center and press buildings. Dust was dislodged from the ceiling of the Launch Control Center and formed a layer on the consoles of mission controllers. William Donn of Columbia University described the blast as one of the loudest noises, natural or artificial, in human history, excepting nuclear explosions. CBS's commentator, Walter Cronkite, and producer Jeff Gralnick put their hands on their trailer's observation window to stop it from shattering as ceiling tiles fell from above. Cronkite found Apollo4 to be the most frightening space mission he covered."
    },
    {
        "source": "On November 6, 1967, at 10:30pm EST (03:30 November7 UTC), the 56+12-hour countdown sequence began with propellant loading. In total there were 89 trailer-truck loads of liquid oxygen, 28 trailer loads of LH2 (liquid hydrogen), and 27 rail cars of RP-1 (highly refined kerosene). This time the problems encountered were few and minor, and did not delay the launch due to the use of built-in holds in the countdown, during which time accumulated delays were made good. Apollo 4 launched on November9 at 7:00am EST (noon UTC). Eight seconds before liftoff, the five F-1 engines ignited, sending tremendous amounts of noise across Kennedy Space Center. Even though the launch pads at LC-39 were more than five kilometers (three miles) from the Vehicle Assembly Building, the sound pressure was much stronger than expected and buffeted the VAB, Launch Control Center and press buildings. Dust was dislodged from the ceiling of the Launch Control Center and formed a layer on the consoles of mission controllers. William Donn of Columbia University described the blast as one of the loudest noises, natural or artificial, in human history, excepting nuclear explosions. CBS's commentator, Walter Cronkite, and producer Jeff Gralnick put their hands on their trailer's observation window to stop it from shattering as ceiling tiles fell from above. Cronkite found Apollo4 to be the most frightening space mission he covered.",
        "target": "The launch placed the S-IVB and CSM into a nearly circular 190-kilometer (100nmi) orbit, a nominal parking orbit that would be used on the lunar missions. After two orbits, in a simulation of the trans-lunar injection burn that would take later Apollo missions towards the Moon, the S-IVB's first in-space re-ignition put the spacecraft into an elliptical orbit with an apogee of 17,218 kilometers (9,297nmi) and a perigee deliberately aimed 84.6 kilometers (45.7nmi) below the Earth's surface; this would ensure both a high-speed atmospheric re-entry of the command module, and destruction after re-entry of the S-IVB. Shortly after this burn, the CSM separated from the S-IVB and fired its service module engine to adjust the apogee to 18,092 kilometers (9,769nmi). After passing apogee, the service module engine fired again for 281 seconds to increase re-entry speed to 11,168 meters per second (36,639ft/s), at an altitude of 120 kilometers (400,000ft) and a flight path angle of 6.93 degrees, simulating conditions on a return from the Moon."
    },
    {
        "source": "Apollo 4 launched on November9 at 7:00am EST (noon UTC). Eight seconds before liftoff, the five F-1 engines ignited, sending tremendous amounts of noise across Kennedy Space Center. Even though the launch pads at LC-39 were more than five kilometers (three miles) from the Vehicle Assembly Building, the sound pressure was much stronger than expected and buffeted the VAB, Launch Control Center and press buildings. Dust was dislodged from the ceiling of the Launch Control Center and formed a layer on the consoles of mission controllers. William Donn of Columbia University described the blast as one of the loudest noises, natural or artificial, in human history, excepting nuclear explosions. CBS's commentator, Walter Cronkite, and producer Jeff Gralnick put their hands on their trailer's observation window to stop it from shattering as ceiling tiles fell from above. Cronkite found Apollo4 to be the most frightening space mission he covered. The launch placed the S-IVB and CSM into a nearly circular 190-kilometer (100nmi) orbit, a nominal parking orbit that would be used on the lunar missions. After two orbits, in a simulation of the trans-lunar injection burn that would take later Apollo missions towards the Moon, the S-IVB's first in-space re-ignition put the spacecraft into an elliptical orbit with an apogee of 17,218 kilometers (9,297nmi) and a perigee deliberately aimed 84.6 kilometers (45.7nmi) below the Earth's surface; this would ensure both a high-speed atmospheric re-entry of the command module, and destruction after re-entry of the S-IVB. Shortly after this burn, the CSM separated from the S-IVB and fired its service module engine to adjust the apogee to 18,092 kilometers (9,769nmi). After passing apogee, the service module engine fired again for 281 seconds to increase re-entry speed to 11,168 meters per second (36,639ft/s), at an altitude of 120 kilometers (400,000ft) and a flight path angle of 6.93 degrees, simulating conditions on a return from the Moon.",
        "target": "The CM landed approximately 8.6 nautical miles (16km) from the target landing site northwest of Midway Island in the North Pacific Ocean. Its descent was visible from the deck of the aircraft carrier USSBennington, the prime recovery ship, which within two hours had recovered it and one of its parachutes, the first time an Apollo parachute had been recovered for inspection. The spacecraft was brought to Hawaii for deactivation, after which it was taken to North American's facility in Downey, California, for post-flight analysis."
    },
    {
        "source": "The launch placed the S-IVB and CSM into a nearly circular 190-kilometer (100nmi) orbit, a nominal parking orbit that would be used on the lunar missions. After two orbits, in a simulation of the trans-lunar injection burn that would take later Apollo missions towards the Moon, the S-IVB's first in-space re-ignition put the spacecraft into an elliptical orbit with an apogee of 17,218 kilometers (9,297nmi) and a perigee deliberately aimed 84.6 kilometers (45.7nmi) below the Earth's surface; this would ensure both a high-speed atmospheric re-entry of the command module, and destruction after re-entry of the S-IVB. Shortly after this burn, the CSM separated from the S-IVB and fired its service module engine to adjust the apogee to 18,092 kilometers (9,769nmi). After passing apogee, the service module engine fired again for 281 seconds to increase re-entry speed to 11,168 meters per second (36,639ft/s), at an altitude of 120 kilometers (400,000ft) and a flight path angle of 6.93 degrees, simulating conditions on a return from the Moon. The CM landed approximately 8.6 nautical miles (16km) from the target landing site northwest of Midway Island in the North Pacific Ocean. Its descent was visible from the deck of the aircraft carrier USSBennington, the prime recovery ship, which within two hours had recovered it and one of its parachutes, the first time an Apollo parachute had been recovered for inspection. The spacecraft was brought to Hawaii for deactivation, after which it was taken to North American's facility in Downey, California, for post-flight analysis.",
        "target": "Two motion-picture cameras were aboard Apollo4. These were mounted on the SaturnV so as to capture the separation of the first stage and interstage from the launch vehicle. They would then be ejected, descend to the Atlantic Ocean in pods with parachutes and radio beacons, and be recovered about 870 kilometers (470nmi) downrange of KSC."
    },
    {
        "source": "The CM landed approximately 8.6 nautical miles (16km) from the target landing site northwest of Midway Island in the North Pacific Ocean. Its descent was visible from the deck of the aircraft carrier USSBennington, the prime recovery ship, which within two hours had recovered it and one of its parachutes, the first time an Apollo parachute had been recovered for inspection. The spacecraft was brought to Hawaii for deactivation, after which it was taken to North American's facility in Downey, California, for post-flight analysis. Two motion-picture cameras were aboard Apollo4. These were mounted on the SaturnV so as to capture the separation of the first stage and interstage from the launch vehicle. They would then be ejected, descend to the Atlantic Ocean in pods with parachutes and radio beacons, and be recovered about 870 kilometers (470nmi) downrange of KSC.",
        "target": "The command module contained an automatic 70mm film camera which captured photographs of almost the entire Earth. For a period of two hours and thirteen minutes as the craft approached and passed its apogee, a total of 755 color images were taken through the Command Pilot's (left-hand) forward-looking window, at altitudes ranging from 13,510 to 18,092 kilometers (7,295 to 9,769nmi). These were the color images taken from the highest altitude at that time. The photographs were not of sufficient resolution to obtain detailed scientific data, but were still of interest to those involved in the Earth sciences."
    },
    {
        "source": "Two motion-picture cameras were aboard Apollo4. These were mounted on the SaturnV so as to capture the separation of the first stage and interstage from the launch vehicle. They would then be ejected, descend to the Atlantic Ocean in pods with parachutes and radio beacons, and be recovered about 870 kilometers (470nmi) downrange of KSC. The command module contained an automatic 70mm film camera which captured photographs of almost the entire Earth. For a period of two hours and thirteen minutes as the craft approached and passed its apogee, a total of 755 color images were taken through the Command Pilot's (left-hand) forward-looking window, at altitudes ranging from 13,510 to 18,092 kilometers (7,295 to 9,769nmi). These were the color images taken from the highest altitude at that time. The photographs were not of sufficient resolution to obtain detailed scientific data, but were still of interest to those involved in the Earth sciences.",
        "target": "Technically, managerially, and psychologically, Apollo4 was an important and successful mission, especially in view of the number of firsts it tackled. It was the first flight of the first and second stages of the SaturnV (the S-IVB stage had flown on the SaturnIB launch vehicles), the first launch of the complete SaturnV, the first restart of the S-IVB in orbital flight, the first liftoff from Complex 39, the first flight test of the BlockII command module heatshield, the first flight of even a simulated lunar module, and so on. The fact that everything worked so well and with so little trouble gave NASA a confident feeling, as Phillips phrased it, that \"Apollo [was] on the way to the moon.\""
    },
    {
        "source": "The command module contained an automatic 70mm film camera which captured photographs of almost the entire Earth. For a period of two hours and thirteen minutes as the craft approached and passed its apogee, a total of 755 color images were taken through the Command Pilot's (left-hand) forward-looking window, at altitudes ranging from 13,510 to 18,092 kilometers (7,295 to 9,769nmi). These were the color images taken from the highest altitude at that time. The photographs were not of sufficient resolution to obtain detailed scientific data, but were still of interest to those involved in the Earth sciences. Technically, managerially, and psychologically, Apollo4 was an important and successful mission, especially in view of the number of firsts it tackled. It was the first flight of the first and second stages of the SaturnV (the S-IVB stage had flown on the SaturnIB launch vehicles), the first launch of the complete SaturnV, the first restart of the S-IVB in orbital flight, the first liftoff from Complex 39, the first flight test of the BlockII command module heatshield, the first flight of even a simulated lunar module, and so on. The fact that everything worked so well and with so little trouble gave NASA a confident feeling, as Phillips phrased it, that \"Apollo [was] on the way to the moon.\"",
        "target": "Courtney G. Brooks, James M. Grimwood and Loyd S. Swenson, Chariots for Apollo: A History of Manned Lunar Spacecraft (1979)"
    },
    {
        "source": "Technically, managerially, and psychologically, Apollo4 was an important and successful mission, especially in view of the number of firsts it tackled. It was the first flight of the first and second stages of the SaturnV (the S-IVB stage had flown on the SaturnIB launch vehicles), the first launch of the complete SaturnV, the first restart of the S-IVB in orbital flight, the first liftoff from Complex 39, the first flight test of the BlockII command module heatshield, the first flight of even a simulated lunar module, and so on. The fact that everything worked so well and with so little trouble gave NASA a confident feeling, as Phillips phrased it, that \"Apollo [was] on the way to the moon.\" Courtney G. Brooks, James M. Grimwood and Loyd S. Swenson, Chariots for Apollo: A History of Manned Lunar Spacecraft (1979)",
        "target": "All Apollo 4 launch vehicle and spacecraft systems performed satisfactorily. On the climb to orbit, each of the SaturnV's three stages burned for slightly longer than expected. This left the craft in an orbit roughly one kilometer higher than expected, something well within tolerance. A burn eleven seconds longer than planned meant that the CM entered the Earth's atmosphere slightly faster and at a shallower angle than planned, but still within tolerance. This discrepancy happened not because of the performance of the guidance system (which was exemplary), but because the burn had been controlled from Earth. The CM's environmental control system kept the ship's cabin within acceptable temperatures and pressures throughout the mission, increasing by only 5.6C (10F) during atmospheric entry."
    },
    {
        "source": "Courtney G. Brooks, James M. Grimwood and Loyd S. Swenson, Chariots for Apollo: A History of Manned Lunar Spacecraft (1979) All Apollo 4 launch vehicle and spacecraft systems performed satisfactorily. On the climb to orbit, each of the SaturnV's three stages burned for slightly longer than expected. This left the craft in an orbit roughly one kilometer higher than expected, something well within tolerance. A burn eleven seconds longer than planned meant that the CM entered the Earth's atmosphere slightly faster and at a shallower angle than planned, but still within tolerance. This discrepancy happened not because of the performance of the guidance system (which was exemplary), but because the burn had been controlled from Earth. The CM's environmental control system kept the ship's cabin within acceptable temperatures and pressures throughout the mission, increasing by only 5.6C (10F) during atmospheric entry.",
        "target": "President Lyndon Johnson described the launch, \"The whole world could see the awesome sight of the first launch of what is now the largest rocket ever flown. This launching symbolizes the power this nation is harnessing for the peaceful exploration of space.\" Von Braun spoke of the mission as \"an expert launching all the way through, from lift-off exactly on time to performance of every single stage\". In his history of the SaturnV, Roger E. Bilstein wrote that \"the flawless mission of Apollo4 elated the entire NASA organization; everyone looked ahead with buoyant spirits.\" Mueller stated that Apollo4 dramatically increased the confidence of many and showed it should be possible for astronauts to land on the Moon by mid-1969."
    },
    {
        "source": "All Apollo 4 launch vehicle and spacecraft systems performed satisfactorily. On the climb to orbit, each of the SaturnV's three stages burned for slightly longer than expected. This left the craft in an orbit roughly one kilometer higher than expected, something well within tolerance. A burn eleven seconds longer than planned meant that the CM entered the Earth's atmosphere slightly faster and at a shallower angle than planned, but still within tolerance. This discrepancy happened not because of the performance of the guidance system (which was exemplary), but because the burn had been controlled from Earth. The CM's environmental control system kept the ship's cabin within acceptable temperatures and pressures throughout the mission, increasing by only 5.6C (10F) during atmospheric entry. President Lyndon Johnson described the launch, \"The whole world could see the awesome sight of the first launch of what is now the largest rocket ever flown. This launching symbolizes the power this nation is harnessing for the peaceful exploration of space.\" Von Braun spoke of the mission as \"an expert launching all the way through, from lift-off exactly on time to performance of every single stage\". In his history of the SaturnV, Roger E. Bilstein wrote that \"the flawless mission of Apollo4 elated the entire NASA organization; everyone looked ahead with buoyant spirits.\" Mueller stated that Apollo4 dramatically increased the confidence of many and showed it should be possible for astronauts to land on the Moon by mid-1969.",
        "target": "Apollo 6, the second flight of the SaturnV, was launched on April 4, 1968. Although the SaturnV's stages gave more trouble than on Apollo4 (the mission experienced pogo oscillation during its first stage and had an early second-stage engine shutdown), it was decided that a third uncrewed flight was unnecessary. The SaturnV flew with a crew for the first time on Apollo8. A SaturnV launched astronauts into space, and (except for Apollo 9) towards the Moon, on each of the Apollo missions that followed."
    },
    {
        "source": "President Lyndon Johnson described the launch, \"The whole world could see the awesome sight of the first launch of what is now the largest rocket ever flown. This launching symbolizes the power this nation is harnessing for the peaceful exploration of space.\" Von Braun spoke of the mission as \"an expert launching all the way through, from lift-off exactly on time to performance of every single stage\". In his history of the SaturnV, Roger E. Bilstein wrote that \"the flawless mission of Apollo4 elated the entire NASA organization; everyone looked ahead with buoyant spirits.\" Mueller stated that Apollo4 dramatically increased the confidence of many and showed it should be possible for astronauts to land on the Moon by mid-1969. Apollo 6, the second flight of the SaturnV, was launched on April 4, 1968. Although the SaturnV's stages gave more trouble than on Apollo4 (the mission experienced pogo oscillation during its first stage and had an early second-stage engine shutdown), it was decided that a third uncrewed flight was unnecessary. The SaturnV flew with a crew for the first time on Apollo8. A SaturnV launched astronauts into space, and (except for Apollo 9) towards the Moon, on each of the Apollo missions that followed.",
        "target": "In January 1969 CM-017 was transferred to the Smithsonian Institution. As of 1978, it was on display at the North Carolina Museum of Life and Science. The CM was subsequently put on public display at NASA's Stennis Space Center, where it remained until 2017. It is currently on display at Stennis Space Center's visitor center, the Infinity Science Center, in Pearlington, Mississippi."
    },
    {
        "source": " Apollo 5 (launched January22, 1968), also known as AS-204, was the uncrewed first flight of the Apollo Lunar Module (LM) that would later carry astronauts to the surface of the Moon. The Saturn IB rocket bearing the LM lifted off from Cape Kennedy on January22, 1968. The mission was successful, though due to programming problems an alternate mission to that originally planned was executed.",
        "target": "Like Apollo 4, this flight was long delayed, due in part to setbacks in development of the LM, manufactured by Grumman Aircraft. The original Saturn IB rocket that was to take the first LM (LM-1) to space was taken down during the delays and replaced with the one that would have launched Apollo 1 if the spacecraft fire that killed three astronauts had not occurred. LM-1 arrived at the Kennedy Space Center in June 1967; the following months were occupied in testing and placing the LM atop the Saturn IB. After final delays due to equipment trouble, the countdown began on January21, 1968, and the space vehicle was launched the following day."
    },
    {
        "source": "Apollo 5 (launched January22, 1968), also known as AS-204, was the uncrewed first flight of the Apollo Lunar Module (LM) that would later carry astronauts to the surface of the Moon. The Saturn IB rocket bearing the LM lifted off from Cape Kennedy on January22, 1968. The mission was successful, though due to programming problems an alternate mission to that originally planned was executed. Like Apollo 4, this flight was long delayed, due in part to setbacks in development of the LM, manufactured by Grumman Aircraft. The original Saturn IB rocket that was to take the first LM (LM-1) to space was taken down during the delays and replaced with the one that would have launched Apollo 1 if the spacecraft fire that killed three astronauts had not occurred. LM-1 arrived at the Kennedy Space Center in June 1967; the following months were occupied in testing and placing the LM atop the Saturn IB. After final delays due to equipment trouble, the countdown began on January21, 1968, and the space vehicle was launched the following day.",
        "target": "Once the craft reached orbit and the LM separated from the S-IVB booster, the program of orbital testing began, but a planned burn was aborted automatically when the Apollo Guidance Computer detected the craft was not going as fast as planned. Flight Director Gene Kranz and his team at Mission Control in Houston quickly decided on an alternate mission, during which the mission's goals of testing LM-1 were accomplished. The mission was successful enough that a contemplated second uncrewed mission to test the LM was cancelled, advancing NASA's plans to land an astronaut on the Moon by the end of the 1960s."
    },
    {
        "source": "Like Apollo 4, this flight was long delayed, due in part to setbacks in development of the LM, manufactured by Grumman Aircraft. The original Saturn IB rocket that was to take the first LM (LM-1) to space was taken down during the delays and replaced with the one that would have launched Apollo 1 if the spacecraft fire that killed three astronauts had not occurred. LM-1 arrived at the Kennedy Space Center in June 1967; the following months were occupied in testing and placing the LM atop the Saturn IB. After final delays due to equipment trouble, the countdown began on January21, 1968, and the space vehicle was launched the following day. Once the craft reached orbit and the LM separated from the S-IVB booster, the program of orbital testing began, but a planned burn was aborted automatically when the Apollo Guidance Computer detected the craft was not going as fast as planned. Flight Director Gene Kranz and his team at Mission Control in Houston quickly decided on an alternate mission, during which the mission's goals of testing LM-1 were accomplished. The mission was successful enough that a contemplated second uncrewed mission to test the LM was cancelled, advancing NASA's plans to land an astronaut on the Moon by the end of the 1960s.",
        "target": "In 1961, United States President John F. Kennedy challenged the United States to land an astronaut on the Moon by the end of the decade, with a safe return to Earth. After considerable debate, NASA (the US government's spaceflight agency) decided in late 1962 that lunar missions would use a lunar orbit rendezvous in which the complete Apollo spacecraft would be propelled towards lunar orbit by the Saturn V launch vehicle's third stage (called the S-IVB). Once in lunar orbit, those astronauts who would land on the Moon would enter what was then called the lunar excursion module (LEM) (later called the lunar module (LM)). This craft would separate from the Apollo's command and service module (CSM) and land on the Moon. When the astronauts were ready to return, they would enter the LM, take off, and re-dock with the CSM. Once the crew reentered the CSM, they would discard the lunar module and return to Earth in the CSM. In 1962, NASA invited eleven companies to bid for the contract to construct the LM. On November7, 1962, NASA announced that it had awarded the contract to Grumman in Bethpage, New York."
    },
    {
        "source": "Once the craft reached orbit and the LM separated from the S-IVB booster, the program of orbital testing began, but a planned burn was aborted automatically when the Apollo Guidance Computer detected the craft was not going as fast as planned. Flight Director Gene Kranz and his team at Mission Control in Houston quickly decided on an alternate mission, during which the mission's goals of testing LM-1 were accomplished. The mission was successful enough that a contemplated second uncrewed mission to test the LM was cancelled, advancing NASA's plans to land an astronaut on the Moon by the end of the 1960s. In 1961, United States President John F. Kennedy challenged the United States to land an astronaut on the Moon by the end of the decade, with a safe return to Earth. After considerable debate, NASA (the US government's spaceflight agency) decided in late 1962 that lunar missions would use a lunar orbit rendezvous in which the complete Apollo spacecraft would be propelled towards lunar orbit by the Saturn V launch vehicle's third stage (called the S-IVB). Once in lunar orbit, those astronauts who would land on the Moon would enter what was then called the lunar excursion module (LEM) (later called the lunar module (LM)). This craft would separate from the Apollo's command and service module (CSM) and land on the Moon. When the astronauts were ready to return, they would enter the LM, take off, and re-dock with the CSM. Once the crew reentered the CSM, they would discard the lunar module and return to Earth in the CSM. In 1962, NASA invited eleven companies to bid for the contract to construct the LM. On November7, 1962, NASA announced that it had awarded the contract to Grumman in Bethpage, New York.",
        "target": "As with Apollo 4, there were significant delays for Apollo5. The primary cause of the Apollo5 delays was the LM, which was behind schedule. Apollo Program Manager Major General Samuel C. Phillips had originally hoped that the uncrewed test flight of LM-1, the first lunar module, would launch in April 1967. Anticipating six months for checkout and testing of the vehicle, NASA asked Grumman to have LM-1 delivered to Kennedy Space Center in Florida by September 1966, but due to difficulties in manufacturing LM-1, delivery was repeatedly delayed. The delivery date was still uncertain when AS-206, the Saturn IB launch vehicle planned to boost LM-1 to orbit, was erected at Launch Complex 37 in January 1967. After the fire that month that killed the Apollo 1 crew, the launch vehicle planned for Apollo1, AS-204, was moved from Launch Complex 34 to Launch Complex37 and replaced AS-206. This was done because AS-204 was the last Saturn IB with full research and development instrumentation, and, with crewed flight on hold, NASA wanted to use that booster for the first flight of the LM.[a]"
    },
    {
        "source": "In 1961, United States President John F. Kennedy challenged the United States to land an astronaut on the Moon by the end of the decade, with a safe return to Earth. After considerable debate, NASA (the US government's spaceflight agency) decided in late 1962 that lunar missions would use a lunar orbit rendezvous in which the complete Apollo spacecraft would be propelled towards lunar orbit by the Saturn V launch vehicle's third stage (called the S-IVB). Once in lunar orbit, those astronauts who would land on the Moon would enter what was then called the lunar excursion module (LEM) (later called the lunar module (LM)). This craft would separate from the Apollo's command and service module (CSM) and land on the Moon. When the astronauts were ready to return, they would enter the LM, take off, and re-dock with the CSM. Once the crew reentered the CSM, they would discard the lunar module and return to Earth in the CSM. In 1962, NASA invited eleven companies to bid for the contract to construct the LM. On November7, 1962, NASA announced that it had awarded the contract to Grumman in Bethpage, New York. As with Apollo 4, there were significant delays for Apollo5. The primary cause of the Apollo5 delays was the LM, which was behind schedule. Apollo Program Manager Major General Samuel C. Phillips had originally hoped that the uncrewed test flight of LM-1, the first lunar module, would launch in April 1967. Anticipating six months for checkout and testing of the vehicle, NASA asked Grumman to have LM-1 delivered to Kennedy Space Center in Florida by September 1966, but due to difficulties in manufacturing LM-1, delivery was repeatedly delayed. The delivery date was still uncertain when AS-206, the Saturn IB launch vehicle planned to boost LM-1 to orbit, was erected at Launch Complex 37 in January 1967. After the fire that month that killed the Apollo 1 crew, the launch vehicle planned for Apollo1, AS-204, was moved from Launch Complex 34 to Launch Complex37 and replaced AS-206. This was done because AS-204 was the last Saturn IB with full research and development instrumentation, and, with crewed flight on hold, NASA wanted to use that booster for the first flight of the LM.[a]",
        "target": "With no LM yet available, Grumman built a plywood mockup of one at Launch Complex37 to aid in facilities verification. On May12, 1967, Apollo Program Spacecraft Manager George M. Low informed NASA headquarters that Grumman was committed to a June28 delivery of LM-1, though Low noted that the goal would be hard to meet. On June23, LM-1 arrived at Cape Kennedy on board Aero Spacelines' Super Guppy; the stages were mated to each other four days later. A 400-person team under John J. Williams, a veteran of launch operations for both Mercury and Gemini, checked to see that LM-1 met specifications, after which they supervised Grumman technicians, who tested and modified the vehicle. Due to leaks in the LM's ascent stage, the two stages were demated in August, and after these were fixed and the stages remated, another leak developed and the stages were demated again in September. During this time, several pieces of equipment were removed for repair by Grumman; the stages were remated again in October."
    },
    {
        "source": "As with Apollo 4, there were significant delays for Apollo5. The primary cause of the Apollo5 delays was the LM, which was behind schedule. Apollo Program Manager Major General Samuel C. Phillips had originally hoped that the uncrewed test flight of LM-1, the first lunar module, would launch in April 1967. Anticipating six months for checkout and testing of the vehicle, NASA asked Grumman to have LM-1 delivered to Kennedy Space Center in Florida by September 1966, but due to difficulties in manufacturing LM-1, delivery was repeatedly delayed. The delivery date was still uncertain when AS-206, the Saturn IB launch vehicle planned to boost LM-1 to orbit, was erected at Launch Complex 37 in January 1967. After the fire that month that killed the Apollo 1 crew, the launch vehicle planned for Apollo1, AS-204, was moved from Launch Complex 34 to Launch Complex37 and replaced AS-206. This was done because AS-204 was the last Saturn IB with full research and development instrumentation, and, with crewed flight on hold, NASA wanted to use that booster for the first flight of the LM.[a] With no LM yet available, Grumman built a plywood mockup of one at Launch Complex37 to aid in facilities verification. On May12, 1967, Apollo Program Spacecraft Manager George M. Low informed NASA headquarters that Grumman was committed to a June28 delivery of LM-1, though Low noted that the goal would be hard to meet. On June23, LM-1 arrived at Cape Kennedy on board Aero Spacelines' Super Guppy; the stages were mated to each other four days later. A 400-person team under John J. Williams, a veteran of launch operations for both Mercury and Gemini, checked to see that LM-1 met specifications, after which they supervised Grumman technicians, who tested and modified the vehicle. Due to leaks in the LM's ascent stage, the two stages were demated in August, and after these were fixed and the stages remated, another leak developed and the stages were demated again in September. During this time, several pieces of equipment were removed for repair by Grumman; the stages were remated again in October.",
        "target": "As of September6, 1967, Apollo5 was running about 39days behind the plan established on July18, but all known issues were being dealt with, with the exception of some leaks from the propulsion system. Most mission documents were ready by late 1967; Mission Director William C. Schneider issued mission rules on November18, 1967. The following day, LM-1 was mated to its launch vehicle, and the space vehicle readiness test was completed in December. In early January 1968, the office of NASA Administrator James E. Webb announced that Apollo 5 would be launched no earlier than January18, 1968. Minor faults such as clogged filters led to some additional delays. The countdown demonstration test concluded on January19 and an abbreviated 22-hour countdown began on January21."
    },
    {
        "source": "With no LM yet available, Grumman built a plywood mockup of one at Launch Complex37 to aid in facilities verification. On May12, 1967, Apollo Program Spacecraft Manager George M. Low informed NASA headquarters that Grumman was committed to a June28 delivery of LM-1, though Low noted that the goal would be hard to meet. On June23, LM-1 arrived at Cape Kennedy on board Aero Spacelines' Super Guppy; the stages were mated to each other four days later. A 400-person team under John J. Williams, a veteran of launch operations for both Mercury and Gemini, checked to see that LM-1 met specifications, after which they supervised Grumman technicians, who tested and modified the vehicle. Due to leaks in the LM's ascent stage, the two stages were demated in August, and after these were fixed and the stages remated, another leak developed and the stages were demated again in September. During this time, several pieces of equipment were removed for repair by Grumman; the stages were remated again in October. As of September6, 1967, Apollo5 was running about 39days behind the plan established on July18, but all known issues were being dealt with, with the exception of some leaks from the propulsion system. Most mission documents were ready by late 1967; Mission Director William C. Schneider issued mission rules on November18, 1967. The following day, LM-1 was mated to its launch vehicle, and the space vehicle readiness test was completed in December. In early January 1968, the office of NASA Administrator James E. Webb announced that Apollo 5 would be launched no earlier than January18, 1968. Minor faults such as clogged filters led to some additional delays. The countdown demonstration test concluded on January19 and an abbreviated 22-hour countdown began on January21.",
        "target": "Apollo5 was intended to verify the operation of the subsystems of the LM. During the flight, the ascent and descent engines would be fired. A \"fire in the hole\" test would be conducted to verify that the ascent stage could still fire while attached to the descent stage, a procedure that would be used on the lunar surface and in the event of an aborted lunar landing. It involved shutting down the descent stage, switching control and power to the ascent stage, and starting the ascent engine while the two stages were still mated. The term \"fire in the hole\" derived from a term used in mining when explosives are about to be used. Additional testing was to check that the LM engines could be restarted after initial use. In addition to testing LM systems, Apollo5 was to test the Instrument Unit in its SaturnV configuration."
    },
    {
        "source": "As of September6, 1967, Apollo5 was running about 39days behind the plan established on July18, but all known issues were being dealt with, with the exception of some leaks from the propulsion system. Most mission documents were ready by late 1967; Mission Director William C. Schneider issued mission rules on November18, 1967. The following day, LM-1 was mated to its launch vehicle, and the space vehicle readiness test was completed in December. In early January 1968, the office of NASA Administrator James E. Webb announced that Apollo 5 would be launched no earlier than January18, 1968. Minor faults such as clogged filters led to some additional delays. The countdown demonstration test concluded on January19 and an abbreviated 22-hour countdown began on January21. Apollo5 was intended to verify the operation of the subsystems of the LM. During the flight, the ascent and descent engines would be fired. A \"fire in the hole\" test would be conducted to verify that the ascent stage could still fire while attached to the descent stage, a procedure that would be used on the lunar surface and in the event of an aborted lunar landing. It involved shutting down the descent stage, switching control and power to the ascent stage, and starting the ascent engine while the two stages were still mated. The term \"fire in the hole\" derived from a term used in mining when explosives are about to be used. Additional testing was to check that the LM engines could be restarted after initial use. In addition to testing LM systems, Apollo5 was to test the Instrument Unit in its SaturnV configuration.",
        "target": "It was expected that the ascent stage of LM-1 would remain in orbit for about two years before re-entering the atmosphere and disintegrating, and the descent stage for about three weeks."
    },
    {
        "source": "Apollo5 was intended to verify the operation of the subsystems of the LM. During the flight, the ascent and descent engines would be fired. A \"fire in the hole\" test would be conducted to verify that the ascent stage could still fire while attached to the descent stage, a procedure that would be used on the lunar surface and in the event of an aborted lunar landing. It involved shutting down the descent stage, switching control and power to the ascent stage, and starting the ascent engine while the two stages were still mated. The term \"fire in the hole\" derived from a term used in mining when explosives are about to be used. Additional testing was to check that the LM engines could be restarted after initial use. In addition to testing LM systems, Apollo5 was to test the Instrument Unit in its SaturnV configuration. It was expected that the ascent stage of LM-1 would remain in orbit for about two years before re-entering the atmosphere and disintegrating, and the descent stage for about three weeks.",
        "target": "Apollo5 was launched into orbit by the SaturnIB, designated SA-204R, which had been assigned to Apollo1. Originally brought to Cape Kennedy in August 1966, it had survived the fire unscathed, having been inspected after the fire for corrosion or other damage. Ignition weight for the launch vehicle, including the spacecraft and propellant, was 589,413 kilograms (1,299,434lb)."
    },
    {
        "source": "It was expected that the ascent stage of LM-1 would remain in orbit for about two years before re-entering the atmosphere and disintegrating, and the descent stage for about three weeks. Apollo5 was launched into orbit by the SaturnIB, designated SA-204R, which had been assigned to Apollo1. Originally brought to Cape Kennedy in August 1966, it had survived the fire unscathed, having been inspected after the fire for corrosion or other damage. Ignition weight for the launch vehicle, including the spacecraft and propellant, was 589,413 kilograms (1,299,434lb).",
        "target": "The space vehicle for this mission was 55 meters (180ft) tall but had a stubby appearance since it had neither a CSM nor a launch escape system. Instead, the LM was housed within the spacecraft-lunar module adapter (SLA) at the top of the vehicle stack. The SLA, numbered as SLA-7, was just below the nose cap in the stack, and had four panels that would open once the nose cap was jettisoned in orbit, allowing the LM room to separate and move away."
    },
    {
        "source": "Apollo5 was launched into orbit by the SaturnIB, designated SA-204R, which had been assigned to Apollo1. Originally brought to Cape Kennedy in August 1966, it had survived the fire unscathed, having been inspected after the fire for corrosion or other damage. Ignition weight for the launch vehicle, including the spacecraft and propellant, was 589,413 kilograms (1,299,434lb). The space vehicle for this mission was 55 meters (180ft) tall but had a stubby appearance since it had neither a CSM nor a launch escape system. Instead, the LM was housed within the spacecraft-lunar module adapter (SLA) at the top of the vehicle stack. The SLA, numbered as SLA-7, was just below the nose cap in the stack, and had four panels that would open once the nose cap was jettisoned in orbit, allowing the LM room to separate and move away.",
        "target": "The LM, designated as LM-1, was the first flight-ready Apollo lunar module. To save weight, and because they would not be necessary during the test mission, LM-1 had no landing legs."
    },
    {
        "source": "The space vehicle for this mission was 55 meters (180ft) tall but had a stubby appearance since it had neither a CSM nor a launch escape system. Instead, the LM was housed within the spacecraft-lunar module adapter (SLA) at the top of the vehicle stack. The SLA, numbered as SLA-7, was just below the nose cap in the stack, and had four panels that would open once the nose cap was jettisoned in orbit, allowing the LM room to separate and move away. The LM, designated as LM-1, was the first flight-ready Apollo lunar module. To save weight, and because they would not be necessary during the test mission, LM-1 had no landing legs.",
        "target": "After one of the windows of LM-5 (which would fly on Apollo 11) broke during testing in December 1967, NASA officials decided to replace the windows of LM-1 with aluminum plates out of concern a window might fail in flight. Since there would be no astronauts aboard, LM-1 had a mission programmer installed, which could control the craft remotely. Not all LM-1 systems were fully activated nor was it given a full load of consumables: for example, its primary batteries were partially discharged to avoid over-voltage complications, and the oxygen tanks for the environmental control systems were only partially full."
    },
    {
        "source": "The LM, designated as LM-1, was the first flight-ready Apollo lunar module. To save weight, and because they would not be necessary during the test mission, LM-1 had no landing legs. After one of the windows of LM-5 (which would fly on Apollo 11) broke during testing in December 1967, NASA officials decided to replace the windows of LM-1 with aluminum plates out of concern a window might fail in flight. Since there would be no astronauts aboard, LM-1 had a mission programmer installed, which could control the craft remotely. Not all LM-1 systems were fully activated nor was it given a full load of consumables: for example, its primary batteries were partially discharged to avoid over-voltage complications, and the oxygen tanks for the environmental control systems were only partially full.",
        "target": "On January22, 1968, Apollo 5 lifted off from Launch Complex37B at Cape Kennedy Air Force Station at 17:48:08 Eastern Standard Time (22:48:08 UTC). The SaturnIB worked perfectly, inserting the second stage and LM into an 88-by-120-nautical-mile (163 by 222km) orbit.[b] The nose cone was jettisoned, and after a coast of 43minutes 52seconds, the LM separated from its adapter, in a 90-by-120-nautical-mile (167 by 222km) orbit."
    },
    {
        "source": "After one of the windows of LM-5 (which would fly on Apollo 11) broke during testing in December 1967, NASA officials decided to replace the windows of LM-1 with aluminum plates out of concern a window might fail in flight. Since there would be no astronauts aboard, LM-1 had a mission programmer installed, which could control the craft remotely. Not all LM-1 systems were fully activated nor was it given a full load of consumables: for example, its primary batteries were partially discharged to avoid over-voltage complications, and the oxygen tanks for the environmental control systems were only partially full. On January22, 1968, Apollo 5 lifted off from Launch Complex37B at Cape Kennedy Air Force Station at 17:48:08 Eastern Standard Time (22:48:08 UTC). The SaturnIB worked perfectly, inserting the second stage and LM into an 88-by-120-nautical-mile (163 by 222km) orbit.[b] The nose cone was jettisoned, and after a coast of 43minutes 52seconds, the LM separated from its adapter, in a 90-by-120-nautical-mile (167 by 222km) orbit.",
        "target": "After two orbits, the first planned 39-second descent-engine burn was started, but this was aborted after only four seconds by the Apollo Guidance Computer, which detected that the spacecraft was not going as fast as expected. This happened because one of the engine's valves was suspected of being leaky and was not armed until it was time to ignite the engine, in orbit, which meant that the propellant took longer to reach the engine, leading to the lag. Programmers could have adjusted the software to account for this, but were not told. In addition, the tanks were only half full, and this contributed to the slowness of the ship. Had this occurred on a crewed mission, the astronauts would have been able to analyze the situation and decide whether the engine should be restarted."
    },
    {
        "source": "On January22, 1968, Apollo 5 lifted off from Launch Complex37B at Cape Kennedy Air Force Station at 17:48:08 Eastern Standard Time (22:48:08 UTC). The SaturnIB worked perfectly, inserting the second stage and LM into an 88-by-120-nautical-mile (163 by 222km) orbit.[b] The nose cone was jettisoned, and after a coast of 43minutes 52seconds, the LM separated from its adapter, in a 90-by-120-nautical-mile (167 by 222km) orbit. After two orbits, the first planned 39-second descent-engine burn was started, but this was aborted after only four seconds by the Apollo Guidance Computer, which detected that the spacecraft was not going as fast as expected. This happened because one of the engine's valves was suspected of being leaky and was not armed until it was time to ignite the engine, in orbit, which meant that the propellant took longer to reach the engine, leading to the lag. Programmers could have adjusted the software to account for this, but were not told. In addition, the tanks were only half full, and this contributed to the slowness of the ship. Had this occurred on a crewed mission, the astronauts would have been able to analyze the situation and decide whether the engine should be restarted.",
        "target": "Gene Kranz was the flight director for Apollo5. Mission Control, under Kranz's command, decided on a plan to conduct the engine and \"fire-in-the-hole\" tests under manual control. There were communication problems with the spacecraft, and omitting these tests would have meant the mission was a failure. Despite this, Kranz's team accomplished every burn. The ascent stage spun out of control eight hours into the mission, after completion of the engine burns, due to a problem with the guidance system."
    },
    {
        "source": "After two orbits, the first planned 39-second descent-engine burn was started, but this was aborted after only four seconds by the Apollo Guidance Computer, which detected that the spacecraft was not going as fast as expected. This happened because one of the engine's valves was suspected of being leaky and was not armed until it was time to ignite the engine, in orbit, which meant that the propellant took longer to reach the engine, leading to the lag. Programmers could have adjusted the software to account for this, but were not told. In addition, the tanks were only half full, and this contributed to the slowness of the ship. Had this occurred on a crewed mission, the astronauts would have been able to analyze the situation and decide whether the engine should be restarted. Gene Kranz was the flight director for Apollo5. Mission Control, under Kranz's command, decided on a plan to conduct the engine and \"fire-in-the-hole\" tests under manual control. There were communication problems with the spacecraft, and omitting these tests would have meant the mission was a failure. Despite this, Kranz's team accomplished every burn. The ascent stage spun out of control eight hours into the mission, after completion of the engine burns, due to a problem with the guidance system.",
        "target": "The stages were left in a low enough orbit that atmospheric drag would soon cause their orbits to decay and re-enter the atmosphere. The ascent stage re-entered on January24 and burned up; the descent stage re-entered on February12, falling into the Pacific several hundred miles southwest of Guam. Simulations showed that the S-IVB stage of the launch vehicle (1968-007B) re-entered about 15.5hours into the flight."
    },
    {
        "source": "Gene Kranz was the flight director for Apollo5. Mission Control, under Kranz's command, decided on a plan to conduct the engine and \"fire-in-the-hole\" tests under manual control. There were communication problems with the spacecraft, and omitting these tests would have meant the mission was a failure. Despite this, Kranz's team accomplished every burn. The ascent stage spun out of control eight hours into the mission, after completion of the engine burns, due to a problem with the guidance system. The stages were left in a low enough orbit that atmospheric drag would soon cause their orbits to decay and re-enter the atmosphere. The ascent stage re-entered on January24 and burned up; the descent stage re-entered on February12, falling into the Pacific several hundred miles southwest of Guam. Simulations showed that the S-IVB stage of the launch vehicle (1968-007B) re-entered about 15.5hours into the flight.",
        "target": "Apollo Spacecraft Program Manager George M. Low said that Apollo5's success \"was due to the fact that we had a good piece of hardware; it was due to the fact that we had outstanding flight control teams under Gene Kranz' able leadership.\" Despite the trouble during the descent-engine burn, NASA deemed the mission a success in demonstrating the LM systems, and a second uncrewed flight test using LM-2 was cancelled. The first crewed LM flight took place on Apollo 9 in March 1969."
    },
    {
        "source": " Apollo 6 (April 4, 1968), also known as AS-502, was the third and final uncrewed flight in the United States' Apollo Program and the second test of the Saturn V launch vehicle. It qualified the Saturn V for use on crewed missions, and it was used beginning with Apollo 8 in December 1968.",
        "target": "Apollo 6 was intended to demonstrate the ability of the Saturn V's third stage, the S-IVB, to propel itself and the Apollo spacecraft to lunar distances. Its components began arriving at the Kennedy Space Center in early 1967. Testing proceeded slowly, often delayed by testing of the Saturn V intended for Apollo 4the inaugural launch of the Saturn V. After that uncrewed mission launched in November 1967, there were fewer delays, but enough so that the flight was postponed from March to April 1968."
    },
    {
        "source": "Apollo 6 (April 4, 1968), also known as AS-502, was the third and final uncrewed flight in the United States' Apollo Program and the second test of the Saturn V launch vehicle. It qualified the Saturn V for use on crewed missions, and it was used beginning with Apollo 8 in December 1968. Apollo 6 was intended to demonstrate the ability of the Saturn V's third stage, the S-IVB, to propel itself and the Apollo spacecraft to lunar distances. Its components began arriving at the Kennedy Space Center in early 1967. Testing proceeded slowly, often delayed by testing of the Saturn V intended for Apollo 4the inaugural launch of the Saturn V. After that uncrewed mission launched in November 1967, there were fewer delays, but enough so that the flight was postponed from March to April 1968.",
        "target": "The flight plan called for, following trans-lunar injection,  a direct return abort using the service module's main engine with a flight time totaling about 10 hours but vibrations damaged some of the Rocketdyne J-2 engines in the second and third stages by rupturing internal fuel lines causing a second-stage engine to shut down early. An additional second-stage engine also shut down early due to cross-wiring with the engine that had shut down. The vehicle's onboard guidance system compensated by burning the second and third stages longer, although the resulting parking orbit was more elliptical than planned. The damaged third-stage engine failed to restart for trans-lunar injection. Flight controllers elected to repeat the flight profile of the previous Apollo 4 test, achieving a high orbit and high-speed return. Despite the engine failures, the flight provided NASA with enough confidence to use the Saturn V for crewed launches; a potential third uncrewed flight was cancelled."
    },
    {
        "source": "Apollo 6 was intended to demonstrate the ability of the Saturn V's third stage, the S-IVB, to propel itself and the Apollo spacecraft to lunar distances. Its components began arriving at the Kennedy Space Center in early 1967. Testing proceeded slowly, often delayed by testing of the Saturn V intended for Apollo 4the inaugural launch of the Saturn V. After that uncrewed mission launched in November 1967, there were fewer delays, but enough so that the flight was postponed from March to April 1968. The flight plan called for, following trans-lunar injection,  a direct return abort using the service module's main engine with a flight time totaling about 10 hours but vibrations damaged some of the Rocketdyne J-2 engines in the second and third stages by rupturing internal fuel lines causing a second-stage engine to shut down early. An additional second-stage engine also shut down early due to cross-wiring with the engine that had shut down. The vehicle's onboard guidance system compensated by burning the second and third stages longer, although the resulting parking orbit was more elliptical than planned. The damaged third-stage engine failed to restart for trans-lunar injection. Flight controllers elected to repeat the flight profile of the previous Apollo 4 test, achieving a high orbit and high-speed return. Despite the engine failures, the flight provided NASA with enough confidence to use the Saturn V for crewed launches; a potential third uncrewed flight was cancelled.",
        "target": "Apollo 6, the second test flight of the \nSaturn V launch vehicle, was intended to send a command and service module (CSM) plus a Lunar Test Article (LTA), a simulated lunar module (LM) with mounted structural vibration sensors, into a trans-lunar trajectory, with the boost from orbit to trans-lunar velocity powered by the Saturn V's third stage, the S-IVB. That trajectory, although passing beyond the orbit of the Moon, would not encounter it. The CSM was to separate from the S-IVB soon after the burn, and the SM engine would then fire to slow the craft, dropping its apogee to 22,204 kilometers (11,989nmi) and causing the CSM to return to Earth, simulating a \"direct-return\" abort. On the return leg, the engine was to fire once more to accelerate the craft to simulate conditions that the Apollo spacecraft would encounter on its return from the Moon, with a re-entry angle of 6.5 degrees and velocity of 11,100 meters per second (36,500ft/s). The entire mission was to last about 10 hours."
    },
    {
        "source": "The flight plan called for, following trans-lunar injection,  a direct return abort using the service module's main engine with a flight time totaling about 10 hours but vibrations damaged some of the Rocketdyne J-2 engines in the second and third stages by rupturing internal fuel lines causing a second-stage engine to shut down early. An additional second-stage engine also shut down early due to cross-wiring with the engine that had shut down. The vehicle's onboard guidance system compensated by burning the second and third stages longer, although the resulting parking orbit was more elliptical than planned. The damaged third-stage engine failed to restart for trans-lunar injection. Flight controllers elected to repeat the flight profile of the previous Apollo 4 test, achieving a high orbit and high-speed return. Despite the engine failures, the flight provided NASA with enough confidence to use the Saturn V for crewed launches; a potential third uncrewed flight was cancelled. Apollo 6, the second test flight of the \nSaturn V launch vehicle, was intended to send a command and service module (CSM) plus a Lunar Test Article (LTA), a simulated lunar module (LM) with mounted structural vibration sensors, into a trans-lunar trajectory, with the boost from orbit to trans-lunar velocity powered by the Saturn V's third stage, the S-IVB. That trajectory, although passing beyond the orbit of the Moon, would not encounter it. The CSM was to separate from the S-IVB soon after the burn, and the SM engine would then fire to slow the craft, dropping its apogee to 22,204 kilometers (11,989nmi) and causing the CSM to return to Earth, simulating a \"direct-return\" abort. On the return leg, the engine was to fire once more to accelerate the craft to simulate conditions that the Apollo spacecraft would encounter on its return from the Moon, with a re-entry angle of 6.5 degrees and velocity of 11,100 meters per second (36,500ft/s). The entire mission was to last about 10 hours.",
        "target": "The mission was intended to test the Saturn V launch vehicle's ability to send the entire Apollo spacecraft to the Moonin particular, to test the stresses on the LM and the vibration modes of the entire Saturn V with near-full loads. With the spacecraft having been qualified for crewed flight through the Apollo 4 mission (the first flight of the Saturn V), the focus was on fully qualifying the launch vehicle. Nominal completion of planned mission events through attainment of the initial parking orbit, and the restarting of the S-IVB to propel the space vehicle towards the planned distance, beyond the Moon's orbit, was deemed sufficient to fulfill Apollo 6's main objectives."
    },
    {
        "source": "Apollo 6, the second test flight of the \nSaturn V launch vehicle, was intended to send a command and service module (CSM) plus a Lunar Test Article (LTA), a simulated lunar module (LM) with mounted structural vibration sensors, into a trans-lunar trajectory, with the boost from orbit to trans-lunar velocity powered by the Saturn V's third stage, the S-IVB. That trajectory, although passing beyond the orbit of the Moon, would not encounter it. The CSM was to separate from the S-IVB soon after the burn, and the SM engine would then fire to slow the craft, dropping its apogee to 22,204 kilometers (11,989nmi) and causing the CSM to return to Earth, simulating a \"direct-return\" abort. On the return leg, the engine was to fire once more to accelerate the craft to simulate conditions that the Apollo spacecraft would encounter on its return from the Moon, with a re-entry angle of 6.5 degrees and velocity of 11,100 meters per second (36,500ft/s). The entire mission was to last about 10 hours. The mission was intended to test the Saturn V launch vehicle's ability to send the entire Apollo spacecraft to the Moonin particular, to test the stresses on the LM and the vibration modes of the entire Saturn V with near-full loads. With the spacecraft having been qualified for crewed flight through the Apollo 4 mission (the first flight of the Saturn V), the focus was on fully qualifying the launch vehicle. Nominal completion of planned mission events through attainment of the initial parking orbit, and the restarting of the S-IVB to propel the space vehicle towards the planned distance, beyond the Moon's orbit, was deemed sufficient to fulfill Apollo 6's main objectives.",
        "target": "Apollo 6's launch vehicle was designated AS-502, the second flight-capable Saturn V. Its payload included CSM-020, a Block I CSM that had some Block II modifications. The Block I CSM did not have the capability of docking with a Lunar Module, as the Block II did. Among the modifications to CSM-020 was a new crew hatch, intended to be tested under lunar return conditions. This new hatch replaced the one which was condemned by the Apollo 1 investigation board as too difficult to open in case of emergency, circumstances that had contributed to the deaths of three astronauts in the Apollo 1 fire of January 27, 1967. The command module used was CM-020; it carried a mission programmer and other equipment to allow it to be operated remotely."
    },
    {
        "source": "The mission was intended to test the Saturn V launch vehicle's ability to send the entire Apollo spacecraft to the Moonin particular, to test the stresses on the LM and the vibration modes of the entire Saturn V with near-full loads. With the spacecraft having been qualified for crewed flight through the Apollo 4 mission (the first flight of the Saturn V), the focus was on fully qualifying the launch vehicle. Nominal completion of planned mission events through attainment of the initial parking orbit, and the restarting of the S-IVB to propel the space vehicle towards the planned distance, beyond the Moon's orbit, was deemed sufficient to fulfill Apollo 6's main objectives. Apollo 6's launch vehicle was designated AS-502, the second flight-capable Saturn V. Its payload included CSM-020, a Block I CSM that had some Block II modifications. The Block I CSM did not have the capability of docking with a Lunar Module, as the Block II did. Among the modifications to CSM-020 was a new crew hatch, intended to be tested under lunar return conditions. This new hatch replaced the one which was condemned by the Apollo 1 investigation board as too difficult to open in case of emergency, circumstances that had contributed to the deaths of three astronauts in the Apollo 1 fire of January 27, 1967. The command module used was CM-020; it carried a mission programmer and other equipment to allow it to be operated remotely.",
        "target": "The service module used was SM-014the originally-planned SM for Apollo 6, SM-020, was used for Apollo 4 after its SM, SM-017, was damaged in an explosion and had to be scrapped. CM-014 was unavailable for flight as it was being used to aid the Apollo 1 investigation. Not all SM systems were activated for the short Apollo 6 mission: the radiators to remove excess heat from the electrical power system and the environmental control system were not connected."
    },
    {
        "source": "Apollo 6's launch vehicle was designated AS-502, the second flight-capable Saturn V. Its payload included CSM-020, a Block I CSM that had some Block II modifications. The Block I CSM did not have the capability of docking with a Lunar Module, as the Block II did. Among the modifications to CSM-020 was a new crew hatch, intended to be tested under lunar return conditions. This new hatch replaced the one which was condemned by the Apollo 1 investigation board as too difficult to open in case of emergency, circumstances that had contributed to the deaths of three astronauts in the Apollo 1 fire of January 27, 1967. The command module used was CM-020; it carried a mission programmer and other equipment to allow it to be operated remotely. The service module used was SM-014the originally-planned SM for Apollo 6, SM-020, was used for Apollo 4 after its SM, SM-017, was damaged in an explosion and had to be scrapped. CM-014 was unavailable for flight as it was being used to aid the Apollo 1 investigation. Not all SM systems were activated for the short Apollo 6 mission: the radiators to remove excess heat from the electrical power system and the environmental control system were not connected.",
        "target": "Kenneth S. Kleinknecht, Command and Service Module manager at the Manned Spaceflight Center in Houston, was pleased with CSM-020 when it arrived at Kennedy Space Center from North American Aviation, the manufacturer, though he was upset it arrived wrapped in flammable mylar. In contrast with Apollo 1's ill-fated CSM, which arrived with hundreds of unresolved issues, CSM-020 had only 23, mostly routine problems."
    },
    {
        "source": "The service module used was SM-014the originally-planned SM for Apollo 6, SM-020, was used for Apollo 4 after its SM, SM-017, was damaged in an explosion and had to be scrapped. CM-014 was unavailable for flight as it was being used to aid the Apollo 1 investigation. Not all SM systems were activated for the short Apollo 6 mission: the radiators to remove excess heat from the electrical power system and the environmental control system were not connected. Kenneth S. Kleinknecht, Command and Service Module manager at the Manned Spaceflight Center in Houston, was pleased with CSM-020 when it arrived at Kennedy Space Center from North American Aviation, the manufacturer, though he was upset it arrived wrapped in flammable mylar. In contrast with Apollo 1's ill-fated CSM, which arrived with hundreds of unresolved issues, CSM-020 had only 23, mostly routine problems.",
        "target": "Also flown on Apollo 6 was a lunar test article: a simulated lunar module, designated as LTA-2R. It included a flight-type descent stage without landing gear, its fuel tanks filled with a waterglycol mixture and freon in its oxidizer tanks. Containing no flight systems, its ascent stage was made of ballasted aluminum and instrumented to show vibration, acoustics and structural integrity. LTA-2R remained inside the Spacecraft-Lunar Module Adapter, numbered SLA-9, throughout the flight."
    },
    {
        "source": "Kenneth S. Kleinknecht, Command and Service Module manager at the Manned Spaceflight Center in Houston, was pleased with CSM-020 when it arrived at Kennedy Space Center from North American Aviation, the manufacturer, though he was upset it arrived wrapped in flammable mylar. In contrast with Apollo 1's ill-fated CSM, which arrived with hundreds of unresolved issues, CSM-020 had only 23, mostly routine problems. Also flown on Apollo 6 was a lunar test article: a simulated lunar module, designated as LTA-2R. It included a flight-type descent stage without landing gear, its fuel tanks filled with a waterglycol mixture and freon in its oxidizer tanks. Containing no flight systems, its ascent stage was made of ballasted aluminum and instrumented to show vibration, acoustics and structural integrity. LTA-2R remained inside the Spacecraft-Lunar Module Adapter, numbered SLA-9, throughout the flight.",
        "target": "The S-IC first stage arrived by barge on March 13, 1967, and was erected in the Vehicle Assembly Building (VAB) four days later; the S-IVB third stage and Instrument Unit computer both arrived on March 17. The S-II second stage was not yet ready and so the dumbbell-shaped spacer, used in preparation for Apollo 4 (which also had a delayed S-II), was substituted so testing could proceed. The spacer had the same height and mass as the S-II along with all the electrical connections. The S-II arrived May 24 and was stacked and mated into the rocket on July 7."
    },
    {
        "source": "Also flown on Apollo 6 was a lunar test article: a simulated lunar module, designated as LTA-2R. It included a flight-type descent stage without landing gear, its fuel tanks filled with a waterglycol mixture and freon in its oxidizer tanks. Containing no flight systems, its ascent stage was made of ballasted aluminum and instrumented to show vibration, acoustics and structural integrity. LTA-2R remained inside the Spacecraft-Lunar Module Adapter, numbered SLA-9, throughout the flight. The S-IC first stage arrived by barge on March 13, 1967, and was erected in the Vehicle Assembly Building (VAB) four days later; the S-IVB third stage and Instrument Unit computer both arrived on March 17. The S-II second stage was not yet ready and so the dumbbell-shaped spacer, used in preparation for Apollo 4 (which also had a delayed S-II), was substituted so testing could proceed. The spacer had the same height and mass as the S-II along with all the electrical connections. The S-II arrived May 24 and was stacked and mated into the rocket on July 7.",
        "target": "Apollo 6 saw the first use of the High Bay 3 of the VAB, and it was quickly discovered that its air conditioning facilities were inadequate. Portable high-capacity units were brought in to keep equipment and workers cool. There were delays in April as personnel and equipment were busy with Apollo 4, and not available for tests on Apollo 6. The S-II second stage arrived on May 25 and was erected in one of the VAB's low bays, but work on Apollo 6 continued to be plagued by delays, many occasioned by work on Apollo 4. The vehicle was erected on Mobile Service Launcher 2, but work on the launcher's arms, which would swing back at launch, proceeded slowly. Also slow to arrive was the CSM itself; the planned late-September arrival was pushed back two months."
    },
    {
        "source": "The S-IC first stage arrived by barge on March 13, 1967, and was erected in the Vehicle Assembly Building (VAB) four days later; the S-IVB third stage and Instrument Unit computer both arrived on March 17. The S-II second stage was not yet ready and so the dumbbell-shaped spacer, used in preparation for Apollo 4 (which also had a delayed S-II), was substituted so testing could proceed. The spacer had the same height and mass as the S-II along with all the electrical connections. The S-II arrived May 24 and was stacked and mated into the rocket on July 7. Apollo 6 saw the first use of the High Bay 3 of the VAB, and it was quickly discovered that its air conditioning facilities were inadequate. Portable high-capacity units were brought in to keep equipment and workers cool. There were delays in April as personnel and equipment were busy with Apollo 4, and not available for tests on Apollo 6. The S-II second stage arrived on May 25 and was erected in one of the VAB's low bays, but work on Apollo 6 continued to be plagued by delays, many occasioned by work on Apollo 4. The vehicle was erected on Mobile Service Launcher 2, but work on the launcher's arms, which would swing back at launch, proceeded slowly. Also slow to arrive was the CSM itself; the planned late-September arrival was pushed back two months.",
        "target": "After Apollo 4's launch on November 9, 1967, the pace of the Apollo 6 project picked up, but there remained many problems with flight hardware.\nThe CSM was erected atop the launch vehicle on December 11, 1967, and the spacecraft stack was rolled out to Launch Complex 39A on February 6, 1968. The rollout was an all-day affair and much of it was conducted in heavy rain. Because the crawler-transporter had to halt for two hours when communications failed, the vehicle did not arrive at the launch pad until it was dark. The mobile service structure could not be moved to the launch pad for two days due to high winds."
    },
    {
        "source": "Apollo 6 saw the first use of the High Bay 3 of the VAB, and it was quickly discovered that its air conditioning facilities were inadequate. Portable high-capacity units were brought in to keep equipment and workers cool. There were delays in April as personnel and equipment were busy with Apollo 4, and not available for tests on Apollo 6. The S-II second stage arrived on May 25 and was erected in one of the VAB's low bays, but work on Apollo 6 continued to be plagued by delays, many occasioned by work on Apollo 4. The vehicle was erected on Mobile Service Launcher 2, but work on the launcher's arms, which would swing back at launch, proceeded slowly. Also slow to arrive was the CSM itself; the planned late-September arrival was pushed back two months. After Apollo 4's launch on November 9, 1967, the pace of the Apollo 6 project picked up, but there remained many problems with flight hardware.\nThe CSM was erected atop the launch vehicle on December 11, 1967, and the spacecraft stack was rolled out to Launch Complex 39A on February 6, 1968. The rollout was an all-day affair and much of it was conducted in heavy rain. Because the crawler-transporter had to halt for two hours when communications failed, the vehicle did not arrive at the launch pad until it was dark. The mobile service structure could not be moved to the launch pad for two days due to high winds.",
        "target": "The flight readiness test concluded on March 8, 1968, and at a review held three days later, Apollo 6 was cleared for launch contingent on the successful completion of testing and some action items identified at the meeting. Launch was set for March 28, 1968, but was postponed to April 1 and then April 3 after problems with some guidance system equipment and with fueling. The countdown demonstration test began on March 24; although it was completed within a week, the launch had to be postponed one more time. On April 3, the final countdown began with liftoff scheduled for the following day. All subsequent problems were fixed during the built-in holds in the countdown and did not delay the mission."
    },
    {
        "source": "After Apollo 4's launch on November 9, 1967, the pace of the Apollo 6 project picked up, but there remained many problems with flight hardware.\nThe CSM was erected atop the launch vehicle on December 11, 1967, and the spacecraft stack was rolled out to Launch Complex 39A on February 6, 1968. The rollout was an all-day affair and much of it was conducted in heavy rain. Because the crawler-transporter had to halt for two hours when communications failed, the vehicle did not arrive at the launch pad until it was dark. The mobile service structure could not be moved to the launch pad for two days due to high winds. The flight readiness test concluded on March 8, 1968, and at a review held three days later, Apollo 6 was cleared for launch contingent on the successful completion of testing and some action items identified at the meeting. Launch was set for March 28, 1968, but was postponed to April 1 and then April 3 after problems with some guidance system equipment and with fueling. The countdown demonstration test began on March 24; although it was completed within a week, the launch had to be postponed one more time. On April 3, the final countdown began with liftoff scheduled for the following day. All subsequent problems were fixed during the built-in holds in the countdown and did not delay the mission.",
        "target": "Apollo 6 launched from Launch Complex 39A at Kennedy Space Center on April 4, 1968, at 7:00 am (1200 UT). For the first two minutes, the Saturn V launch vehicle behaved normally. Then, as the Saturn V's S-IC first stage burned, pogo oscillations shook the vehicle. The thrust variations caused the Saturn V to experience a g-force of 0.6 g (5.9m/s2), though it had only been designed for a maximum of 0.25 g (2.5m/s2). The vehicle suffered no damage, other than the loss of one of the panels of the Spacecraft-Lunar Module Adapter (SLA)."
    },
    {
        "source": "The flight readiness test concluded on March 8, 1968, and at a review held three days later, Apollo 6 was cleared for launch contingent on the successful completion of testing and some action items identified at the meeting. Launch was set for March 28, 1968, but was postponed to April 1 and then April 3 after problems with some guidance system equipment and with fueling. The countdown demonstration test began on March 24; although it was completed within a week, the launch had to be postponed one more time. On April 3, the final countdown began with liftoff scheduled for the following day. All subsequent problems were fixed during the built-in holds in the countdown and did not delay the mission. Apollo 6 launched from Launch Complex 39A at Kennedy Space Center on April 4, 1968, at 7:00 am (1200 UT). For the first two minutes, the Saturn V launch vehicle behaved normally. Then, as the Saturn V's S-IC first stage burned, pogo oscillations shook the vehicle. The thrust variations caused the Saturn V to experience a g-force of 0.6 g (5.9m/s2), though it had only been designed for a maximum of 0.25 g (2.5m/s2). The vehicle suffered no damage, other than the loss of one of the panels of the Spacecraft-Lunar Module Adapter (SLA).",
        "target": "NASA Associate Administrator for Manned Space Flight George Mueller explained the cause to a congressional hearing:"
    },
    {
        "source": "Apollo 6 launched from Launch Complex 39A at Kennedy Space Center on April 4, 1968, at 7:00 am (1200 UT). For the first two minutes, the Saturn V launch vehicle behaved normally. Then, as the Saturn V's S-IC first stage burned, pogo oscillations shook the vehicle. The thrust variations caused the Saturn V to experience a g-force of 0.6 g (5.9m/s2), though it had only been designed for a maximum of 0.25 g (2.5m/s2). The vehicle suffered no damage, other than the loss of one of the panels of the Spacecraft-Lunar Module Adapter (SLA). NASA Associate Administrator for Manned Space Flight George Mueller explained the cause to a congressional hearing:",
        "target": "Pogo arises fundamentally because you have thrust fluctuations in the engines. Those are normal characteristics of engines. All engines have what you might call noise in their output because the combustion is not quite uniform, so you have this fluctuation in thrust of the first stage as a normal characteristic of all engine burning."
    },
    {
        "source": "NASA Associate Administrator for Manned Space Flight George Mueller explained the cause to a congressional hearing: Pogo arises fundamentally because you have thrust fluctuations in the engines. Those are normal characteristics of engines. All engines have what you might call noise in their output because the combustion is not quite uniform, so you have this fluctuation in thrust of the first stage as a normal characteristic of all engine burning.",
        "target": "Now, in turn, the engine is fed through a pipe that takes the fuel out of the tanks and feeds it into the engine. That pipe's length is something like an organ pipe so it has a certain resonance frequency of its own and it really turns out that it will oscillate just like an organ pipe does."
    },
    {
        "source": "Pogo arises fundamentally because you have thrust fluctuations in the engines. Those are normal characteristics of engines. All engines have what you might call noise in their output because the combustion is not quite uniform, so you have this fluctuation in thrust of the first stage as a normal characteristic of all engine burning. Now, in turn, the engine is fed through a pipe that takes the fuel out of the tanks and feeds it into the engine. That pipe's length is something like an organ pipe so it has a certain resonance frequency of its own and it really turns out that it will oscillate just like an organ pipe does.",
        "target": "The structure of the vehicle is much like a tuning fork, so if you strike it right, it will oscillate up and down longitudinally. In a gross sense it is the interaction between the various frequencies that causes the vehicle to oscillate."
    },
    {
        "source": "Now, in turn, the engine is fed through a pipe that takes the fuel out of the tanks and feeds it into the engine. That pipe's length is something like an organ pipe so it has a certain resonance frequency of its own and it really turns out that it will oscillate just like an organ pipe does. The structure of the vehicle is much like a tuning fork, so if you strike it right, it will oscillate up and down longitudinally. In a gross sense it is the interaction between the various frequencies that causes the vehicle to oscillate.",
        "target": "After the first stage was jettisoned, the S-II second stage began to experience problems with its J-2 engines. Engine number two had performance problems from 225 seconds after liftoff, abruptly worsening at T+319 seconds. At T+412 seconds the Instrument Unit shut it down altogether, and two seconds later, engine number three also shut down. The fault was in engine two, but due to cross-connection of wires, the command from the Instrument Unit also shut down engine three, which had been running normally. The Instrument Unit was able to compensate, and the remaining three engines burned for 58 seconds longer than planned. The S-IVB third stage also had to burn for 29 seconds longer than usual. The S-IVB also experienced a slight performance loss."
    },
    {
        "source": "The structure of the vehicle is much like a tuning fork, so if you strike it right, it will oscillate up and down longitudinally. In a gross sense it is the interaction between the various frequencies that causes the vehicle to oscillate. After the first stage was jettisoned, the S-II second stage began to experience problems with its J-2 engines. Engine number two had performance problems from 225 seconds after liftoff, abruptly worsening at T+319 seconds. At T+412 seconds the Instrument Unit shut it down altogether, and two seconds later, engine number three also shut down. The fault was in engine two, but due to cross-connection of wires, the command from the Instrument Unit also shut down engine three, which had been running normally. The Instrument Unit was able to compensate, and the remaining three engines burned for 58 seconds longer than planned. The S-IVB third stage also had to burn for 29 seconds longer than usual. The S-IVB also experienced a slight performance loss.",
        "target": "Due to the less-than-nominal launch, the CSM and S-IVB were inserted into a 173.14-kilometer (93.49nmi) by 360.10-kilometer (194.44nmi) parking orbit, instead of the planned 190-kilometer (100nmi) circular parking orbit. This deviation from the flight plan did not preclude continuing the mission. During the first orbit, the S-IVB maneuvered, changing its attitude towards the horizon to qualify techniques that future astronauts could use in landmark tracking. Then, after the standard two orbits to assess the vehicle's readiness for trans-lunar injection (TLI), the S-IVB was ordered to restart, but failed to do so."
    },
    {
        "source": "After the first stage was jettisoned, the S-II second stage began to experience problems with its J-2 engines. Engine number two had performance problems from 225 seconds after liftoff, abruptly worsening at T+319 seconds. At T+412 seconds the Instrument Unit shut it down altogether, and two seconds later, engine number three also shut down. The fault was in engine two, but due to cross-connection of wires, the command from the Instrument Unit also shut down engine three, which had been running normally. The Instrument Unit was able to compensate, and the remaining three engines burned for 58 seconds longer than planned. The S-IVB third stage also had to burn for 29 seconds longer than usual. The S-IVB also experienced a slight performance loss. Due to the less-than-nominal launch, the CSM and S-IVB were inserted into a 173.14-kilometer (93.49nmi) by 360.10-kilometer (194.44nmi) parking orbit, instead of the planned 190-kilometer (100nmi) circular parking orbit. This deviation from the flight plan did not preclude continuing the mission. During the first orbit, the S-IVB maneuvered, changing its attitude towards the horizon to qualify techniques that future astronauts could use in landmark tracking. Then, after the standard two orbits to assess the vehicle's readiness for trans-lunar injection (TLI), the S-IVB was ordered to restart, but failed to do so.",
        "target": "Deciding on a pre-planned alternate mission, the flight director, Clifford E. Charlesworth and his team in Mission Control chose to use the SM's Service Propulsion System (SPS) engine to raise the spacecraft into an orbit with a high apogee (point of furthest distance from Earth), with a low perigee that would result in re-entry, as had been done in Apollo 4. This plan would complete some of the mission objectives. The SPS engine burned for 442 seconds to get to the planned 22,204-kilometer (11,989nmi) apogee. There was now, however, not enough propellant to speed up the atmospheric reentry with a second SPS engine burn, and the spacecraft only entered the atmosphere at a speed of 10,000 meters per second (33,000ft/s) instead of the planned 11,000 meters per second (37,000ft/s) that would simulate a lunar return. While at high altitudes, the CM was able to return data on the extent to which future astronauts would be protected from the Van Allen Belts by the skin of the spacecraft."
    },
    {
        "source": "Due to the less-than-nominal launch, the CSM and S-IVB were inserted into a 173.14-kilometer (93.49nmi) by 360.10-kilometer (194.44nmi) parking orbit, instead of the planned 190-kilometer (100nmi) circular parking orbit. This deviation from the flight plan did not preclude continuing the mission. During the first orbit, the S-IVB maneuvered, changing its attitude towards the horizon to qualify techniques that future astronauts could use in landmark tracking. Then, after the standard two orbits to assess the vehicle's readiness for trans-lunar injection (TLI), the S-IVB was ordered to restart, but failed to do so. Deciding on a pre-planned alternate mission, the flight director, Clifford E. Charlesworth and his team in Mission Control chose to use the SM's Service Propulsion System (SPS) engine to raise the spacecraft into an orbit with a high apogee (point of furthest distance from Earth), with a low perigee that would result in re-entry, as had been done in Apollo 4. This plan would complete some of the mission objectives. The SPS engine burned for 442 seconds to get to the planned 22,204-kilometer (11,989nmi) apogee. There was now, however, not enough propellant to speed up the atmospheric reentry with a second SPS engine burn, and the spacecraft only entered the atmosphere at a speed of 10,000 meters per second (33,000ft/s) instead of the planned 11,000 meters per second (37,000ft/s) that would simulate a lunar return. While at high altitudes, the CM was able to return data on the extent to which future astronauts would be protected from the Van Allen Belts by the skin of the spacecraft.",
        "target": "Ten hours after launch, the CM landed 80 kilometers (43nmi) from the planned touchdown point in the North Pacific Ocean north of Hawaii, and was lifted on board USSOkinawa. The SM was jettisoned just before reaching the atmosphere and burned up. The S-IVB's orbit gradually decayed and it reentered the atmosphere on April 26, 1968."
    },
    {
        "source": "Deciding on a pre-planned alternate mission, the flight director, Clifford E. Charlesworth and his team in Mission Control chose to use the SM's Service Propulsion System (SPS) engine to raise the spacecraft into an orbit with a high apogee (point of furthest distance from Earth), with a low perigee that would result in re-entry, as had been done in Apollo 4. This plan would complete some of the mission objectives. The SPS engine burned for 442 seconds to get to the planned 22,204-kilometer (11,989nmi) apogee. There was now, however, not enough propellant to speed up the atmospheric reentry with a second SPS engine burn, and the spacecraft only entered the atmosphere at a speed of 10,000 meters per second (33,000ft/s) instead of the planned 11,000 meters per second (37,000ft/s) that would simulate a lunar return. While at high altitudes, the CM was able to return data on the extent to which future astronauts would be protected from the Van Allen Belts by the skin of the spacecraft. Ten hours after launch, the CM landed 80 kilometers (43nmi) from the planned touchdown point in the North Pacific Ocean north of Hawaii, and was lifted on board USSOkinawa. The SM was jettisoned just before reaching the atmosphere and burned up. The S-IVB's orbit gradually decayed and it reentered the atmosphere on April 26, 1968.",
        "target": "In a post-launch press conference, Apollo Program Director Samuel C. Phillips said, \"there's no question that it's less than a perfect mission\", but that the launch vehicle's reaching orbit despite the loss of two engines was \"a major unplanned accomplishment\". Mueller called Apollo 6 \"a good job all around, an excellent launch, and, in balance, a successful mission... and we have learned a great deal\", but later stated that Apollo 6 \"will have to be defined as a failure\"."
    },
    {
        "source": "Ten hours after launch, the CM landed 80 kilometers (43nmi) from the planned touchdown point in the North Pacific Ocean north of Hawaii, and was lifted on board USSOkinawa. The SM was jettisoned just before reaching the atmosphere and burned up. The S-IVB's orbit gradually decayed and it reentered the atmosphere on April 26, 1968. In a post-launch press conference, Apollo Program Director Samuel C. Phillips said, \"there's no question that it's less than a perfect mission\", but that the launch vehicle's reaching orbit despite the loss of two engines was \"a major unplanned accomplishment\". Mueller called Apollo 6 \"a good job all around, an excellent launch, and, in balance, a successful mission... and we have learned a great deal\", but later stated that Apollo 6 \"will have to be defined as a failure\".",
        "target": "The phenomenon of pogo, experienced during the first stage of the flight, was well known. However, NASA thought that the Saturn V had been \"detuned\"that is, prevented from vibrating at its natural frequencies. Soon after the Apollo 6 flight, NASA and its contractors sought to eliminate the problems for future flights, and about 1,000 government and industry engineers worked on the problem. To damp pressure oscillations in the F-1 and J-2 engines, cavities in valves leading to them were filled with helium gas shortly before takeoff as a shock absorber."
    },
    {
        "source": "In a post-launch press conference, Apollo Program Director Samuel C. Phillips said, \"there's no question that it's less than a perfect mission\", but that the launch vehicle's reaching orbit despite the loss of two engines was \"a major unplanned accomplishment\". Mueller called Apollo 6 \"a good job all around, an excellent launch, and, in balance, a successful mission... and we have learned a great deal\", but later stated that Apollo 6 \"will have to be defined as a failure\". The phenomenon of pogo, experienced during the first stage of the flight, was well known. However, NASA thought that the Saturn V had been \"detuned\"that is, prevented from vibrating at its natural frequencies. Soon after the Apollo 6 flight, NASA and its contractors sought to eliminate the problems for future flights, and about 1,000 government and industry engineers worked on the problem. To damp pressure oscillations in the F-1 and J-2 engines, cavities in valves leading to them were filled with helium gas shortly before takeoff as a shock absorber.",
        "target": "The problems with the S-II and the S-IVB were traced to the J-2 engines, present in both stages. Tests showed that the propellant lines leading to the spark igniters could fail in low atmospheric pressure or in vacuum. The propellant lines had metal bellows to allow for thermal expansion. In ground testing the cold propellants passing through the propellant lines would form a layer of frost on the LOX line and liquid air on the LH2 line, damping out any vibrations. In the vacuum of space, there was no such protection: the bellows vibrated rapidly and failed at peak flow, causing a burn-through of the propellant lines. The bellows were replaced with rigid bends and the lines strengthened. In Apollo 6's wake, NASA engineers debated whether to configure the spacecraft's emergency detection system to automatically abort in the event of excessive pogo; this plan was opposed by Director of Flight Crew Operations Deke Slayton. Instead, work began on having a \"pogo abort sensor\" to allow the flight crew to judge whether to abort, but by August 1968, it had become clear that pogo could be dealt with without such a sensor, and work on it was abandoned."
    },
    {
        "source": "The phenomenon of pogo, experienced during the first stage of the flight, was well known. However, NASA thought that the Saturn V had been \"detuned\"that is, prevented from vibrating at its natural frequencies. Soon after the Apollo 6 flight, NASA and its contractors sought to eliminate the problems for future flights, and about 1,000 government and industry engineers worked on the problem. To damp pressure oscillations in the F-1 and J-2 engines, cavities in valves leading to them were filled with helium gas shortly before takeoff as a shock absorber. The problems with the S-II and the S-IVB were traced to the J-2 engines, present in both stages. Tests showed that the propellant lines leading to the spark igniters could fail in low atmospheric pressure or in vacuum. The propellant lines had metal bellows to allow for thermal expansion. In ground testing the cold propellants passing through the propellant lines would form a layer of frost on the LOX line and liquid air on the LH2 line, damping out any vibrations. In the vacuum of space, there was no such protection: the bellows vibrated rapidly and failed at peak flow, causing a burn-through of the propellant lines. The bellows were replaced with rigid bends and the lines strengthened. In Apollo 6's wake, NASA engineers debated whether to configure the spacecraft's emergency detection system to automatically abort in the event of excessive pogo; this plan was opposed by Director of Flight Crew Operations Deke Slayton. Instead, work began on having a \"pogo abort sensor\" to allow the flight crew to judge whether to abort, but by August 1968, it had become clear that pogo could be dealt with without such a sensor, and work on it was abandoned.",
        "target": "The SLA problem was caused by its honeycomb structure. As the rocket accelerated through the atmosphere, the cells expanded due to trapped air and water, causing the adapter surface to break free. In response, engineers drilled small holes in the surface to allow trapped gases to dissipate, and placed a thin layer of cork on the adapter to help absorb moisture."
    },
    {
        "source": "The problems with the S-II and the S-IVB were traced to the J-2 engines, present in both stages. Tests showed that the propellant lines leading to the spark igniters could fail in low atmospheric pressure or in vacuum. The propellant lines had metal bellows to allow for thermal expansion. In ground testing the cold propellants passing through the propellant lines would form a layer of frost on the LOX line and liquid air on the LH2 line, damping out any vibrations. In the vacuum of space, there was no such protection: the bellows vibrated rapidly and failed at peak flow, causing a burn-through of the propellant lines. The bellows were replaced with rigid bends and the lines strengthened. In Apollo 6's wake, NASA engineers debated whether to configure the spacecraft's emergency detection system to automatically abort in the event of excessive pogo; this plan was opposed by Director of Flight Crew Operations Deke Slayton. Instead, work began on having a \"pogo abort sensor\" to allow the flight crew to judge whether to abort, but by August 1968, it had become clear that pogo could be dealt with without such a sensor, and work on it was abandoned. The SLA problem was caused by its honeycomb structure. As the rocket accelerated through the atmosphere, the cells expanded due to trapped air and water, causing the adapter surface to break free. In response, engineers drilled small holes in the surface to allow trapped gases to dissipate, and placed a thin layer of cork on the adapter to help absorb moisture.",
        "target": "NASA's efforts were enough to satisfy the Senate Committee on Aeronautical and Space Sciences. In late April, the committee reported that the agency had quickly analyzed and diagnosed the abnormalities of Apollo 6, and had taken corrective action. After detailed analysis of the Saturn V's performance, and of the fixes for future launch vehicles, engineers at the Marshall Space Flight Center in Alabama concluded that a third uncrewed test flight of the Saturn V was unnecessary. Therefore, the next Saturn V to fly, on Apollo 8, would carry a crew (Apollo 7, the first crewed Apollo mission to fly, would be launched by a Saturn IB)."
    },
    {
        "source": "The SLA problem was caused by its honeycomb structure. As the rocket accelerated through the atmosphere, the cells expanded due to trapped air and water, causing the adapter surface to break free. In response, engineers drilled small holes in the surface to allow trapped gases to dissipate, and placed a thin layer of cork on the adapter to help absorb moisture. NASA's efforts were enough to satisfy the Senate Committee on Aeronautical and Space Sciences. In late April, the committee reported that the agency had quickly analyzed and diagnosed the abnormalities of Apollo 6, and had taken corrective action. After detailed analysis of the Saturn V's performance, and of the fixes for future launch vehicles, engineers at the Marshall Space Flight Center in Alabama concluded that a third uncrewed test flight of the Saturn V was unnecessary. Therefore, the next Saturn V to fly, on Apollo 8, would carry a crew (Apollo 7, the first crewed Apollo mission to fly, would be launched by a Saturn IB).",
        "target": "After the mission, CM-020 was transferred to the Smithsonian Institution. The Apollo 6 command module is on display at the Fernbank Science Center in Atlanta, Georgia."
    },
    {
        "source": "NASA's efforts were enough to satisfy the Senate Committee on Aeronautical and Space Sciences. In late April, the committee reported that the agency had quickly analyzed and diagnosed the abnormalities of Apollo 6, and had taken corrective action. After detailed analysis of the Saturn V's performance, and of the fixes for future launch vehicles, engineers at the Marshall Space Flight Center in Alabama concluded that a third uncrewed test flight of the Saturn V was unnecessary. Therefore, the next Saturn V to fly, on Apollo 8, would carry a crew (Apollo 7, the first crewed Apollo mission to fly, would be launched by a Saturn IB). After the mission, CM-020 was transferred to the Smithsonian Institution. The Apollo 6 command module is on display at the Fernbank Science Center in Atlanta, Georgia.",
        "target": "The Saturn V had several cameras affixed to it, intended to be ejected and later recovered. Three of the four cameras on board the S-IC failed to eject and thus were destroyed, and only one of the two cameras on the S-II was recovered. Two of these cameras were intended to film the S-IC/S-II separation and the other two were to film the liquid oxygen tank; the one that was recovered had filmed separation. The failure to eject was attributed to a lack of nitrogen pressure in the bottles that were to cause the ejection. The command module carried a motion picture camera, intended to be activated during launch and during re-entry. Because the mission took about ten minutes longer than planned, re-entry events were not filmed."
    },
    {
        "source": "After the mission, CM-020 was transferred to the Smithsonian Institution. The Apollo 6 command module is on display at the Fernbank Science Center in Atlanta, Georgia. The Saturn V had several cameras affixed to it, intended to be ejected and later recovered. Three of the four cameras on board the S-IC failed to eject and thus were destroyed, and only one of the two cameras on the S-II was recovered. Two of these cameras were intended to film the S-IC/S-II separation and the other two were to film the liquid oxygen tank; the one that was recovered had filmed separation. The failure to eject was attributed to a lack of nitrogen pressure in the bottles that were to cause the ejection. The command module carried a motion picture camera, intended to be activated during launch and during re-entry. Because the mission took about ten minutes longer than planned, re-entry events were not filmed.",
        "target": "A 70 mm still camera operated in the CM during part of the mission, pointed at the Earth through the hatch window. Coverage included parts of the United States, the Atlantic Ocean, Africa, and the western Pacific Ocean. The camera had haze-penetrating film and filter combination, with better color balance and higher resolution than photographs taken on previous American crewed missions. These proved excellent for cartographic, topographic, and geographic studies."
    },
    {
        "source": "The Saturn V had several cameras affixed to it, intended to be ejected and later recovered. Three of the four cameras on board the S-IC failed to eject and thus were destroyed, and only one of the two cameras on the S-II was recovered. Two of these cameras were intended to film the S-IC/S-II separation and the other two were to film the liquid oxygen tank; the one that was recovered had filmed separation. The failure to eject was attributed to a lack of nitrogen pressure in the bottles that were to cause the ejection. The command module carried a motion picture camera, intended to be activated during launch and during re-entry. Because the mission took about ten minutes longer than planned, re-entry events were not filmed. A 70 mm still camera operated in the CM during part of the mission, pointed at the Earth through the hatch window. Coverage included parts of the United States, the Atlantic Ocean, Africa, and the western Pacific Ocean. The camera had haze-penetrating film and filter combination, with better color balance and higher resolution than photographs taken on previous American crewed missions. These proved excellent for cartographic, topographic, and geographic studies.",
        "target": "There was little press coverage of the Apollo 6 mission mainly because on the same day as the launch, Martin Luther King Jr. was assassinated in Memphis, and President Lyndon B. Johnson had announced he would not seek reelection only four days earlier."
    },
    {
        "source": " Apollo 7 (October 1122, 1968) was the first crewed flight in NASA's Apollo program, and saw the resumption of human spaceflight by the agency after the fire that had killed the three Apollo1 astronauts during a launch rehearsal test on January 27, 1967. The Apollo7 crew was commanded by Walter M. Schirra, with command module pilot Donn F. Eisele and Lunar Module pilot R. Walter Cunningham (so designated even though Apollo7 did not carry a Lunar Module).",
        "target": "The three astronauts were originally designated for the second crewed Apollo flight, and then as backups for Apollo1. After the Apollo1 fire, crewed flights were suspended while the cause of the accident was investigated and improvements made to the spacecraft and safety procedures, and uncrewed test flights made. Determined to prevent a repetition of the fire, the crew spent long periods monitoring the construction of their Apollo command and service modules (CSM). Training continued over much of the 21-month pause that followed the Apollo1 disaster."
    },
    {
        "source": "Apollo 7 (October 1122, 1968) was the first crewed flight in NASA's Apollo program, and saw the resumption of human spaceflight by the agency after the fire that had killed the three Apollo1 astronauts during a launch rehearsal test on January 27, 1967. The Apollo7 crew was commanded by Walter M. Schirra, with command module pilot Donn F. Eisele and Lunar Module pilot R. Walter Cunningham (so designated even though Apollo7 did not carry a Lunar Module). The three astronauts were originally designated for the second crewed Apollo flight, and then as backups for Apollo1. After the Apollo1 fire, crewed flights were suspended while the cause of the accident was investigated and improvements made to the spacecraft and safety procedures, and uncrewed test flights made. Determined to prevent a repetition of the fire, the crew spent long periods monitoring the construction of their Apollo command and service modules (CSM). Training continued over much of the 21-month pause that followed the Apollo1 disaster.",
        "target": "Apollo 7 was launched on October 11, 1968, from Cape Kennedy Air Force Station, Florida, and splashed down in the Atlantic Ocean eleven days later. Extensive testing of the CSM took place, and also the first live television broadcast from an American spacecraft. Despite tension between the crew and ground controllers, the mission was a complete technical success, giving NASA the confidence to send Apollo8 into orbit around the Moon two months later. In part because of these tensions, none of the crew flew in space again, though Schirra had already announced he would retire from NASA after the flight. Apollo7 fulfilled Apollo1's mission of testing the CSM in low Earth orbit, and was a significant step towards NASA's goal of landing astronauts on the Moon."
    },
    {
        "source": "The three astronauts were originally designated for the second crewed Apollo flight, and then as backups for Apollo1. After the Apollo1 fire, crewed flights were suspended while the cause of the accident was investigated and improvements made to the spacecraft and safety procedures, and uncrewed test flights made. Determined to prevent a repetition of the fire, the crew spent long periods monitoring the construction of their Apollo command and service modules (CSM). Training continued over much of the 21-month pause that followed the Apollo1 disaster. Apollo 7 was launched on October 11, 1968, from Cape Kennedy Air Force Station, Florida, and splashed down in the Atlantic Ocean eleven days later. Extensive testing of the CSM took place, and also the first live television broadcast from an American spacecraft. Despite tension between the crew and ground controllers, the mission was a complete technical success, giving NASA the confidence to send Apollo8 into orbit around the Moon two months later. In part because of these tensions, none of the crew flew in space again, though Schirra had already announced he would retire from NASA after the flight. Apollo7 fulfilled Apollo1's mission of testing the CSM in low Earth orbit, and was a significant step towards NASA's goal of landing astronauts on the Moon.",
        "target": "Schirra, one of the original \"Mercury Seven\" astronauts, graduated from the United States Naval Academy in 1945. He flew Mercury-Atlas 8 in 1962, the fifth crewed flight of Project Mercury and the third to reach orbit, and in 1965 was the command pilot for Gemini 6A. He was a 45-year-old captain in the Navy at the time of Apollo7. Eisele graduated from the Naval Academy in 1952 with a B.S. in aeronautics. He elected to be commissioned in the Air Force, and was a 38-year-old major at the time of Apollo7. Cunningham joined the U.S. Navy in 1951, began flight training the following year, and served in a Marine flight squadron from 1953 to 1956, and was a civilian, aged 36, serving in the Marine Corps reserves with a rank of major, at the time of Apollo7. He received degrees in physics from UCLA, a B.A. in 1960 and an M.A. in 1961. Both Eisele and Cunningham were selected as part of the third group of astronauts in 1963."
    },
    {
        "source": "Apollo 7 was launched on October 11, 1968, from Cape Kennedy Air Force Station, Florida, and splashed down in the Atlantic Ocean eleven days later. Extensive testing of the CSM took place, and also the first live television broadcast from an American spacecraft. Despite tension between the crew and ground controllers, the mission was a complete technical success, giving NASA the confidence to send Apollo8 into orbit around the Moon two months later. In part because of these tensions, none of the crew flew in space again, though Schirra had already announced he would retire from NASA after the flight. Apollo7 fulfilled Apollo1's mission of testing the CSM in low Earth orbit, and was a significant step towards NASA's goal of landing astronauts on the Moon. Schirra, one of the original \"Mercury Seven\" astronauts, graduated from the United States Naval Academy in 1945. He flew Mercury-Atlas 8 in 1962, the fifth crewed flight of Project Mercury and the third to reach orbit, and in 1965 was the command pilot for Gemini 6A. He was a 45-year-old captain in the Navy at the time of Apollo7. Eisele graduated from the Naval Academy in 1952 with a B.S. in aeronautics. He elected to be commissioned in the Air Force, and was a 38-year-old major at the time of Apollo7. Cunningham joined the U.S. Navy in 1951, began flight training the following year, and served in a Marine flight squadron from 1953 to 1956, and was a civilian, aged 36, serving in the Marine Corps reserves with a rank of major, at the time of Apollo7. He received degrees in physics from UCLA, a B.A. in 1960 and an M.A. in 1961. Both Eisele and Cunningham were selected as part of the third group of astronauts in 1963.",
        "target": "Eisele was originally slotted for a position on Gus Grissom's Apollo1 crew along with Ed White, but days prior to the official announcement on March 25, 1966, Eisele sustained a shoulder injury that would require surgery. Instead, Roger Chaffee was given the position and Eisele was reassigned to Schirra's crew."
    },
    {
        "source": "Schirra, one of the original \"Mercury Seven\" astronauts, graduated from the United States Naval Academy in 1945. He flew Mercury-Atlas 8 in 1962, the fifth crewed flight of Project Mercury and the third to reach orbit, and in 1965 was the command pilot for Gemini 6A. He was a 45-year-old captain in the Navy at the time of Apollo7. Eisele graduated from the Naval Academy in 1952 with a B.S. in aeronautics. He elected to be commissioned in the Air Force, and was a 38-year-old major at the time of Apollo7. Cunningham joined the U.S. Navy in 1951, began flight training the following year, and served in a Marine flight squadron from 1953 to 1956, and was a civilian, aged 36, serving in the Marine Corps reserves with a rank of major, at the time of Apollo7. He received degrees in physics from UCLA, a B.A. in 1960 and an M.A. in 1961. Both Eisele and Cunningham were selected as part of the third group of astronauts in 1963. Eisele was originally slotted for a position on Gus Grissom's Apollo1 crew along with Ed White, but days prior to the official announcement on March 25, 1966, Eisele sustained a shoulder injury that would require surgery. Instead, Roger Chaffee was given the position and Eisele was reassigned to Schirra's crew.",
        "target": "Schirra, Eisele, and Cunningham were first named as an Apollo crew on September 29, 1966. They were to fly a second Earth orbital test of the Apollo Command Module (CM). Although delighted as a rookie to be assigned to a prime crew without having served as a backup, Cunningham was troubled by the fact that a second Earth orbital test flight, dubbed Apollo2, seemed unnecessary if Apollo1 was successful. He learned later that Director of Flight Crew Operations Deke Slayton, another of the Mercury Seven who had been grounded for medical reasons and supervised the astronauts, planned, with Schirra's support, to command the mission if he gained medical clearance. When this was not forthcoming, Schirra remained in command of the crew, and in November 1966, Apollo2 was cancelled and Schirra's crew assigned as backup to Grissom's. Thomas P. Staffordassigned at that point as the backup commander of the second orbital teststated that the cancellation followed Schirra and his crew submitting a list of demands to NASA management (Schirra wanted the mission to include a lunar module and a CM capable of docking with it), and that the assignment as backups left Schirra complaining that Slayton and Chief Astronaut Alan Shepard had destroyed his career."
    },
    {
        "source": "Eisele was originally slotted for a position on Gus Grissom's Apollo1 crew along with Ed White, but days prior to the official announcement on March 25, 1966, Eisele sustained a shoulder injury that would require surgery. Instead, Roger Chaffee was given the position and Eisele was reassigned to Schirra's crew. Schirra, Eisele, and Cunningham were first named as an Apollo crew on September 29, 1966. They were to fly a second Earth orbital test of the Apollo Command Module (CM). Although delighted as a rookie to be assigned to a prime crew without having served as a backup, Cunningham was troubled by the fact that a second Earth orbital test flight, dubbed Apollo2, seemed unnecessary if Apollo1 was successful. He learned later that Director of Flight Crew Operations Deke Slayton, another of the Mercury Seven who had been grounded for medical reasons and supervised the astronauts, planned, with Schirra's support, to command the mission if he gained medical clearance. When this was not forthcoming, Schirra remained in command of the crew, and in November 1966, Apollo2 was cancelled and Schirra's crew assigned as backup to Grissom's. Thomas P. Staffordassigned at that point as the backup commander of the second orbital teststated that the cancellation followed Schirra and his crew submitting a list of demands to NASA management (Schirra wanted the mission to include a lunar module and a CM capable of docking with it), and that the assignment as backups left Schirra complaining that Slayton and Chief Astronaut Alan Shepard had destroyed his career.",
        "target": "On January 27, 1967, Grissom's crew was conducting a launch-pad test for their planned February 21 mission, when a fire broke out in the cabin, killing all three men. A complete safety review of the Apollo program followed. Soon after the fire, Slayton asked Schirra, Eisele and Cunningham to fly the first mission after the pause. Apollo 7 would use the BlockII spacecraft designed for the lunar missions, as opposed to the Block I CSM used for Apollo 1, which was intended only to be used for the early Earth-orbit missions, as it lacked the capability of docking with a lunar module. The CM and astronauts' spacesuits had been extensively redesigned, to reduce any chance of a repeat of the accident which killed the first crew. Schirra's crew would test the life support, propulsion, guidance and control systems during this \"open-ended\" mission (meaning it would be extended as it passed each test). The duration was limited to 11 days, reduced from the original 14-day limit for Apollo1."
    },
    {
        "source": "Schirra, Eisele, and Cunningham were first named as an Apollo crew on September 29, 1966. They were to fly a second Earth orbital test of the Apollo Command Module (CM). Although delighted as a rookie to be assigned to a prime crew without having served as a backup, Cunningham was troubled by the fact that a second Earth orbital test flight, dubbed Apollo2, seemed unnecessary if Apollo1 was successful. He learned later that Director of Flight Crew Operations Deke Slayton, another of the Mercury Seven who had been grounded for medical reasons and supervised the astronauts, planned, with Schirra's support, to command the mission if he gained medical clearance. When this was not forthcoming, Schirra remained in command of the crew, and in November 1966, Apollo2 was cancelled and Schirra's crew assigned as backup to Grissom's. Thomas P. Staffordassigned at that point as the backup commander of the second orbital teststated that the cancellation followed Schirra and his crew submitting a list of demands to NASA management (Schirra wanted the mission to include a lunar module and a CM capable of docking with it), and that the assignment as backups left Schirra complaining that Slayton and Chief Astronaut Alan Shepard had destroyed his career. On January 27, 1967, Grissom's crew was conducting a launch-pad test for their planned February 21 mission, when a fire broke out in the cabin, killing all three men. A complete safety review of the Apollo program followed. Soon after the fire, Slayton asked Schirra, Eisele and Cunningham to fly the first mission after the pause. Apollo 7 would use the BlockII spacecraft designed for the lunar missions, as opposed to the Block I CSM used for Apollo 1, which was intended only to be used for the early Earth-orbit missions, as it lacked the capability of docking with a lunar module. The CM and astronauts' spacesuits had been extensively redesigned, to reduce any chance of a repeat of the accident which killed the first crew. Schirra's crew would test the life support, propulsion, guidance and control systems during this \"open-ended\" mission (meaning it would be extended as it passed each test). The duration was limited to 11 days, reduced from the original 14-day limit for Apollo1.",
        "target": "The backup crew consisted of Stafford as commander, John W. Young as command module pilot, and Eugene A. Cernan as lunar module pilot. They became the prime crew of Apollo10. Ronald E. Evans, John L. 'Jack' Swigert, and Edward G. Givens were assigned to the support crew for the mission. Givens died in a car accident on June 6, 1967, and William R. Pogue was assigned as his replacement. Evans was involved in hardware testing at Kennedy Space Center (KSC). Swigert was the launch capsule communicator (CAPCOM) and worked on the mission's operational aspects. Pogue spent time modifying procedures. The support crew also filled in when the primary and backup crews were unavailable."
    },
    {
        "source": "On January 27, 1967, Grissom's crew was conducting a launch-pad test for their planned February 21 mission, when a fire broke out in the cabin, killing all three men. A complete safety review of the Apollo program followed. Soon after the fire, Slayton asked Schirra, Eisele and Cunningham to fly the first mission after the pause. Apollo 7 would use the BlockII spacecraft designed for the lunar missions, as opposed to the Block I CSM used for Apollo 1, which was intended only to be used for the early Earth-orbit missions, as it lacked the capability of docking with a lunar module. The CM and astronauts' spacesuits had been extensively redesigned, to reduce any chance of a repeat of the accident which killed the first crew. Schirra's crew would test the life support, propulsion, guidance and control systems during this \"open-ended\" mission (meaning it would be extended as it passed each test). The duration was limited to 11 days, reduced from the original 14-day limit for Apollo1. The backup crew consisted of Stafford as commander, John W. Young as command module pilot, and Eugene A. Cernan as lunar module pilot. They became the prime crew of Apollo10. Ronald E. Evans, John L. 'Jack' Swigert, and Edward G. Givens were assigned to the support crew for the mission. Givens died in a car accident on June 6, 1967, and William R. Pogue was assigned as his replacement. Evans was involved in hardware testing at Kennedy Space Center (KSC). Swigert was the launch capsule communicator (CAPCOM) and worked on the mission's operational aspects. Pogue spent time modifying procedures. The support crew also filled in when the primary and backup crews were unavailable.",
        "target": "CAPCOMs, the person in Mission Control responsible for communicating with the spacecraft (then always an astronaut) were Evans, Pogue, Stafford, Swigert, Young and Cernan. Flight directors were Glynn Lunney, Gene Kranz and Gerry Griffin."
    },
    {
        "source": "The backup crew consisted of Stafford as commander, John W. Young as command module pilot, and Eugene A. Cernan as lunar module pilot. They became the prime crew of Apollo10. Ronald E. Evans, John L. 'Jack' Swigert, and Edward G. Givens were assigned to the support crew for the mission. Givens died in a car accident on June 6, 1967, and William R. Pogue was assigned as his replacement. Evans was involved in hardware testing at Kennedy Space Center (KSC). Swigert was the launch capsule communicator (CAPCOM) and worked on the mission's operational aspects. Pogue spent time modifying procedures. The support crew also filled in when the primary and backup crews were unavailable. CAPCOMs, the person in Mission Control responsible for communicating with the spacecraft (then always an astronaut) were Evans, Pogue, Stafford, Swigert, Young and Cernan. Flight directors were Glynn Lunney, Gene Kranz and Gerry Griffin.",
        "target": "According to Cunningham, Schirra originally had limited interest in making a third spaceflight, beginning to focus on his post-NASA career. Flying the first mission after the fire changed things: \"Wally Schirra was being pictured as the man chosen to rescue the manned space program. And that was a task worthy of Wally's interest.\" Eisele noted, \"coming on the heels of the fire, we knew the fate and future of the entire manned space programnot to mention our own skinswas riding on the success or failure of Apollo7.\""
    },
    {
        "source": "CAPCOMs, the person in Mission Control responsible for communicating with the spacecraft (then always an astronaut) were Evans, Pogue, Stafford, Swigert, Young and Cernan. Flight directors were Glynn Lunney, Gene Kranz and Gerry Griffin. According to Cunningham, Schirra originally had limited interest in making a third spaceflight, beginning to focus on his post-NASA career. Flying the first mission after the fire changed things: \"Wally Schirra was being pictured as the man chosen to rescue the manned space program. And that was a task worthy of Wally's interest.\" Eisele noted, \"coming on the heels of the fire, we knew the fate and future of the entire manned space programnot to mention our own skinswas riding on the success or failure of Apollo7.\"",
        "target": "Given the circumstances of the fire, the crew initially had little confidence in the staff at North American Aviation's plant at Downey, California, who built the Apollo command modules, and they were determined to follow their craft every step of the way through construction and testing. This interfered with training, but the simulators of the CM were not yet ready, and they knew it would be a long time until they launched. They spent long periods at Downey. Simulators were constructed at Houston's Manned Spacecraft Center and at KSC in Florida. Once these were available for use, the crew had difficulty finding enough time to do everything, even with the help of the backup and support crews; the crew often worked 12 or 14 hours per day. After the CM was completed and shipped to KSC, the focus of the crew's training shifted to Florida, though they went to Houston for planning and technical meetings. Rather than return to their Houston homes for the weekend, they often had to remain at KSC in order to participate in training or spacecraft testing. According to former astronaut Tom Jones in a 2018 article, Schirra, \"with indisputable evidence of the risks his crew would be taking, now had immense leverage with management at NASA and North American, and he used it. In conference rooms or on the spacecraft assembly line, Schirra got his way.\""
    },
    {
        "source": "According to Cunningham, Schirra originally had limited interest in making a third spaceflight, beginning to focus on his post-NASA career. Flying the first mission after the fire changed things: \"Wally Schirra was being pictured as the man chosen to rescue the manned space program. And that was a task worthy of Wally's interest.\" Eisele noted, \"coming on the heels of the fire, we knew the fate and future of the entire manned space programnot to mention our own skinswas riding on the success or failure of Apollo7.\" Given the circumstances of the fire, the crew initially had little confidence in the staff at North American Aviation's plant at Downey, California, who built the Apollo command modules, and they were determined to follow their craft every step of the way through construction and testing. This interfered with training, but the simulators of the CM were not yet ready, and they knew it would be a long time until they launched. They spent long periods at Downey. Simulators were constructed at Houston's Manned Spacecraft Center and at KSC in Florida. Once these were available for use, the crew had difficulty finding enough time to do everything, even with the help of the backup and support crews; the crew often worked 12 or 14 hours per day. After the CM was completed and shipped to KSC, the focus of the crew's training shifted to Florida, though they went to Houston for planning and technical meetings. Rather than return to their Houston homes for the weekend, they often had to remain at KSC in order to participate in training or spacecraft testing. According to former astronaut Tom Jones in a 2018 article, Schirra, \"with indisputable evidence of the risks his crew would be taking, now had immense leverage with management at NASA and North American, and he used it. In conference rooms or on the spacecraft assembly line, Schirra got his way.\"",
        "target": "The Apollo 7 crew spent five hours in training for every hour they could expect to remain aboard if the mission went its full eleven days. In addition, they attended technical briefings and pilots' meetings, and studied on their own. They undertook launch pad evacuation training, water egress training to exit the vehicle after splashdown, and learned to use firefighting equipment. They trained on the Apollo Guidance Computer at MIT. Each crew member spent 160 hours in CM simulations, in some of which Mission Control in Houston participated live. The \"plugs out\" testthe test that had killed the Apollo1 crewwas conducted with the prime crew in the spacecraft, but with the hatch open. One reason the Apollo1 crew had died was because it was impossible to open the inward-opening hatch before the fire raced through the cabin; this was changed for Apollo7."
    },
    {
        "source": "Given the circumstances of the fire, the crew initially had little confidence in the staff at North American Aviation's plant at Downey, California, who built the Apollo command modules, and they were determined to follow their craft every step of the way through construction and testing. This interfered with training, but the simulators of the CM were not yet ready, and they knew it would be a long time until they launched. They spent long periods at Downey. Simulators were constructed at Houston's Manned Spacecraft Center and at KSC in Florida. Once these were available for use, the crew had difficulty finding enough time to do everything, even with the help of the backup and support crews; the crew often worked 12 or 14 hours per day. After the CM was completed and shipped to KSC, the focus of the crew's training shifted to Florida, though they went to Houston for planning and technical meetings. Rather than return to their Houston homes for the weekend, they often had to remain at KSC in order to participate in training or spacecraft testing. According to former astronaut Tom Jones in a 2018 article, Schirra, \"with indisputable evidence of the risks his crew would be taking, now had immense leverage with management at NASA and North American, and he used it. In conference rooms or on the spacecraft assembly line, Schirra got his way.\" The Apollo 7 crew spent five hours in training for every hour they could expect to remain aboard if the mission went its full eleven days. In addition, they attended technical briefings and pilots' meetings, and studied on their own. They undertook launch pad evacuation training, water egress training to exit the vehicle after splashdown, and learned to use firefighting equipment. They trained on the Apollo Guidance Computer at MIT. Each crew member spent 160 hours in CM simulations, in some of which Mission Control in Houston participated live. The \"plugs out\" testthe test that had killed the Apollo1 crewwas conducted with the prime crew in the spacecraft, but with the hatch open. One reason the Apollo1 crew had died was because it was impossible to open the inward-opening hatch before the fire raced through the cabin; this was changed for Apollo7.",
        "target": "Command modules similar to that used on Apollo7 were subjected to tests in the run-up to the mission. A three-astronaut crew (Joseph P. Kerwin, Vance D. Brand and Joe H. Engle) was inside a CM that was placed in a vacuum chamber at the Manned Spaceflight Center in Houston for eight days in June 1968 to test spacecraft systems. Another crew (James Lovell, Stuart Roosa and Charles M. Duke) spent 48 hours at sea aboard a CM lowered into the Gulf of Mexico from a naval vessel in April 1968, to test how systems would respond to seawater. Further tests were conducted the following month in a tank at Houston. Fires were set aboard a boilerplate CM using various atmospheric compositions and pressures. The results led to the decision to use 60 percent oxygen and 40 percent nitrogen within the CM at launch, which would be replaced with a lower pressure of pure oxygen within four hours, as providing adequate fire protection. Other boilerplate spacecraft were subjected to drops to test parachutes, and to simulate the likely damage if a CM came down on land. All results were satisfactory."
    },
    {
        "source": "The Apollo 7 crew spent five hours in training for every hour they could expect to remain aboard if the mission went its full eleven days. In addition, they attended technical briefings and pilots' meetings, and studied on their own. They undertook launch pad evacuation training, water egress training to exit the vehicle after splashdown, and learned to use firefighting equipment. They trained on the Apollo Guidance Computer at MIT. Each crew member spent 160 hours in CM simulations, in some of which Mission Control in Houston participated live. The \"plugs out\" testthe test that had killed the Apollo1 crewwas conducted with the prime crew in the spacecraft, but with the hatch open. One reason the Apollo1 crew had died was because it was impossible to open the inward-opening hatch before the fire raced through the cabin; this was changed for Apollo7. Command modules similar to that used on Apollo7 were subjected to tests in the run-up to the mission. A three-astronaut crew (Joseph P. Kerwin, Vance D. Brand and Joe H. Engle) was inside a CM that was placed in a vacuum chamber at the Manned Spaceflight Center in Houston for eight days in June 1968 to test spacecraft systems. Another crew (James Lovell, Stuart Roosa and Charles M. Duke) spent 48 hours at sea aboard a CM lowered into the Gulf of Mexico from a naval vessel in April 1968, to test how systems would respond to seawater. Further tests were conducted the following month in a tank at Houston. Fires were set aboard a boilerplate CM using various atmospheric compositions and pressures. The results led to the decision to use 60 percent oxygen and 40 percent nitrogen within the CM at launch, which would be replaced with a lower pressure of pure oxygen within four hours, as providing adequate fire protection. Other boilerplate spacecraft were subjected to drops to test parachutes, and to simulate the likely damage if a CM came down on land. All results were satisfactory.",
        "target": "During the run-up to the mission, the Soviets sent uncrewed probes Zond4 and Zond5 (Zond 5 carried two tortoises) around the Moon, seeming to foreshadow a circumlunar crewed mission. NASA's Lunar Module (LM) was suffering delays, and Apollo Program Spacecraft Manager George Low proposed that if Apollo7 was a success, that Apollo8 go to lunar orbit without a LM. The acceptance of Low's proposal raised the stakes for Apollo7. According to Stafford, Schirra \"clearly felt the full weight of the program riding on a successful mission and as a result became more openly critical and more sarcastic.\""
    },
    {
        "source": "Command modules similar to that used on Apollo7 were subjected to tests in the run-up to the mission. A three-astronaut crew (Joseph P. Kerwin, Vance D. Brand and Joe H. Engle) was inside a CM that was placed in a vacuum chamber at the Manned Spaceflight Center in Houston for eight days in June 1968 to test spacecraft systems. Another crew (James Lovell, Stuart Roosa and Charles M. Duke) spent 48 hours at sea aboard a CM lowered into the Gulf of Mexico from a naval vessel in April 1968, to test how systems would respond to seawater. Further tests were conducted the following month in a tank at Houston. Fires were set aboard a boilerplate CM using various atmospheric compositions and pressures. The results led to the decision to use 60 percent oxygen and 40 percent nitrogen within the CM at launch, which would be replaced with a lower pressure of pure oxygen within four hours, as providing adequate fire protection. Other boilerplate spacecraft were subjected to drops to test parachutes, and to simulate the likely damage if a CM came down on land. All results were satisfactory. During the run-up to the mission, the Soviets sent uncrewed probes Zond4 and Zond5 (Zond 5 carried two tortoises) around the Moon, seeming to foreshadow a circumlunar crewed mission. NASA's Lunar Module (LM) was suffering delays, and Apollo Program Spacecraft Manager George Low proposed that if Apollo7 was a success, that Apollo8 go to lunar orbit without a LM. The acceptance of Low's proposal raised the stakes for Apollo7. According to Stafford, Schirra \"clearly felt the full weight of the program riding on a successful mission and as a result became more openly critical and more sarcastic.\"",
        "target": "Throughout the Mercury and Gemini programs, McDonnell Aircraft engineer Guenter Wendt led the spacecraft launch pad teams, with ultimate responsibility for condition of the spacecraft at launch. He earned the astronauts' respect and admiration, including Schirra's. However, the spacecraft contractor had changed from McDonnell (Mercury and Gemini) to North American (Apollo), so Wendt was not the pad leader for Apollo1. So adamant was Schirra in his desire to have Wendt back as pad leader for his Apollo flight, that he got his boss Slayton to persuade North American management to hire Wendt away from McDonnell, and Schirra personally lobbied North American's launch operations manager to change Wendt's shift from midnight to day so he could be pad leader for Apollo7. Wendt remained as pad leader for the entire Apollo program. When he departed the spacecraft area as the pad was evacuated prior to launch, after Cunningham said, \"I think Guenter's going\", Eisele responded \"Yes, I think Guenter went.\"[b]"
    },
    {
        "source": "During the run-up to the mission, the Soviets sent uncrewed probes Zond4 and Zond5 (Zond 5 carried two tortoises) around the Moon, seeming to foreshadow a circumlunar crewed mission. NASA's Lunar Module (LM) was suffering delays, and Apollo Program Spacecraft Manager George Low proposed that if Apollo7 was a success, that Apollo8 go to lunar orbit without a LM. The acceptance of Low's proposal raised the stakes for Apollo7. According to Stafford, Schirra \"clearly felt the full weight of the program riding on a successful mission and as a result became more openly critical and more sarcastic.\" Throughout the Mercury and Gemini programs, McDonnell Aircraft engineer Guenter Wendt led the spacecraft launch pad teams, with ultimate responsibility for condition of the spacecraft at launch. He earned the astronauts' respect and admiration, including Schirra's. However, the spacecraft contractor had changed from McDonnell (Mercury and Gemini) to North American (Apollo), so Wendt was not the pad leader for Apollo1. So adamant was Schirra in his desire to have Wendt back as pad leader for his Apollo flight, that he got his boss Slayton to persuade North American management to hire Wendt away from McDonnell, and Schirra personally lobbied North American's launch operations manager to change Wendt's shift from midnight to day so he could be pad leader for Apollo7. Wendt remained as pad leader for the entire Apollo program. When he departed the spacecraft area as the pad was evacuated prior to launch, after Cunningham said, \"I think Guenter's going\", Eisele responded \"Yes, I think Guenter went.\"[b]",
        "target": "The Apollo 7 spacecraft included Command and Service Module 101 (CSM-101), the first BlockII CSM to be flown. The BlockII craft had the capability of docking with a LM, though none was flown on Apollo7. The spacecraft also included the launch escape system and a spacecraft-lunar module adapter (SLA, numbered as SLA-5), though the latter included no LM and instead provided a mating structure between the SM and the S-IVB's Instrument Unit, with a structural stiffener substituted for the LM. The launch escape system was jettisoned after S-IVB ignition, while the SLA was left behind on the spent S-IVB when the CSM separated from it in orbit."
    },
    {
        "source": "Throughout the Mercury and Gemini programs, McDonnell Aircraft engineer Guenter Wendt led the spacecraft launch pad teams, with ultimate responsibility for condition of the spacecraft at launch. He earned the astronauts' respect and admiration, including Schirra's. However, the spacecraft contractor had changed from McDonnell (Mercury and Gemini) to North American (Apollo), so Wendt was not the pad leader for Apollo1. So adamant was Schirra in his desire to have Wendt back as pad leader for his Apollo flight, that he got his boss Slayton to persuade North American management to hire Wendt away from McDonnell, and Schirra personally lobbied North American's launch operations manager to change Wendt's shift from midnight to day so he could be pad leader for Apollo7. Wendt remained as pad leader for the entire Apollo program. When he departed the spacecraft area as the pad was evacuated prior to launch, after Cunningham said, \"I think Guenter's going\", Eisele responded \"Yes, I think Guenter went.\"[b] The Apollo 7 spacecraft included Command and Service Module 101 (CSM-101), the first BlockII CSM to be flown. The BlockII craft had the capability of docking with a LM, though none was flown on Apollo7. The spacecraft also included the launch escape system and a spacecraft-lunar module adapter (SLA, numbered as SLA-5), though the latter included no LM and instead provided a mating structure between the SM and the S-IVB's Instrument Unit, with a structural stiffener substituted for the LM. The launch escape system was jettisoned after S-IVB ignition, while the SLA was left behind on the spent S-IVB when the CSM separated from it in orbit.",
        "target": "Following the Apollo 1 fire, the BlockII CSM was extensively redesignedmore than 1,800 changes were recommended, of which 1,300 were implemented for Apollo7. Prominent among these was the new aluminum and fiberglass outward-opening hatch, which the crew could open in seven seconds from within, and the pad crew in ten seconds from outside. Other changes included replacement of aluminum tubing in the high-pressure oxygen system with stainless steel, replacement of flammable materials with non-flammable (including changing plastic switches for metal ones) and, for crew protection in the event of a fire, an emergency oxygen system to shield them from toxic fumes, as well as firefighting equipment."
    },
    {
        "source": "The Apollo 7 spacecraft included Command and Service Module 101 (CSM-101), the first BlockII CSM to be flown. The BlockII craft had the capability of docking with a LM, though none was flown on Apollo7. The spacecraft also included the launch escape system and a spacecraft-lunar module adapter (SLA, numbered as SLA-5), though the latter included no LM and instead provided a mating structure between the SM and the S-IVB's Instrument Unit, with a structural stiffener substituted for the LM. The launch escape system was jettisoned after S-IVB ignition, while the SLA was left behind on the spent S-IVB when the CSM separated from it in orbit. Following the Apollo 1 fire, the BlockII CSM was extensively redesignedmore than 1,800 changes were recommended, of which 1,300 were implemented for Apollo7. Prominent among these was the new aluminum and fiberglass outward-opening hatch, which the crew could open in seven seconds from within, and the pad crew in ten seconds from outside. Other changes included replacement of aluminum tubing in the high-pressure oxygen system with stainless steel, replacement of flammable materials with non-flammable (including changing plastic switches for metal ones) and, for crew protection in the event of a fire, an emergency oxygen system to shield them from toxic fumes, as well as firefighting equipment.",
        "target": "After the Gemini 3 craft was dubbed Molly Brown by Grissom, NASA forbade naming spacecraft. Despite this prohibition, Schirra wanted to name his ship \"Phoenix,\" but NASA refused him permission. The first CM to be given a call sign other than the mission designation would be that of Apollo 9, which carried a LM that would separate from it and then re-dock, necessitating distinct call signs for the two vehicles."
    },
    {
        "source": "Following the Apollo 1 fire, the BlockII CSM was extensively redesignedmore than 1,800 changes were recommended, of which 1,300 were implemented for Apollo7. Prominent among these was the new aluminum and fiberglass outward-opening hatch, which the crew could open in seven seconds from within, and the pad crew in ten seconds from outside. Other changes included replacement of aluminum tubing in the high-pressure oxygen system with stainless steel, replacement of flammable materials with non-flammable (including changing plastic switches for metal ones) and, for crew protection in the event of a fire, an emergency oxygen system to shield them from toxic fumes, as well as firefighting equipment. After the Gemini 3 craft was dubbed Molly Brown by Grissom, NASA forbade naming spacecraft. Despite this prohibition, Schirra wanted to name his ship \"Phoenix,\" but NASA refused him permission. The first CM to be given a call sign other than the mission designation would be that of Apollo 9, which carried a LM that would separate from it and then re-dock, necessitating distinct call signs for the two vehicles.",
        "target": "Since it flew in low Earth orbit and did not include a LM, Apollo7 was launched with the Saturn IB booster rather than the much larger and more powerful Saturn V. That Saturn IB was designated SA-205, and was the fifth Saturn IB to be flownthe earlier ones did not carry crews into space. It differed from its predecessors in that stronger propellant lines to the augmented spark igniter in the J-2 engines had been installed, so as to prevent a repetition of the early shutdown that had occurred on the uncrewed Apollo6 flight; postflight analysis had shown that the propellant lines to the J-2 engines, also used in the Saturn V tested on Apollo6, had leaked."
    },
    {
        "source": "After the Gemini 3 craft was dubbed Molly Brown by Grissom, NASA forbade naming spacecraft. Despite this prohibition, Schirra wanted to name his ship \"Phoenix,\" but NASA refused him permission. The first CM to be given a call sign other than the mission designation would be that of Apollo 9, which carried a LM that would separate from it and then re-dock, necessitating distinct call signs for the two vehicles. Since it flew in low Earth orbit and did not include a LM, Apollo7 was launched with the Saturn IB booster rather than the much larger and more powerful Saturn V. That Saturn IB was designated SA-205, and was the fifth Saturn IB to be flownthe earlier ones did not carry crews into space. It differed from its predecessors in that stronger propellant lines to the augmented spark igniter in the J-2 engines had been installed, so as to prevent a repetition of the early shutdown that had occurred on the uncrewed Apollo6 flight; postflight analysis had shown that the propellant lines to the J-2 engines, also used in the Saturn V tested on Apollo6, had leaked.",
        "target": "The Saturn IB was a two-stage rocket, with the second stage an S-IVB similar to the third stage of the Saturn V, the rocket used by all later Apollo missions. The Saturn IB was used after the close of the Apollo Program to bring crews in Apollo CSMs to Skylab, and for the ApolloSoyuz Test Project."
    },
    {
        "source": "Since it flew in low Earth orbit and did not include a LM, Apollo7 was launched with the Saturn IB booster rather than the much larger and more powerful Saturn V. That Saturn IB was designated SA-205, and was the fifth Saturn IB to be flownthe earlier ones did not carry crews into space. It differed from its predecessors in that stronger propellant lines to the augmented spark igniter in the J-2 engines had been installed, so as to prevent a repetition of the early shutdown that had occurred on the uncrewed Apollo6 flight; postflight analysis had shown that the propellant lines to the J-2 engines, also used in the Saturn V tested on Apollo6, had leaked. The Saturn IB was a two-stage rocket, with the second stage an S-IVB similar to the third stage of the Saturn V, the rocket used by all later Apollo missions. The Saturn IB was used after the close of the Apollo Program to bring crews in Apollo CSMs to Skylab, and for the ApolloSoyuz Test Project.",
        "target": "Apollo 7 was the only crewed Apollo mission to launch from Cape Kennedy Air Force Station's Launch Complex 34. All subsequent Apollo and Skylab spacecraft flights (including ApolloSoyuz) were launched from Launch Complex 39 at the nearby Kennedy Space Center. Launch Complex 34 was declared redundant and decommissioned in 1969, making Apollo7 the last human spaceflight mission to launch from the Cape Air Force Station in the 20th century."
    },
    {
        "source": "The Saturn IB was a two-stage rocket, with the second stage an S-IVB similar to the third stage of the Saturn V, the rocket used by all later Apollo missions. The Saturn IB was used after the close of the Apollo Program to bring crews in Apollo CSMs to Skylab, and for the ApolloSoyuz Test Project. Apollo 7 was the only crewed Apollo mission to launch from Cape Kennedy Air Force Station's Launch Complex 34. All subsequent Apollo and Skylab spacecraft flights (including ApolloSoyuz) were launched from Launch Complex 39 at the nearby Kennedy Space Center. Launch Complex 34 was declared redundant and decommissioned in 1969, making Apollo7 the last human spaceflight mission to launch from the Cape Air Force Station in the 20th century.",
        "target": "The main purposes of the Apollo7 flight were to show that the Block II CM would be habitable and reliable over the length of time required for a lunar mission, to show that the service propulsion system (SPS, the spacecraft's main engine) and the CM's guidance systems could perform a rendezvous in orbit, and later make a precision reentry and splashdown. In addition, there were a number of specific objectives, including evaluating the communications systems and the accuracy of onboard systems such as the propellant tank gauges. Many of the activities aimed at gathering these data were scheduled for early in the mission, so that if the mission was terminated prematurely, they would already have been completed, allowing for fixes to be made prior to the next Apollo flight."
    },
    {
        "source": "Apollo 7 was the only crewed Apollo mission to launch from Cape Kennedy Air Force Station's Launch Complex 34. All subsequent Apollo and Skylab spacecraft flights (including ApolloSoyuz) were launched from Launch Complex 39 at the nearby Kennedy Space Center. Launch Complex 34 was declared redundant and decommissioned in 1969, making Apollo7 the last human spaceflight mission to launch from the Cape Air Force Station in the 20th century. The main purposes of the Apollo7 flight were to show that the Block II CM would be habitable and reliable over the length of time required for a lunar mission, to show that the service propulsion system (SPS, the spacecraft's main engine) and the CM's guidance systems could perform a rendezvous in orbit, and later make a precision reentry and splashdown. In addition, there were a number of specific objectives, including evaluating the communications systems and the accuracy of onboard systems such as the propellant tank gauges. Many of the activities aimed at gathering these data were scheduled for early in the mission, so that if the mission was terminated prematurely, they would already have been completed, allowing for fixes to be made prior to the next Apollo flight.",
        "target": "Apollo 7, the first crewed American space flight in 22 months, launched from Launch Complex 34 at 11:02:45am EDT (15:02:45UTC) on Friday, October 11, 1968."
    },
    {
        "source": "The main purposes of the Apollo7 flight were to show that the Block II CM would be habitable and reliable over the length of time required for a lunar mission, to show that the service propulsion system (SPS, the spacecraft's main engine) and the CM's guidance systems could perform a rendezvous in orbit, and later make a precision reentry and splashdown. In addition, there were a number of specific objectives, including evaluating the communications systems and the accuracy of onboard systems such as the propellant tank gauges. Many of the activities aimed at gathering these data were scheduled for early in the mission, so that if the mission was terminated prematurely, they would already have been completed, allowing for fixes to be made prior to the next Apollo flight. Apollo 7, the first crewed American space flight in 22 months, launched from Launch Complex 34 at 11:02:45am EDT (15:02:45UTC) on Friday, October 11, 1968.",
        "target": "During the countdown, the wind was blowing in from the east. Launching under these weather conditions was in violation of safety rules, since in the event of a launch vehicle malfunction and abort, the CM might be blown back over land instead of making the usual water landing. Apollo7 was equipped with the old Apollo1-style crew couches, which provided less protection than later ones. Schirra later related that he felt the launch should have been scrubbed, but managers waived the rule and he yielded under pressure."
    },
    {
        "source": "Apollo 7, the first crewed American space flight in 22 months, launched from Launch Complex 34 at 11:02:45am EDT (15:02:45UTC) on Friday, October 11, 1968. During the countdown, the wind was blowing in from the east. Launching under these weather conditions was in violation of safety rules, since in the event of a launch vehicle malfunction and abort, the CM might be blown back over land instead of making the usual water landing. Apollo7 was equipped with the old Apollo1-style crew couches, which provided less protection than later ones. Schirra later related that he felt the launch should have been scrubbed, but managers waived the rule and he yielded under pressure.",
        "target": "Liftoff proceeded flawlessly; the Saturn IB performed well on its first crewed launch and there were no significant anomalies during the boost phase. The astronauts described it as very smooth. The ascent made the 45-year-old Schirra the oldest person to that point to enter space, and, as it proved, the only astronaut to fly Mercury, Gemini and Apollo missions."
    },
    {
        "source": "During the countdown, the wind was blowing in from the east. Launching under these weather conditions was in violation of safety rules, since in the event of a launch vehicle malfunction and abort, the CM might be blown back over land instead of making the usual water landing. Apollo7 was equipped with the old Apollo1-style crew couches, which provided less protection than later ones. Schirra later related that he felt the launch should have been scrubbed, but managers waived the rule and he yielded under pressure. Liftoff proceeded flawlessly; the Saturn IB performed well on its first crewed launch and there were no significant anomalies during the boost phase. The astronauts described it as very smooth. The ascent made the 45-year-old Schirra the oldest person to that point to enter space, and, as it proved, the only astronaut to fly Mercury, Gemini and Apollo missions.",
        "target": "Within the first three hours of flight, the astronauts performed two actions which simulated what would be required on a lunar mission. First, they maneuvered the craft with the S-IVB still attached, as would be required for the burn that would take lunar missions to the Moon. Then, after separation from the S-IVB, Schirra turned the CSM around and approached a docking target painted on the S-IVB, simulating the docking maneuver with the lunar module on Moon-bound missions prior to extracting the combined craft. Cunningham reported that the hinged SLA panels on the S-IVB had not fully opened, which CAPCOM Tom Stafford likened to the \"angry alligator\" from his Gemini 9A flight. Partially open panels would have presented a collision hazard on flights with an LM, so on subsequent missions the SLA panels were jettisoned after the CSM had separated.\nAfter station keeping with the S-IVB for 20 minutes, Schirra let it drift away, putting 76 miles (122km) between the CSM and it in preparation for the following day's rendezvous attempt."
    },
    {
        "source": "Liftoff proceeded flawlessly; the Saturn IB performed well on its first crewed launch and there were no significant anomalies during the boost phase. The astronauts described it as very smooth. The ascent made the 45-year-old Schirra the oldest person to that point to enter space, and, as it proved, the only astronaut to fly Mercury, Gemini and Apollo missions. Within the first three hours of flight, the astronauts performed two actions which simulated what would be required on a lunar mission. First, they maneuvered the craft with the S-IVB still attached, as would be required for the burn that would take lunar missions to the Moon. Then, after separation from the S-IVB, Schirra turned the CSM around and approached a docking target painted on the S-IVB, simulating the docking maneuver with the lunar module on Moon-bound missions prior to extracting the combined craft. Cunningham reported that the hinged SLA panels on the S-IVB had not fully opened, which CAPCOM Tom Stafford likened to the \"angry alligator\" from his Gemini 9A flight. Partially open panels would have presented a collision hazard on flights with an LM, so on subsequent missions the SLA panels were jettisoned after the CSM had separated.\nAfter station keeping with the S-IVB for 20 minutes, Schirra let it drift away, putting 76 miles (122km) between the CSM and it in preparation for the following day's rendezvous attempt.",
        "target": "The astronauts also enjoyed a hot lunch, the first hot meal prepared on an American spacecraft. Schirra had brought instant coffee along over the opposition of NASA doctors, who argued it added nothing nutritionally. Five hours after launch, he reported having, and enjoying, his first plastic bag full of coffee."
    },
    {
        "source": "Within the first three hours of flight, the astronauts performed two actions which simulated what would be required on a lunar mission. First, they maneuvered the craft with the S-IVB still attached, as would be required for the burn that would take lunar missions to the Moon. Then, after separation from the S-IVB, Schirra turned the CSM around and approached a docking target painted on the S-IVB, simulating the docking maneuver with the lunar module on Moon-bound missions prior to extracting the combined craft. Cunningham reported that the hinged SLA panels on the S-IVB had not fully opened, which CAPCOM Tom Stafford likened to the \"angry alligator\" from his Gemini 9A flight. Partially open panels would have presented a collision hazard on flights with an LM, so on subsequent missions the SLA panels were jettisoned after the CSM had separated.\nAfter station keeping with the S-IVB for 20 minutes, Schirra let it drift away, putting 76 miles (122km) between the CSM and it in preparation for the following day's rendezvous attempt. The astronauts also enjoyed a hot lunch, the first hot meal prepared on an American spacecraft. Schirra had brought instant coffee along over the opposition of NASA doctors, who argued it added nothing nutritionally. Five hours after launch, he reported having, and enjoying, his first plastic bag full of coffee.",
        "target": "The purpose of the rendezvous was to demonstrate the CSM's ability to match orbits with and rescue a LM after an aborted lunar landing attempt, or following liftoff from the lunar surface. This was to occur on the second day; but by the end of the first, Schirra had reported he had a cold, and, despite Slayton coming on the loop to argue in favor, declined Mission Control's request that the crew power up and test the onboard television camera prior to the rendezvous, citing the cold, that the crew had not eaten, and that there was already a very full schedule."
    },
    {
        "source": "The astronauts also enjoyed a hot lunch, the first hot meal prepared on an American spacecraft. Schirra had brought instant coffee along over the opposition of NASA doctors, who argued it added nothing nutritionally. Five hours after launch, he reported having, and enjoying, his first plastic bag full of coffee. The purpose of the rendezvous was to demonstrate the CSM's ability to match orbits with and rescue a LM after an aborted lunar landing attempt, or following liftoff from the lunar surface. This was to occur on the second day; but by the end of the first, Schirra had reported he had a cold, and, despite Slayton coming on the loop to argue in favor, declined Mission Control's request that the crew power up and test the onboard television camera prior to the rendezvous, citing the cold, that the crew had not eaten, and that there was already a very full schedule.",
        "target": "The rendezvous was complicated by the fact that the Apollo7 spacecraft lacked a rendezvous radar, something the Moon-bound missions would have. The SPS, the engine that would be needed to send later Apollo CSMs into and out of lunar orbit, had been fired only on a test stand. Although the astronauts were confident it would work, they were concerned it might fire in an unexpected manner, necessitating an early end to the mission. The burns would be computed from the ground but the final work in maneuvering up to the S-IVB would require Eisele to use the telescope and sextant to compute the final burns, with Schirra applying the ship's reaction control system (RCS) thrusters. Eisele was startled by the violent jolt caused by activating the SPS. The thrust caused Schirra to yell, \"Yabba dabba doo!\" in reference to The Flintstones cartoon. Schirra eased the craft close to the S-IVB, which was tumbling out of control, successfully completing the rendezvous."
    },
    {
        "source": "The purpose of the rendezvous was to demonstrate the CSM's ability to match orbits with and rescue a LM after an aborted lunar landing attempt, or following liftoff from the lunar surface. This was to occur on the second day; but by the end of the first, Schirra had reported he had a cold, and, despite Slayton coming on the loop to argue in favor, declined Mission Control's request that the crew power up and test the onboard television camera prior to the rendezvous, citing the cold, that the crew had not eaten, and that there was already a very full schedule. The rendezvous was complicated by the fact that the Apollo7 spacecraft lacked a rendezvous radar, something the Moon-bound missions would have. The SPS, the engine that would be needed to send later Apollo CSMs into and out of lunar orbit, had been fired only on a test stand. Although the astronauts were confident it would work, they were concerned it might fire in an unexpected manner, necessitating an early end to the mission. The burns would be computed from the ground but the final work in maneuvering up to the S-IVB would require Eisele to use the telescope and sextant to compute the final burns, with Schirra applying the ship's reaction control system (RCS) thrusters. Eisele was startled by the violent jolt caused by activating the SPS. The thrust caused Schirra to yell, \"Yabba dabba doo!\" in reference to The Flintstones cartoon. Schirra eased the craft close to the S-IVB, which was tumbling out of control, successfully completing the rendezvous.",
        "target": "The first television broadcast took place on October 14. It began with a view of a card reading \"From the Lovely Apollo Room high atop everything\", recalling tag lines used by band leaders on 1930s radio broadcasts. Cunningham served as camera operator with Eisele as emcee. During the seven-minute broadcast, the crew showed off the spacecraft and gave the audience views of the southern United States. Before the close, Schirra held another sign, \"Keep those cards and letters coming in folks\", another old-time radio tag line that had been used recently by Dean Martin. This was the first live television broadcast from an American spacecraft (Gordon Cooper had transmitted slow scan television pictures from Faith7 in 1963, but the pictures were of poor quality and were never broadcast). According to Jones, \"these apparently amiable astronauts delivered to NASA a solid public relations coup.\"  Daily television broadcasts of about 10 minutes each followed, during which the crew held up more signs and educated their audience about spaceflight; after the return to Earth, they were awarded a special Emmy for the telecasts."
    },
    {
        "source": "The rendezvous was complicated by the fact that the Apollo7 spacecraft lacked a rendezvous radar, something the Moon-bound missions would have. The SPS, the engine that would be needed to send later Apollo CSMs into and out of lunar orbit, had been fired only on a test stand. Although the astronauts were confident it would work, they were concerned it might fire in an unexpected manner, necessitating an early end to the mission. The burns would be computed from the ground but the final work in maneuvering up to the S-IVB would require Eisele to use the telescope and sextant to compute the final burns, with Schirra applying the ship's reaction control system (RCS) thrusters. Eisele was startled by the violent jolt caused by activating the SPS. The thrust caused Schirra to yell, \"Yabba dabba doo!\" in reference to The Flintstones cartoon. Schirra eased the craft close to the S-IVB, which was tumbling out of control, successfully completing the rendezvous. The first television broadcast took place on October 14. It began with a view of a card reading \"From the Lovely Apollo Room high atop everything\", recalling tag lines used by band leaders on 1930s radio broadcasts. Cunningham served as camera operator with Eisele as emcee. During the seven-minute broadcast, the crew showed off the spacecraft and gave the audience views of the southern United States. Before the close, Schirra held another sign, \"Keep those cards and letters coming in folks\", another old-time radio tag line that had been used recently by Dean Martin. This was the first live television broadcast from an American spacecraft (Gordon Cooper had transmitted slow scan television pictures from Faith7 in 1963, but the pictures were of poor quality and were never broadcast). According to Jones, \"these apparently amiable astronauts delivered to NASA a solid public relations coup.\"  Daily television broadcasts of about 10 minutes each followed, during which the crew held up more signs and educated their audience about spaceflight; after the return to Earth, they were awarded a special Emmy for the telecasts.",
        "target": "Later on October 14, the craft's onboard radar receiver was able to lock onto a ground-based transmitter, again showing a CSM in lunar orbit could keep contact with a LM returning from the Moon's surface. Throughout the remainder of the mission, the crew continued to run tests on the CSM, including of the propulsion, navigation, environmental, electrical and thermal control systems. All checked out well; according to authors Francis French and Colin Burgess, \"The redesigned Apollo spacecraft was better than anyone had dared to hope.\" Eisele found that navigation was not as easy as anticipated; he found it difficult to use Earth's horizon in sighting stars due to the fuzziness of the atmosphere, and water dumps made it difficult to discern which glistening points were stars and which ice particles. By the end of the mission, the SPS engine had been fired eight times without any problems."
    },
    {
        "source": "The first television broadcast took place on October 14. It began with a view of a card reading \"From the Lovely Apollo Room high atop everything\", recalling tag lines used by band leaders on 1930s radio broadcasts. Cunningham served as camera operator with Eisele as emcee. During the seven-minute broadcast, the crew showed off the spacecraft and gave the audience views of the southern United States. Before the close, Schirra held another sign, \"Keep those cards and letters coming in folks\", another old-time radio tag line that had been used recently by Dean Martin. This was the first live television broadcast from an American spacecraft (Gordon Cooper had transmitted slow scan television pictures from Faith7 in 1963, but the pictures were of poor quality and were never broadcast). According to Jones, \"these apparently amiable astronauts delivered to NASA a solid public relations coup.\"  Daily television broadcasts of about 10 minutes each followed, during which the crew held up more signs and educated their audience about spaceflight; after the return to Earth, they were awarded a special Emmy for the telecasts. Later on October 14, the craft's onboard radar receiver was able to lock onto a ground-based transmitter, again showing a CSM in lunar orbit could keep contact with a LM returning from the Moon's surface. Throughout the remainder of the mission, the crew continued to run tests on the CSM, including of the propulsion, navigation, environmental, electrical and thermal control systems. All checked out well; according to authors Francis French and Colin Burgess, \"The redesigned Apollo spacecraft was better than anyone had dared to hope.\" Eisele found that navigation was not as easy as anticipated; he found it difficult to use Earth's horizon in sighting stars due to the fuzziness of the atmosphere, and water dumps made it difficult to discern which glistening points were stars and which ice particles. By the end of the mission, the SPS engine had been fired eight times without any problems.",
        "target": "One difficulty that was encountered was with the sleep schedule, which called for one crew member to remain awake at all times; Eisele was to remain awake while the others slept, and sleep during part of the time the others were awake. This did not work well, as it was hard for crew members to work without making a disturbance. Cunningham later remembered waking up to find Eisele dozing."
    },
    {
        "source": "Later on October 14, the craft's onboard radar receiver was able to lock onto a ground-based transmitter, again showing a CSM in lunar orbit could keep contact with a LM returning from the Moon's surface. Throughout the remainder of the mission, the crew continued to run tests on the CSM, including of the propulsion, navigation, environmental, electrical and thermal control systems. All checked out well; according to authors Francis French and Colin Burgess, \"The redesigned Apollo spacecraft was better than anyone had dared to hope.\" Eisele found that navigation was not as easy as anticipated; he found it difficult to use Earth's horizon in sighting stars due to the fuzziness of the atmosphere, and water dumps made it difficult to discern which glistening points were stars and which ice particles. By the end of the mission, the SPS engine had been fired eight times without any problems. One difficulty that was encountered was with the sleep schedule, which called for one crew member to remain awake at all times; Eisele was to remain awake while the others slept, and sleep during part of the time the others were awake. This did not work well, as it was hard for crew members to work without making a disturbance. Cunningham later remembered waking up to find Eisele dozing.",
        "target": "Schirra was angered by NASA managers allowing the launch to proceed despite the winds, saying \"The mission pushed us to the wall in terms of risk.\" Jones said, \"This prelaunch dispute was the prelude to a tug of war over command decisions for the rest of the mission.\" Lack of sleep and Schirra's cold probably contributed to the conflict between the astronauts and Mission Control that surfaced from time to time during the flight."
    },
    {
        "source": "One difficulty that was encountered was with the sleep schedule, which called for one crew member to remain awake at all times; Eisele was to remain awake while the others slept, and sleep during part of the time the others were awake. This did not work well, as it was hard for crew members to work without making a disturbance. Cunningham later remembered waking up to find Eisele dozing. Schirra was angered by NASA managers allowing the launch to proceed despite the winds, saying \"The mission pushed us to the wall in terms of risk.\" Jones said, \"This prelaunch dispute was the prelude to a tug of war over command decisions for the rest of the mission.\" Lack of sleep and Schirra's cold probably contributed to the conflict between the astronauts and Mission Control that surfaced from time to time during the flight.",
        "target": "The testing of the television resulted in a disagreement between the crew and Houston. Schirra stated at the time, \"You've added two burns to this flight schedule, and you've added a urine water dump; and we have a new vehicle up here, and I can tell you at this point, TV will be delayed without any further discussion until after the rendezvous.\" Schirra later wrote, \"we'd resist anything that interfered with our main mission objectives. On this particular Saturday morning a TV program clearly interfered.\" Eisele agreed in his memoirs, \"We were preoccupied with preparations for that critical exercise and didn't want to divert our attention with what seemed to be trivialities at the time.... Evidently the earth people felt differently; there was a real stink about the hotheaded, recalcitrant Apollo7 crew who wouldn't take orders.\" French and Burgess wrote, \"When this point is considered objectivelythat in a front-loaded mission the rendezvous, alignment, and engine tests should be done before television showsit is hard to argue with him [Schirra].\" Although Slayton gave in to Schirra, the commander's attitude surprised flight controllers."
    },
    {
        "source": "Schirra was angered by NASA managers allowing the launch to proceed despite the winds, saying \"The mission pushed us to the wall in terms of risk.\" Jones said, \"This prelaunch dispute was the prelude to a tug of war over command decisions for the rest of the mission.\" Lack of sleep and Schirra's cold probably contributed to the conflict between the astronauts and Mission Control that surfaced from time to time during the flight. The testing of the television resulted in a disagreement between the crew and Houston. Schirra stated at the time, \"You've added two burns to this flight schedule, and you've added a urine water dump; and we have a new vehicle up here, and I can tell you at this point, TV will be delayed without any further discussion until after the rendezvous.\" Schirra later wrote, \"we'd resist anything that interfered with our main mission objectives. On this particular Saturday morning a TV program clearly interfered.\" Eisele agreed in his memoirs, \"We were preoccupied with preparations for that critical exercise and didn't want to divert our attention with what seemed to be trivialities at the time.... Evidently the earth people felt differently; there was a real stink about the hotheaded, recalcitrant Apollo7 crew who wouldn't take orders.\" French and Burgess wrote, \"When this point is considered objectivelythat in a front-loaded mission the rendezvous, alignment, and engine tests should be done before television showsit is hard to argue with him [Schirra].\" Although Slayton gave in to Schirra, the commander's attitude surprised flight controllers.",
        "target": "On Day 8, after being asked to follow a new procedure passed up from the ground that caused the computer to freeze, Eisele radioed, \"We didn't get the results that you were after. We didn't get a damn thing, in fact... you bet your ass... as far as we're concerned, somebody down there screwed up royally when he laid that one on us.\" Schirra later stated his belief that this was the one main occasion when Eisele upset Mission Control. The next day saw more conflict, with Schirra telling Mission Control after having to make repeated firings of the RCS system to keep the spacecraft stable during a test, \"I wish you would find out the idiot's name who thought up this test. I want to find out, and I want to talk to him personally when I get back down.\" Eisele joined in, \"While you are at it, find out who dreamed up 'P22 horizon test'; that is a beauty also.\"[c]"
    },
    {
        "source": "The testing of the television resulted in a disagreement between the crew and Houston. Schirra stated at the time, \"You've added two burns to this flight schedule, and you've added a urine water dump; and we have a new vehicle up here, and I can tell you at this point, TV will be delayed without any further discussion until after the rendezvous.\" Schirra later wrote, \"we'd resist anything that interfered with our main mission objectives. On this particular Saturday morning a TV program clearly interfered.\" Eisele agreed in his memoirs, \"We were preoccupied with preparations for that critical exercise and didn't want to divert our attention with what seemed to be trivialities at the time.... Evidently the earth people felt differently; there was a real stink about the hotheaded, recalcitrant Apollo7 crew who wouldn't take orders.\" French and Burgess wrote, \"When this point is considered objectivelythat in a front-loaded mission the rendezvous, alignment, and engine tests should be done before television showsit is hard to argue with him [Schirra].\" Although Slayton gave in to Schirra, the commander's attitude surprised flight controllers. On Day 8, after being asked to follow a new procedure passed up from the ground that caused the computer to freeze, Eisele radioed, \"We didn't get the results that you were after. We didn't get a damn thing, in fact... you bet your ass... as far as we're concerned, somebody down there screwed up royally when he laid that one on us.\" Schirra later stated his belief that this was the one main occasion when Eisele upset Mission Control. The next day saw more conflict, with Schirra telling Mission Control after having to make repeated firings of the RCS system to keep the spacecraft stable during a test, \"I wish you would find out the idiot's name who thought up this test. I want to find out, and I want to talk to him personally when I get back down.\" Eisele joined in, \"While you are at it, find out who dreamed up 'P22 horizon test'; that is a beauty also.\"[c]",
        "target": "A further source of tension between Mission Control and the crew was that Schirra repeatedly expressed the view that the reentry should be conducted with their helmets off. He perceived a risk that their eardrums might burst due to the sinus pressure from their colds, and they wanted to be able to pinch their noses and blow to equalize the pressure as it increased during reentry. This would have been impossible wearing the helmets. Over several days, Schirra refused advice from the ground that the helmets should be worn, stating it was his prerogative as commander to decide this, though Slayton warned him he would have to answer for it after the flight. Schirra stated in 1994, \"In this case I had a cold, and I'd had enough discussion with the ground, and I didn't have much more time to talk about whether we would put the helmet on or off. I said, essentially, I'm on board, I'm commanding. They could wear all the black armbands they wanted if I was lost or if I lost my hearing. But I had the responsibility for getting through the mission.\" No helmets were worn during the entry. Director of Flight Operations Christopher C. Kraft demanded an explanation for what he believed was Schirra's insubordination from the CAPCOM, Stafford. Kraft later said, \"Schirra was exercising his commanders right to have the last word, and that was that.\""
    },
    {
        "source": "On Day 8, after being asked to follow a new procedure passed up from the ground that caused the computer to freeze, Eisele radioed, \"We didn't get the results that you were after. We didn't get a damn thing, in fact... you bet your ass... as far as we're concerned, somebody down there screwed up royally when he laid that one on us.\" Schirra later stated his belief that this was the one main occasion when Eisele upset Mission Control. The next day saw more conflict, with Schirra telling Mission Control after having to make repeated firings of the RCS system to keep the spacecraft stable during a test, \"I wish you would find out the idiot's name who thought up this test. I want to find out, and I want to talk to him personally when I get back down.\" Eisele joined in, \"While you are at it, find out who dreamed up 'P22 horizon test'; that is a beauty also.\"[c] A further source of tension between Mission Control and the crew was that Schirra repeatedly expressed the view that the reentry should be conducted with their helmets off. He perceived a risk that their eardrums might burst due to the sinus pressure from their colds, and they wanted to be able to pinch their noses and blow to equalize the pressure as it increased during reentry. This would have been impossible wearing the helmets. Over several days, Schirra refused advice from the ground that the helmets should be worn, stating it was his prerogative as commander to decide this, though Slayton warned him he would have to answer for it after the flight. Schirra stated in 1994, \"In this case I had a cold, and I'd had enough discussion with the ground, and I didn't have much more time to talk about whether we would put the helmet on or off. I said, essentially, I'm on board, I'm commanding. They could wear all the black armbands they wanted if I was lost or if I lost my hearing. But I had the responsibility for getting through the mission.\" No helmets were worn during the entry. Director of Flight Operations Christopher C. Kraft demanded an explanation for what he believed was Schirra's insubordination from the CAPCOM, Stafford. Kraft later said, \"Schirra was exercising his commanders right to have the last word, and that was that.\"",
        "target": "Apollo 7 splashed down without incident at 11:11:48 UTC on October 22, 1968, 200 nautical miles (230mi; 370km) SSW of Bermuda and 7 nautical miles (8mi; 13km) north of the recovery ship USS Essex. The mission's duration was 10days, 20hours, 9minutes and 3seconds."
    },
    {
        "source": "A further source of tension between Mission Control and the crew was that Schirra repeatedly expressed the view that the reentry should be conducted with their helmets off. He perceived a risk that their eardrums might burst due to the sinus pressure from their colds, and they wanted to be able to pinch their noses and blow to equalize the pressure as it increased during reentry. This would have been impossible wearing the helmets. Over several days, Schirra refused advice from the ground that the helmets should be worn, stating it was his prerogative as commander to decide this, though Slayton warned him he would have to answer for it after the flight. Schirra stated in 1994, \"In this case I had a cold, and I'd had enough discussion with the ground, and I didn't have much more time to talk about whether we would put the helmet on or off. I said, essentially, I'm on board, I'm commanding. They could wear all the black armbands they wanted if I was lost or if I lost my hearing. But I had the responsibility for getting through the mission.\" No helmets were worn during the entry. Director of Flight Operations Christopher C. Kraft demanded an explanation for what he believed was Schirra's insubordination from the CAPCOM, Stafford. Kraft later said, \"Schirra was exercising his commanders right to have the last word, and that was that.\" Apollo 7 splashed down without incident at 11:11:48 UTC on October 22, 1968, 200 nautical miles (230mi; 370km) SSW of Bermuda and 7 nautical miles (8mi; 13km) north of the recovery ship USS Essex. The mission's duration was 10days, 20hours, 9minutes and 3seconds.",
        "target": "After the mission, NASA awarded Schirra, Eisele and Cunningham its Exceptional Service Medal in recognition of their success. On November 2, 1968, President Lyndon Johnson held a ceremony at the LBJ Ranch in Johnson City, Texas, to present the astronauts with the medals. He also presented NASA's highest honor, the Distinguished Service Medal, to recently retired NASA administrator James E. Webb, for his \"outstanding leadership of America's space program\" since the beginning of Apollo. Johnson also invited the crew to the White House, and they went there in December 1968."
    },
    {
        "source": "Apollo 7 splashed down without incident at 11:11:48 UTC on October 22, 1968, 200 nautical miles (230mi; 370km) SSW of Bermuda and 7 nautical miles (8mi; 13km) north of the recovery ship USS Essex. The mission's duration was 10days, 20hours, 9minutes and 3seconds. After the mission, NASA awarded Schirra, Eisele and Cunningham its Exceptional Service Medal in recognition of their success. On November 2, 1968, President Lyndon Johnson held a ceremony at the LBJ Ranch in Johnson City, Texas, to present the astronauts with the medals. He also presented NASA's highest honor, the Distinguished Service Medal, to recently retired NASA administrator James E. Webb, for his \"outstanding leadership of America's space program\" since the beginning of Apollo. Johnson also invited the crew to the White House, and they went there in December 1968.",
        "target": "Despite the difficulties between the crew and Mission Control, the mission successfully met its objectives to verify the Apollo command and service module's flightworthiness, allowing Apollo8's flight to the Moon to proceed just two months later. John T. McQuiston wrote in The New York Times after Eisele's death in 1987 that Apollo7's success brought renewed confidence to NASA's space program. According to Jones, \"Three weeks after the Apollo7 crew returned, NASA administrator Thomas Paine green-lighted Apollo8 to launch in late December and orbit the Moon. Apollo7 had delivered NASA from its trial by fireit was the first small step down a path that would lead another crew, nine months later, to the Sea of Tranquility.\""
    },
    {
        "source": "After the mission, NASA awarded Schirra, Eisele and Cunningham its Exceptional Service Medal in recognition of their success. On November 2, 1968, President Lyndon Johnson held a ceremony at the LBJ Ranch in Johnson City, Texas, to present the astronauts with the medals. He also presented NASA's highest honor, the Distinguished Service Medal, to recently retired NASA administrator James E. Webb, for his \"outstanding leadership of America's space program\" since the beginning of Apollo. Johnson also invited the crew to the White House, and they went there in December 1968. Despite the difficulties between the crew and Mission Control, the mission successfully met its objectives to verify the Apollo command and service module's flightworthiness, allowing Apollo8's flight to the Moon to proceed just two months later. John T. McQuiston wrote in The New York Times after Eisele's death in 1987 that Apollo7's success brought renewed confidence to NASA's space program. According to Jones, \"Three weeks after the Apollo7 crew returned, NASA administrator Thomas Paine green-lighted Apollo8 to launch in late December and orbit the Moon. Apollo7 had delivered NASA from its trial by fireit was the first small step down a path that would lead another crew, nine months later, to the Sea of Tranquility.\"",
        "target": "General Sam Phillips, the Apollo Program Manager, said at the time, \"Apollo7 goes into my book as a perfect mission. We accomplished 101 percent of our objectives.\" Kraft wrote, \"Schirra and his crew did it allor at least all of it that counted... [T]hey proved to everyone's satisfaction that the SPS engine was one of the most reliable we'd ever sent into space. They operated the Command and Service Modules with true professionalism.\" Eisele wrote, \"We were insolent, high-handed, and Machiavellian at times. Call it paranoia, call it smartit got the job done. We had a great flight.\"\nKranz stated in 1998, \"we all look back now with a longer perspective. Schirra really wasn't on us as bad as it seemed at the time.... Bottom line was, even with a grumpy commander, we got the job done as a team.\""
    },
    {
        "source": "Despite the difficulties between the crew and Mission Control, the mission successfully met its objectives to verify the Apollo command and service module's flightworthiness, allowing Apollo8's flight to the Moon to proceed just two months later. John T. McQuiston wrote in The New York Times after Eisele's death in 1987 that Apollo7's success brought renewed confidence to NASA's space program. According to Jones, \"Three weeks after the Apollo7 crew returned, NASA administrator Thomas Paine green-lighted Apollo8 to launch in late December and orbit the Moon. Apollo7 had delivered NASA from its trial by fireit was the first small step down a path that would lead another crew, nine months later, to the Sea of Tranquility.\" General Sam Phillips, the Apollo Program Manager, said at the time, \"Apollo7 goes into my book as a perfect mission. We accomplished 101 percent of our objectives.\" Kraft wrote, \"Schirra and his crew did it allor at least all of it that counted... [T]hey proved to everyone's satisfaction that the SPS engine was one of the most reliable we'd ever sent into space. They operated the Command and Service Modules with true professionalism.\" Eisele wrote, \"We were insolent, high-handed, and Machiavellian at times. Call it paranoia, call it smartit got the job done. We had a great flight.\"\nKranz stated in 1998, \"we all look back now with a longer perspective. Schirra really wasn't on us as bad as it seemed at the time.... Bottom line was, even with a grumpy commander, we got the job done as a team.\"",
        "target": "None of the Apollo 7 crew members flew in space again. According to Jim Lovell, \"Apollo7 was a very successful flightthey did an excellent jobbut it was a very contentious flight. They all teed off the ground people quite considerably, and I think that kind of put a stop on future flights [for them].\" Schirra had announced, before the flight, his retirement from NASA and the Navy, effective July 1, 1969. The other two crew members had their spaceflight careers stunted by their involvement in Apollo7; by some accounts, Kraft told Slayton he was unwilling to work in future with any member of the crew. Cunningham heard the rumors that Kraft had said this and confronted him in early 1969; Kraft denied making the statement \"but his reaction wasn't exactly outraged innocence.\" Eisele's career may also have been affected by becoming the first active astronaut to divorce, followed by a quick remarriage, and an indifferent performance as backup CMP for Apollo10. He resigned from the Astronaut Office in 1970 though he remained with NASA at the Langley Research Center in Virginia until 1972, when he was eligible for retirement. Cunningham was made the leader of the Astronaut Office's Skylab division. He related that he was informally offered command of the first Skylab crew, but when this instead went to Apollo12 commander Pete Conrad, with Cunningham offered the position of backup commander, he resigned as an astronaut in 1971."
    },
    {
        "source": "General Sam Phillips, the Apollo Program Manager, said at the time, \"Apollo7 goes into my book as a perfect mission. We accomplished 101 percent of our objectives.\" Kraft wrote, \"Schirra and his crew did it allor at least all of it that counted... [T]hey proved to everyone's satisfaction that the SPS engine was one of the most reliable we'd ever sent into space. They operated the Command and Service Modules with true professionalism.\" Eisele wrote, \"We were insolent, high-handed, and Machiavellian at times. Call it paranoia, call it smartit got the job done. We had a great flight.\"\nKranz stated in 1998, \"we all look back now with a longer perspective. Schirra really wasn't on us as bad as it seemed at the time.... Bottom line was, even with a grumpy commander, we got the job done as a team.\" None of the Apollo 7 crew members flew in space again. According to Jim Lovell, \"Apollo7 was a very successful flightthey did an excellent jobbut it was a very contentious flight. They all teed off the ground people quite considerably, and I think that kind of put a stop on future flights [for them].\" Schirra had announced, before the flight, his retirement from NASA and the Navy, effective July 1, 1969. The other two crew members had their spaceflight careers stunted by their involvement in Apollo7; by some accounts, Kraft told Slayton he was unwilling to work in future with any member of the crew. Cunningham heard the rumors that Kraft had said this and confronted him in early 1969; Kraft denied making the statement \"but his reaction wasn't exactly outraged innocence.\" Eisele's career may also have been affected by becoming the first active astronaut to divorce, followed by a quick remarriage, and an indifferent performance as backup CMP for Apollo10. He resigned from the Astronaut Office in 1970 though he remained with NASA at the Langley Research Center in Virginia until 1972, when he was eligible for retirement. Cunningham was made the leader of the Astronaut Office's Skylab division. He related that he was informally offered command of the first Skylab crew, but when this instead went to Apollo12 commander Pete Conrad, with Cunningham offered the position of backup commander, he resigned as an astronaut in 1971.",
        "target": "Schirra, Eisele and Cunningham were the only crew, of all the Apollo, Skylab and ApolloSoyuz missions, who had not been awarded the Distinguished Service Medal immediately following their missions (though Schirra had received the medal twice before, for his Mercury and Gemini missions). Therefore, NASA administrator Michael D. Griffin decided to belatedly award the medals to the crew in October 2008, \"[f]or exemplary performance in meeting all the Apollo7 mission objectives and more on the first crewed Apollo mission, paving the way for the first flight to the Moon on Apollo8 and the first crewed lunar landing on Apollo11.\" Only Cunningham was still alive at the time as Eisele had died in 1987 and Schirra in 2007. Eisele's widow accepted his medal, and Apollo8 crew member Bill Anders accepted Schirra's. Other Apollo astronauts, including Neil Armstrong, Buzz Aldrin, and Alan Bean, were present at the award ceremony. Kraft, who had been in conflict with the crew during the mission, sent a conciliatory video message of congratulations, saying: \"We gave you a hard time once but you certainly survived that and have done extremely well since... I am frankly, very proud to call you a friend.\""
    },
    {
        "source": "None of the Apollo 7 crew members flew in space again. According to Jim Lovell, \"Apollo7 was a very successful flightthey did an excellent jobbut it was a very contentious flight. They all teed off the ground people quite considerably, and I think that kind of put a stop on future flights [for them].\" Schirra had announced, before the flight, his retirement from NASA and the Navy, effective July 1, 1969. The other two crew members had their spaceflight careers stunted by their involvement in Apollo7; by some accounts, Kraft told Slayton he was unwilling to work in future with any member of the crew. Cunningham heard the rumors that Kraft had said this and confronted him in early 1969; Kraft denied making the statement \"but his reaction wasn't exactly outraged innocence.\" Eisele's career may also have been affected by becoming the first active astronaut to divorce, followed by a quick remarriage, and an indifferent performance as backup CMP for Apollo10. He resigned from the Astronaut Office in 1970 though he remained with NASA at the Langley Research Center in Virginia until 1972, when he was eligible for retirement. Cunningham was made the leader of the Astronaut Office's Skylab division. He related that he was informally offered command of the first Skylab crew, but when this instead went to Apollo12 commander Pete Conrad, with Cunningham offered the position of backup commander, he resigned as an astronaut in 1971. Schirra, Eisele and Cunningham were the only crew, of all the Apollo, Skylab and ApolloSoyuz missions, who had not been awarded the Distinguished Service Medal immediately following their missions (though Schirra had received the medal twice before, for his Mercury and Gemini missions). Therefore, NASA administrator Michael D. Griffin decided to belatedly award the medals to the crew in October 2008, \"[f]or exemplary performance in meeting all the Apollo7 mission objectives and more on the first crewed Apollo mission, paving the way for the first flight to the Moon on Apollo8 and the first crewed lunar landing on Apollo11.\" Only Cunningham was still alive at the time as Eisele had died in 1987 and Schirra in 2007. Eisele's widow accepted his medal, and Apollo8 crew member Bill Anders accepted Schirra's. Other Apollo astronauts, including Neil Armstrong, Buzz Aldrin, and Alan Bean, were present at the award ceremony. Kraft, who had been in conflict with the crew during the mission, sent a conciliatory video message of congratulations, saying: \"We gave you a hard time once but you certainly survived that and have done extremely well since... I am frankly, very proud to call you a friend.\"",
        "target": "The insignia for the flight shows a command and service module with its SPS engine firing, the trail from that fire encircling a globe and extending past the edges of the patch symbolizing the Earth-orbital nature of the mission. The Roman numeralVII appears in the South Pacific Ocean and the crew's names appear on a wide black arc at the bottom. The patch was designed by Allen Stevens of Rockwell International."
    },
    {
        "source": "Schirra, Eisele and Cunningham were the only crew, of all the Apollo, Skylab and ApolloSoyuz missions, who had not been awarded the Distinguished Service Medal immediately following their missions (though Schirra had received the medal twice before, for his Mercury and Gemini missions). Therefore, NASA administrator Michael D. Griffin decided to belatedly award the medals to the crew in October 2008, \"[f]or exemplary performance in meeting all the Apollo7 mission objectives and more on the first crewed Apollo mission, paving the way for the first flight to the Moon on Apollo8 and the first crewed lunar landing on Apollo11.\" Only Cunningham was still alive at the time as Eisele had died in 1987 and Schirra in 2007. Eisele's widow accepted his medal, and Apollo8 crew member Bill Anders accepted Schirra's. Other Apollo astronauts, including Neil Armstrong, Buzz Aldrin, and Alan Bean, were present at the award ceremony. Kraft, who had been in conflict with the crew during the mission, sent a conciliatory video message of congratulations, saying: \"We gave you a hard time once but you certainly survived that and have done extremely well since... I am frankly, very proud to call you a friend.\" The insignia for the flight shows a command and service module with its SPS engine firing, the trail from that fire encircling a globe and extending past the edges of the patch symbolizing the Earth-orbital nature of the mission. The Roman numeralVII appears in the South Pacific Ocean and the crew's names appear on a wide black arc at the bottom. The patch was designed by Allen Stevens of Rockwell International.",
        "target": "In January 1969, the Apollo7 command module was displayed on the NASA float in the inauguration parade of President Richard M. Nixon. The Apollo7 astronauts rode in an open car. After being transferred to the Smithsonian Institution in 1970, the spacecraft was loaned to the National Museum of Science and Technology, in Ottawa, Ontario. It was returned to the United States in 2004. Currently, the Apollo7 CM is on loan to the Frontiers of Flight Museum at Love Field in Dallas, Texas."
    },
    {
        "source": "The insignia for the flight shows a command and service module with its SPS engine firing, the trail from that fire encircling a globe and extending past the edges of the patch symbolizing the Earth-orbital nature of the mission. The Roman numeralVII appears in the South Pacific Ocean and the crew's names appear on a wide black arc at the bottom. The patch was designed by Allen Stevens of Rockwell International. In January 1969, the Apollo7 command module was displayed on the NASA float in the inauguration parade of President Richard M. Nixon. The Apollo7 astronauts rode in an open car. After being transferred to the Smithsonian Institution in 1970, the spacecraft was loaned to the National Museum of Science and Technology, in Ottawa, Ontario. It was returned to the United States in 2004. Currently, the Apollo7 CM is on loan to the Frontiers of Flight Museum at Love Field in Dallas, Texas.",
        "target": "On November 6, 1968, comedian Bob Hope broadcast one of his variety television specials from NASA's Manned Spacecraft Center in Houston to honor the Apollo7 crew. Barbara Eden, star of the popular comedy series I Dream of Jeannie, which featured fictional astronauts among its regular characters, appeared with Schirra, Eisele and Cunningham."
    },
    {
        "source": "In January 1969, the Apollo7 command module was displayed on the NASA float in the inauguration parade of President Richard M. Nixon. The Apollo7 astronauts rode in an open car. After being transferred to the Smithsonian Institution in 1970, the spacecraft was loaned to the National Museum of Science and Technology, in Ottawa, Ontario. It was returned to the United States in 2004. Currently, the Apollo7 CM is on loan to the Frontiers of Flight Museum at Love Field in Dallas, Texas. On November 6, 1968, comedian Bob Hope broadcast one of his variety television specials from NASA's Manned Spacecraft Center in Houston to honor the Apollo7 crew. Barbara Eden, star of the popular comedy series I Dream of Jeannie, which featured fictional astronauts among its regular characters, appeared with Schirra, Eisele and Cunningham.",
        "target": "Schirra parlayed the head cold he contracted during Apollo7 into a television advertising contract as a spokesman for Actifed, an over-the-counter version of the medicine he took in space."
    },
    {
        "source": "On November 6, 1968, comedian Bob Hope broadcast one of his variety television specials from NASA's Manned Spacecraft Center in Houston to honor the Apollo7 crew. Barbara Eden, star of the popular comedy series I Dream of Jeannie, which featured fictional astronauts among its regular characters, appeared with Schirra, Eisele and Cunningham. Schirra parlayed the head cold he contracted during Apollo7 into a television advertising contract as a spokesman for Actifed, an over-the-counter version of the medicine he took in space.",
        "target": "The Apollo 7 mission is dramatized in the 1998 miniseries From the Earth to the Moon episode \"We Have Cleared the Tower\", with Mark Harmon as Schirra, John Mese as Eisele, Fredric Lehne as Cunningham and Nick Searcy as Slayton."
    },
    {
        "source": " Apollo 8 (December 2127, 1968) was the first crewed spacecraft to leave Earth's gravitational sphere of influence, and the first human spaceflight to reach the Moon. The crew orbited the Moon ten times without landing and then returned to Earth. The three astronautsFrank Borman, James Lovell, and William Anderswere the first humans to see and photograph the far side of the Moon and an Earthrise.",
        "target": "Apollo 8 launched on December 21, 1968, and was the second crewed spaceflight mission flown in the United States Apollo space program (the first, Apollo7, stayed in Earth orbit). Apollo8 was the third flight and the first crewed launch of the Saturn V rocket. It was the first human spaceflight from the Kennedy Space Center, adjacent to Cape Kennedy Air Force Station in Florida."
    },
    {
        "source": "Apollo 8 (December 2127, 1968) was the first crewed spacecraft to leave Earth's gravitational sphere of influence, and the first human spaceflight to reach the Moon. The crew orbited the Moon ten times without landing and then returned to Earth. The three astronautsFrank Borman, James Lovell, and William Anderswere the first humans to see and photograph the far side of the Moon and an Earthrise. Apollo 8 launched on December 21, 1968, and was the second crewed spaceflight mission flown in the United States Apollo space program (the first, Apollo7, stayed in Earth orbit). Apollo8 was the third flight and the first crewed launch of the Saturn V rocket. It was the first human spaceflight from the Kennedy Space Center, adjacent to Cape Kennedy Air Force Station in Florida.",
        "target": "Originally planned as the second crewed Apollo Lunar Module and command module test, to be flown in an elliptical medium Earth orbit in early 1969, the mission profile was changed in August 1968 to a more ambitious command-module-only lunar orbital flight to be flown in December, as the lunar module was not yet ready to make its first flight. Astronaut Jim McDivitt's crew, who were training to fly the first lunar module flight in low Earth orbit, became the crew for the Apollo9 mission, and Borman's crew were moved to the Apollo8 mission. This left Borman's crew with two to three months' less training and preparation time than originally planned, and replaced the planned lunar module training with translunar navigation training."
    },
    {
        "source": "Apollo 8 launched on December 21, 1968, and was the second crewed spaceflight mission flown in the United States Apollo space program (the first, Apollo7, stayed in Earth orbit). Apollo8 was the third flight and the first crewed launch of the Saturn V rocket. It was the first human spaceflight from the Kennedy Space Center, adjacent to Cape Kennedy Air Force Station in Florida. Originally planned as the second crewed Apollo Lunar Module and command module test, to be flown in an elliptical medium Earth orbit in early 1969, the mission profile was changed in August 1968 to a more ambitious command-module-only lunar orbital flight to be flown in December, as the lunar module was not yet ready to make its first flight. Astronaut Jim McDivitt's crew, who were training to fly the first lunar module flight in low Earth orbit, became the crew for the Apollo9 mission, and Borman's crew were moved to the Apollo8 mission. This left Borman's crew with two to three months' less training and preparation time than originally planned, and replaced the planned lunar module training with translunar navigation training.",
        "target": "Apollo 8 took 68 hours to travel to the Moon. The crew orbited the Moon ten times over the course of twenty hours, during which they made a Christmas Eve television broadcast where they read the first ten verses from the Book of Genesis. At the time, the broadcast was the most watched TV program ever. Apollo8's successful mission paved the way for Apollo 10 and, with Apollo11 in July 1969, the fulfillment of U.S. president John F. Kennedy's goal of landing a man on the Moon before the end of the decade. The Apollo8 astronauts returned to Earth on December 27, 1968, when their spacecraft splashed down in the northern Pacific Ocean. The crew members were named Time magazine's \"Men of the Year\" for 1968 upon their return."
    },
    {
        "source": "Originally planned as the second crewed Apollo Lunar Module and command module test, to be flown in an elliptical medium Earth orbit in early 1969, the mission profile was changed in August 1968 to a more ambitious command-module-only lunar orbital flight to be flown in December, as the lunar module was not yet ready to make its first flight. Astronaut Jim McDivitt's crew, who were training to fly the first lunar module flight in low Earth orbit, became the crew for the Apollo9 mission, and Borman's crew were moved to the Apollo8 mission. This left Borman's crew with two to three months' less training and preparation time than originally planned, and replaced the planned lunar module training with translunar navigation training. Apollo 8 took 68 hours to travel to the Moon. The crew orbited the Moon ten times over the course of twenty hours, during which they made a Christmas Eve television broadcast where they read the first ten verses from the Book of Genesis. At the time, the broadcast was the most watched TV program ever. Apollo8's successful mission paved the way for Apollo 10 and, with Apollo11 in July 1969, the fulfillment of U.S. president John F. Kennedy's goal of landing a man on the Moon before the end of the decade. The Apollo8 astronauts returned to Earth on December 27, 1968, when their spacecraft splashed down in the northern Pacific Ocean. The crew members were named Time magazine's \"Men of the Year\" for 1968 upon their return.",
        "target": "In the late 1950s and early 1960s, the United States was engaged in the Cold War, a geopolitical rivalry with the Soviet Union. On October 4, 1957, the Soviet Union launched Sputnik 1, the first artificial satellite. This unexpected success stoked fears and imaginations around the world. It not only demonstrated that the Soviet Union had the capability to deliver nuclear weapons over intercontinental distances, it challenged American claims of military, economic, and technological superiority. The launch precipitated the Sputnik crisis and triggered the Space Race."
    },
    {
        "source": "Apollo 8 took 68 hours to travel to the Moon. The crew orbited the Moon ten times over the course of twenty hours, during which they made a Christmas Eve television broadcast where they read the first ten verses from the Book of Genesis. At the time, the broadcast was the most watched TV program ever. Apollo8's successful mission paved the way for Apollo 10 and, with Apollo11 in July 1969, the fulfillment of U.S. president John F. Kennedy's goal of landing a man on the Moon before the end of the decade. The Apollo8 astronauts returned to Earth on December 27, 1968, when their spacecraft splashed down in the northern Pacific Ocean. The crew members were named Time magazine's \"Men of the Year\" for 1968 upon their return. In the late 1950s and early 1960s, the United States was engaged in the Cold War, a geopolitical rivalry with the Soviet Union. On October 4, 1957, the Soviet Union launched Sputnik 1, the first artificial satellite. This unexpected success stoked fears and imaginations around the world. It not only demonstrated that the Soviet Union had the capability to deliver nuclear weapons over intercontinental distances, it challenged American claims of military, economic, and technological superiority. The launch precipitated the Sputnik crisis and triggered the Space Race.",
        "target": "President John F. Kennedy believed that not only was it in the national interest of the United States to be superior to other nations, but that the perception of American power was at least as important as the actuality. It was therefore intolerable to him for the Soviet Union to be more advanced in the field of space exploration. He was determined that the United States should compete, and sought a challenge that maximized its chances of winning."
    },
    {
        "source": "In the late 1950s and early 1960s, the United States was engaged in the Cold War, a geopolitical rivalry with the Soviet Union. On October 4, 1957, the Soviet Union launched Sputnik 1, the first artificial satellite. This unexpected success stoked fears and imaginations around the world. It not only demonstrated that the Soviet Union had the capability to deliver nuclear weapons over intercontinental distances, it challenged American claims of military, economic, and technological superiority. The launch precipitated the Sputnik crisis and triggered the Space Race. President John F. Kennedy believed that not only was it in the national interest of the United States to be superior to other nations, but that the perception of American power was at least as important as the actuality. It was therefore intolerable to him for the Soviet Union to be more advanced in the field of space exploration. He was determined that the United States should compete, and sought a challenge that maximized its chances of winning.",
        "target": "The Soviet Union had heavier-lifting carrier rockets, which meant Kennedy needed to choose a goal that was beyond the capacity of the existing generation of rocketry, one where the US and Soviet Union would be starting from a position of equalitysomething spectacular, even if it could not be justified on military, economic, or scientific grounds. After consulting with his experts and advisors, he chose such a project: to land a man on the Moon and return him to the Earth. This project already had a name: Project Apollo."
    },
    {
        "source": "President John F. Kennedy believed that not only was it in the national interest of the United States to be superior to other nations, but that the perception of American power was at least as important as the actuality. It was therefore intolerable to him for the Soviet Union to be more advanced in the field of space exploration. He was determined that the United States should compete, and sought a challenge that maximized its chances of winning. The Soviet Union had heavier-lifting carrier rockets, which meant Kennedy needed to choose a goal that was beyond the capacity of the existing generation of rocketry, one where the US and Soviet Union would be starting from a position of equalitysomething spectacular, even if it could not be justified on military, economic, or scientific grounds. After consulting with his experts and advisors, he chose such a project: to land a man on the Moon and return him to the Earth. This project already had a name: Project Apollo.",
        "target": "An early and crucial decision was the adoption of lunar orbit rendezvous, under which a specialized spacecraft would land on the lunar surface. The Apollo spacecraft therefore had three primary components: a command module (CM) with a cabin for the three astronauts, and the only part that would return to Earth; a service module (SM) to provide the command module with propulsion, electrical power, oxygen, and water; and a two-stage lunar module (LM), which comprised a descent stage for landing on the Moon and an ascent stage to return the astronauts to lunar orbit. This configuration could be launched by the Saturn V rocket that was then under development."
    },
    {
        "source": "The Soviet Union had heavier-lifting carrier rockets, which meant Kennedy needed to choose a goal that was beyond the capacity of the existing generation of rocketry, one where the US and Soviet Union would be starting from a position of equalitysomething spectacular, even if it could not be justified on military, economic, or scientific grounds. After consulting with his experts and advisors, he chose such a project: to land a man on the Moon and return him to the Earth. This project already had a name: Project Apollo. An early and crucial decision was the adoption of lunar orbit rendezvous, under which a specialized spacecraft would land on the lunar surface. The Apollo spacecraft therefore had three primary components: a command module (CM) with a cabin for the three astronauts, and the only part that would return to Earth; a service module (SM) to provide the command module with propulsion, electrical power, oxygen, and water; and a two-stage lunar module (LM), which comprised a descent stage for landing on the Moon and an ascent stage to return the astronauts to lunar orbit. This configuration could be launched by the Saturn V rocket that was then under development.",
        "target": "The initial crew assignment of Frank Borman as Commander, Michael Collins as Command Module Pilot (CMP) and William Anders as Lunar Module Pilot (LMP) for the third crewed Apollo flight was officially announced on November 20, 1967.[n 3] Collins was replaced by Jim Lovell in July 1968, after suffering a cervical disc herniation that required surgery to repair. This crew was unique among pre-Space Shuttle era missions in that the commander was not the most experienced member of the crew: Lovell had flown twice before, on Gemini VII and Gemini XII. This would also be the first case of a commander of a previous mission (Lovell, Gemini XII) flying as a non-commander. This was also the first mission to reunite crewmates from a previous mission (Lovell and Borman, Gemini VII)."
    },
    {
        "source": "An early and crucial decision was the adoption of lunar orbit rendezvous, under which a specialized spacecraft would land on the lunar surface. The Apollo spacecraft therefore had three primary components: a command module (CM) with a cabin for the three astronauts, and the only part that would return to Earth; a service module (SM) to provide the command module with propulsion, electrical power, oxygen, and water; and a two-stage lunar module (LM), which comprised a descent stage for landing on the Moon and an ascent stage to return the astronauts to lunar orbit. This configuration could be launched by the Saturn V rocket that was then under development. The initial crew assignment of Frank Borman as Commander, Michael Collins as Command Module Pilot (CMP) and William Anders as Lunar Module Pilot (LMP) for the third crewed Apollo flight was officially announced on November 20, 1967.[n 3] Collins was replaced by Jim Lovell in July 1968, after suffering a cervical disc herniation that required surgery to repair. This crew was unique among pre-Space Shuttle era missions in that the commander was not the most experienced member of the crew: Lovell had flown twice before, on Gemini VII and Gemini XII. This would also be the first case of a commander of a previous mission (Lovell, Gemini XII) flying as a non-commander. This was also the first mission to reunite crewmates from a previous mission (Lovell and Borman, Gemini VII).",
        "target": "As of June 2024, James Lovell is the last surviving Apollo 8 astronaut. Frank Borman and William Anders died on November 7, 2023, and on June 7, 2024, respectively."
    },
    {
        "source": "The initial crew assignment of Frank Borman as Commander, Michael Collins as Command Module Pilot (CMP) and William Anders as Lunar Module Pilot (LMP) for the third crewed Apollo flight was officially announced on November 20, 1967.[n 3] Collins was replaced by Jim Lovell in July 1968, after suffering a cervical disc herniation that required surgery to repair. This crew was unique among pre-Space Shuttle era missions in that the commander was not the most experienced member of the crew: Lovell had flown twice before, on Gemini VII and Gemini XII. This would also be the first case of a commander of a previous mission (Lovell, Gemini XII) flying as a non-commander. This was also the first mission to reunite crewmates from a previous mission (Lovell and Borman, Gemini VII). As of June 2024, James Lovell is the last surviving Apollo 8 astronaut. Frank Borman and William Anders died on November 7, 2023, and on June 7, 2024, respectively.",
        "target": "The backup crew assignment of Neil Armstrong as Commander, Lovell as CMP, and Buzz Aldrin as LMP for the third crewed Apollo flight was officially announced at the same time as the prime crew. When Lovell was reassigned to the prime crew, Aldrin was moved to CMP, and Fred Haise was brought in as backup LMP. Armstrong would later command Apollo11, with Aldrin as LMP and Collins as CMP. Haise served on the backup crew of Apollo11 as LMP and flew on Apollo13 as LMP."
    },
    {
        "source": "As of June 2024, James Lovell is the last surviving Apollo 8 astronaut. Frank Borman and William Anders died on November 7, 2023, and on June 7, 2024, respectively. The backup crew assignment of Neil Armstrong as Commander, Lovell as CMP, and Buzz Aldrin as LMP for the third crewed Apollo flight was officially announced at the same time as the prime crew. When Lovell was reassigned to the prime crew, Aldrin was moved to CMP, and Fred Haise was brought in as backup LMP. Armstrong would later command Apollo11, with Aldrin as LMP and Collins as CMP. Haise served on the backup crew of Apollo11 as LMP and flew on Apollo13 as LMP.",
        "target": "During Projects Mercury and Gemini, each mission had a prime and a backup crew. For Apollo, a third crew of astronauts was added, known as the support crew. The support crew maintained the flight plan, checklists, and mission ground rules, and ensured that the prime and backup crews were apprised of any changes. The support crew developed procedures in the simulators, especially those for emergency situations, so that the prime and backup crews could practice and master them in their simulator training. For Apollo8, the support crew consisted of Ken Mattingly, Vance Brand, and Gerald Carr."
    },
    {
        "source": "The backup crew assignment of Neil Armstrong as Commander, Lovell as CMP, and Buzz Aldrin as LMP for the third crewed Apollo flight was officially announced at the same time as the prime crew. When Lovell was reassigned to the prime crew, Aldrin was moved to CMP, and Fred Haise was brought in as backup LMP. Armstrong would later command Apollo11, with Aldrin as LMP and Collins as CMP. Haise served on the backup crew of Apollo11 as LMP and flew on Apollo13 as LMP. During Projects Mercury and Gemini, each mission had a prime and a backup crew. For Apollo, a third crew of astronauts was added, known as the support crew. The support crew maintained the flight plan, checklists, and mission ground rules, and ensured that the prime and backup crews were apprised of any changes. The support crew developed procedures in the simulators, especially those for emergency situations, so that the prime and backup crews could practice and master them in their simulator training. For Apollo8, the support crew consisted of Ken Mattingly, Vance Brand, and Gerald Carr.",
        "target": "The capsule communicator (CAPCOM) was an astronaut at the Mission Control Center in Houston, Texas, who was the only person who communicated directly with the flight crew. For Apollo8, the CAPCOMs were Michael Collins, Gerald Carr, Ken Mattingly, Neil Armstrong, Buzz Aldrin, Vance Brand, and Fred Haise."
    },
    {
        "source": "During Projects Mercury and Gemini, each mission had a prime and a backup crew. For Apollo, a third crew of astronauts was added, known as the support crew. The support crew maintained the flight plan, checklists, and mission ground rules, and ensured that the prime and backup crews were apprised of any changes. The support crew developed procedures in the simulators, especially those for emergency situations, so that the prime and backup crews could practice and master them in their simulator training. For Apollo8, the support crew consisted of Ken Mattingly, Vance Brand, and Gerald Carr. The capsule communicator (CAPCOM) was an astronaut at the Mission Control Center in Houston, Texas, who was the only person who communicated directly with the flight crew. For Apollo8, the CAPCOMs were Michael Collins, Gerald Carr, Ken Mattingly, Neil Armstrong, Buzz Aldrin, Vance Brand, and Fred Haise.",
        "target": "The mission control teams rotated in three shifts, each led by a flight director. The directors for Apollo8 were Clifford E. Charlesworth (Green team), Glynn Lunney (Black team), and Milton Windler (Maroon team)."
    },
    {
        "source": "The capsule communicator (CAPCOM) was an astronaut at the Mission Control Center in Houston, Texas, who was the only person who communicated directly with the flight crew. For Apollo8, the CAPCOMs were Michael Collins, Gerald Carr, Ken Mattingly, Neil Armstrong, Buzz Aldrin, Vance Brand, and Fred Haise. The mission control teams rotated in three shifts, each led by a flight director. The directors for Apollo8 were Clifford E. Charlesworth (Green team), Glynn Lunney (Black team), and Milton Windler (Maroon team).",
        "target": "The triangular shape of the insignia refers to the shape of the Apollo CM. It shows a red figure8 looping around the Earth and Moon to reflect both the mission number and the circumlunar nature of the mission. On the bottom of the8 are the names of the three astronauts. The initial design of the insignia was developed by Jim Lovell, who reportedly sketched it while riding in the back seat of a T-38 flight from California to Houston shortly after learning of Apollo8's re-designation as a lunar-orbital mission."
    },
    {
        "source": "The mission control teams rotated in three shifts, each led by a flight director. The directors for Apollo8 were Clifford E. Charlesworth (Green team), Glynn Lunney (Black team), and Milton Windler (Maroon team). The triangular shape of the insignia refers to the shape of the Apollo CM. It shows a red figure8 looping around the Earth and Moon to reflect both the mission number and the circumlunar nature of the mission. On the bottom of the8 are the names of the three astronauts. The initial design of the insignia was developed by Jim Lovell, who reportedly sketched it while riding in the back seat of a T-38 flight from California to Houston shortly after learning of Apollo8's re-designation as a lunar-orbital mission.",
        "target": "The crew wanted to name their spacecraft, but NASA did not allow it. The crew would have likely chosen Columbiad, the name of the giant cannon that launches a space vehicle in Jules Verne's 1865 novel From the Earth to the Moon. The Apollo11 CM was named Columbia in part for that reason."
    },
    {
        "source": "The triangular shape of the insignia refers to the shape of the Apollo CM. It shows a red figure8 looping around the Earth and Moon to reflect both the mission number and the circumlunar nature of the mission. On the bottom of the8 are the names of the three astronauts. The initial design of the insignia was developed by Jim Lovell, who reportedly sketched it while riding in the back seat of a T-38 flight from California to Houston shortly after learning of Apollo8's re-designation as a lunar-orbital mission. The crew wanted to name their spacecraft, but NASA did not allow it. The crew would have likely chosen Columbiad, the name of the giant cannon that launches a space vehicle in Jules Verne's 1865 novel From the Earth to the Moon. The Apollo11 CM was named Columbia in part for that reason.",
        "target": "On September 20, 1967, NASA adopted a seven-step plan for Apollo missions, with the final step being a Moon landing. Apollo4 and Apollo6 were \"A\" missions, tests of the SaturnV launch vehicle using an uncrewed Block I production model of the command and service module (CSM) in Earth orbit. Apollo5 was a \"B\" mission, a test of the LM in Earth orbit. Apollo7, scheduled for October 1968, would be a \"C\" mission, a crewed Earth-orbit flight of the CSM. Further missions depended on the readiness of the LM. It had been decided as early as May 1967 that there would be at least four additional missions. Apollo8 was planned as the \"D\" mission, a test of the LM in a low Earth orbit in December 1968 by James McDivitt, David Scott, and Russell Schweickart, while Borman's crew would fly the \"E\" mission, a more rigorous LM test in an elliptical medium Earth orbit as Apollo9, in early 1969. The \"F\" Mission would test the CSM and LM in lunar orbit, and the \"G\" mission would be the finale, the Moon landing."
    },
    {
        "source": "The crew wanted to name their spacecraft, but NASA did not allow it. The crew would have likely chosen Columbiad, the name of the giant cannon that launches a space vehicle in Jules Verne's 1865 novel From the Earth to the Moon. The Apollo11 CM was named Columbia in part for that reason. On September 20, 1967, NASA adopted a seven-step plan for Apollo missions, with the final step being a Moon landing. Apollo4 and Apollo6 were \"A\" missions, tests of the SaturnV launch vehicle using an uncrewed Block I production model of the command and service module (CSM) in Earth orbit. Apollo5 was a \"B\" mission, a test of the LM in Earth orbit. Apollo7, scheduled for October 1968, would be a \"C\" mission, a crewed Earth-orbit flight of the CSM. Further missions depended on the readiness of the LM. It had been decided as early as May 1967 that there would be at least four additional missions. Apollo8 was planned as the \"D\" mission, a test of the LM in a low Earth orbit in December 1968 by James McDivitt, David Scott, and Russell Schweickart, while Borman's crew would fly the \"E\" mission, a more rigorous LM test in an elliptical medium Earth orbit as Apollo9, in early 1969. The \"F\" Mission would test the CSM and LM in lunar orbit, and the \"G\" mission would be the finale, the Moon landing.",
        "target": "Production of the LM fell behind schedule, and when Apollo8's LM-3 arrived at the Kennedy Space Center (KSC) in June 1968, more than a hundred significant defects were discovered, leading Bob Gilruth, the director of the Manned Spacecraft Center (MSC), and others to conclude that there was no prospect of LM-3 being ready to fly in 1968. Indeed, it was possible that delivery would slip to February or March 1969. Following the original seven-step plan would have meant delaying the \"D\" and subsequent missions, and endangering the program's goal of a lunar landing before the end of 1969. George Low, the Manager of the Apollo Spacecraft Program Office, proposed a solution in August 1968 to keep the program on track despite the LM delay. Since the next CSM (designated as \"CSM-103\") would be ready three months before LM-3, a CSM-only mission could be flown in December 1968. Instead of repeating the \"C\" mission flight of Apollo7, this CSM could be sent all the way to the Moon, with the possibility of entering a lunar orbit and returning to Earth. The new mission would also allow NASA to test lunar landing procedures that would otherwise have had to wait until Apollo10, the scheduled \"F\" mission. This also meant that the medium Earth orbit \"E\" mission could be dispensed with. The net result was that only the \"D\" mission had to be delayed, and the plan for lunar landing in mid-1969 could remain on timeline."
    },
    {
        "source": "On September 20, 1967, NASA adopted a seven-step plan for Apollo missions, with the final step being a Moon landing. Apollo4 and Apollo6 were \"A\" missions, tests of the SaturnV launch vehicle using an uncrewed Block I production model of the command and service module (CSM) in Earth orbit. Apollo5 was a \"B\" mission, a test of the LM in Earth orbit. Apollo7, scheduled for October 1968, would be a \"C\" mission, a crewed Earth-orbit flight of the CSM. Further missions depended on the readiness of the LM. It had been decided as early as May 1967 that there would be at least four additional missions. Apollo8 was planned as the \"D\" mission, a test of the LM in a low Earth orbit in December 1968 by James McDivitt, David Scott, and Russell Schweickart, while Borman's crew would fly the \"E\" mission, a more rigorous LM test in an elliptical medium Earth orbit as Apollo9, in early 1969. The \"F\" Mission would test the CSM and LM in lunar orbit, and the \"G\" mission would be the finale, the Moon landing. Production of the LM fell behind schedule, and when Apollo8's LM-3 arrived at the Kennedy Space Center (KSC) in June 1968, more than a hundred significant defects were discovered, leading Bob Gilruth, the director of the Manned Spacecraft Center (MSC), and others to conclude that there was no prospect of LM-3 being ready to fly in 1968. Indeed, it was possible that delivery would slip to February or March 1969. Following the original seven-step plan would have meant delaying the \"D\" and subsequent missions, and endangering the program's goal of a lunar landing before the end of 1969. George Low, the Manager of the Apollo Spacecraft Program Office, proposed a solution in August 1968 to keep the program on track despite the LM delay. Since the next CSM (designated as \"CSM-103\") would be ready three months before LM-3, a CSM-only mission could be flown in December 1968. Instead of repeating the \"C\" mission flight of Apollo7, this CSM could be sent all the way to the Moon, with the possibility of entering a lunar orbit and returning to Earth. The new mission would also allow NASA to test lunar landing procedures that would otherwise have had to wait until Apollo10, the scheduled \"F\" mission. This also meant that the medium Earth orbit \"E\" mission could be dispensed with. The net result was that only the \"D\" mission had to be delayed, and the plan for lunar landing in mid-1969 could remain on timeline.",
        "target": "On August 9, 1968, Low discussed the idea with Gilruth, Flight Director Chris Kraft, and the Director of Flight Crew Operations, Donald Slayton. They then flew to the Marshall Space Flight Center (MSFC) in Huntsville, Alabama, where they met with KSC Director Kurt Debus, Apollo Program Director Samuel C. Phillips, Rocco Petrone, and Wernher von Braun. Jerry Wittenstein, deputy chief of flight mechanics, presented trajectories for the new mission. Kraft considered the proposal feasible from a flight control standpoint; Debus and Petrone agreed that the next Saturn V, AS-503, could be made ready by December 1; and von Braun was confident the pogo oscillation problems that had afflicted Apollo6 had been fixed. Almost every senior manager at NASA agreed with this new mission, citing confidence in both the hardware and the personnel, along with the potential for a circumlunar flight providing a significant morale boost. The only person who needed some convincing was James E. Webb, the NASA administrator. Backed by the full support of his agency, Webb authorized the mission. Apollo8 was officially changed from a \"D\" mission to a \"C-Prime\" lunar-orbit mission."
    },
    {
        "source": "Production of the LM fell behind schedule, and when Apollo8's LM-3 arrived at the Kennedy Space Center (KSC) in June 1968, more than a hundred significant defects were discovered, leading Bob Gilruth, the director of the Manned Spacecraft Center (MSC), and others to conclude that there was no prospect of LM-3 being ready to fly in 1968. Indeed, it was possible that delivery would slip to February or March 1969. Following the original seven-step plan would have meant delaying the \"D\" and subsequent missions, and endangering the program's goal of a lunar landing before the end of 1969. George Low, the Manager of the Apollo Spacecraft Program Office, proposed a solution in August 1968 to keep the program on track despite the LM delay. Since the next CSM (designated as \"CSM-103\") would be ready three months before LM-3, a CSM-only mission could be flown in December 1968. Instead of repeating the \"C\" mission flight of Apollo7, this CSM could be sent all the way to the Moon, with the possibility of entering a lunar orbit and returning to Earth. The new mission would also allow NASA to test lunar landing procedures that would otherwise have had to wait until Apollo10, the scheduled \"F\" mission. This also meant that the medium Earth orbit \"E\" mission could be dispensed with. The net result was that only the \"D\" mission had to be delayed, and the plan for lunar landing in mid-1969 could remain on timeline. On August 9, 1968, Low discussed the idea with Gilruth, Flight Director Chris Kraft, and the Director of Flight Crew Operations, Donald Slayton. They then flew to the Marshall Space Flight Center (MSFC) in Huntsville, Alabama, where they met with KSC Director Kurt Debus, Apollo Program Director Samuel C. Phillips, Rocco Petrone, and Wernher von Braun. Jerry Wittenstein, deputy chief of flight mechanics, presented trajectories for the new mission. Kraft considered the proposal feasible from a flight control standpoint; Debus and Petrone agreed that the next Saturn V, AS-503, could be made ready by December 1; and von Braun was confident the pogo oscillation problems that had afflicted Apollo6 had been fixed. Almost every senior manager at NASA agreed with this new mission, citing confidence in both the hardware and the personnel, along with the potential for a circumlunar flight providing a significant morale boost. The only person who needed some convincing was James E. Webb, the NASA administrator. Backed by the full support of his agency, Webb authorized the mission. Apollo8 was officially changed from a \"D\" mission to a \"C-Prime\" lunar-orbit mission.",
        "target": "With the change in mission for Apollo 8, Slayton asked McDivitt if he still wanted to fly it. McDivitt turned it down; his crew had spent a great deal of time preparing to test the LM, and that was what he still wanted to do. Slayton then decided to swap the prime and backup crews of the Dand Emissions. This swap also meant a swap of spacecraft, requiring Borman's crew to use CSM-103, while McDivitt's crew would use CSM-104, since CM-104 could not be made ready by December. David Scott was not happy about giving up CM-103, the testing of which he had closely supervised, for CM-104, although the two were almost identical, and Anders was less than enthusiastic about being an LMP on a flight with no LM. Instead, Apollo8 would carry the LM test article, a boilerplate model that would simulate the correct weight and balance of LM-3."
    },
    {
        "source": "On August 9, 1968, Low discussed the idea with Gilruth, Flight Director Chris Kraft, and the Director of Flight Crew Operations, Donald Slayton. They then flew to the Marshall Space Flight Center (MSFC) in Huntsville, Alabama, where they met with KSC Director Kurt Debus, Apollo Program Director Samuel C. Phillips, Rocco Petrone, and Wernher von Braun. Jerry Wittenstein, deputy chief of flight mechanics, presented trajectories for the new mission. Kraft considered the proposal feasible from a flight control standpoint; Debus and Petrone agreed that the next Saturn V, AS-503, could be made ready by December 1; and von Braun was confident the pogo oscillation problems that had afflicted Apollo6 had been fixed. Almost every senior manager at NASA agreed with this new mission, citing confidence in both the hardware and the personnel, along with the potential for a circumlunar flight providing a significant morale boost. The only person who needed some convincing was James E. Webb, the NASA administrator. Backed by the full support of his agency, Webb authorized the mission. Apollo8 was officially changed from a \"D\" mission to a \"C-Prime\" lunar-orbit mission. With the change in mission for Apollo 8, Slayton asked McDivitt if he still wanted to fly it. McDivitt turned it down; his crew had spent a great deal of time preparing to test the LM, and that was what he still wanted to do. Slayton then decided to swap the prime and backup crews of the Dand Emissions. This swap also meant a swap of spacecraft, requiring Borman's crew to use CSM-103, while McDivitt's crew would use CSM-104, since CM-104 could not be made ready by December. David Scott was not happy about giving up CM-103, the testing of which he had closely supervised, for CM-104, although the two were almost identical, and Anders was less than enthusiastic about being an LMP on a flight with no LM. Instead, Apollo8 would carry the LM test article, a boilerplate model that would simulate the correct weight and balance of LM-3.",
        "target": "Added pressure on the Apollo program to make its 1969 landing goal was provided by the Soviet Union's Zond5 mission, which flew some living creatures, including Russian tortoises, in a cislunar loop around the Moon and returned them to Earth on September 21. There was speculation within NASA and the press that they might be preparing to launch cosmonauts on a similar circumlunar mission before the end of 1968.  Compounding these concerns, American reconnaissance satellites observed a mockup N1 being rolled to the pad at Baikonur on November 25, 1967."
    },
    {
        "source": "With the change in mission for Apollo 8, Slayton asked McDivitt if he still wanted to fly it. McDivitt turned it down; his crew had spent a great deal of time preparing to test the LM, and that was what he still wanted to do. Slayton then decided to swap the prime and backup crews of the Dand Emissions. This swap also meant a swap of spacecraft, requiring Borman's crew to use CSM-103, while McDivitt's crew would use CSM-104, since CM-104 could not be made ready by December. David Scott was not happy about giving up CM-103, the testing of which he had closely supervised, for CM-104, although the two were almost identical, and Anders was less than enthusiastic about being an LMP on a flight with no LM. Instead, Apollo8 would carry the LM test article, a boilerplate model that would simulate the correct weight and balance of LM-3. Added pressure on the Apollo program to make its 1969 landing goal was provided by the Soviet Union's Zond5 mission, which flew some living creatures, including Russian tortoises, in a cislunar loop around the Moon and returned them to Earth on September 21. There was speculation within NASA and the press that they might be preparing to launch cosmonauts on a similar circumlunar mission before the end of 1968.  Compounding these concerns, American reconnaissance satellites observed a mockup N1 being rolled to the pad at Baikonur on November 25, 1967.",
        "target": "The Apollo 8 crew, now living in the crew quarters at Kennedy Space Center, received a visit from Charles Lindbergh and his wife, Anne Morrow Lindbergh, the night before the launch. They talked about how, before his 1927 flight, Lindbergh had used a piece of string to measure the distance from New York City to Paris on a globe and from that calculated the fuel needed for the flight. The total he had carried was a tenth of the amount that the Saturn V would burn every second. The next day, the Lindberghs watched the launch of Apollo8 from a nearby dune."
    },
    {
        "source": "Added pressure on the Apollo program to make its 1969 landing goal was provided by the Soviet Union's Zond5 mission, which flew some living creatures, including Russian tortoises, in a cislunar loop around the Moon and returned them to Earth on September 21. There was speculation within NASA and the press that they might be preparing to launch cosmonauts on a similar circumlunar mission before the end of 1968.  Compounding these concerns, American reconnaissance satellites observed a mockup N1 being rolled to the pad at Baikonur on November 25, 1967. The Apollo 8 crew, now living in the crew quarters at Kennedy Space Center, received a visit from Charles Lindbergh and his wife, Anne Morrow Lindbergh, the night before the launch. They talked about how, before his 1927 flight, Lindbergh had used a piece of string to measure the distance from New York City to Paris on a globe and from that calculated the fuel needed for the flight. The total he had carried was a tenth of the amount that the Saturn V would burn every second. The next day, the Lindberghs watched the launch of Apollo8 from a nearby dune.",
        "target": "The Saturn V rocket used by Apollo8 was designated AS-503, or the \"03rd\" model of the SaturnV (\"5\") rocket to be used in the Apollo-Saturn (\"AS\") program. When it was erected in the Vehicle Assembly Building on December 20, 1967, it was thought that the rocket would be used for an uncrewed Earth-orbit test flight carrying a boilerplate command and service module. Apollo6 had suffered several major problems during its April 1968 flight, including severe pogo oscillation during its first stage, two second-stage engine failures, and a third stage that failed to reignite in orbit. Without assurances that these problems had been rectified, NASA administrators could not justify risking a crewed mission until additional uncrewed test flights proved the Saturn V was ready."
    },
    {
        "source": "The Apollo 8 crew, now living in the crew quarters at Kennedy Space Center, received a visit from Charles Lindbergh and his wife, Anne Morrow Lindbergh, the night before the launch. They talked about how, before his 1927 flight, Lindbergh had used a piece of string to measure the distance from New York City to Paris on a globe and from that calculated the fuel needed for the flight. The total he had carried was a tenth of the amount that the Saturn V would burn every second. The next day, the Lindberghs watched the launch of Apollo8 from a nearby dune. The Saturn V rocket used by Apollo8 was designated AS-503, or the \"03rd\" model of the SaturnV (\"5\") rocket to be used in the Apollo-Saturn (\"AS\") program. When it was erected in the Vehicle Assembly Building on December 20, 1967, it was thought that the rocket would be used for an uncrewed Earth-orbit test flight carrying a boilerplate command and service module. Apollo6 had suffered several major problems during its April 1968 flight, including severe pogo oscillation during its first stage, two second-stage engine failures, and a third stage that failed to reignite in orbit. Without assurances that these problems had been rectified, NASA administrators could not justify risking a crewed mission until additional uncrewed test flights proved the Saturn V was ready.",
        "target": "Teams from the MSFC went to work on the problems. Of primary concern was the pogo oscillation, which would not only hamper engine performance, but could exert significant g-forces on a crew. A task force of contractors, NASA agency representatives, and MSFC researchers concluded that the engines vibrated at a frequency similar to the frequency at which the spacecraft itself vibrated, causing a resonance effect that induced oscillations in the rocket. A system that used helium gas to absorb some of these vibrations was installed."
    },
    {
        "source": "The Saturn V rocket used by Apollo8 was designated AS-503, or the \"03rd\" model of the SaturnV (\"5\") rocket to be used in the Apollo-Saturn (\"AS\") program. When it was erected in the Vehicle Assembly Building on December 20, 1967, it was thought that the rocket would be used for an uncrewed Earth-orbit test flight carrying a boilerplate command and service module. Apollo6 had suffered several major problems during its April 1968 flight, including severe pogo oscillation during its first stage, two second-stage engine failures, and a third stage that failed to reignite in orbit. Without assurances that these problems had been rectified, NASA administrators could not justify risking a crewed mission until additional uncrewed test flights proved the Saturn V was ready. Teams from the MSFC went to work on the problems. Of primary concern was the pogo oscillation, which would not only hamper engine performance, but could exert significant g-forces on a crew. A task force of contractors, NASA agency representatives, and MSFC researchers concluded that the engines vibrated at a frequency similar to the frequency at which the spacecraft itself vibrated, causing a resonance effect that induced oscillations in the rocket. A system that used helium gas to absorb some of these vibrations was installed.",
        "target": "Of equal importance was the failure of three engines during flight. Researchers quickly determined that a leaking hydrogen fuel line ruptured when exposed to vacuum, causing a loss of fuel pressure in engine two. When an automatic shutoff attempted to close the liquid hydrogen valve and shut down engine two, it had accidentally shut down engine three's liquid oxygen due to a miswired connection. As a result, engine three failed within one second of engine two's shutdown. Further investigation revealed the same problem for the third-stage enginea faulty igniter line. The team modified the igniter lines and fuel conduits, hoping to avoid similar problems on future launches."
    },
    {
        "source": "Teams from the MSFC went to work on the problems. Of primary concern was the pogo oscillation, which would not only hamper engine performance, but could exert significant g-forces on a crew. A task force of contractors, NASA agency representatives, and MSFC researchers concluded that the engines vibrated at a frequency similar to the frequency at which the spacecraft itself vibrated, causing a resonance effect that induced oscillations in the rocket. A system that used helium gas to absorb some of these vibrations was installed. Of equal importance was the failure of three engines during flight. Researchers quickly determined that a leaking hydrogen fuel line ruptured when exposed to vacuum, causing a loss of fuel pressure in engine two. When an automatic shutoff attempted to close the liquid hydrogen valve and shut down engine two, it had accidentally shut down engine three's liquid oxygen due to a miswired connection. As a result, engine three failed within one second of engine two's shutdown. Further investigation revealed the same problem for the third-stage enginea faulty igniter line. The team modified the igniter lines and fuel conduits, hoping to avoid similar problems on future launches.",
        "target": "The teams tested their solutions in August 1968 at the MSFC. A Saturn stage IC was equipped with shock-absorbing devices to demonstrate the team's solution to the problem of pogo oscillation, while a Saturn Stage II was retrofitted with modified fuel lines to demonstrate their resistance to leaks and ruptures in vacuum conditions. Once NASA administrators were convinced that the problems had been solved, they gave their approval for a crewed mission using AS-503."
    },
    {
        "source": "Of equal importance was the failure of three engines during flight. Researchers quickly determined that a leaking hydrogen fuel line ruptured when exposed to vacuum, causing a loss of fuel pressure in engine two. When an automatic shutoff attempted to close the liquid hydrogen valve and shut down engine two, it had accidentally shut down engine three's liquid oxygen due to a miswired connection. As a result, engine three failed within one second of engine two's shutdown. Further investigation revealed the same problem for the third-stage enginea faulty igniter line. The team modified the igniter lines and fuel conduits, hoping to avoid similar problems on future launches. The teams tested their solutions in August 1968 at the MSFC. A Saturn stage IC was equipped with shock-absorbing devices to demonstrate the team's solution to the problem of pogo oscillation, while a Saturn Stage II was retrofitted with modified fuel lines to demonstrate their resistance to leaks and ruptures in vacuum conditions. Once NASA administrators were convinced that the problems had been solved, they gave their approval for a crewed mission using AS-503.",
        "target": "The Apollo 8 spacecraft was placed on top of the rocket on September 21, and the rocket made the slow 3-mile (4.8km) journey to the launch pad atop one of NASA's two massive crawler-transporters on October9. Testing continued all through December until the day before launch, including various levels of readiness testing from December5 through 11. Final testing of modifications to address the problems of pogo oscillation, ruptured fuel lines, and bad igniter lines took place on December 18, three days before the scheduled launch."
    },
    {
        "source": "The teams tested their solutions in August 1968 at the MSFC. A Saturn stage IC was equipped with shock-absorbing devices to demonstrate the team's solution to the problem of pogo oscillation, while a Saturn Stage II was retrofitted with modified fuel lines to demonstrate their resistance to leaks and ruptures in vacuum conditions. Once NASA administrators were convinced that the problems had been solved, they gave their approval for a crewed mission using AS-503. The Apollo 8 spacecraft was placed on top of the rocket on September 21, and the rocket made the slow 3-mile (4.8km) journey to the launch pad atop one of NASA's two massive crawler-transporters on October9. Testing continued all through December until the day before launch, including various levels of readiness testing from December5 through 11. Final testing of modifications to address the problems of pogo oscillation, ruptured fuel lines, and bad igniter lines took place on December 18, three days before the scheduled launch.",
        "target": "As the first crewed spacecraft to orbit more than one celestial body, Apollo8's profile had two different sets of orbital parameters, separated by a translunar injection maneuver. Apollo lunar missions would begin with a nominal 100-nautical-mile (185.2km) circular Earth parking orbit. Apollo8 was launched into an initial orbit with an apogee of 99.99 nautical miles (185.18km) and a perigee of 99.57 nautical miles (184.40km), with an inclination of 32.51 to the Equator, and an orbital period of 88.19 minutes. Propellant venting increased the apogee by 6.4 nautical miles (11.9km) over the 2hours, 44 minutes, and 30 seconds spent in the parking orbit."
    },
    {
        "source": "The Apollo 8 spacecraft was placed on top of the rocket on September 21, and the rocket made the slow 3-mile (4.8km) journey to the launch pad atop one of NASA's two massive crawler-transporters on October9. Testing continued all through December until the day before launch, including various levels of readiness testing from December5 through 11. Final testing of modifications to address the problems of pogo oscillation, ruptured fuel lines, and bad igniter lines took place on December 18, three days before the scheduled launch. As the first crewed spacecraft to orbit more than one celestial body, Apollo8's profile had two different sets of orbital parameters, separated by a translunar injection maneuver. Apollo lunar missions would begin with a nominal 100-nautical-mile (185.2km) circular Earth parking orbit. Apollo8 was launched into an initial orbit with an apogee of 99.99 nautical miles (185.18km) and a perigee of 99.57 nautical miles (184.40km), with an inclination of 32.51 to the Equator, and an orbital period of 88.19 minutes. Propellant venting increased the apogee by 6.4 nautical miles (11.9km) over the 2hours, 44 minutes, and 30 seconds spent in the parking orbit.",
        "target": "This was followed by a trans-lunar injection (TLI) burn of the S-IVB third stage for 318 seconds, accelerating the 63,650lb (28,870kg) command and service module and 19,900lb (9,000kg) LM test article from an orbital velocity of 25,567 feet per second (7,793m/s) to the injection velocity of 35,505ft/s (10,822m/s) which set a record for the highest speed, relative to Earth, that humans had ever traveled. This speed was slightly less than the Earth's escape velocity of 36,747 feet per second (11,200m/s), but put Apollo8 into an elongated elliptical Earth orbit, close enough to the Moon to be captured by the Moon's gravity."
    },
    {
        "source": "As the first crewed spacecraft to orbit more than one celestial body, Apollo8's profile had two different sets of orbital parameters, separated by a translunar injection maneuver. Apollo lunar missions would begin with a nominal 100-nautical-mile (185.2km) circular Earth parking orbit. Apollo8 was launched into an initial orbit with an apogee of 99.99 nautical miles (185.18km) and a perigee of 99.57 nautical miles (184.40km), with an inclination of 32.51 to the Equator, and an orbital period of 88.19 minutes. Propellant venting increased the apogee by 6.4 nautical miles (11.9km) over the 2hours, 44 minutes, and 30 seconds spent in the parking orbit. This was followed by a trans-lunar injection (TLI) burn of the S-IVB third stage for 318 seconds, accelerating the 63,650lb (28,870kg) command and service module and 19,900lb (9,000kg) LM test article from an orbital velocity of 25,567 feet per second (7,793m/s) to the injection velocity of 35,505ft/s (10,822m/s) which set a record for the highest speed, relative to Earth, that humans had ever traveled. This speed was slightly less than the Earth's escape velocity of 36,747 feet per second (11,200m/s), but put Apollo8 into an elongated elliptical Earth orbit, close enough to the Moon to be captured by the Moon's gravity.",
        "target": "The standard lunar orbit for Apollo missions was planned as a nominal 60-nautical-mile (110km) circular orbit above the Moon's surface. Initial lunar orbit insertion was an ellipse with a perilune of 60.0 nautical miles (111.1km) and an apolune of 168.5 nautical miles (312.1km), at an inclination of 12 from the lunar equator. This was then circularized at 60.7 by 59.7 nautical miles (112.4 by 110.6km), with an orbital period of 128.7 minutes. The effect of lunar mass concentrations (\"mascons\") on the orbit was found to be greater than initially predicted; over the course of the ten lunar orbits lasting twenty hours, the orbital distance was perturbated to 63.6 by 58.6 nautical miles (117.8 by 108.5km)."
    },
    {
        "source": "This was followed by a trans-lunar injection (TLI) burn of the S-IVB third stage for 318 seconds, accelerating the 63,650lb (28,870kg) command and service module and 19,900lb (9,000kg) LM test article from an orbital velocity of 25,567 feet per second (7,793m/s) to the injection velocity of 35,505ft/s (10,822m/s) which set a record for the highest speed, relative to Earth, that humans had ever traveled. This speed was slightly less than the Earth's escape velocity of 36,747 feet per second (11,200m/s), but put Apollo8 into an elongated elliptical Earth orbit, close enough to the Moon to be captured by the Moon's gravity. The standard lunar orbit for Apollo missions was planned as a nominal 60-nautical-mile (110km) circular orbit above the Moon's surface. Initial lunar orbit insertion was an ellipse with a perilune of 60.0 nautical miles (111.1km) and an apolune of 168.5 nautical miles (312.1km), at an inclination of 12 from the lunar equator. This was then circularized at 60.7 by 59.7 nautical miles (112.4 by 110.6km), with an orbital period of 128.7 minutes. The effect of lunar mass concentrations (\"mascons\") on the orbit was found to be greater than initially predicted; over the course of the ten lunar orbits lasting twenty hours, the orbital distance was perturbated to 63.6 by 58.6 nautical miles (117.8 by 108.5km).",
        "target": "Apollo 8 achieved a maximum distance from Earth of 203,752 nautical miles (234,474 statute miles; 377,349 kilometers)."
    },
    {
        "source": "The standard lunar orbit for Apollo missions was planned as a nominal 60-nautical-mile (110km) circular orbit above the Moon's surface. Initial lunar orbit insertion was an ellipse with a perilune of 60.0 nautical miles (111.1km) and an apolune of 168.5 nautical miles (312.1km), at an inclination of 12 from the lunar equator. This was then circularized at 60.7 by 59.7 nautical miles (112.4 by 110.6km), with an orbital period of 128.7 minutes. The effect of lunar mass concentrations (\"mascons\") on the orbit was found to be greater than initially predicted; over the course of the ten lunar orbits lasting twenty hours, the orbital distance was perturbated to 63.6 by 58.6 nautical miles (117.8 by 108.5km). Apollo 8 achieved a maximum distance from Earth of 203,752 nautical miles (234,474 statute miles; 377,349 kilometers).",
        "target": "Apollo 8 was launched at 12:51:00 UTC (07:51:00 Eastern Standard Time) on December 21, 1968, using the Saturn V's three stages to achieve Earth orbit. The S-IC first stage landed in the Atlantic Ocean at 3012N 747W / 30.200N 74.117W / 30.200; -74.117 (Apollo 8 S-IC impact), and the S-II second stage landed at 3150N 3717W / 31.833N 37.283W / 31.833; -37.283 (Apollo 8 S-II impact). The S-IVB third stage injected the craft into Earth orbit and remained attached to perform the TLI burn that would put the spacecraft on a trajectory to the Moon."
    },
    {
        "source": "Apollo 8 achieved a maximum distance from Earth of 203,752 nautical miles (234,474 statute miles; 377,349 kilometers). Apollo 8 was launched at 12:51:00 UTC (07:51:00 Eastern Standard Time) on December 21, 1968, using the Saturn V's three stages to achieve Earth orbit. The S-IC first stage landed in the Atlantic Ocean at 3012N 747W / 30.200N 74.117W / 30.200; -74.117 (Apollo 8 S-IC impact), and the S-II second stage landed at 3150N 3717W / 31.833N 37.283W / 31.833; -37.283 (Apollo 8 S-II impact). The S-IVB third stage injected the craft into Earth orbit and remained attached to perform the TLI burn that would put the spacecraft on a trajectory to the Moon.",
        "target": "Once the vehicle reached Earth orbit, both the crew and Houston flight controllers spent the next 2hours and 38 minutes checking that the spacecraft was in proper working order and ready for TLI. The proper operation of the S-IVB third stage of the rocket was crucial, and in the last uncrewed test, it had failed to reignite for this burn. Collins was the first CAPCOM on duty, and at 2hours, 27 minutes and 22 seconds after launch he radioed, \"Apollo8. You are Go for TLI.\" This communication meant that Mission Control had given official permission for Apollo8 to go to the Moon. The S-IVB engine ignited on time and performed the TLI burn perfectly. Over the next five minutes, the spacecraft's speed increased from 7,600 to 10,800 meters per second (25,000 to 35,000ft/s)."
    },
    {
        "source": "Apollo 8 was launched at 12:51:00 UTC (07:51:00 Eastern Standard Time) on December 21, 1968, using the Saturn V's three stages to achieve Earth orbit. The S-IC first stage landed in the Atlantic Ocean at 3012N 747W / 30.200N 74.117W / 30.200; -74.117 (Apollo 8 S-IC impact), and the S-II second stage landed at 3150N 3717W / 31.833N 37.283W / 31.833; -37.283 (Apollo 8 S-II impact). The S-IVB third stage injected the craft into Earth orbit and remained attached to perform the TLI burn that would put the spacecraft on a trajectory to the Moon. Once the vehicle reached Earth orbit, both the crew and Houston flight controllers spent the next 2hours and 38 minutes checking that the spacecraft was in proper working order and ready for TLI. The proper operation of the S-IVB third stage of the rocket was crucial, and in the last uncrewed test, it had failed to reignite for this burn. Collins was the first CAPCOM on duty, and at 2hours, 27 minutes and 22 seconds after launch he radioed, \"Apollo8. You are Go for TLI.\" This communication meant that Mission Control had given official permission for Apollo8 to go to the Moon. The S-IVB engine ignited on time and performed the TLI burn perfectly. Over the next five minutes, the spacecraft's speed increased from 7,600 to 10,800 meters per second (25,000 to 35,000ft/s).",
        "target": "After the S-IVB had placed the mission on course for the Moon, the command and service modules (CSM), the remaining Apollo8 spacecraft, separated from it. The crew then rotated the spacecraft to take photographs of the spent stage and then practiced flying in formation with it. As the crew rotated the spacecraft, they had their first views of the Earth as they moved away from itthis marked the first time humans had viewed the whole Earth at once. Borman became worried that the S-IVB was staying too close to the CSM and suggested to Mission Control that the crew perform a separation maneuver. Mission Control first suggested pointing the spacecraft towards Earth and using the small reaction control system (RCS) thrusters on the service module (SM) to add 1.1ft/s (0.34m/s) to their velocity away from the Earth, but Borman did not want to lose sight of the S-IVB. After discussion, the crew and Mission Control decided to burn in the Earth direction to increase speed, but at 7.7ft/s (2.3m/s) instead. The time needed to prepare and perform the additional burn put the crew an hour behind their onboard tasks."
    },
    {
        "source": "Once the vehicle reached Earth orbit, both the crew and Houston flight controllers spent the next 2hours and 38 minutes checking that the spacecraft was in proper working order and ready for TLI. The proper operation of the S-IVB third stage of the rocket was crucial, and in the last uncrewed test, it had failed to reignite for this burn. Collins was the first CAPCOM on duty, and at 2hours, 27 minutes and 22 seconds after launch he radioed, \"Apollo8. You are Go for TLI.\" This communication meant that Mission Control had given official permission for Apollo8 to go to the Moon. The S-IVB engine ignited on time and performed the TLI burn perfectly. Over the next five minutes, the spacecraft's speed increased from 7,600 to 10,800 meters per second (25,000 to 35,000ft/s). After the S-IVB had placed the mission on course for the Moon, the command and service modules (CSM), the remaining Apollo8 spacecraft, separated from it. The crew then rotated the spacecraft to take photographs of the spent stage and then practiced flying in formation with it. As the crew rotated the spacecraft, they had their first views of the Earth as they moved away from itthis marked the first time humans had viewed the whole Earth at once. Borman became worried that the S-IVB was staying too close to the CSM and suggested to Mission Control that the crew perform a separation maneuver. Mission Control first suggested pointing the spacecraft towards Earth and using the small reaction control system (RCS) thrusters on the service module (SM) to add 1.1ft/s (0.34m/s) to their velocity away from the Earth, but Borman did not want to lose sight of the S-IVB. After discussion, the crew and Mission Control decided to burn in the Earth direction to increase speed, but at 7.7ft/s (2.3m/s) instead. The time needed to prepare and perform the additional burn put the crew an hour behind their onboard tasks.",
        "target": "Five hours after launch, Mission Control sent a command to the S-IVB to vent its remaining fuel, changing its trajectory. The S-IVB, with the test article attached, posed no further hazard to Apollo8, passing the orbit of the Moon and going into a 0.99-by-0.92-astronomical-unit (148 by 138Gm) solar orbit with an inclination of 23.47 from the Earth's equatorial plane, and an orbital period of 340.80 days. It became a derelict object, and will continue to orbit the Sun for many years, if not retrieved."
    },
    {
        "source": "After the S-IVB had placed the mission on course for the Moon, the command and service modules (CSM), the remaining Apollo8 spacecraft, separated from it. The crew then rotated the spacecraft to take photographs of the spent stage and then practiced flying in formation with it. As the crew rotated the spacecraft, they had their first views of the Earth as they moved away from itthis marked the first time humans had viewed the whole Earth at once. Borman became worried that the S-IVB was staying too close to the CSM and suggested to Mission Control that the crew perform a separation maneuver. Mission Control first suggested pointing the spacecraft towards Earth and using the small reaction control system (RCS) thrusters on the service module (SM) to add 1.1ft/s (0.34m/s) to their velocity away from the Earth, but Borman did not want to lose sight of the S-IVB. After discussion, the crew and Mission Control decided to burn in the Earth direction to increase speed, but at 7.7ft/s (2.3m/s) instead. The time needed to prepare and perform the additional burn put the crew an hour behind their onboard tasks. Five hours after launch, Mission Control sent a command to the S-IVB to vent its remaining fuel, changing its trajectory. The S-IVB, with the test article attached, posed no further hazard to Apollo8, passing the orbit of the Moon and going into a 0.99-by-0.92-astronomical-unit (148 by 138Gm) solar orbit with an inclination of 23.47 from the Earth's equatorial plane, and an orbital period of 340.80 days. It became a derelict object, and will continue to orbit the Sun for many years, if not retrieved.",
        "target": "The Apollo 8 crew were the first humans to pass through the Van Allen radiation belts, which extend up to 15,000 miles (24,000km) from Earth. Scientists predicted that passing through the belts quickly at the spacecraft's high speed would cause a radiation dosage of no more than a chest X-ray, or 1milligray (mGy; during a year, the average human receives a dose of 2to 3mGy from background radiation). To record the actual radiation dosages, each crew member wore a Personal Radiation Dosimeter that transmitted data to Earth, as well as three passive film dosimeters that showed the cumulative radiation experienced by the crew. By the end of the mission, the crew members experienced an average radiation dose of 1.6 mGy."
    },
    {
        "source": "Five hours after launch, Mission Control sent a command to the S-IVB to vent its remaining fuel, changing its trajectory. The S-IVB, with the test article attached, posed no further hazard to Apollo8, passing the orbit of the Moon and going into a 0.99-by-0.92-astronomical-unit (148 by 138Gm) solar orbit with an inclination of 23.47 from the Earth's equatorial plane, and an orbital period of 340.80 days. It became a derelict object, and will continue to orbit the Sun for many years, if not retrieved. The Apollo 8 crew were the first humans to pass through the Van Allen radiation belts, which extend up to 15,000 miles (24,000km) from Earth. Scientists predicted that passing through the belts quickly at the spacecraft's high speed would cause a radiation dosage of no more than a chest X-ray, or 1milligray (mGy; during a year, the average human receives a dose of 2to 3mGy from background radiation). To record the actual radiation dosages, each crew member wore a Personal Radiation Dosimeter that transmitted data to Earth, as well as three passive film dosimeters that showed the cumulative radiation experienced by the crew. By the end of the mission, the crew members experienced an average radiation dose of 1.6 mGy.",
        "target": "Lovell's main job as Command Module Pilot was as navigator. Although Mission Control normally performed all the navigation calculations, it was necessary to have a crew member adept at navigation so that the crew could return to Earth in case communication with Mission Control was lost. Lovell navigated by star sightings using a sextant built into the spacecraft, measuring the angle between a star and the Earth's (or the Moon's) horizon. This task was made difficult by a large cloud of debris around the spacecraft, which made it hard to distinguish the stars."
    },
    {
        "source": "The Apollo 8 crew were the first humans to pass through the Van Allen radiation belts, which extend up to 15,000 miles (24,000km) from Earth. Scientists predicted that passing through the belts quickly at the spacecraft's high speed would cause a radiation dosage of no more than a chest X-ray, or 1milligray (mGy; during a year, the average human receives a dose of 2to 3mGy from background radiation). To record the actual radiation dosages, each crew member wore a Personal Radiation Dosimeter that transmitted data to Earth, as well as three passive film dosimeters that showed the cumulative radiation experienced by the crew. By the end of the mission, the crew members experienced an average radiation dose of 1.6 mGy. Lovell's main job as Command Module Pilot was as navigator. Although Mission Control normally performed all the navigation calculations, it was necessary to have a crew member adept at navigation so that the crew could return to Earth in case communication with Mission Control was lost. Lovell navigated by star sightings using a sextant built into the spacecraft, measuring the angle between a star and the Earth's (or the Moon's) horizon. This task was made difficult by a large cloud of debris around the spacecraft, which made it hard to distinguish the stars.",
        "target": "By seven hours into the mission, the crew was about 1hour and 40 minutes behind flight plan because of the problems in moving away from the S-IVB and Lovell's obscured star sightings. The crew placed the spacecraft into Passive Thermal Control (PTC), also called \"barbecue roll\", in which the spacecraft rotated about once per hour around its long axis to ensure even heat distribution across the surface of the spacecraft. In direct sunlight, parts of the spacecraft's outer surface could be heated to over 200C (392F), while the parts in shadow would be 100C (148F). These temperatures could cause the heat shield to crack and propellant lines to burst. Because it was impossible to get a perfect roll, the spacecraft swept out a cone as it rotated. The crew had to make minor adjustments every half hour as the cone pattern got larger and larger."
    },
    {
        "source": "Lovell's main job as Command Module Pilot was as navigator. Although Mission Control normally performed all the navigation calculations, it was necessary to have a crew member adept at navigation so that the crew could return to Earth in case communication with Mission Control was lost. Lovell navigated by star sightings using a sextant built into the spacecraft, measuring the angle between a star and the Earth's (or the Moon's) horizon. This task was made difficult by a large cloud of debris around the spacecraft, which made it hard to distinguish the stars. By seven hours into the mission, the crew was about 1hour and 40 minutes behind flight plan because of the problems in moving away from the S-IVB and Lovell's obscured star sightings. The crew placed the spacecraft into Passive Thermal Control (PTC), also called \"barbecue roll\", in which the spacecraft rotated about once per hour around its long axis to ensure even heat distribution across the surface of the spacecraft. In direct sunlight, parts of the spacecraft's outer surface could be heated to over 200C (392F), while the parts in shadow would be 100C (148F). These temperatures could cause the heat shield to crack and propellant lines to burst. Because it was impossible to get a perfect roll, the spacecraft swept out a cone as it rotated. The crew had to make minor adjustments every half hour as the cone pattern got larger and larger.",
        "target": "The first mid-course correction came eleven hours into the flight. The crew had been awake for more than 16 hours. Before launch, NASA had decided at least one crew member should be awake at all times to deal with problems that might arise. Borman started the first sleep shift but found sleeping difficult because of the constant radio chatter and mechanical noises. Testing on the ground had shown that the service propulsion system (SPS) engine had a small chance of exploding when burned for long periods unless its combustion chamber was \"coated\" first by burning the engine for a short period. This first correction burn was only 2.4 seconds and added about 20.4ft/s (6.2m/s) velocity prograde (in the direction of travel). This change was less than the planned 24.8ft/s (7.6m/s), because of a bubble of helium in the oxidizer lines, which caused unexpectedly low propellant pressure. The crew had to use the small RCS thrusters to make up the shortfall. Two later planned mid-course corrections were canceled because the Apollo8 trajectory was found to be perfect."
    },
    {
        "source": "By seven hours into the mission, the crew was about 1hour and 40 minutes behind flight plan because of the problems in moving away from the S-IVB and Lovell's obscured star sightings. The crew placed the spacecraft into Passive Thermal Control (PTC), also called \"barbecue roll\", in which the spacecraft rotated about once per hour around its long axis to ensure even heat distribution across the surface of the spacecraft. In direct sunlight, parts of the spacecraft's outer surface could be heated to over 200C (392F), while the parts in shadow would be 100C (148F). These temperatures could cause the heat shield to crack and propellant lines to burst. Because it was impossible to get a perfect roll, the spacecraft swept out a cone as it rotated. The crew had to make minor adjustments every half hour as the cone pattern got larger and larger. The first mid-course correction came eleven hours into the flight. The crew had been awake for more than 16 hours. Before launch, NASA had decided at least one crew member should be awake at all times to deal with problems that might arise. Borman started the first sleep shift but found sleeping difficult because of the constant radio chatter and mechanical noises. Testing on the ground had shown that the service propulsion system (SPS) engine had a small chance of exploding when burned for long periods unless its combustion chamber was \"coated\" first by burning the engine for a short period. This first correction burn was only 2.4 seconds and added about 20.4ft/s (6.2m/s) velocity prograde (in the direction of travel). This change was less than the planned 24.8ft/s (7.6m/s), because of a bubble of helium in the oxidizer lines, which caused unexpectedly low propellant pressure. The crew had to use the small RCS thrusters to make up the shortfall. Two later planned mid-course corrections were canceled because the Apollo8 trajectory was found to be perfect.",
        "target": "About an hour after starting his sleep shift, Borman obtained permission from ground control to take a Seconal sleeping pill. The pill had little effect. Borman eventually fell asleep, and then awoke feeling ill. He vomited twice and had a bout of diarrhea; this left the spacecraft full of small globules of vomit and feces, which the crew cleaned up as well as they could. Borman initially did not want everyone to know about his medical problems, but Lovell and Anders wanted to inform Mission Control. The crew decided to use the Data Storage Equipment (DSE), which could tape voice recordings and telemetry and dump them to Mission Control at high speed. After recording a description of Borman's illness they asked Mission Control to check the recording, stating that they \"would like an evaluation of the voice comments\"."
    },
    {
        "source": "The first mid-course correction came eleven hours into the flight. The crew had been awake for more than 16 hours. Before launch, NASA had decided at least one crew member should be awake at all times to deal with problems that might arise. Borman started the first sleep shift but found sleeping difficult because of the constant radio chatter and mechanical noises. Testing on the ground had shown that the service propulsion system (SPS) engine had a small chance of exploding when burned for long periods unless its combustion chamber was \"coated\" first by burning the engine for a short period. This first correction burn was only 2.4 seconds and added about 20.4ft/s (6.2m/s) velocity prograde (in the direction of travel). This change was less than the planned 24.8ft/s (7.6m/s), because of a bubble of helium in the oxidizer lines, which caused unexpectedly low propellant pressure. The crew had to use the small RCS thrusters to make up the shortfall. Two later planned mid-course corrections were canceled because the Apollo8 trajectory was found to be perfect. About an hour after starting his sleep shift, Borman obtained permission from ground control to take a Seconal sleeping pill. The pill had little effect. Borman eventually fell asleep, and then awoke feeling ill. He vomited twice and had a bout of diarrhea; this left the spacecraft full of small globules of vomit and feces, which the crew cleaned up as well as they could. Borman initially did not want everyone to know about his medical problems, but Lovell and Anders wanted to inform Mission Control. The crew decided to use the Data Storage Equipment (DSE), which could tape voice recordings and telemetry and dump them to Mission Control at high speed. After recording a description of Borman's illness they asked Mission Control to check the recording, stating that they \"would like an evaluation of the voice comments\".",
        "target": "The Apollo 8 crew and Mission Control medical personnel held a conference using an unoccupied second-floor control room (there were two identical control rooms in Houston, on the second and third floors, only one of which was used during a mission). The conference participants concluded that there was little to worry about and that Borman's illness was either a 24-hour flu, as Borman thought, or a reaction to the sleeping pill. Researchers now believe that he was suffering from space adaptation syndrome, which affects about a third of astronauts during their first day in space as their vestibular system adapts to weightlessness. Space adaptation syndrome had not occurred on previous spacecraft (Mercury and Gemini), because those astronauts could not move freely in the small cabins of those spacecraft. The increased cabin space in the Apollo command module afforded astronauts greater freedom of movement, contributing to symptoms of space sickness for Borman and, later, astronaut Rusty Schweickart during Apollo9."
    },
    {
        "source": "About an hour after starting his sleep shift, Borman obtained permission from ground control to take a Seconal sleeping pill. The pill had little effect. Borman eventually fell asleep, and then awoke feeling ill. He vomited twice and had a bout of diarrhea; this left the spacecraft full of small globules of vomit and feces, which the crew cleaned up as well as they could. Borman initially did not want everyone to know about his medical problems, but Lovell and Anders wanted to inform Mission Control. The crew decided to use the Data Storage Equipment (DSE), which could tape voice recordings and telemetry and dump them to Mission Control at high speed. After recording a description of Borman's illness they asked Mission Control to check the recording, stating that they \"would like an evaluation of the voice comments\". The Apollo 8 crew and Mission Control medical personnel held a conference using an unoccupied second-floor control room (there were two identical control rooms in Houston, on the second and third floors, only one of which was used during a mission). The conference participants concluded that there was little to worry about and that Borman's illness was either a 24-hour flu, as Borman thought, or a reaction to the sleeping pill. Researchers now believe that he was suffering from space adaptation syndrome, which affects about a third of astronauts during their first day in space as their vestibular system adapts to weightlessness. Space adaptation syndrome had not occurred on previous spacecraft (Mercury and Gemini), because those astronauts could not move freely in the small cabins of those spacecraft. The increased cabin space in the Apollo command module afforded astronauts greater freedom of movement, contributing to symptoms of space sickness for Borman and, later, astronaut Rusty Schweickart during Apollo9.",
        "target": "The cruise phase was a relatively uneventful part of the flight, except for the crew's checking that the spacecraft was in working order and that they were on course. During this time, NASA scheduled a television broadcast at 31 hours after launch. The Apollo8 crew used a 2-kilogram (4.4lb) camera that broadcast in black-and-white only, using a Vidicon tube. The camera had two lenses, a very wide-angle (160) lens, and a telephoto (9) lens."
    },
    {
        "source": "The Apollo 8 crew and Mission Control medical personnel held a conference using an unoccupied second-floor control room (there were two identical control rooms in Houston, on the second and third floors, only one of which was used during a mission). The conference participants concluded that there was little to worry about and that Borman's illness was either a 24-hour flu, as Borman thought, or a reaction to the sleeping pill. Researchers now believe that he was suffering from space adaptation syndrome, which affects about a third of astronauts during their first day in space as their vestibular system adapts to weightlessness. Space adaptation syndrome had not occurred on previous spacecraft (Mercury and Gemini), because those astronauts could not move freely in the small cabins of those spacecraft. The increased cabin space in the Apollo command module afforded astronauts greater freedom of movement, contributing to symptoms of space sickness for Borman and, later, astronaut Rusty Schweickart during Apollo9. The cruise phase was a relatively uneventful part of the flight, except for the crew's checking that the spacecraft was in working order and that they were on course. During this time, NASA scheduled a television broadcast at 31 hours after launch. The Apollo8 crew used a 2-kilogram (4.4lb) camera that broadcast in black-and-white only, using a Vidicon tube. The camera had two lenses, a very wide-angle (160) lens, and a telephoto (9) lens.",
        "target": "During this first broadcast, the crew gave a tour of the spacecraft and attempted to show how the Earth appeared from space. However, difficulties aiming the narrow-angle lens without the aid of a monitor to show what it was looking at made showing the Earth impossible. Additionally, without proper filters, the Earth image became saturated by any bright source. In the end, all the crew could show the people watching back on Earth was a bright blob. After broadcasting for 17 minutes, the rotation of the spacecraft took the high-gain antenna out of view of the receiving stations on Earth and they ended the transmission with Lovell wishing his mother a happy birthday."
    },
    {
        "source": "The cruise phase was a relatively uneventful part of the flight, except for the crew's checking that the spacecraft was in working order and that they were on course. During this time, NASA scheduled a television broadcast at 31 hours after launch. The Apollo8 crew used a 2-kilogram (4.4lb) camera that broadcast in black-and-white only, using a Vidicon tube. The camera had two lenses, a very wide-angle (160) lens, and a telephoto (9) lens. During this first broadcast, the crew gave a tour of the spacecraft and attempted to show how the Earth appeared from space. However, difficulties aiming the narrow-angle lens without the aid of a monitor to show what it was looking at made showing the Earth impossible. Additionally, without proper filters, the Earth image became saturated by any bright source. In the end, all the crew could show the people watching back on Earth was a bright blob. After broadcasting for 17 minutes, the rotation of the spacecraft took the high-gain antenna out of view of the receiving stations on Earth and they ended the transmission with Lovell wishing his mother a happy birthday.",
        "target": "By this time, the crew had completely abandoned the planned sleep shifts. Lovell went to sleep 32+12 hours into the flight three-and-a-half hours before he had planned to. A short while later, Anders also went to sleep after taking a sleeping pill. The crew was unable to see the Moon for much of the outward cruise. Two factors made the Moon almost impossible to see from inside the spacecraft: three of the five windows fogging up due to out-gassed oils from the silicone sealant, and the attitude required for passive thermal control. It was not until the crew had gone behind the Moon that they would be able to see it for the first time."
    },
    {
        "source": "During this first broadcast, the crew gave a tour of the spacecraft and attempted to show how the Earth appeared from space. However, difficulties aiming the narrow-angle lens without the aid of a monitor to show what it was looking at made showing the Earth impossible. Additionally, without proper filters, the Earth image became saturated by any bright source. In the end, all the crew could show the people watching back on Earth was a bright blob. After broadcasting for 17 minutes, the rotation of the spacecraft took the high-gain antenna out of view of the receiving stations on Earth and they ended the transmission with Lovell wishing his mother a happy birthday. By this time, the crew had completely abandoned the planned sleep shifts. Lovell went to sleep 32+12 hours into the flight three-and-a-half hours before he had planned to. A short while later, Anders also went to sleep after taking a sleeping pill. The crew was unable to see the Moon for much of the outward cruise. Two factors made the Moon almost impossible to see from inside the spacecraft: three of the five windows fogging up due to out-gassed oils from the silicone sealant, and the attitude required for passive thermal control. It was not until the crew had gone behind the Moon that they would be able to see it for the first time.",
        "target": "Apollo 8 made a second television broadcast at 55 hours into the flight. This time, the crew rigged up filters meant for the still cameras so they could acquire images of the Earth through the telephoto lens. Although difficult to aim, as they had to maneuver the entire spacecraft, the crew was able to broadcast back to Earth the first television pictures of the Earth. The crew spent the transmission describing the Earth, what was visible, and the colors they could see. The transmission lasted 23 minutes."
    },
    {
        "source": "By this time, the crew had completely abandoned the planned sleep shifts. Lovell went to sleep 32+12 hours into the flight three-and-a-half hours before he had planned to. A short while later, Anders also went to sleep after taking a sleeping pill. The crew was unable to see the Moon for much of the outward cruise. Two factors made the Moon almost impossible to see from inside the spacecraft: three of the five windows fogging up due to out-gassed oils from the silicone sealant, and the attitude required for passive thermal control. It was not until the crew had gone behind the Moon that they would be able to see it for the first time. Apollo 8 made a second television broadcast at 55 hours into the flight. This time, the crew rigged up filters meant for the still cameras so they could acquire images of the Earth through the telephoto lens. Although difficult to aim, as they had to maneuver the entire spacecraft, the crew was able to broadcast back to Earth the first television pictures of the Earth. The crew spent the transmission describing the Earth, what was visible, and the colors they could see. The transmission lasted 23 minutes.",
        "target": "At about 55 hours and 40 minutes into the flight, and 13 hours before entering lunar orbit, the crew of Apollo8 became the first humans to enter the gravitational sphere of influence of another celestial body. In other words, the effect of the Moon's gravitational force on Apollo8 became stronger than that of the Earth. At the time it happened, Apollo8 was 38,759 miles (62,377km) from the Moon and had a speed of 3,990ft/s (1,220m/s) relative to the Moon. This historic moment was of little interest to the crew, since they were still calculating their trajectory with respect to the launch pad at Kennedy Space Center. They would continue to do so until they performed their last mid-course correction, switching to a reference frame based on ideal orientation for the second engine burn they would make in lunar orbit."
    },
    {
        "source": "Apollo 8 made a second television broadcast at 55 hours into the flight. This time, the crew rigged up filters meant for the still cameras so they could acquire images of the Earth through the telephoto lens. Although difficult to aim, as they had to maneuver the entire spacecraft, the crew was able to broadcast back to Earth the first television pictures of the Earth. The crew spent the transmission describing the Earth, what was visible, and the colors they could see. The transmission lasted 23 minutes. At about 55 hours and 40 minutes into the flight, and 13 hours before entering lunar orbit, the crew of Apollo8 became the first humans to enter the gravitational sphere of influence of another celestial body. In other words, the effect of the Moon's gravitational force on Apollo8 became stronger than that of the Earth. At the time it happened, Apollo8 was 38,759 miles (62,377km) from the Moon and had a speed of 3,990ft/s (1,220m/s) relative to the Moon. This historic moment was of little interest to the crew, since they were still calculating their trajectory with respect to the launch pad at Kennedy Space Center. They would continue to do so until they performed their last mid-course correction, switching to a reference frame based on ideal orientation for the second engine burn they would make in lunar orbit.",
        "target": "The last major event before Lunar Orbit Insertion (LOI) was a second mid-course correction. It was in retrograde (against the direction of travel) and slowed the spacecraft down by 2.0ft/s (0.61m/s), effectively reducing the closest distance at which the spacecraft would pass the Moon. At exactly 61 hours after launch, about 24,200 miles (38,900km) from the Moon, the crew burned the RCS for 11 seconds. They would now pass 71.7 miles (115.4km) from the lunar surface."
    },
    {
        "source": "At about 55 hours and 40 minutes into the flight, and 13 hours before entering lunar orbit, the crew of Apollo8 became the first humans to enter the gravitational sphere of influence of another celestial body. In other words, the effect of the Moon's gravitational force on Apollo8 became stronger than that of the Earth. At the time it happened, Apollo8 was 38,759 miles (62,377km) from the Moon and had a speed of 3,990ft/s (1,220m/s) relative to the Moon. This historic moment was of little interest to the crew, since they were still calculating their trajectory with respect to the launch pad at Kennedy Space Center. They would continue to do so until they performed their last mid-course correction, switching to a reference frame based on ideal orientation for the second engine burn they would make in lunar orbit. The last major event before Lunar Orbit Insertion (LOI) was a second mid-course correction. It was in retrograde (against the direction of travel) and slowed the spacecraft down by 2.0ft/s (0.61m/s), effectively reducing the closest distance at which the spacecraft would pass the Moon. At exactly 61 hours after launch, about 24,200 miles (38,900km) from the Moon, the crew burned the RCS for 11 seconds. They would now pass 71.7 miles (115.4km) from the lunar surface.",
        "target": "At 64 hours into the flight, the crew began to prepare for Lunar Orbit Insertion1 (LOI-1). This maneuver had to be performed perfectly, and due to orbital mechanics had to be on the far side of the Moon, out of contact with the Earth. After Mission Control was polled for a \"go/no go\" decision, the crew was told at 68 hours that they were Go and \"riding the best bird we can find\". Lovell replied, \"We'll see you on the other side\", and for the first time in history, humans travelled behind the Moon and out of radio contact with the Earth. Frances \"Poppy\" Northcutt, who was the first woman in NASA's mission control and helped calculate the return to Earth trajectory for this mission, recounts what it was like when Apollo 8 went behind the Moon for the first time in an interview: \"That was a very nerve-racking period on the team I was on, and I think it was a very nerve-racking period in general because of this thing with losing signal. Youve got this big mystery going on there on the backside of the Moon. You do not know whats happening and theres not a darn thing anybody here can do about it until we hear from them\""
    },
    {
        "source": "The last major event before Lunar Orbit Insertion (LOI) was a second mid-course correction. It was in retrograde (against the direction of travel) and slowed the spacecraft down by 2.0ft/s (0.61m/s), effectively reducing the closest distance at which the spacecraft would pass the Moon. At exactly 61 hours after launch, about 24,200 miles (38,900km) from the Moon, the crew burned the RCS for 11 seconds. They would now pass 71.7 miles (115.4km) from the lunar surface. At 64 hours into the flight, the crew began to prepare for Lunar Orbit Insertion1 (LOI-1). This maneuver had to be performed perfectly, and due to orbital mechanics had to be on the far side of the Moon, out of contact with the Earth. After Mission Control was polled for a \"go/no go\" decision, the crew was told at 68 hours that they were Go and \"riding the best bird we can find\". Lovell replied, \"We'll see you on the other side\", and for the first time in history, humans travelled behind the Moon and out of radio contact with the Earth. Frances \"Poppy\" Northcutt, who was the first woman in NASA's mission control and helped calculate the return to Earth trajectory for this mission, recounts what it was like when Apollo 8 went behind the Moon for the first time in an interview: \"That was a very nerve-racking period on the team I was on, and I think it was a very nerve-racking period in general because of this thing with losing signal. Youve got this big mystery going on there on the backside of the Moon. You do not know whats happening and theres not a darn thing anybody here can do about it until we hear from them\"",
        "target": "With ten minutes remaining before LOI-1, the crew began one last check of the spacecraft systems and made sure that every switch was in its correct position. At that time, they finally got their first glimpses of the Moon. They had been flying over the unlit side, and it was Lovell who saw the first shafts of sunlight obliquely illuminating the lunar surface. The LOI burn was only two minutes away, so the crew had little time to appreciate the view."
    },
    {
        "source": "At 64 hours into the flight, the crew began to prepare for Lunar Orbit Insertion1 (LOI-1). This maneuver had to be performed perfectly, and due to orbital mechanics had to be on the far side of the Moon, out of contact with the Earth. After Mission Control was polled for a \"go/no go\" decision, the crew was told at 68 hours that they were Go and \"riding the best bird we can find\". Lovell replied, \"We'll see you on the other side\", and for the first time in history, humans travelled behind the Moon and out of radio contact with the Earth. Frances \"Poppy\" Northcutt, who was the first woman in NASA's mission control and helped calculate the return to Earth trajectory for this mission, recounts what it was like when Apollo 8 went behind the Moon for the first time in an interview: \"That was a very nerve-racking period on the team I was on, and I think it was a very nerve-racking period in general because of this thing with losing signal. Youve got this big mystery going on there on the backside of the Moon. You do not know whats happening and theres not a darn thing anybody here can do about it until we hear from them\" With ten minutes remaining before LOI-1, the crew began one last check of the spacecraft systems and made sure that every switch was in its correct position. At that time, they finally got their first glimpses of the Moon. They had been flying over the unlit side, and it was Lovell who saw the first shafts of sunlight obliquely illuminating the lunar surface. The LOI burn was only two minutes away, so the crew had little time to appreciate the view.",
        "target": "The SPS was ignited at 69 hours, 8minutes, and 16 seconds after launch and burned for 4minutes and 7seconds, placing the Apollo8 spacecraft in orbit around the Moon. The crew described the burn as being the longest four minutes of their lives. If the burn had not lasted exactly the correct amount of time, the spacecraft could have ended up in a highly elliptical lunar orbit or even been flung off into space. If it had lasted too long, they could have struck the Moon. After making sure the spacecraft was working, they finally had a chance to look at the Moon, which they would orbit for the next 20 hours."
    },
    {
        "source": "With ten minutes remaining before LOI-1, the crew began one last check of the spacecraft systems and made sure that every switch was in its correct position. At that time, they finally got their first glimpses of the Moon. They had been flying over the unlit side, and it was Lovell who saw the first shafts of sunlight obliquely illuminating the lunar surface. The LOI burn was only two minutes away, so the crew had little time to appreciate the view. The SPS was ignited at 69 hours, 8minutes, and 16 seconds after launch and burned for 4minutes and 7seconds, placing the Apollo8 spacecraft in orbit around the Moon. The crew described the burn as being the longest four minutes of their lives. If the burn had not lasted exactly the correct amount of time, the spacecraft could have ended up in a highly elliptical lunar orbit or even been flung off into space. If it had lasted too long, they could have struck the Moon. After making sure the spacecraft was working, they finally had a chance to look at the Moon, which they would orbit for the next 20 hours.",
        "target": "On Earth, Mission Control continued to wait. If the crew had not burned the engine, or the burn had not lasted the planned length of time, the crew would have appeared early from behind the Moon. Exactly at the calculated moment the signal was received from the spacecraft, indicating it was in a 193.3-by-69.5-mile (311.1 by 111.8km) orbit around the Moon."
    },
    {
        "source": "The SPS was ignited at 69 hours, 8minutes, and 16 seconds after launch and burned for 4minutes and 7seconds, placing the Apollo8 spacecraft in orbit around the Moon. The crew described the burn as being the longest four minutes of their lives. If the burn had not lasted exactly the correct amount of time, the spacecraft could have ended up in a highly elliptical lunar orbit or even been flung off into space. If it had lasted too long, they could have struck the Moon. After making sure the spacecraft was working, they finally had a chance to look at the Moon, which they would orbit for the next 20 hours. On Earth, Mission Control continued to wait. If the crew had not burned the engine, or the burn had not lasted the planned length of time, the crew would have appeared early from behind the Moon. Exactly at the calculated moment the signal was received from the spacecraft, indicating it was in a 193.3-by-69.5-mile (311.1 by 111.8km) orbit around the Moon.",
        "target": "After reporting on the status of the spacecraft, Lovell gave the first description of what the lunar surface looked like:"
    },
    {
        "source": "On Earth, Mission Control continued to wait. If the crew had not burned the engine, or the burn had not lasted the planned length of time, the crew would have appeared early from behind the Moon. Exactly at the calculated moment the signal was received from the spacecraft, indicating it was in a 193.3-by-69.5-mile (311.1 by 111.8km) orbit around the Moon. After reporting on the status of the spacecraft, Lovell gave the first description of what the lunar surface looked like:",
        "target": "The Moon is essentially grey, no color; looks like plaster of Paris or sort of a grayish beach sand. We can see quite a bit of detail. The Sea of Fertility doesn't stand out as well here as it does back on Earth. There's not as much contrast between that and the surrounding craters. The craters are all rounded off. There's quite a few of them, some of them are newer. Many of them look likeespecially the round oneslook like hit by meteorites or projectiles of some sort. Langrenus is quite a huge crater; it's got a central cone to it. The walls of the crater are terraced, about six or seven different terraces on the way down."
    },
    {
        "source": "After reporting on the status of the spacecraft, Lovell gave the first description of what the lunar surface looked like: The Moon is essentially grey, no color; looks like plaster of Paris or sort of a grayish beach sand. We can see quite a bit of detail. The Sea of Fertility doesn't stand out as well here as it does back on Earth. There's not as much contrast between that and the surrounding craters. The craters are all rounded off. There's quite a few of them, some of them are newer. Many of them look likeespecially the round oneslook like hit by meteorites or projectiles of some sort. Langrenus is quite a huge crater; it's got a central cone to it. The walls of the crater are terraced, about six or seven different terraces on the way down.",
        "target": "Lovell continued to describe the terrain they were passing over. One of the crew's major tasks was reconnaissance of planned future landing sites on the Moon, especially one in Mare Tranquillitatis that was planned as the Apollo11 landing site. The launch time of Apollo8 had been chosen to give the best lighting conditions for examining the site. A film camera had been set up in one of the spacecraft windows to record one frame per second of the Moon below. Bill Anders spent much of the next 20 hours taking as many photographs as possible of targets of interest. By the end of the mission, the crew had taken over eight hundred 70mm still photographs and 700 feet (210m) of 16mm movie film."
    },
    {
        "source": "The Moon is essentially grey, no color; looks like plaster of Paris or sort of a grayish beach sand. We can see quite a bit of detail. The Sea of Fertility doesn't stand out as well here as it does back on Earth. There's not as much contrast between that and the surrounding craters. The craters are all rounded off. There's quite a few of them, some of them are newer. Many of them look likeespecially the round oneslook like hit by meteorites or projectiles of some sort. Langrenus is quite a huge crater; it's got a central cone to it. The walls of the crater are terraced, about six or seven different terraces on the way down. Lovell continued to describe the terrain they were passing over. One of the crew's major tasks was reconnaissance of planned future landing sites on the Moon, especially one in Mare Tranquillitatis that was planned as the Apollo11 landing site. The launch time of Apollo8 had been chosen to give the best lighting conditions for examining the site. A film camera had been set up in one of the spacecraft windows to record one frame per second of the Moon below. Bill Anders spent much of the next 20 hours taking as many photographs as possible of targets of interest. By the end of the mission, the crew had taken over eight hundred 70mm still photographs and 700 feet (210m) of 16mm movie film.",
        "target": "Throughout the hour that the spacecraft was in contact with Earth, Borman kept asking how the data for the SPS looked. He wanted to make sure that the engine was working and could be used to return early to the Earth if necessary. He also asked that they receive a \"go/no go\" decision before they passed behind the Moon on each orbit."
    },
    {
        "source": "Lovell continued to describe the terrain they were passing over. One of the crew's major tasks was reconnaissance of planned future landing sites on the Moon, especially one in Mare Tranquillitatis that was planned as the Apollo11 landing site. The launch time of Apollo8 had been chosen to give the best lighting conditions for examining the site. A film camera had been set up in one of the spacecraft windows to record one frame per second of the Moon below. Bill Anders spent much of the next 20 hours taking as many photographs as possible of targets of interest. By the end of the mission, the crew had taken over eight hundred 70mm still photographs and 700 feet (210m) of 16mm movie film. Throughout the hour that the spacecraft was in contact with Earth, Borman kept asking how the data for the SPS looked. He wanted to make sure that the engine was working and could be used to return early to the Earth if necessary. He also asked that they receive a \"go/no go\" decision before they passed behind the Moon on each orbit.",
        "target": "As they reappeared for their second pass in front of the Moon, the crew set up equipment to broadcast a view of the lunar surface. Anders described the craters that they were passing over. At the end of this second orbit, they performed an 11-second LOI-2 burn of the SPS to circularize the orbit to 70.0 by 71.3 miles (112.7 by 114.7km)."
    },
    {
        "source": "Throughout the hour that the spacecraft was in contact with Earth, Borman kept asking how the data for the SPS looked. He wanted to make sure that the engine was working and could be used to return early to the Earth if necessary. He also asked that they receive a \"go/no go\" decision before they passed behind the Moon on each orbit. As they reappeared for their second pass in front of the Moon, the crew set up equipment to broadcast a view of the lunar surface. Anders described the craters that they were passing over. At the end of this second orbit, they performed an 11-second LOI-2 burn of the SPS to circularize the orbit to 70.0 by 71.3 miles (112.7 by 114.7km).",
        "target": "Throughout the next two orbits, the crew continued to check the spacecraft and to observe and photograph the Moon. During the third pass, Borman read a small prayer for his church. He had been scheduled to participate in a service at St. Christopher's Episcopal Church near Seabrook, Texas, but due to the Apollo8 flight, he was unable to attend. A fellow parishioner and engineer at Mission Control, Rod Rose, suggested that Borman read the prayer, which could be recorded and then replayed during the service."
    },
    {
        "source": "As they reappeared for their second pass in front of the Moon, the crew set up equipment to broadcast a view of the lunar surface. Anders described the craters that they were passing over. At the end of this second orbit, they performed an 11-second LOI-2 burn of the SPS to circularize the orbit to 70.0 by 71.3 miles (112.7 by 114.7km). Throughout the next two orbits, the crew continued to check the spacecraft and to observe and photograph the Moon. During the third pass, Borman read a small prayer for his church. He had been scheduled to participate in a service at St. Christopher's Episcopal Church near Seabrook, Texas, but due to the Apollo8 flight, he was unable to attend. A fellow parishioner and engineer at Mission Control, Rod Rose, suggested that Borman read the prayer, which could be recorded and then replayed during the service.",
        "target": "When the spacecraft came out from behind the Moon for its fourth pass across the front, the crew witnessed an \"Earthrise\" in person for the first time in human history. NASA's Lunar Orbiter 1 had taken the first picture of an Earthrise from the vicinity of the Moon, on August 23, 1966. Anders saw the Earth emerging from behind the lunar horizon and called in excitement to the others, taking a black-and-white photograph as he did so. Anders asked Lovell for color film and then took Earthrise, a now famous color photo, later picked by Life magazine as one of its hundred photos of the century."
    },
    {
        "source": "Throughout the next two orbits, the crew continued to check the spacecraft and to observe and photograph the Moon. During the third pass, Borman read a small prayer for his church. He had been scheduled to participate in a service at St. Christopher's Episcopal Church near Seabrook, Texas, but due to the Apollo8 flight, he was unable to attend. A fellow parishioner and engineer at Mission Control, Rod Rose, suggested that Borman read the prayer, which could be recorded and then replayed during the service. When the spacecraft came out from behind the Moon for its fourth pass across the front, the crew witnessed an \"Earthrise\" in person for the first time in human history. NASA's Lunar Orbiter 1 had taken the first picture of an Earthrise from the vicinity of the Moon, on August 23, 1966. Anders saw the Earth emerging from behind the lunar horizon and called in excitement to the others, taking a black-and-white photograph as he did so. Anders asked Lovell for color film and then took Earthrise, a now famous color photo, later picked by Life magazine as one of its hundred photos of the century.",
        "target": "Due to the synchronous rotation of the Moon about the Earth, Earthrise is not generally visible from the lunar surface. This is because, as seen from any one place on the Moon's surface, Earth remains in approximately the same position in the lunar sky, either above or below the horizon. Earthrise is generally visible only while orbiting the Moon, and at selected surface locations near the Moon's limb, where libration carries the Earth slightly above and below the lunar horizon."
    },
    {
        "source": "When the spacecraft came out from behind the Moon for its fourth pass across the front, the crew witnessed an \"Earthrise\" in person for the first time in human history. NASA's Lunar Orbiter 1 had taken the first picture of an Earthrise from the vicinity of the Moon, on August 23, 1966. Anders saw the Earth emerging from behind the lunar horizon and called in excitement to the others, taking a black-and-white photograph as he did so. Anders asked Lovell for color film and then took Earthrise, a now famous color photo, later picked by Life magazine as one of its hundred photos of the century. Due to the synchronous rotation of the Moon about the Earth, Earthrise is not generally visible from the lunar surface. This is because, as seen from any one place on the Moon's surface, Earth remains in approximately the same position in the lunar sky, either above or below the horizon. Earthrise is generally visible only while orbiting the Moon, and at selected surface locations near the Moon's limb, where libration carries the Earth slightly above and below the lunar horizon.",
        "target": "Anders continued to take photographs while Lovell assumed control of the spacecraft so that Borman could rest. Despite the difficulty resting in the cramped and noisy spacecraft, Borman was able to sleep for two orbits, awakening periodically to ask questions about their status. Borman awoke fully when he started to hear his fellow crew members make mistakes. They were beginning to not understand questions and had to ask for the answers to be repeated. Borman realized that everyone was extremely tired from not having a good night's sleep in over three days. He ordered Anders and Lovell to get some sleep and that the rest of the flight plan regarding observing the Moon be scrubbed. Anders initially protested, saying that he was fine, but Borman would not be swayed. Anders finally agreed under the condition that Borman would set up the camera to continue to take automatic pictures of the Moon. Borman also remembered that there was a second television broadcast planned, and with so many people expected to be watching, he wanted the crew to be alert. For the next two orbits, Anders and Lovell slept while Borman sat at the helm."
    },
    {
        "source": "Due to the synchronous rotation of the Moon about the Earth, Earthrise is not generally visible from the lunar surface. This is because, as seen from any one place on the Moon's surface, Earth remains in approximately the same position in the lunar sky, either above or below the horizon. Earthrise is generally visible only while orbiting the Moon, and at selected surface locations near the Moon's limb, where libration carries the Earth slightly above and below the lunar horizon. Anders continued to take photographs while Lovell assumed control of the spacecraft so that Borman could rest. Despite the difficulty resting in the cramped and noisy spacecraft, Borman was able to sleep for two orbits, awakening periodically to ask questions about their status. Borman awoke fully when he started to hear his fellow crew members make mistakes. They were beginning to not understand questions and had to ask for the answers to be repeated. Borman realized that everyone was extremely tired from not having a good night's sleep in over three days. He ordered Anders and Lovell to get some sleep and that the rest of the flight plan regarding observing the Moon be scrubbed. Anders initially protested, saying that he was fine, but Borman would not be swayed. Anders finally agreed under the condition that Borman would set up the camera to continue to take automatic pictures of the Moon. Borman also remembered that there was a second television broadcast planned, and with so many people expected to be watching, he wanted the crew to be alert. For the next two orbits, Anders and Lovell slept while Borman sat at the helm.",
        "target": "As they rounded the Moon for the ninth time, the astronauts began the second television transmission. Borman introduced the crew, followed by each man giving his impression of the lunar surface and what it was like to be orbiting the Moon. Borman described it as being \"a vast, lonely, forbidding expanse of nothing\". Then, after talking about what they were flying over, Anders said that the crew had a message for all those on Earth. Each man on board read a section from the Biblical creation story from the Book of Genesis. Borman finished the broadcast by wishing a Merry Christmas to everyone on Earth. His message appeared to sum up the feelings that all three crewmen had from their vantage point in lunar orbit. Borman said, \"And from the crew of Apollo8, we close with good night, good luck, a Merry Christmas and God bless all of youall of you on the good Earth.\""
    },
    {
        "source": "Anders continued to take photographs while Lovell assumed control of the spacecraft so that Borman could rest. Despite the difficulty resting in the cramped and noisy spacecraft, Borman was able to sleep for two orbits, awakening periodically to ask questions about their status. Borman awoke fully when he started to hear his fellow crew members make mistakes. They were beginning to not understand questions and had to ask for the answers to be repeated. Borman realized that everyone was extremely tired from not having a good night's sleep in over three days. He ordered Anders and Lovell to get some sleep and that the rest of the flight plan regarding observing the Moon be scrubbed. Anders initially protested, saying that he was fine, but Borman would not be swayed. Anders finally agreed under the condition that Borman would set up the camera to continue to take automatic pictures of the Moon. Borman also remembered that there was a second television broadcast planned, and with so many people expected to be watching, he wanted the crew to be alert. For the next two orbits, Anders and Lovell slept while Borman sat at the helm. As they rounded the Moon for the ninth time, the astronauts began the second television transmission. Borman introduced the crew, followed by each man giving his impression of the lunar surface and what it was like to be orbiting the Moon. Borman described it as being \"a vast, lonely, forbidding expanse of nothing\". Then, after talking about what they were flying over, Anders said that the crew had a message for all those on Earth. Each man on board read a section from the Biblical creation story from the Book of Genesis. Borman finished the broadcast by wishing a Merry Christmas to everyone on Earth. His message appeared to sum up the feelings that all three crewmen had from their vantage point in lunar orbit. Borman said, \"And from the crew of Apollo8, we close with good night, good luck, a Merry Christmas and God bless all of youall of you on the good Earth.\"",
        "target": "The only task left for the crew at this point was to perform the trans-Earth injection (TEI), which was scheduled for 2+12 hours after the end of the television transmission. The TEI was the most critical burn of the flight, as any failure of the SPS to ignite would strand the crew in lunar orbit, with little hope of escape. As with the previous burn, the crew had to perform the maneuver above the far side of the Moon, out of contact with Earth. The burn occurred exactly on time. The spacecraft telemetry was reacquired as it re-emerged from behind the Moon at 89 hours, 28 minutes, and 39 seconds, the exact time calculated. When voice contact was regained, Lovell announced, \"Please be informed, there is a Santa Claus\", to which Ken Mattingly, the current CAPCOM, replied, \"That's affirmative, you are the best ones to know.\" The spacecraft began its journey back to Earth on December 25, Christmas Day."
    },
    {
        "source": "As they rounded the Moon for the ninth time, the astronauts began the second television transmission. Borman introduced the crew, followed by each man giving his impression of the lunar surface and what it was like to be orbiting the Moon. Borman described it as being \"a vast, lonely, forbidding expanse of nothing\". Then, after talking about what they were flying over, Anders said that the crew had a message for all those on Earth. Each man on board read a section from the Biblical creation story from the Book of Genesis. Borman finished the broadcast by wishing a Merry Christmas to everyone on Earth. His message appeared to sum up the feelings that all three crewmen had from their vantage point in lunar orbit. Borman said, \"And from the crew of Apollo8, we close with good night, good luck, a Merry Christmas and God bless all of youall of you on the good Earth.\" The only task left for the crew at this point was to perform the trans-Earth injection (TEI), which was scheduled for 2+12 hours after the end of the television transmission. The TEI was the most critical burn of the flight, as any failure of the SPS to ignite would strand the crew in lunar orbit, with little hope of escape. As with the previous burn, the crew had to perform the maneuver above the far side of the Moon, out of contact with Earth. The burn occurred exactly on time. The spacecraft telemetry was reacquired as it re-emerged from behind the Moon at 89 hours, 28 minutes, and 39 seconds, the exact time calculated. When voice contact was regained, Lovell announced, \"Please be informed, there is a Santa Claus\", to which Ken Mattingly, the current CAPCOM, replied, \"That's affirmative, you are the best ones to know.\" The spacecraft began its journey back to Earth on December 25, Christmas Day.",
        "target": "Later, Lovell used some otherwise idle time to do some navigational sightings, maneuvering the module to view various stars by using the computer keyboard. He accidentally erased some of the computer's memory, which caused the inertial measurement unit (IMU) to contain data indicating that the module was in the same relative orientation it had been in before lift-off; the IMU then fired the thrusters to \"correct\" the module's attitude."
    },
    {
        "source": "The only task left for the crew at this point was to perform the trans-Earth injection (TEI), which was scheduled for 2+12 hours after the end of the television transmission. The TEI was the most critical burn of the flight, as any failure of the SPS to ignite would strand the crew in lunar orbit, with little hope of escape. As with the previous burn, the crew had to perform the maneuver above the far side of the Moon, out of contact with Earth. The burn occurred exactly on time. The spacecraft telemetry was reacquired as it re-emerged from behind the Moon at 89 hours, 28 minutes, and 39 seconds, the exact time calculated. When voice contact was regained, Lovell announced, \"Please be informed, there is a Santa Claus\", to which Ken Mattingly, the current CAPCOM, replied, \"That's affirmative, you are the best ones to know.\" The spacecraft began its journey back to Earth on December 25, Christmas Day. Later, Lovell used some otherwise idle time to do some navigational sightings, maneuvering the module to view various stars by using the computer keyboard. He accidentally erased some of the computer's memory, which caused the inertial measurement unit (IMU) to contain data indicating that the module was in the same relative orientation it had been in before lift-off; the IMU then fired the thrusters to \"correct\" the module's attitude.",
        "target": "Once the crew realized why the computer had changed the module's attitude, they realized that they would have to reenter data to tell the computer the module's actual orientation. It took Lovell ten minutes to figure out the right numbers, using the thrusters to get the stars Rigel and Sirius aligned, and another 15 minutes to enter the corrected data into the computer. Sixteen months later, during the Apollo13 mission, Lovell would have to perform a similar manual realignment under more critical conditions after the module's IMU had to be turned off to conserve energy."
    },
    {
        "source": "Later, Lovell used some otherwise idle time to do some navigational sightings, maneuvering the module to view various stars by using the computer keyboard. He accidentally erased some of the computer's memory, which caused the inertial measurement unit (IMU) to contain data indicating that the module was in the same relative orientation it had been in before lift-off; the IMU then fired the thrusters to \"correct\" the module's attitude. Once the crew realized why the computer had changed the module's attitude, they realized that they would have to reenter data to tell the computer the module's actual orientation. It took Lovell ten minutes to figure out the right numbers, using the thrusters to get the stars Rigel and Sirius aligned, and another 15 minutes to enter the corrected data into the computer. Sixteen months later, during the Apollo13 mission, Lovell would have to perform a similar manual realignment under more critical conditions after the module's IMU had to be turned off to conserve energy.",
        "target": "The cruise back to Earth was mostly a time for the crew to relax and monitor the spacecraft. As long as the trajectory specialists had calculated everything correctly, the spacecraft would reenter Earth's atmosphere two-and-a-half days after TEI and splash down in the Pacific."
    },
    {
        "source": "Once the crew realized why the computer had changed the module's attitude, they realized that they would have to reenter data to tell the computer the module's actual orientation. It took Lovell ten minutes to figure out the right numbers, using the thrusters to get the stars Rigel and Sirius aligned, and another 15 minutes to enter the corrected data into the computer. Sixteen months later, during the Apollo13 mission, Lovell would have to perform a similar manual realignment under more critical conditions after the module's IMU had to be turned off to conserve energy. The cruise back to Earth was mostly a time for the crew to relax and monitor the spacecraft. As long as the trajectory specialists had calculated everything correctly, the spacecraft would reenter Earth's atmosphere two-and-a-half days after TEI and splash down in the Pacific.",
        "target": "On Christmas afternoon, the crew made their fifth television broadcast. This time, they gave a tour of the spacecraft, showing how an astronaut lived in space. When they finished broadcasting, they found a small present from Slayton in the food locker: a real turkey dinner with stuffing, in the same kind of pack given to the troops in Vietnam."
    },
    {
        "source": "The cruise back to Earth was mostly a time for the crew to relax and monitor the spacecraft. As long as the trajectory specialists had calculated everything correctly, the spacecraft would reenter Earth's atmosphere two-and-a-half days after TEI and splash down in the Pacific. On Christmas afternoon, the crew made their fifth television broadcast. This time, they gave a tour of the spacecraft, showing how an astronaut lived in space. When they finished broadcasting, they found a small present from Slayton in the food locker: a real turkey dinner with stuffing, in the same kind of pack given to the troops in Vietnam.",
        "target": "Another Slayton surprise was a gift of three miniature bottles of brandy, which Borman ordered the crew to leave alone until after they landed. They remained unopened, even years after the flight. There were also small presents to the crew from their wives. The next day, at about 124 hours into the mission, the sixth and final TV transmission showed the mission's best video images of the Earth, during a four-minute broadcast. After two uneventful days, the crew prepared for reentry. The computer would control the reentry, and all the crew had to do was put the spacecraft in the correct attitude, with the blunt end forward. In the event of computer failure, Borman was ready to take over."
    },
    {
        "source": "On Christmas afternoon, the crew made their fifth television broadcast. This time, they gave a tour of the spacecraft, showing how an astronaut lived in space. When they finished broadcasting, they found a small present from Slayton in the food locker: a real turkey dinner with stuffing, in the same kind of pack given to the troops in Vietnam. Another Slayton surprise was a gift of three miniature bottles of brandy, which Borman ordered the crew to leave alone until after they landed. They remained unopened, even years after the flight. There were also small presents to the crew from their wives. The next day, at about 124 hours into the mission, the sixth and final TV transmission showed the mission's best video images of the Earth, during a four-minute broadcast. After two uneventful days, the crew prepared for reentry. The computer would control the reentry, and all the crew had to do was put the spacecraft in the correct attitude, with the blunt end forward. In the event of computer failure, Borman was ready to take over.",
        "target": "Separation from the service module prepared the command module for reentry by exposing the heat shield and shedding unneeded mass. The service module would burn up in the atmosphere as planned. Six minutes before they hit the top of the atmosphere, the crew saw the Moon rising above the Earth's horizon, just as had been calculated by the trajectory specialists. As the module hit the thin outer atmosphere, the crew noticed that it was becoming hazy outside as glowing plasma formed around the spacecraft. The spacecraft started slowing down, and the deceleration peaked at 6 standard gravities (59m/s2). With the computer controlling the descent by changing the attitude of the spacecraft, Apollo8 rose briefly like a skipping stone before descending to the ocean. At 30,000 feet (9.1km), the drogue parachute deployed, stabilizing the spacecraft, followed at 10,000 feet (3.0km) by the three main parachutes. The spacecraft splashdown position was officially reported as 88N 1651W / 8.133N 165.017W / 8.133; -165.017 (Apollo 8 estimated splashdown) in the North Pacific Ocean, southwest of Hawaii at 15:51:42 UTC on December 27, 1968."
    },
    {
        "source": "Another Slayton surprise was a gift of three miniature bottles of brandy, which Borman ordered the crew to leave alone until after they landed. They remained unopened, even years after the flight. There were also small presents to the crew from their wives. The next day, at about 124 hours into the mission, the sixth and final TV transmission showed the mission's best video images of the Earth, during a four-minute broadcast. After two uneventful days, the crew prepared for reentry. The computer would control the reentry, and all the crew had to do was put the spacecraft in the correct attitude, with the blunt end forward. In the event of computer failure, Borman was ready to take over. Separation from the service module prepared the command module for reentry by exposing the heat shield and shedding unneeded mass. The service module would burn up in the atmosphere as planned. Six minutes before they hit the top of the atmosphere, the crew saw the Moon rising above the Earth's horizon, just as had been calculated by the trajectory specialists. As the module hit the thin outer atmosphere, the crew noticed that it was becoming hazy outside as glowing plasma formed around the spacecraft. The spacecraft started slowing down, and the deceleration peaked at 6 standard gravities (59m/s2). With the computer controlling the descent by changing the attitude of the spacecraft, Apollo8 rose briefly like a skipping stone before descending to the ocean. At 30,000 feet (9.1km), the drogue parachute deployed, stabilizing the spacecraft, followed at 10,000 feet (3.0km) by the three main parachutes. The spacecraft splashdown position was officially reported as 88N 1651W / 8.133N 165.017W / 8.133; -165.017 (Apollo 8 estimated splashdown) in the North Pacific Ocean, southwest of Hawaii at 15:51:42 UTC on December 27, 1968.",
        "target": "When the spacecraft hit the water, the parachutes dragged it over and left it upside down, in what was termed Stable2 position. As they were buffeted by a 10-foot (3.0m) swell, Borman vomited, waiting for the three flotation balloons to right the spacecraft. About six minutes after splashdown, the command module was righted into a normal apex-up (Stable 1) orientation by its inflatable bag uprighting system. The first frogman from aircraft carrier USSYorktown arrived 43 minutes after splashdown. Forty-five minutes later, the crew was safe on the flight deck of the Yorktown."
    },
    {
        "source": "Separation from the service module prepared the command module for reentry by exposing the heat shield and shedding unneeded mass. The service module would burn up in the atmosphere as planned. Six minutes before they hit the top of the atmosphere, the crew saw the Moon rising above the Earth's horizon, just as had been calculated by the trajectory specialists. As the module hit the thin outer atmosphere, the crew noticed that it was becoming hazy outside as glowing plasma formed around the spacecraft. The spacecraft started slowing down, and the deceleration peaked at 6 standard gravities (59m/s2). With the computer controlling the descent by changing the attitude of the spacecraft, Apollo8 rose briefly like a skipping stone before descending to the ocean. At 30,000 feet (9.1km), the drogue parachute deployed, stabilizing the spacecraft, followed at 10,000 feet (3.0km) by the three main parachutes. The spacecraft splashdown position was officially reported as 88N 1651W / 8.133N 165.017W / 8.133; -165.017 (Apollo 8 estimated splashdown) in the North Pacific Ocean, southwest of Hawaii at 15:51:42 UTC on December 27, 1968. When the spacecraft hit the water, the parachutes dragged it over and left it upside down, in what was termed Stable2 position. As they were buffeted by a 10-foot (3.0m) swell, Borman vomited, waiting for the three flotation balloons to right the spacecraft. About six minutes after splashdown, the command module was righted into a normal apex-up (Stable 1) orientation by its inflatable bag uprighting system. The first frogman from aircraft carrier USSYorktown arrived 43 minutes after splashdown. Forty-five minutes later, the crew was safe on the flight deck of the Yorktown.",
        "target": "Apollo 8 came at the end of 1968, a year that had seen much upheaval in the United States and most of the world. Even though the year saw political assassinations, political unrest in the streets of Europe and America, and the Prague Spring, Time magazine chose the crew of Apollo8 as its Men of the Year for 1968, recognizing them as the people who most influenced events in the preceding year. They had been the first people ever to leave the gravitational influence of the Earth and orbit another celestial body. They had survived a mission that even the crew themselves had rated as having only a fifty-fifty chance of fully succeeding. The effect of Apollo8 was summed up in a telegram from a stranger, received by Borman after the mission, that stated simply, \"Thank you Apollo8. You saved 1968.\""
    },
    {
        "source": "When the spacecraft hit the water, the parachutes dragged it over and left it upside down, in what was termed Stable2 position. As they were buffeted by a 10-foot (3.0m) swell, Borman vomited, waiting for the three flotation balloons to right the spacecraft. About six minutes after splashdown, the command module was righted into a normal apex-up (Stable 1) orientation by its inflatable bag uprighting system. The first frogman from aircraft carrier USSYorktown arrived 43 minutes after splashdown. Forty-five minutes later, the crew was safe on the flight deck of the Yorktown. Apollo 8 came at the end of 1968, a year that had seen much upheaval in the United States and most of the world. Even though the year saw political assassinations, political unrest in the streets of Europe and America, and the Prague Spring, Time magazine chose the crew of Apollo8 as its Men of the Year for 1968, recognizing them as the people who most influenced events in the preceding year. They had been the first people ever to leave the gravitational influence of the Earth and orbit another celestial body. They had survived a mission that even the crew themselves had rated as having only a fifty-fifty chance of fully succeeding. The effect of Apollo8 was summed up in a telegram from a stranger, received by Borman after the mission, that stated simply, \"Thank you Apollo8. You saved 1968.\"",
        "target": "One of the most famous aspects of the flight was the Earthrise picture that the crew took as they came around for their fourth orbit of the Moon. This was the first time that humans had taken such a picture while actually behind the camera, and it has been credited as one of the inspirations of the first Earth Day in 1970. It was selected as the first of Life magazine's 100 Photographs That Changed the World."
    },
    {
        "source": "Apollo 8 came at the end of 1968, a year that had seen much upheaval in the United States and most of the world. Even though the year saw political assassinations, political unrest in the streets of Europe and America, and the Prague Spring, Time magazine chose the crew of Apollo8 as its Men of the Year for 1968, recognizing them as the people who most influenced events in the preceding year. They had been the first people ever to leave the gravitational influence of the Earth and orbit another celestial body. They had survived a mission that even the crew themselves had rated as having only a fifty-fifty chance of fully succeeding. The effect of Apollo8 was summed up in a telegram from a stranger, received by Borman after the mission, that stated simply, \"Thank you Apollo8. You saved 1968.\" One of the most famous aspects of the flight was the Earthrise picture that the crew took as they came around for their fourth orbit of the Moon. This was the first time that humans had taken such a picture while actually behind the camera, and it has been credited as one of the inspirations of the first Earth Day in 1970. It was selected as the first of Life magazine's 100 Photographs That Changed the World.",
        "target": "Apollo 11 astronaut Michael Collins said, \"Eight's momentous historic significance was foremost\"; while space historian Robert K. Poole saw Apollo8 as the most historically significant of all the Apollo missions. The mission was the most widely covered by the media since the first American orbital flight, Mercury-Atlas 6 by John Glenn, in 1962. There were 1,200 journalists covering the mission, with the BBC's coverage broadcast in 54 countries in 15 different languages. The Soviet newspaper Pravda featured a quote from Boris Nikolaevich Petrov[be; de; ru], Chairman of the Soviet Interkosmos program, who described the flight as an \"outstanding achievement of American space sciences and technology\". It is estimated that a quarter of the people alive at the time saweither live or delayedthe Christmas Eve transmission during the ninth orbit of the Moon. The Apollo8 broadcasts won an Emmy Award, the highest honor given by the Academy of Television Arts & Sciences."
    },
    {
        "source": "One of the most famous aspects of the flight was the Earthrise picture that the crew took as they came around for their fourth orbit of the Moon. This was the first time that humans had taken such a picture while actually behind the camera, and it has been credited as one of the inspirations of the first Earth Day in 1970. It was selected as the first of Life magazine's 100 Photographs That Changed the World. Apollo 11 astronaut Michael Collins said, \"Eight's momentous historic significance was foremost\"; while space historian Robert K. Poole saw Apollo8 as the most historically significant of all the Apollo missions. The mission was the most widely covered by the media since the first American orbital flight, Mercury-Atlas 6 by John Glenn, in 1962. There were 1,200 journalists covering the mission, with the BBC's coverage broadcast in 54 countries in 15 different languages. The Soviet newspaper Pravda featured a quote from Boris Nikolaevich Petrov[be; de; ru], Chairman of the Soviet Interkosmos program, who described the flight as an \"outstanding achievement of American space sciences and technology\". It is estimated that a quarter of the people alive at the time saweither live or delayedthe Christmas Eve transmission during the ninth orbit of the Moon. The Apollo8 broadcasts won an Emmy Award, the highest honor given by the Academy of Television Arts & Sciences.",
        "target": "Madalyn Murray O'Hair, an atheist, later caused controversy by bringing a lawsuit against NASA over the reading from Genesis. O'Hair wanted the courts to ban American astronautswho were all government employeesfrom public prayer in space. Though the case was rejected by the Supreme Court of the United States, apparently for lack of jurisdiction in outer space, it caused NASA to be skittish about the issue of religion throughout the rest of the Apollo program. Buzz Aldrin, on Apollo11, self-communicated Presbyterian Communion on the surface of the Moon after landing; he refrained from mentioning this publicly for several years and referred to it only obliquely at the time."
    },
    {
        "source": "Apollo 11 astronaut Michael Collins said, \"Eight's momentous historic significance was foremost\"; while space historian Robert K. Poole saw Apollo8 as the most historically significant of all the Apollo missions. The mission was the most widely covered by the media since the first American orbital flight, Mercury-Atlas 6 by John Glenn, in 1962. There were 1,200 journalists covering the mission, with the BBC's coverage broadcast in 54 countries in 15 different languages. The Soviet newspaper Pravda featured a quote from Boris Nikolaevich Petrov[be; de; ru], Chairman of the Soviet Interkosmos program, who described the flight as an \"outstanding achievement of American space sciences and technology\". It is estimated that a quarter of the people alive at the time saweither live or delayedthe Christmas Eve transmission during the ninth orbit of the Moon. The Apollo8 broadcasts won an Emmy Award, the highest honor given by the Academy of Television Arts & Sciences. Madalyn Murray O'Hair, an atheist, later caused controversy by bringing a lawsuit against NASA over the reading from Genesis. O'Hair wanted the courts to ban American astronautswho were all government employeesfrom public prayer in space. Though the case was rejected by the Supreme Court of the United States, apparently for lack of jurisdiction in outer space, it caused NASA to be skittish about the issue of religion throughout the rest of the Apollo program. Buzz Aldrin, on Apollo11, self-communicated Presbyterian Communion on the surface of the Moon after landing; he refrained from mentioning this publicly for several years and referred to it only obliquely at the time.",
        "target": "In 1969, the United States Post Office Department issued a postage stamp (Scott catalogue #1371) commemorating the Apollo8 flight around the Moon. The stamp featured a detail of the famous photograph of the Earthrise over the Moon taken by Anders on Christmas Eve, and the words, \"In the beginning God...\", the first words of the book of Genesis. In January 1969, just 18 days after the crew's return to Earth, they appeared in the Super Bowl III pre-game show, reciting the Pledge of Allegiance, before the national anthem was performed by trumpeter Lloyd Geisler of the Washington National Symphony Orchestra.[n 4]"
    },
    {
        "source": "Madalyn Murray O'Hair, an atheist, later caused controversy by bringing a lawsuit against NASA over the reading from Genesis. O'Hair wanted the courts to ban American astronautswho were all government employeesfrom public prayer in space. Though the case was rejected by the Supreme Court of the United States, apparently for lack of jurisdiction in outer space, it caused NASA to be skittish about the issue of religion throughout the rest of the Apollo program. Buzz Aldrin, on Apollo11, self-communicated Presbyterian Communion on the surface of the Moon after landing; he refrained from mentioning this publicly for several years and referred to it only obliquely at the time. In 1969, the United States Post Office Department issued a postage stamp (Scott catalogue #1371) commemorating the Apollo8 flight around the Moon. The stamp featured a detail of the famous photograph of the Earthrise over the Moon taken by Anders on Christmas Eve, and the words, \"In the beginning God...\", the first words of the book of Genesis. In January 1969, just 18 days after the crew's return to Earth, they appeared in the Super Bowl III pre-game show, reciting the Pledge of Allegiance, before the national anthem was performed by trumpeter Lloyd Geisler of the Washington National Symphony Orchestra.[n 4]",
        "target": "In January 1970, the spacecraft was delivered to Osaka, Japan, for display in the U.S. pavilion at Expo '70. It is now displayed at the Chicago Museum of Science and Industry, along with a collection of personal items from the flight donated by Lovell and the space suit worn by Frank Borman. Jim Lovell's Apollo8 space suit is on public display in the Visitor Center at NASA's Glenn Research Center. Bill Anders's space suit is on display at the Science Museum in London, United Kingdom."
    },
    {
        "source": "In 1969, the United States Post Office Department issued a postage stamp (Scott catalogue #1371) commemorating the Apollo8 flight around the Moon. The stamp featured a detail of the famous photograph of the Earthrise over the Moon taken by Anders on Christmas Eve, and the words, \"In the beginning God...\", the first words of the book of Genesis. In January 1969, just 18 days after the crew's return to Earth, they appeared in the Super Bowl III pre-game show, reciting the Pledge of Allegiance, before the national anthem was performed by trumpeter Lloyd Geisler of the Washington National Symphony Orchestra.[n 4] In January 1970, the spacecraft was delivered to Osaka, Japan, for display in the U.S. pavilion at Expo '70. It is now displayed at the Chicago Museum of Science and Industry, along with a collection of personal items from the flight donated by Lovell and the space suit worn by Frank Borman. Jim Lovell's Apollo8 space suit is on public display in the Visitor Center at NASA's Glenn Research Center. Bill Anders's space suit is on display at the Science Museum in London, United Kingdom.",
        "target": "Apollo 8's historic mission has been depicted and referred to in several forms, both documentary and fiction. The various television transmissions and 16 mm footage shot by the crew of Apollo8 were compiled and released by NASA in the 1969 documentary Debrief: Apollo8, hosted by Burgess Meredith. In addition, Spacecraft Films released, in 2003, a three-disc DVD set containing all of NASA's TV and 16mm film footage related to the mission, including all TV transmissions from space, training and launch footage, and motion pictures taken in flight. Other documentaries include \"Race to the Moon\" (2005) as part of season 18 of American Experience and In the Shadow of the Moon (2007). Apollo's Daring Mission aired on PBS' Nova in December 2018, marking the flight's 50th anniversary."
    },
    {
        "source": "In January 1970, the spacecraft was delivered to Osaka, Japan, for display in the U.S. pavilion at Expo '70. It is now displayed at the Chicago Museum of Science and Industry, along with a collection of personal items from the flight donated by Lovell and the space suit worn by Frank Borman. Jim Lovell's Apollo8 space suit is on public display in the Visitor Center at NASA's Glenn Research Center. Bill Anders's space suit is on display at the Science Museum in London, United Kingdom. Apollo 8's historic mission has been depicted and referred to in several forms, both documentary and fiction. The various television transmissions and 16 mm footage shot by the crew of Apollo8 were compiled and released by NASA in the 1969 documentary Debrief: Apollo8, hosted by Burgess Meredith. In addition, Spacecraft Films released, in 2003, a three-disc DVD set containing all of NASA's TV and 16mm film footage related to the mission, including all TV transmissions from space, training and launch footage, and motion pictures taken in flight. Other documentaries include \"Race to the Moon\" (2005) as part of season 18 of American Experience and In the Shadow of the Moon (2007). Apollo's Daring Mission aired on PBS' Nova in December 2018, marking the flight's 50th anniversary.",
        "target": "The 1994 album The Songs of Distant Earth by Mike Oldfield uses the Anders' reading for the cut \"In The Beginning\"."
    },
    {
        "source": "Apollo 8's historic mission has been depicted and referred to in several forms, both documentary and fiction. The various television transmissions and 16 mm footage shot by the crew of Apollo8 were compiled and released by NASA in the 1969 documentary Debrief: Apollo8, hosted by Burgess Meredith. In addition, Spacecraft Films released, in 2003, a three-disc DVD set containing all of NASA's TV and 16mm film footage related to the mission, including all TV transmissions from space, training and launch footage, and motion pictures taken in flight. Other documentaries include \"Race to the Moon\" (2005) as part of season 18 of American Experience and In the Shadow of the Moon (2007). Apollo's Daring Mission aired on PBS' Nova in December 2018, marking the flight's 50th anniversary. The 1994 album The Songs of Distant Earth by Mike Oldfield uses the Anders' reading for the cut \"In The Beginning\".",
        "target": "Parts of the mission are dramatized in the 1998 miniseries From the Earth to the Moon episode \"1968\". The S-IVB stage of Apollo8 was also portrayed as the location of an alien device in the 1970 UFO episode \"Conflict\". Apollo8's lunar orbit insertion was chronicled with actual recordings in the song \"The Other Side\", on the 2015 album The Race for Space, by the band Public Service Broadcasting."
    },
    {
        "source": "The 1994 album The Songs of Distant Earth by Mike Oldfield uses the Anders' reading for the cut \"In The Beginning\". Parts of the mission are dramatized in the 1998 miniseries From the Earth to the Moon episode \"1968\". The S-IVB stage of Apollo8 was also portrayed as the location of an alien device in the 1970 UFO episode \"Conflict\". Apollo8's lunar orbit insertion was chronicled with actual recordings in the song \"The Other Side\", on the 2015 album The Race for Space, by the band Public Service Broadcasting.",
        "target": "A documentary film, First to the Moon: The Journey of Apollo 8 was released in 2018."
    },
    {
        "source": "Parts of the mission are dramatized in the 1998 miniseries From the Earth to the Moon episode \"1968\". The S-IVB stage of Apollo8 was also portrayed as the location of an alien device in the 1970 UFO episode \"Conflict\". Apollo8's lunar orbit insertion was chronicled with actual recordings in the song \"The Other Side\", on the 2015 album The Race for Space, by the band Public Service Broadcasting. A documentary film, First to the Moon: The Journey of Apollo 8 was released in 2018.",
        "target": "This article incorporates public domain material from websites or documents of the National Aeronautics and Space Administration."
    },
    {
        "source": "A documentary film, First to the Moon: The Journey of Apollo 8 was released in 2018. This article incorporates public domain material from websites or documents of the National Aeronautics and Space Administration.",
        "target": "This article incorporates public domain material from websites or documents of the National Aeronautics and Space Administration."
    }
]